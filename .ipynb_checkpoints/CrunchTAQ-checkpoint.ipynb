{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "import h5py\n",
    "import copy\n",
    "import datetime\n",
    "\n",
    "# Do you wanna see?\n",
    "verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FMNS testing pull request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformData(dataset, datainfo):\n",
    "  \n",
    "    # Use the column-name information to rename the columns.\n",
    "    renameCol = {i:col[0] for i,col in enumerate(datainfo)}\n",
    "  \n",
    "    # Rename\n",
    "    dataset = dataset.rename(columns=renameCol)\n",
    "  \n",
    "    # Use the datatype information to convert the arrays back to the right datatype.\n",
    "    dt = {col[0]:str if col[1] == 'object' else col[1] for col in datainfo}\n",
    "\n",
    "    # Convert the datatypes\n",
    "    dataset = dataset.astype(dt)\n",
    "\n",
    "    # Strip the string-type arrays for the unintended characters.\n",
    "    for ele in datainfo:\n",
    "        # if the datatype is string, we need to do some additional conversion.\n",
    "        if ele[1] == 'object':\n",
    "\n",
    "            dataset[ele[0]] = list(map(f,dataset[ele[0]]))\n",
    "\n",
    "            if 'date' in ele[0].lower():\n",
    "                dataset[ele[0]] = dataset[ele[0]].astype(np.datetime64) \n",
    "\n",
    "    return dataset\n",
    "\n",
    "# We create a function to clean the string-type arrays\n",
    "f = lambda a: re.split('[\\']',a)[1]\n",
    "\n",
    "# Function to clean the unpacked data from the compressed files.\n",
    "def strList(ls):\n",
    "    return list(map(lambda x: x.decode('utf-8'),ls))\n",
    "\n",
    "# The following function is based on the research of (Lunde, 2016), summarized in the slides found here:\n",
    "# https://econ.au.dk/fileadmin/site_files/filer_oekonomi/subsites/creates/Diverse_2016/PhD_High-Frequency/HF_TrQuData_v01.pdf\n",
    "\n",
    "def formatDate(date,timestamps):\n",
    "    return list(map(lambda x: date[0:4]+'/'+date[4:6]+'/'+date[6:]+' '+str(datetime.timedelta(seconds = int(str(x)[0:5]),\n",
    "                                                     milliseconds = int(str(x)[5:11]))),timestamps))\n",
    "def HFDataCleaning(cleaningProcedures,dataToClean,dataType,p3Exchanges = []):\n",
    "    \n",
    "    # There are 11 cleaning procedures, with 3 relevant for both trade and quote data and 4 for either trade or quote data.\n",
    "    # The cleaning procedures are listed below for simplicity\n",
    "    \n",
    "    # Applicable for both trade and quote data\n",
    "    \n",
    "    # P1. Delete entries with a time stamp outside the 9:30 am to 4 pm window when the exchange is open.\n",
    "    # P2. Delete entries with a bid, ask or transaction price equal to zero.\n",
    "    # P3. Retain entries originating from a single exchange. Delete other entries.\n",
    "    \n",
    "    # Applicable for just trade data\n",
    "    \n",
    "    # T1. Delete entries with corrected trades. (Trades with a Correction Indicator, CORR != 0).\n",
    "    # T2. Delete entries with abnormal Sale Condition. (Trades where COND has a letter code, except for “E” and “F”).\n",
    "    # T3. If multiple transactions have the same time stamp: use the median price.\n",
    "    # T4. Delete entries with prices that are above the ask plus the bid-ask spread. \n",
    "    # Similar for entries with prices below the bid minus the bid-ask spread.\n",
    "    \n",
    "    # Applicable for just quote data\n",
    "    \n",
    "    # Q1. When multiple quotes have the same timestamp, we replace all these with a single entry \n",
    "    # with the median bid and median ask price.\n",
    "    # Q2. Delete entries for which the spread is negative.\n",
    "    # Q3. Delete entries for which the spread is more that 50 times the median spread on that day.\n",
    "    # Q4. Delete entries for which the mid-quote deviated by more than 5 median absolute deviations from \n",
    "    # a centered median (excluding the observation under consideration) of 50 observations.\n",
    "\n",
    "    # Some comments, by (Lunde,2016), on the relative importance of the individual cleaning procedures\n",
    "    \n",
    "    # ➤ By far the most important rules here are P3, T3 and Q1.\n",
    "    # ➤ In our empirical work we will see the impact of suspending P3. It is used to reduce the impact\n",
    "    # of time-delays in the reporting of trades and quote updates.\n",
    "    # ➤ Some form of T3 and Q1 rule seems inevitable here, and it is these rules which lead to the largest deletion of data.\n",
    "    # ➤ T4 is an attractive rule, as it disciplines the trade data using quotes. However, it has the disadvantage \n",
    "    # that it cannot be applied when quote data is not available.\n",
    "    # ➤ In situations where quote data is not available, Q4 can be applied to the transaction prices in place of T4.\n",
    "\n",
    "    dataType = dataType.lower().strip()\n",
    "    \n",
    "  \n",
    "        \n",
    "    for cp in cleaningProcedures:\n",
    "        \n",
    "        cp = cp.lower().strip()\n",
    "        \n",
    "        \n",
    "        # check if cp is sensible\n",
    "        if (cp.startswith('t')) & (dataType != 'trade'):\n",
    "            raise ValueError(f'Cleaning procedure {cp} is not compatible with dataType {dataType}')  \n",
    "            \n",
    "        elif (cp.startswith('q')) & (dataType != 'quote'):\n",
    "            raise ValueError(f'Cleaning procedure {cp} is not compatible with dataType {dataType}') \n",
    "\n",
    "\n",
    "        # if the cleaning procedure in question is p1.\n",
    "        if cp == 'p1':\n",
    "            \n",
    "            dataToClean = dataToClean[(datetime.timedelta(hour = 9,\n",
    "                                                         minutes = 30) <= dataToClean.Timestamp)&\\\n",
    "                                      (dataToClean.Timestamp <= datetime.timedelta(hour = 16,\n",
    "                                                                                   minutes = 0))].reset_index(drop=True)\n",
    "        \n",
    "        # if the cleaning procedure in question is p2.\n",
    "        elif cp == 'p2':\n",
    "            \n",
    "            # if the cleaning procedure in question is p1.\n",
    "            if dataType == 'trade':\n",
    "                \n",
    "                dataToClean = dataToClean[dataToClean.price != 0].reset_index(drop=True)\n",
    "                \n",
    "            elif dataType == 'quote':\n",
    "                \n",
    "                dataToClean = dataToClean[(dataToClean.bid != 0) | (dataToClean.ofr != 0)].reset_index(drop=True)\n",
    "                \n",
    "                \n",
    "        # if the cleaning procedure in question is p3.\n",
    "        elif cp == 'p3':\n",
    "            \n",
    "            if len(p3Exchanges) == 0:\n",
    "                \n",
    "                raise ValueError('No exchanges, to filter on, has been provided.\\nPlease provide a list with minimum one exchanges to filter on.')\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                # Ensuring correct format\n",
    "                p3Exchanges = [ele.lower().strip() for ele in p3Exchanges]\n",
    "                \n",
    "                # Filtering on exchanges ### Consider to use \"isin\" on the dataToClean.ex-Series instead, to improve execution time.\n",
    "                dataToClean = dataToClean[[True if ele.lower().strip() in p3Exchanges else False for ele in dataToClean.ex]].reset_index(drop=True)\n",
    "        \n",
    "        \n",
    "        # if the cleaning procedure in question is t1.\n",
    "        # T1. Delete entries with corrected trades. (Trades with a Correction Indicator, CORR != 0).\n",
    "        elif cp == 't1':\n",
    "\n",
    "            dataToClean = dataToClean[dataToClean.corr == 0].reset_index(drop=True)                \n",
    "                \n",
    "                \n",
    "        # if the cleaning procedure in question is t2.\n",
    "        # T2. Delete entries with abnormal Sale Condition. (Trades where COND has a letter code, except for “E” and “F”).\n",
    "        # FMNS: Most are COND = '@ XX' such as '@ TI', make sure this works properly. Assuming startswith('@') is cool\n",
    "        elif cp == 't2':\n",
    "            \n",
    "            dataToClean = dataToClean[(dataToClean.cond.startswith('@')) | (dataToClean.cond in ['E', 'F'])].reset_index(drop=True) \n",
    "            \n",
    "            \n",
    "        # if the cleaning procedure in question is t3.\n",
    "        # T3. If multiple transactions have the same time stamp: use the median price.\n",
    "        # FMNS: Let's consider if these median prices are cheating in relation to OHLC bars\n",
    "        elif cp == 't3':\n",
    "\n",
    "            # get unique timestamps\n",
    "            unique_ts_idx = np.unique(dataToClean.Timestamp, return_index=True)[1]\n",
    "            \n",
    "            # get median prices\n",
    "            median_price = dataToClean[['Timestamp', 'price']].groupby('Timestamp')['price'].median().values\n",
    "                \n",
    "            # keep only unique timestamps\n",
    "            dataToClean = dataToClean.iloc[unique_ts_idx, :].reset_index(drop=True)\n",
    "            \n",
    "            # fill the price variable with medians matched on unique_ts\n",
    "            dataToClean.loc[:,'price'] = median_price\n",
    "            \n",
    "            ### We could add a print to tell how many duplicated values there where? - Kris\n",
    "            \n",
    "            # note that all other variables now hold the first entry for each timestamp!\n",
    "\n",
    "            \n",
    "        # if the cleaning procedure in question is t3.        \n",
    "        # T4. Delete entries with prices that are above the ask plus the bid-ask spread. \n",
    "        # Similar for entries with prices below the bid minus the bid-ask spread.\n",
    "        # FMNS: We have no bid/ask/spread in trades-table. \n",
    "        #       To do this, we would probably need to cross-match timestamps between trades and quotes properly\n",
    "        elif cp == 't4':\n",
    "            \n",
    "            raise ValueError(f'Cleaning procedure {cp} is on hold')          \n",
    "\n",
    "            \n",
    "        # if the cleaning procedure in question is q1.\n",
    "        # Q1. When multiple quotes have the same timestamp, we replace all these with a single entry \n",
    "        # with the median bid and median ask price.   \n",
    "        # FMNS: Let's consider if these median prices are cheating in relation to OHLC bars\n",
    "        elif cp == 'q1':\n",
    "            \n",
    "            if datatype == 'quote':\n",
    "            \n",
    "                # get unique timestamps\n",
    "                unique_ts_idx = np.unique(dataToClean.Timestamp, return_index=True)[1]\n",
    "\n",
    "                # get median prices\n",
    "                median_price = dataToClean[['Timestamp', 'bid', 'ofr']].groupby('Timestamp')['bid', 'ofr'].median().values\n",
    "\n",
    "                # keep only unique timestamps\n",
    "                dataToClean = dataToClean.iloc[unique_ts_idx, :].reset_index(drop=True)\n",
    "\n",
    "                # fill the price variable with medians matched on unique_ts\n",
    "                dataToClean.loc[:,['bid','ofr']] = median_price\n",
    "\n",
    "                # note that all other variables now hold the first entry for each timestamp!\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                raise ValueError('The datatype has to be quote, in order to apply this cleaning procedure.\\nPlease revisit your request.')\n",
    "            \n",
    "\n",
    "        # if the cleaning procedure in question is q2.\n",
    "        # Q2. Delete entries for which the spread is negative.\n",
    "        elif cp == 'q2':\n",
    "            \n",
    "            if datatype == 'quote':\n",
    "                \n",
    "                dataToClean = dataToClean[dataToClean.ofr - dataToClean.bid >= 0].reset_index(drop=True)     \n",
    "            \n",
    "            else:\n",
    "                raise ValueError('The datatype has to be quote, in order to apply this cleaning procedure.\\nPlease revisit your request.')\n",
    "\n",
    "        # if the cleaning procedure in question is q3.\n",
    "        # Q3. Delete entries for which the spread is more that 50 times the median spread on that day.\n",
    "        elif cp == 'q3':\n",
    "            \n",
    "            if datatype == 'quote':\n",
    "                \n",
    "                # get all spreads across days, groupby Date and take daily median spreads\n",
    "                all_spreads = dataToClean[['Date', 'bid', 'ofr']]\n",
    "                all_spreads['spread'] =  dataToClean.ofr - dataToClean.bid\n",
    "                all_spreads.drop(['bid','ofr'], axis=1, inplace=True)\n",
    "\n",
    "                median_spreads = all_spreads.groupby('Date').median().values     \n",
    "\n",
    "\n",
    "                total_keep_idx = []\n",
    "                # for each unique day ...\n",
    "                for day in np.unique(dataToClean.Date):\n",
    "\n",
    "                    # for every spread within this day, check if it's below 50*median \n",
    "                    # (below_50median is a boolean with all existing index)\n",
    "                    below_50median = (all_spreads[all_spreads.Date == day].spread <= 50*median_spreads[median_spreads.index == day].values[0][0])\n",
    "\n",
    "                    # get the indices where below_50median == True (meaning individual spread is within 50*median)\n",
    "                    below_50median[below_50median].index\n",
    "\n",
    "                    total_keep_idx.append(below_50median[below_50median].index)\n",
    "\n",
    "\n",
    "                # after going through all days, flatten the list\n",
    "                total_keep_idx = [ele for intraday_idx in total_keep_idx for ele in intraday_idx]\n",
    "\n",
    "                # keep all entries that passed the filter\n",
    "                dataToClean = dataToClean.iloc[total_keep_idx, :]\n",
    "            \n",
    "            else:\n",
    "\n",
    "                raise ValueError('The datatype has to be quote, in order to apply this cleaning procedure.\\nPlease revisit your request.')\n",
    "        \n",
    "        # if the cleaning procedure in question is q4.\n",
    "        # Q4. Delete entries for which the mid-quote deviated by more than 5 median absolute deviations from \n",
    "        # a centered median (excluding the observation under consideration) of 50 observations.        \n",
    "        elif cp == 'q4':\n",
    "            \n",
    "            raise ValueError(f'Cleaning procedure {cp} is on hold')             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading in data, LOBSTER as well as TAQ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TAQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.git', '.gitignore', '.ipynb_checkpoints', 'CrunchTAQ.ipynb', 'hello.py', 'README.md', 'Speciale to-do.docx', 'Speciale to-do.txt']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir())\n",
    "path = 'a:/taqhdf5'\n",
    "allFiles = os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8485,\n",
       " ['taq_19930315.h5',\n",
       "  'taq_19930104.h5',\n",
       "  'taq_19930317.h5',\n",
       "  'taq_19930105.h5',\n",
       "  'taq_19930316.h5'],\n",
       " ['taqtrade_20200507.h5',\n",
       "  'taqtrade_20200508.h5',\n",
       "  'taqtrade_20200511.h5',\n",
       "  'taqquote_20200504.h5',\n",
       "  'taqtrade_20200512.h5'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#allFiles\n",
    "len(allFiles), allFiles[:5], allFiles[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['taqquote_20200501.h5',\n",
       " 'taqtrade_20200501.h5',\n",
       " 'taqtrade_20200504.h5',\n",
       " 'taqtrade_20200505.h5',\n",
       " 'taqtrade_20200506.h5',\n",
       " 'taqtrade_20200507.h5',\n",
       " 'taqtrade_20200508.h5',\n",
       " 'taqtrade_20200511.h5',\n",
       " 'taqquote_20200504.h5',\n",
       " 'taqtrade_20200512.h5']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allFiles[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Date range #####\n",
      "\n",
      "Date, Min: 20200401\n",
      "Date, Max: 20200401\n",
      "\n",
      "##### Data Extraction begins #####\n",
      "\n",
      "quote data is being extracted..\n",
      "\n",
      "### Quote Data ###\n",
      "\n",
      "The raw H5 quote file contains:  ['QuoteIndex', 'Quotes'] \n",
      "\n",
      "Ticker Information:  (b'GOOG             ', 403024728, 600343) \n",
      "\n",
      "Sneak peak of the data\n",
      "\n",
      "            utcsec ex      bid  bidsize      ofr  ofrsize mode      Date  \\\n",
      "0  14400049177409  P   963.00        1     0.00        0    R  20200401   \n",
      "1  14400049177610  P   985.65        1     0.00        0    R  20200401   \n",
      "2  14400049181518  P   999.00        1     0.00        0    R  20200401   \n",
      "3  14400049181691  P  1018.00        1     0.00        0    R  20200401   \n",
      "4  14400049274621  P  1018.00        1  1188.88        3    R  20200401   \n",
      "\n",
      "                Timestamp TSRemainder  Hour  Minute Ticker  \n",
      "0 2020-04-01 04:00:49.177         409     4       0   GOOG  \n",
      "1 2020-04-01 04:00:49.177         610     4       0   GOOG  \n",
      "2 2020-04-01 04:00:49.181         518     4       0   GOOG  \n",
      "3 2020-04-01 04:00:49.181         691     4       0   GOOG  \n",
      "4 2020-04-01 04:00:49.274         621     4       0   GOOG  \n",
      "Ticker Information:  (b'MSFT             ', 659389624, 5607207) \n",
      "\n",
      "The extraction time was 857.676 seconds.\n"
     ]
    }
   ],
   "source": [
    "# Measuring the exraction time\n",
    "start = time.time()\n",
    "\n",
    "# Provide a list of dates of interest (format: yyyymmdd)\n",
    "dates = np.array(['20200401']).astype(int)#,'20200402'\n",
    "\n",
    "# Provide a list of tickers of interest\n",
    "tickers = ['GOOG','MSFT']\n",
    "\n",
    "# Do we need data on trades, quotes or both?\n",
    "dataNeeded = 'quotes' # 'trades', 'quotes' or 'both'\n",
    "\n",
    "# Extracting just the dates of each file\n",
    "allDates = np.array([re.split(\"[._]\",ele)[1] if (\".\" in ele ) & (\"_\" in ele) else 0 for ele in allFiles]).astype(int)\n",
    "\n",
    "minDate = np.min(dates)\n",
    "maxDate = np.max(dates)\n",
    "\n",
    "if verbose:\n",
    "    print('##### Date range #####\\n\\nDate, Min: %i\\nDate, Max: %i\\n'%(minDate,maxDate))\n",
    "\n",
    "# Locating what files we need.\n",
    "index = np.where((minDate <= allDates) & (allDates <= maxDate))\n",
    "\n",
    "relevantFiles = np.array(allFiles)[index[0]]\n",
    "\n",
    "# Separating the files into trade and quote files.\n",
    "trade = [ele for ele in relevantFiles if 'trade' in ele]\n",
    "quote = [ele for ele in relevantFiles if 'quote' in ele]\n",
    "\n",
    "if verbose:\n",
    "    print('##### Data Extraction begins #####\\n')\n",
    "    \n",
    "    if dataNeeded.lower() == 'both':\n",
    "        print('Both trade and quote data is being extracted..\\n')\n",
    "    else:\n",
    "        print('%s data is being extracted..\\n' % dataNeeded[0:5])\n",
    "        \n",
    "if (dataNeeded == 'both') | (dataNeeded == 'trades'):\n",
    "           \n",
    "# Lets start out by extracting the trade data\n",
    "\n",
    "    for i,file in enumerate(trade):\n",
    "\n",
    "        if (verbose) & (i == 0):\n",
    "            print('### Trade Data ###\\n')\n",
    "\n",
    "        # Reading one file at a time\n",
    "        raw_data = h5py.File(path+'/'+file,'r')\n",
    "\n",
    "        # Store the trade indecies\n",
    "        TI = raw_data['TradeIndex']\n",
    "\n",
    "        if (verbose) & (i==0):\n",
    "            print('The raw H5 trade file contains: ',list(raw_data.keys()),'\\n')\n",
    "\n",
    "        # Extracting just the tickers\n",
    "        TIC = np.array([ele[0].astype(str).strip() for ele in TI])\n",
    "\n",
    "        # Lets get data on each ticker for the file processed at the moment\n",
    "        for j,ticker in enumerate(tickers):\n",
    "\n",
    "            # Getting the specific ticker information\n",
    "            tickerInfo = TI[TIC==ticker][0]\n",
    "\n",
    "            if (verbose) & (i == 0):\n",
    "                    print('Ticker Information: ',tickerInfo,'\\n')\n",
    "\n",
    "            # Raw data\n",
    "            tempData = raw_data['Trades'][np.arange(tickerInfo[1],tickerInfo[1]+tickerInfo[2])]\n",
    "\n",
    "            # For first file and first ticker.\n",
    "            if (i == 0) & (j == 0):    \n",
    "\n",
    "                tradeData = pd.DataFrame(tempData, columns= tempData.dtype.names)\n",
    "\n",
    "                tradeData.loc[:,'ex'] = strList(tradeData.ex)\n",
    "                tradeData.loc[:,'cond'] = strList(tradeData.cond)\n",
    "                tradeData.loc[:,'TradeStopStockIndicator'] = strList(tradeData.TradeStopStockIndicator)\n",
    "                tradeData.loc[:,'corr'] = strList(tradeData['corr'])\n",
    "                tradeData.loc[:,'TradeID'] = strList(tradeData.TradeID)\n",
    "                tradeData.loc[:,'TTE'] = strList(tradeData.TTE)\n",
    "                tradeData.loc[:,'TradeReportingFacility'] = strList(tradeData.TradeReportingFacility)\n",
    "                tradeData.loc[:,'SourceOfTrade'] = strList(tradeData.SourceOfTrade)\n",
    "\n",
    "                # Adding the date of the file to the dataframe.\n",
    "                tradeData['Date'] = re.split('[._]',file)[1]\n",
    "\n",
    "                # Adding a more readable timestamp - TEST IT\n",
    "                tradeData['Timestamp'] = pd.to_datetime(formatDate(re.split('[._]',file)[1],tradeData.utcsec))\n",
    "                tradeData['TSRemainder'] = list(map(lambda x: str(x)[11:], tradeData.utcsec))\n",
    "                tradeData['Hour'] = tradeData.Timestamp.dt.hour\n",
    "                tradeData['Minute'] = tradeData.Timestamp.dt.minute\n",
    "                # Adding the ticker\n",
    "                tradeData['Ticker'] = ticker\n",
    "\n",
    "                if (verbose) & (i==0) & (j==0):\n",
    "                    print('Sneak peak of the data\\n\\n',tradeData.head())\n",
    "\n",
    "            else:\n",
    "\n",
    "                # Storing the data on the following tickers in a temporary variable.\n",
    "\n",
    "                temp = pd.DataFrame(tempData, columns= tempData.dtype.names)\n",
    "\n",
    "                temp.loc[:,'ex'] = strList(temp.ex)\n",
    "                temp.loc[:,'cond'] = strList(temp.cond)\n",
    "                temp.loc[:,'TradeStopStockIndicator'] = strList(temp.TradeStopStockIndicator)\n",
    "                temp.loc[:,'corr'] = strList(temp['corr'])\n",
    "                temp.loc[:,'TradeID'] = strList(temp.TradeID)\n",
    "                temp.loc[:,'TTE'] = strList(temp.TTE)\n",
    "                temp.loc[:,'TradeReportingFacility'] = strList(temp.TradeReportingFacility)\n",
    "                temp.loc[:,'SourceOfTrade'] = strList(temp.SourceOfTrade)\n",
    "\n",
    "                # Adding the date of the file to the dataframe.\n",
    "                temp['Date'] = re.split('[._]',file)[1]\n",
    "\n",
    "                # Adding a more readable timestamp - TEST IT\n",
    "                temp['Timestamp'] = pd.to_datetime(formatDate(re.split('[._]',file)[1],temp.utcsec))\n",
    "                temp['TSRemainder'] = list(map(lambda x: str(x)[11:], temp.utcsec))\n",
    "                temp['Hour'] = temp.Timestamp.dt.hour\n",
    "                temp['Minute'] = temp.Timestamp.dt.minute\n",
    "\n",
    "                # Adding the ticker\n",
    "                temp['Ticker'] = ticker\n",
    "\n",
    "                # Adding the new data \n",
    "                tradeData = pd.concat([tradeData,temp])\n",
    "\n",
    "if (dataNeeded == 'both') | (dataNeeded == 'quotes'):\n",
    "    \n",
    "    # Now to the quote data\n",
    "    for i,file in enumerate(quote):\n",
    "\n",
    "        if (verbose) & (i == 0):\n",
    "            print('### Quote Data ###\\n')\n",
    "\n",
    "        # Reading one file at a time\n",
    "        raw_data = h5py.File(path+'/'+file,'r')\n",
    "\n",
    "        # Store the trade indecies\n",
    "        QI = raw_data['QuoteIndex']\n",
    "\n",
    "        if (verbose) & (i==0):\n",
    "            print('The raw H5 quote file contains: ',list(raw_data.keys()),'\\n')\n",
    "\n",
    "        # Extracting just the tickers\n",
    "        QIC = np.array([ele[0].astype(str).strip() for ele in QI])\n",
    "\n",
    "        # Lets get data on each ticker for the file processed at the moment\n",
    "        for j,ticker in enumerate(tickers):\n",
    "\n",
    "            # Getting the specific ticker information\n",
    "            tickerInfo = QI[QIC==ticker][0]\n",
    "\n",
    "            if (verbose) & (i == 0):\n",
    "                    print('Ticker Information: ',tickerInfo,'\\n')\n",
    "\n",
    "            # Raw data\n",
    "            tempData = raw_data['Quotes'][np.arange(tickerInfo[1],tickerInfo[1]+tickerInfo[2])]\n",
    "\n",
    "            # For first file and first ticker.\n",
    "            if (i == 0) & (j == 0):    \n",
    "\n",
    "                quoteData = pd.DataFrame(tempData, columns= tempData.dtype.names)\n",
    "                # We remove all unnecessary variables\n",
    "                unnecessaryVariables = ['NationalBBOInd',\n",
    "                                        'FinraBBOInd',\n",
    "                                        'FinraQuoteIndicator',\n",
    "                                        'SequenceNumber',\n",
    "                                        'FinraAdfMpidIndicator',\n",
    "                                        'QuoteCancelCorrection',\n",
    "                                        'SourceQuote',\n",
    "                                        'RPI',\n",
    "                                        'ShortSaleRestrictionIndicator',\n",
    "                                        'LuldBBOIndicator',\n",
    "                                        'SIPGeneratedMessageIdent',\n",
    "                                        'NationalBBOLuldIndicator',\n",
    "                                        'ParticipantTimestamp',\n",
    "                                        'FinraTimestamp',\n",
    "                                        'FinraQuoteIndicator',\n",
    "                                        'SecurityStatusIndicator']\n",
    "                \n",
    "                quoteData = quoteData.drop(columns=unnecessaryVariables)\n",
    "\n",
    "                quoteData.loc[:,'ex'] = strList(quoteData.ex)\n",
    "                quoteData.loc[:,'mode'] = strList(quoteData['mode'])\n",
    "                \n",
    "                # Adding the date of the file to the dataframe.\n",
    "                quoteData['Date'] = re.split('[._]',file)[1]\n",
    "\n",
    "                # Adding a more readable timestamp - TEST IT\n",
    "                quoteData['Timestamp'] = pd.to_datetime(formatDate(re.split('[._]',file)[1],quoteData.utcsec))\n",
    "                quoteData['TSRemainder'] = list(map(lambda x: str(x)[11:], quoteData.utcsec))\n",
    "                quoteData['Hour'] = quoteData.Timestamp.dt.hour\n",
    "                quoteData['Minute'] = quoteData.Timestamp.dt.minute\n",
    "                # Adding the ticker\n",
    "                quoteData['Ticker'] = ticker\n",
    "\n",
    "                if (verbose) & (i==0) & (j==0):\n",
    "                    print('Sneak peak of the data\\n\\n',quoteData.head())\n",
    "\n",
    "            else:\n",
    "\n",
    "                # Storing the data on the following tickers in a temporary variable.\n",
    "\n",
    "                temp = pd.DataFrame(tempData, columns= tempData.dtype.names)\n",
    "                # Removing all unnecessary variables\n",
    "                temp = temp.drop(columns=unnecessaryVariables)\n",
    "                \n",
    "                temp.loc[:,'ex'] = strList(temp.ex)\n",
    "                temp.loc[:,'mode'] = strList(temp['mode'])\n",
    "\n",
    "                # Adding the date of the file to the dataframe.\n",
    "                temp['Date'] = re.split('[._]',file)[1]\n",
    "\n",
    "                # Adding a more readable timestamp - TEST IT\n",
    "                temp['Timestamp'] = pd.to_datetime(formatDate(re.split('[._]',file)[1],temp.utcsec))\n",
    "                temp['TSRemainder'] = list(map(lambda x: str(x)[11:], temp.utcsec))\n",
    "                temp['Hour'] = temp.Timestamp.dt.hour\n",
    "                temp['Minute'] = temp.Timestamp.dt.minute\n",
    "\n",
    "                # Adding the ticker\n",
    "                temp['Ticker'] = ticker\n",
    "\n",
    "                # Adding the new data \n",
    "                quoteData = pd.concat([quoteData,temp])\n",
    "                    \n",
    "end = time.time()\n",
    "\n",
    "if verbose:\n",
    "    print('The extraction time was %.3f seconds.' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utcsec</th>\n",
       "      <th>ex</th>\n",
       "      <th>bid</th>\n",
       "      <th>bidsize</th>\n",
       "      <th>ofr</th>\n",
       "      <th>ofrsize</th>\n",
       "      <th>mode</th>\n",
       "      <th>Date</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>TSRemainder</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Minute</th>\n",
       "      <th>Ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14400049177409</td>\n",
       "      <td>P</td>\n",
       "      <td>963.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>R</td>\n",
       "      <td>20200401</td>\n",
       "      <td>2020-04-01 04:00:49.177</td>\n",
       "      <td>409</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>GOOG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14400049177610</td>\n",
       "      <td>P</td>\n",
       "      <td>985.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>R</td>\n",
       "      <td>20200401</td>\n",
       "      <td>2020-04-01 04:00:49.177</td>\n",
       "      <td>610</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>GOOG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14400049181518</td>\n",
       "      <td>P</td>\n",
       "      <td>999.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>R</td>\n",
       "      <td>20200401</td>\n",
       "      <td>2020-04-01 04:00:49.181</td>\n",
       "      <td>518</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>GOOG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14400049181691</td>\n",
       "      <td>P</td>\n",
       "      <td>1018.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>R</td>\n",
       "      <td>20200401</td>\n",
       "      <td>2020-04-01 04:00:49.181</td>\n",
       "      <td>691</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>GOOG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14400049274621</td>\n",
       "      <td>P</td>\n",
       "      <td>1018.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1188.88</td>\n",
       "      <td>3</td>\n",
       "      <td>R</td>\n",
       "      <td>20200401</td>\n",
       "      <td>2020-04-01 04:00:49.274</td>\n",
       "      <td>621</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>GOOG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           utcsec ex      bid  bidsize      ofr  ofrsize mode      Date  \\\n",
       "0  14400049177409  P   963.00        1     0.00        0    R  20200401   \n",
       "1  14400049177610  P   985.65        1     0.00        0    R  20200401   \n",
       "2  14400049181518  P   999.00        1     0.00        0    R  20200401   \n",
       "3  14400049181691  P  1018.00        1     0.00        0    R  20200401   \n",
       "4  14400049274621  P  1018.00        1  1188.88        3    R  20200401   \n",
       "\n",
       "                Timestamp TSRemainder  Hour  Minute Ticker  \n",
       "0 2020-04-01 04:00:49.177         409     4       0   GOOG  \n",
       "1 2020-04-01 04:00:49.177         610     4       0   GOOG  \n",
       "2 2020-04-01 04:00:49.181         518     4       0   GOOG  \n",
       "3 2020-04-01 04:00:49.181         691     4       0   GOOG  \n",
       "4 2020-04-01 04:00:49.274         621     4       0   GOOG  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quoteData.head()\n",
    "#tradeData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['utcsec', 'ex', 'bid', 'bidsize', 'ofr', 'ofrsize', 'mode', 'Date',\n",
       "       'Timestamp', 'TSRemainder', 'Hour', 'Minute', 'Ticker'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quoteData.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utcsec</th>\n",
       "      <th>ex</th>\n",
       "      <th>bid</th>\n",
       "      <th>bidsize</th>\n",
       "      <th>ofr</th>\n",
       "      <th>ofrsize</th>\n",
       "      <th>mode</th>\n",
       "      <th>Date</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>TSRemainder</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Minute</th>\n",
       "      <th>Ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14400049177409</td>\n",
       "      <td>P</td>\n",
       "      <td>963.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>R</td>\n",
       "      <td>20200401</td>\n",
       "      <td>2020-04-01 04:00:49.177</td>\n",
       "      <td>409</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>GOOG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14400049177610</td>\n",
       "      <td>P</td>\n",
       "      <td>985.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>R</td>\n",
       "      <td>20200401</td>\n",
       "      <td>2020-04-01 04:00:49.177</td>\n",
       "      <td>610</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>GOOG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14400049181518</td>\n",
       "      <td>P</td>\n",
       "      <td>999.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>R</td>\n",
       "      <td>20200401</td>\n",
       "      <td>2020-04-01 04:00:49.181</td>\n",
       "      <td>518</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>GOOG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14400049181691</td>\n",
       "      <td>P</td>\n",
       "      <td>1018.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>R</td>\n",
       "      <td>20200401</td>\n",
       "      <td>2020-04-01 04:00:49.181</td>\n",
       "      <td>691</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>GOOG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14400049274621</td>\n",
       "      <td>P</td>\n",
       "      <td>1018.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1188.88</td>\n",
       "      <td>3</td>\n",
       "      <td>R</td>\n",
       "      <td>20200401</td>\n",
       "      <td>2020-04-01 04:00:49.274</td>\n",
       "      <td>621</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>GOOG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5607202</th>\n",
       "      <td>71990849475938</td>\n",
       "      <td>K</td>\n",
       "      <td>153.41</td>\n",
       "      <td>2</td>\n",
       "      <td>153.59</td>\n",
       "      <td>2</td>\n",
       "      <td>R</td>\n",
       "      <td>20200401</td>\n",
       "      <td>2020-04-01 20:13:59.475</td>\n",
       "      <td>938</td>\n",
       "      <td>20</td>\n",
       "      <td>13</td>\n",
       "      <td>MSFT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5607203</th>\n",
       "      <td>71993763255970</td>\n",
       "      <td>K</td>\n",
       "      <td>153.41</td>\n",
       "      <td>2</td>\n",
       "      <td>153.59</td>\n",
       "      <td>2</td>\n",
       "      <td>R</td>\n",
       "      <td>20200401</td>\n",
       "      <td>2020-04-01 20:12:36.255</td>\n",
       "      <td>970</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>MSFT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5607204</th>\n",
       "      <td>71996762822526</td>\n",
       "      <td>K</td>\n",
       "      <td>153.58</td>\n",
       "      <td>2</td>\n",
       "      <td>153.59</td>\n",
       "      <td>2</td>\n",
       "      <td>R</td>\n",
       "      <td>20200401</td>\n",
       "      <td>2020-04-01 20:12:38.822</td>\n",
       "      <td>526</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>MSFT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5607205</th>\n",
       "      <td>71998862697002</td>\n",
       "      <td>K</td>\n",
       "      <td>153.58</td>\n",
       "      <td>2</td>\n",
       "      <td>153.59</td>\n",
       "      <td>1</td>\n",
       "      <td>R</td>\n",
       "      <td>20200401</td>\n",
       "      <td>2020-04-01 20:14:20.697</td>\n",
       "      <td>002</td>\n",
       "      <td>20</td>\n",
       "      <td>14</td>\n",
       "      <td>MSFT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5607206</th>\n",
       "      <td>71999986468655</td>\n",
       "      <td>K</td>\n",
       "      <td>153.58</td>\n",
       "      <td>1</td>\n",
       "      <td>153.59</td>\n",
       "      <td>1</td>\n",
       "      <td>R</td>\n",
       "      <td>20200401</td>\n",
       "      <td>2020-04-01 20:16:25.468</td>\n",
       "      <td>655</td>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>MSFT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6207550 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 utcsec ex      bid  bidsize      ofr  ofrsize mode      Date  \\\n",
       "0        14400049177409  P   963.00        1     0.00        0    R  20200401   \n",
       "1        14400049177610  P   985.65        1     0.00        0    R  20200401   \n",
       "2        14400049181518  P   999.00        1     0.00        0    R  20200401   \n",
       "3        14400049181691  P  1018.00        1     0.00        0    R  20200401   \n",
       "4        14400049274621  P  1018.00        1  1188.88        3    R  20200401   \n",
       "...                 ... ..      ...      ...      ...      ...  ...       ...   \n",
       "5607202  71990849475938  K   153.41        2   153.59        2    R  20200401   \n",
       "5607203  71993763255970  K   153.41        2   153.59        2    R  20200401   \n",
       "5607204  71996762822526  K   153.58        2   153.59        2    R  20200401   \n",
       "5607205  71998862697002  K   153.58        2   153.59        1    R  20200401   \n",
       "5607206  71999986468655  K   153.58        1   153.59        1    R  20200401   \n",
       "\n",
       "                      Timestamp TSRemainder  Hour  Minute Ticker  \n",
       "0       2020-04-01 04:00:49.177         409     4       0   GOOG  \n",
       "1       2020-04-01 04:00:49.177         610     4       0   GOOG  \n",
       "2       2020-04-01 04:00:49.181         518     4       0   GOOG  \n",
       "3       2020-04-01 04:00:49.181         691     4       0   GOOG  \n",
       "4       2020-04-01 04:00:49.274         621     4       0   GOOG  \n",
       "...                         ...         ...   ...     ...    ...  \n",
       "5607202 2020-04-01 20:13:59.475         938    20      13   MSFT  \n",
       "5607203 2020-04-01 20:12:36.255         970    20      12   MSFT  \n",
       "5607204 2020-04-01 20:12:38.822         526    20      12   MSFT  \n",
       "5607205 2020-04-01 20:14:20.697         002    20      14   MSFT  \n",
       "5607206 2020-04-01 20:16:25.468         655    20      16   MSFT  \n",
       "\n",
       "[6207550 rows x 13 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quoteData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>utcsec</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th>Ticker</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">20200401</th>\n",
       "      <th>GOOG</th>\n",
       "      <td>71427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSFT</th>\n",
       "      <td>531829</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 utcsec\n",
       "Date     Ticker        \n",
       "20200401 GOOG     71427\n",
       "         MSFT    531829"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['Date','Ticker','utcsec']].groupby(['Date','Ticker']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['@ TI', '@FTI', '@FT ', '@ T ', '@  I', '@   ', '@  Q', '@F I',\n",
       "       '@O X', '@F  ', '@4 I', '@4  ', '@4ZI', '@ ZI', '@ Z ', '@4 W',\n",
       "       'N  I', '@7 V', 'C  I', '@  W', '@  M', '@6 X', '@ TW', 'N T ',\n",
       "       '@ TP', 'R   ', '@4Z ', '@7  ', 'C   ', 'N   ', '@  P', '@6  '],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.cond.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utcsec</th>\n",
       "      <th>ex</th>\n",
       "      <th>cond</th>\n",
       "      <th>volume</th>\n",
       "      <th>price</th>\n",
       "      <th>TradeStopStockIndicator</th>\n",
       "      <th>corr</th>\n",
       "      <th>TradeSequenceNumber</th>\n",
       "      <th>TradeID</th>\n",
       "      <th>SourceOfTrade</th>\n",
       "      <th>TradeReportingFacility</th>\n",
       "      <th>ParticipantTime</th>\n",
       "      <th>TRFTime</th>\n",
       "      <th>TTE</th>\n",
       "      <th>Date</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>TSRemainder</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Minute</th>\n",
       "      <th>Ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>14599950781367</td>\n",
       "      <td>P</td>\n",
       "      <td>@ TI</td>\n",
       "      <td>3</td>\n",
       "      <td>1135.00</td>\n",
       "      <td></td>\n",
       "      <td>00</td>\n",
       "      <td>1627</td>\n",
       "      <td>6</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>14599950405120</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>20200401</td>\n",
       "      <td>2020-04-01 04:19:09.781</td>\n",
       "      <td>367</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>GOOG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>16114425993578</td>\n",
       "      <td>P</td>\n",
       "      <td>@ TI</td>\n",
       "      <td>10</td>\n",
       "      <td>1132.00</td>\n",
       "      <td></td>\n",
       "      <td>00</td>\n",
       "      <td>2181</td>\n",
       "      <td>15</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>16114425610240</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>20200401</td>\n",
       "      <td>2020-04-01 04:35:39.993</td>\n",
       "      <td>578</td>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>GOOG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>16114425993843</td>\n",
       "      <td>P</td>\n",
       "      <td>@ TI</td>\n",
       "      <td>4</td>\n",
       "      <td>1128.16</td>\n",
       "      <td></td>\n",
       "      <td>00</td>\n",
       "      <td>2182</td>\n",
       "      <td>16</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>16114425610240</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>20200401</td>\n",
       "      <td>2020-04-01 04:35:39.993</td>\n",
       "      <td>843</td>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>GOOG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>16155688003715</td>\n",
       "      <td>P</td>\n",
       "      <td>@ TI</td>\n",
       "      <td>20</td>\n",
       "      <td>1128.60</td>\n",
       "      <td></td>\n",
       "      <td>00</td>\n",
       "      <td>2219</td>\n",
       "      <td>19</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>16155687619328</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>20200401</td>\n",
       "      <td>2020-04-01 04:40:43.003</td>\n",
       "      <td>715</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>GOOG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>16155688003965</td>\n",
       "      <td>P</td>\n",
       "      <td>@ TI</td>\n",
       "      <td>8</td>\n",
       "      <td>1128.20</td>\n",
       "      <td></td>\n",
       "      <td>00</td>\n",
       "      <td>2220</td>\n",
       "      <td>20</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>16155687619328</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>20200401</td>\n",
       "      <td>2020-04-01 04:40:43.003</td>\n",
       "      <td>965</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>GOOG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531144</th>\n",
       "      <td>68363847877197</td>\n",
       "      <td>P</td>\n",
       "      <td>@ TI</td>\n",
       "      <td>2</td>\n",
       "      <td>153.05</td>\n",
       "      <td></td>\n",
       "      <td>00</td>\n",
       "      <td>4155224</td>\n",
       "      <td>47885</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>68363847483904</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>20200401</td>\n",
       "      <td>2020-04-01 19:13:30.877</td>\n",
       "      <td>197</td>\n",
       "      <td>19</td>\n",
       "      <td>13</td>\n",
       "      <td>MSFT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531169</th>\n",
       "      <td>68379470524894</td>\n",
       "      <td>P</td>\n",
       "      <td>@FT</td>\n",
       "      <td>118</td>\n",
       "      <td>153.00</td>\n",
       "      <td></td>\n",
       "      <td>00</td>\n",
       "      <td>4155261</td>\n",
       "      <td>47892</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>68379470146560</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>20200401</td>\n",
       "      <td>2020-04-01 19:07:29.524</td>\n",
       "      <td>894</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "      <td>MSFT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531196</th>\n",
       "      <td>68427745066677</td>\n",
       "      <td>P</td>\n",
       "      <td>@FTI</td>\n",
       "      <td>40</td>\n",
       "      <td>153.00</td>\n",
       "      <td></td>\n",
       "      <td>00</td>\n",
       "      <td>4155341</td>\n",
       "      <td>47895</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>68427744682240</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>20200401</td>\n",
       "      <td>2020-04-01 19:12:52.066</td>\n",
       "      <td>677</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>MSFT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531360</th>\n",
       "      <td>69551250328996</td>\n",
       "      <td>P</td>\n",
       "      <td>@FTI</td>\n",
       "      <td>20</td>\n",
       "      <td>152.88</td>\n",
       "      <td></td>\n",
       "      <td>00</td>\n",
       "      <td>4155855</td>\n",
       "      <td>47909</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>69551249939200</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>20200401</td>\n",
       "      <td>2020-04-01 19:23:21.328</td>\n",
       "      <td>996</td>\n",
       "      <td>19</td>\n",
       "      <td>23</td>\n",
       "      <td>MSFT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531567</th>\n",
       "      <td>70918808092230</td>\n",
       "      <td>P</td>\n",
       "      <td>@ TI</td>\n",
       "      <td>10</td>\n",
       "      <td>153.49</td>\n",
       "      <td></td>\n",
       "      <td>00</td>\n",
       "      <td>4156444</td>\n",
       "      <td>47928</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>70918807713536</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>20200401</td>\n",
       "      <td>2020-04-01 19:55:26.092</td>\n",
       "      <td>230</td>\n",
       "      <td>19</td>\n",
       "      <td>55</td>\n",
       "      <td>MSFT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20203 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                utcsec ex  cond  volume    price TradeStopStockIndicator corr  \\\n",
       "12      14599950781367  P  @ TI       3  1135.00                           00   \n",
       "23      16114425993578  P  @ TI      10  1132.00                           00   \n",
       "24      16114425993843  P  @ TI       4  1128.16                           00   \n",
       "27      16155688003715  P  @ TI      20  1128.60                           00   \n",
       "28      16155688003965  P  @ TI       8  1128.20                           00   \n",
       "...                ... ..   ...     ...      ...                     ...  ...   \n",
       "531144  68363847877197  P  @ TI       2   153.05                           00   \n",
       "531169  68379470524894  P  @FT      118   153.00                           00   \n",
       "531196  68427745066677  P  @FTI      40   153.00                           00   \n",
       "531360  69551250328996  P  @FTI      20   152.88                           00   \n",
       "531567  70918808092230  P  @ TI      10   153.49                           00   \n",
       "\n",
       "        TradeSequenceNumber TradeID SourceOfTrade TradeReportingFacility  \\\n",
       "12                     1627       6             N                          \n",
       "23                     2181      15             N                          \n",
       "24                     2182      16             N                          \n",
       "27                     2219      19             N                          \n",
       "28                     2220      20             N                          \n",
       "...                     ...     ...           ...                    ...   \n",
       "531144              4155224   47885             N                          \n",
       "531169              4155261   47892             N                          \n",
       "531196              4155341   47895             N                          \n",
       "531360              4155855   47909             N                          \n",
       "531567              4156444   47928             N                          \n",
       "\n",
       "        ParticipantTime  TRFTime TTE      Date               Timestamp  \\\n",
       "12       14599950405120       99   0  20200401 2020-04-01 04:19:09.781   \n",
       "23       16114425610240       99   0  20200401 2020-04-01 04:35:39.993   \n",
       "24       16114425610240       99   0  20200401 2020-04-01 04:35:39.993   \n",
       "27       16155687619328       99   0  20200401 2020-04-01 04:40:43.003   \n",
       "28       16155687619328       99   0  20200401 2020-04-01 04:40:43.003   \n",
       "...                 ...      ...  ..       ...                     ...   \n",
       "531144   68363847483904       99   0  20200401 2020-04-01 19:13:30.877   \n",
       "531169   68379470146560       99   1  20200401 2020-04-01 19:07:29.524   \n",
       "531196   68427744682240       99   1  20200401 2020-04-01 19:12:52.066   \n",
       "531360   69551249939200       99   1  20200401 2020-04-01 19:23:21.328   \n",
       "531567   70918807713536       99   0  20200401 2020-04-01 19:55:26.092   \n",
       "\n",
       "       TSRemainder  Hour  Minute Ticker  \n",
       "12             367     4      19   GOOG  \n",
       "23             578     4      35   GOOG  \n",
       "24             843     4      35   GOOG  \n",
       "27             715     4      40   GOOG  \n",
       "28             965     4      40   GOOG  \n",
       "...            ...   ...     ...    ...  \n",
       "531144         197    19      13   MSFT  \n",
       "531169         894    19       7   MSFT  \n",
       "531196         677    19      12   MSFT  \n",
       "531360         996    19      23   MSFT  \n",
       "531567         230    19      55   MSFT  \n",
       "\n",
       "[20203 rows x 20 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.duplicated(['Timestamp'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
