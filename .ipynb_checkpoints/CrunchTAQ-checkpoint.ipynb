{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "import h5py\n",
    "import copy\n",
    "import datetime\n",
    "\n",
    "# Do you wanna see?\n",
    "verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FMNS testing pull request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformData(dataset, datainfo):\n",
    "  \n",
    "    # Use the column-name information to rename the columns.\n",
    "    renameCol = {i:col[0] for i,col in enumerate(datainfo)}\n",
    "  \n",
    "    # Rename\n",
    "    dataset = dataset.rename(columns=renameCol)\n",
    "  \n",
    "    # Use the datatype information to convert the arrays back to the right datatype.\n",
    "    dt = {col[0]:str if col[1] == 'object' else col[1] for col in datainfo}\n",
    "\n",
    "    # Convert the datatypes\n",
    "    dataset = dataset.astype(dt)\n",
    "\n",
    "    # Strip the string-type arrays for the unintended characters.\n",
    "    for ele in datainfo:\n",
    "        # if the datatype is string, we need to do some additional conversion.\n",
    "        if ele[1] == 'object':\n",
    "\n",
    "            dataset[ele[0]] = list(map(f,dataset[ele[0]]))\n",
    "\n",
    "            if 'date' in ele[0].lower():\n",
    "                dataset[ele[0]] = dataset[ele[0]].astype(np.datetime64) \n",
    "\n",
    "    return dataset\n",
    "\n",
    "# We create a function to clean the string-type arrays\n",
    "f = lambda a: re.split('[\\']',a)[1]\n",
    "\n",
    "# Function to clean the unpacked data from the compressed files.\n",
    "def strList(ls):\n",
    "    return list(map(lambda x: x.decode('utf-8'),ls))\n",
    "\n",
    "# The following function is based on the research of (Lunde, 2016), summarized in the slides found here:\n",
    "# https://econ.au.dk/fileadmin/site_files/filer_oekonomi/subsites/creates/Diverse_2016/PhD_High-Frequency/HF_TrQuData_v01.pdf\n",
    "\n",
    "def formatDate(date,timestamps):\n",
    "    return list(map(lambda x: date[0:4]+'/'+date[4:6]+'/'+date[6:]+' '+str(datetime.timedelta(seconds = int(str(x)[0:5]),\n",
    "                                                     milliseconds = int(str(x)[5:11]))),timestamps))\n",
    "def HFDataCleaning(cleaningProcedures,dataToClean,dataType,p3Exchanges = []):\n",
    "    \n",
    "    # There are 11 cleaning procedures, with 3 relevant for both trade and quote data and 4 for either trade or quote data.\n",
    "    # The cleaning procedures are listed below for simplicity\n",
    "    \n",
    "    # Applicable for both trade and quote data\n",
    "    \n",
    "    # P1. Delete entries with a time stamp outside the 9:30 am to 4 pm window when the exchange is open.\n",
    "    # P2. Delete entries with a bid, ask or transaction price equal to zero.\n",
    "    # P3. Retain entries originating from a single exchange. Delete other entries.\n",
    "    \n",
    "    # Applicable for just trade data\n",
    "    \n",
    "    # T1. Delete entries with corrected trades. (Trades with a Correction Indicator, CORR != 0).\n",
    "    # T2. Delete entries with abnormal Sale Condition. (Trades where COND has a letter code, except for “E” and “F”).\n",
    "    # T3. If multiple transactions have the same time stamp: use the median price.\n",
    "    # T4. Delete entries with prices that are above the ask plus the bid-ask spread. \n",
    "    # Similar for entries with prices below the bid minus the bid-ask spread.\n",
    "    \n",
    "    # Applicable for just quote data\n",
    "    \n",
    "    # Q1. When multiple quotes have the same timestamp, we replace all these with a single entry \n",
    "    # with the median bid and median ask price.\n",
    "    # Q2. Delete entries for which the spread is negative.\n",
    "    # Q3. Delete entries for which the spread is more that 50 times the median spread on that day.\n",
    "    # Q4. Delete entries for which the mid-quote deviated by more than 5 median absolute deviations from \n",
    "    # a centered median (excluding the observation under consideration) of 50 observations.\n",
    "\n",
    "    # Some comments, by (Lunde,2016), on the relative importance of the individual cleaning procedures\n",
    "    \n",
    "    # ➤ By far the most important rules here are P3, T3 and Q1.\n",
    "    # ➤ In our empirical work we will see the impact of suspending P3. It is used to reduce the impact\n",
    "    # of time-delays in the reporting of trades and quote updates.\n",
    "    # ➤ Some form of T3 and Q1 rule seems inevitable here, and it is these rules which lead to the largest deletion of data.\n",
    "    # ➤ T4 is an attractive rule, as it disciplines the trade data using quotes. However, it has the disadvantage \n",
    "    # that it cannot be applied when quote data is not available.\n",
    "    # ➤ In situations where quote data is not available, Q4 can be applied to the transaction prices in place of T4.\n",
    "\n",
    "    dataType = dataType.lower().strip()\n",
    "    \n",
    "  \n",
    "        \n",
    "    for cp in cleaningProcedures:\n",
    "        \n",
    "        cp = cp.lower().strip()\n",
    "        \n",
    "        \n",
    "        # check if cp is sensible\n",
    "        if (cp.startswith('t')) & (dataType != 'trade'):\n",
    "            raise ValueError(f'Cleaning procedure {cp} is not compatible with dataType {dataType}')  \n",
    "            \n",
    "        elif (cp.startswith('q')) & (dataType != 'quote'):\n",
    "            raise ValueError(f'Cleaning procedure {cp} is not compatible with dataType {dataType}') \n",
    "\n",
    "\n",
    "        # if the cleaning procedure in question is p1.\n",
    "        if cp == 'p1':\n",
    "            \n",
    "            dataToClean = dataToClean[(datetime.timedelta(hour = 9,\n",
    "                                                         minutes = 30) <= dataToClean.Timestamp)&\\\n",
    "                                      (dataToClean.Timestamp <= datetime.timedelta(hour = 16,\n",
    "                                                                                   minutes = 0))].reset_index(drop=True)\n",
    "        \n",
    "        # if the cleaning procedure in question is p2.\n",
    "        elif cp == 'p2':\n",
    "            \n",
    "            # if the cleaning procedure in question is p1.\n",
    "            if dataType == 'trade':\n",
    "                \n",
    "                dataToClean = dataToClean[dataToClean.price != 0].reset_index(drop=True)\n",
    "                \n",
    "            elif dataType == 'quote':\n",
    "                \n",
    "                dataToClean = dataToClean[(dataToClean.bid != 0) | (dataToClean.ofr != 0)].reset_index(drop=True)\n",
    "                \n",
    "                \n",
    "        # if the cleaning procedure in question is p3.\n",
    "        elif cp == 'p3':\n",
    "            \n",
    "            if len(p3Exchanges) == 0:\n",
    "                \n",
    "                raise ValueError('No exchanges, to filter on, has been provided.\\nPlease provide a list with minimum one exchanges to filter on.')\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                # Ensuring correct format\n",
    "                p3Exchanges = [ele.lower().strip() for ele in p3Exchanges]\n",
    "                \n",
    "                # Filtering on exchanges ### Consider to use \"isin\" on the dataToClean.ex-Series instead, to improve execution time.\n",
    "                dataToClean = dataToClean[[True if ele.lower().strip() in p3Exchanges else False for ele in dataToClean.ex]].reset_index(drop=True)\n",
    "        \n",
    "        \n",
    "        # if the cleaning procedure in question is t1.\n",
    "        # T1. Delete entries with corrected trades. (Trades with a Correction Indicator, CORR != 0).\n",
    "        elif cp == 't1':\n",
    "\n",
    "            dataToClean = dataToClean[dataToClean.corr == 0].reset_index(drop=True)                \n",
    "                \n",
    "                \n",
    "        # if the cleaning procedure in question is t2.\n",
    "        # T2. Delete entries with abnormal Sale Condition. (Trades where COND has a letter code, except for “E” and “F”).\n",
    "        # FMNS: Most are COND = '@ XX' such as '@ TI', make sure this works properly. Assuming startswith('@') is cool\n",
    "        elif cp == 't2':\n",
    "            \n",
    "            dataToClean = dataToClean[(dataToClean.cond.startswith('@')) | (dataToClean.cond in ['E', 'F'])].reset_index(drop=True) \n",
    "            \n",
    "            \n",
    "        # if the cleaning procedure in question is t3.\n",
    "        # T3. If multiple transactions have the same time stamp: use the median price.\n",
    "        # FMNS: Let's consider if these median prices are cheating in relation to OHLC bars\n",
    "        elif cp == 't3':\n",
    "\n",
    "            # get unique timestamps\n",
    "            unique_ts_idx = np.unique(dataToClean.Timestamp, return_index=True)[1]\n",
    "            \n",
    "            # get median prices\n",
    "            median_price = dataToClean[['Timestamp', 'price']].groupby('Timestamp')['price'].median().values\n",
    "                \n",
    "            # keep only unique timestamps\n",
    "            dataToClean = dataToClean.iloc[unique_ts_idx, :].reset_index(drop=True)\n",
    "            \n",
    "            # fill the price variable with medians matched on unique_ts\n",
    "            dataToClean.loc[:,'price'] = median_price\n",
    "            \n",
    "            ### We could add a print to tell how many duplicated values there where? - Kris\n",
    "            \n",
    "            # note that all other variables now hold the first entry for each timestamp!\n",
    "\n",
    "            \n",
    "        # if the cleaning procedure in question is t3.        \n",
    "        # T4. Delete entries with prices that are above the ask plus the bid-ask spread. \n",
    "        # Similar for entries with prices below the bid minus the bid-ask spread.\n",
    "        # FMNS: We have no bid/ask/spread in trades-table. \n",
    "        #       To do this, we would probably need to cross-match timestamps between trades and quotes properly\n",
    "        elif cp == 't4':\n",
    "            \n",
    "            raise ValueError(f'Cleaning procedure {cp} is on hold')          \n",
    "\n",
    "            \n",
    "        # if the cleaning procedure in question is q1.\n",
    "        # Q1. When multiple quotes have the same timestamp, we replace all these with a single entry \n",
    "        # with the median bid and median ask price.   \n",
    "        # FMNS: Let's consider if these median prices are cheating in relation to OHLC bars\n",
    "        elif cp == 'q1':\n",
    "            \n",
    "            if datatype == 'quote':\n",
    "            \n",
    "                # get unique timestamps\n",
    "                unique_ts_idx = np.unique(dataToClean.Timestamp, return_index=True)[1]\n",
    "\n",
    "                # get median prices\n",
    "                median_price = dataToClean[['Timestamp', 'bid', 'ofr']].groupby('Timestamp')['bid', 'ofr'].median().values\n",
    "\n",
    "                # keep only unique timestamps\n",
    "                dataToClean = dataToClean.iloc[unique_ts_idx, :].reset_index(drop=True)\n",
    "\n",
    "                # fill the price variable with medians matched on unique_ts\n",
    "                dataToClean.loc[:,['bid','ofr']] = median_price\n",
    "\n",
    "                # note that all other variables now hold the first entry for each timestamp!\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                raise ValueError('The datatype has to be quote, in order to apply this cleaning procedure.\\nPlease revisit your request.')\n",
    "            \n",
    "\n",
    "        # if the cleaning procedure in question is q2.\n",
    "        # Q2. Delete entries for which the spread is negative.\n",
    "        elif cp == 'q2':\n",
    "            \n",
    "            if datatype == 'quote':\n",
    "                \n",
    "                dataToClean = dataToClean[dataToClean.ofr - dataToClean.bid >= 0].reset_index(drop=True)     \n",
    "            \n",
    "            else:\n",
    "                raise ValueError('The datatype has to be quote, in order to apply this cleaning procedure.\\nPlease revisit your request.')\n",
    "\n",
    "        # if the cleaning procedure in question is q3.\n",
    "        # Q3. Delete entries for which the spread is more that 50 times the median spread on that day.\n",
    "        elif cp == 'q3':\n",
    "            \n",
    "            if datatype == 'quote':\n",
    "                \n",
    "                # get all spreads across days, groupby Date and take daily median spreads\n",
    "                all_spreads = dataToClean[['Date', 'bid', 'ofr']]\n",
    "                all_spreads['spread'] =  dataToClean.ofr - dataToClean.bid\n",
    "                all_spreads.drop(['bid','ofr'], axis=1, inplace=True)\n",
    "\n",
    "                median_spreads = all_spreads.groupby('Date').median().values     \n",
    "\n",
    "\n",
    "                total_keep_idx = []\n",
    "                # for each unique day ...\n",
    "                for day in np.unique(dataToClean.Date):\n",
    "\n",
    "                    # for every spread within this day, check if it's below 50*median \n",
    "                    # (below_50median is a boolean with all existing index)\n",
    "                    below_50median = (all_spreads[all_spreads.Date == day].spread <= 50*median_spreads[median_spreads.index == day].values[0][0])\n",
    "\n",
    "                    # get the indices where below_50median == True (meaning individual spread is within 50*median)\n",
    "                    below_50median[below_50median].index\n",
    "\n",
    "                    total_keep_idx.append(below_50median[below_50median].index)\n",
    "\n",
    "\n",
    "                # after going through all days, flatten the list\n",
    "                total_keep_idx = [ele for intraday_idx in total_keep_idx for ele in intraday_idx]\n",
    "\n",
    "                # keep all entries that passed the filter\n",
    "                dataToClean = dataToClean.iloc[total_keep_idx, :]\n",
    "            \n",
    "            else:\n",
    "\n",
    "                raise ValueError('The datatype has to be quote, in order to apply this cleaning procedure.\\nPlease revisit your request.')\n",
    "        \n",
    "        # if the cleaning procedure in question is q4.\n",
    "        # Q4. Delete entries for which the mid-quote deviated by more than 5 median absolute deviations from \n",
    "        # a centered median (excluding the observation under consideration) of 50 observations.        \n",
    "        elif cp == 'q4':\n",
    "            \n",
    "            raise ValueError(f'Cleaning procedure {cp} is on hold')             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading in data, LOBSTER as well as TAQ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TAQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.git', '.gitignore', '.ipynb_checkpoints', 'CrunchTAQ.ipynb', 'hello.py', 'README.md', 'Speciale to-do.docx', 'Speciale to-do.txt']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir())\n",
    "path = 'a:/taqhdf5'\n",
    "allFiles = os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8502,\n",
       " ['taq_19930315.h5',\n",
       "  'taq_19930104.h5',\n",
       "  'taq_19930317.h5',\n",
       "  'taq_19930105.h5',\n",
       "  'taq_19930316.h5'],\n",
       " ['taqtrade_20200528.h5',\n",
       "  'taqtrade_20200529.h5',\n",
       "  'taqquote_20200507.h5',\n",
       "  'taqquote_20200508.h5',\n",
       "  'taqquote_20200511.h5'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#allFiles\n",
    "len(allFiles), allFiles[:5], allFiles[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['taqtrade_20200521.h5',\n",
       " 'taqtrade_20200522.h5',\n",
       " 'taqtrade_20200526.h5',\n",
       " 'taqtrade_20200527.h5',\n",
       " 'taqquote_20200506.h5',\n",
       " 'taqtrade_20200528.h5',\n",
       " 'taqtrade_20200529.h5',\n",
       " 'taqquote_20200507.h5',\n",
       " 'taqquote_20200508.h5',\n",
       " 'taqquote_20200511.h5']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allFiles[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Date range #####\n",
      "\n",
      "Date, Min: 20200401\n",
      "Date, Max: 20200401\n",
      "\n",
      "##### Data Extraction begins #####\n",
      "\n",
      "Both trade and quote data is being extracted..\n",
      "\n",
      "### Trade Data ###\n",
      "\n",
      "The raw H5 trade file contains:  ['TradeIndex', 'Trades'] \n",
      "\n",
      "Ticker Information:  (b'GOOG            ', 26900500, 71427) \n",
      "\n",
      "Sneak peak of the data\n",
      "\n",
      "            utcsec ex  cond  volume    price TradeStopStockIndicator corr  \\\n",
      "0  14400048517953  P  @ TI      67  1139.44                           00   \n",
      "1  14422296771981  P  @ TI      20  1138.55                           00   \n",
      "2  14429472894282  Q  @FTI       1  1138.54                           00   \n",
      "3  14506997225243  P  @ TI      31  1143.65                           00   \n",
      "4  14516526073882  P  @ TI       1  1143.59                           00   \n",
      "\n",
      "   TradeSequenceNumber TradeID SourceOfTrade TradeReportingFacility  \\\n",
      "0                 1507       1             N                          \n",
      "1                 1552       2             N                          \n",
      "2                 1554       1             N                          \n",
      "3                 1581       3             N                          \n",
      "4                 1587       4             N                          \n",
      "\n",
      "   ParticipantTime  TRFTime TTE      Date               Timestamp TSRemainder  \\\n",
      "0   14400048141056       99   0  20200401 2020-04-01 04:00:48.517         953   \n",
      "1   14422296394240       99   0  20200401 2020-04-01 04:05:18.771         981   \n",
      "2   14429472872353       99   1  20200401 2020-04-01 04:08:21.894         282   \n",
      "3   14506996848640       99   0  20200401 2020-04-01 04:18:23.225         243   \n",
      "4   14516525699840       99   0  20200401 2020-04-01 04:10:42.073         882   \n",
      "\n",
      "   Hour  Minute Ticker  \n",
      "0     4       0   GOOG  \n",
      "1     4       5   GOOG  \n",
      "2     4       8   GOOG  \n",
      "3     4      18   GOOG  \n",
      "4     4      10   GOOG  \n",
      "### Quote Data ###\n",
      "\n",
      "The raw H5 quote file contains:  ['QuoteIndex', 'Quotes'] \n",
      "\n",
      "Ticker Information:  (b'GOOG             ', 403024728, 600343) \n",
      "\n",
      "Sneak peak of the data\n",
      "\n",
      "            utcsec ex      bid  bidsize      ofr  ofrsize mode      Date  \\\n",
      "0  14400049177409  P   963.00        1     0.00        0    R  20200401   \n",
      "1  14400049177610  P   985.65        1     0.00        0    R  20200401   \n",
      "2  14400049181518  P   999.00        1     0.00        0    R  20200401   \n",
      "3  14400049181691  P  1018.00        1     0.00        0    R  20200401   \n",
      "4  14400049274621  P  1018.00        1  1188.88        3    R  20200401   \n",
      "\n",
      "                Timestamp TSRemainder  Hour  Minute Ticker  \n",
      "0 2020-04-01 04:00:49.177         409     4       0   GOOG  \n",
      "1 2020-04-01 04:00:49.177         610     4       0   GOOG  \n",
      "2 2020-04-01 04:00:49.181         518     4       0   GOOG  \n",
      "3 2020-04-01 04:00:49.181         691     4       0   GOOG  \n",
      "4 2020-04-01 04:00:49.274         621     4       0   GOOG  \n",
      "The extraction time was 138.532 seconds.\n"
     ]
    }
   ],
   "source": [
    "# Measuring the exraction time\n",
    "start = time.time()\n",
    "\n",
    "# Provide a list of dates of interest (format: yyyymmdd)\n",
    "dates = np.array(['20200401']).astype(int)#,'20200402'\n",
    "\n",
    "# Provide a list of tickers of interest\n",
    "tickers = ['GOOG']#'MSFT'\n",
    "\n",
    "# Do we need data on trades, quotes or both?\n",
    "dataNeeded = 'both' # 'trades', 'quotes' or 'both'\n",
    "\n",
    "# Extracting just the dates of each file\n",
    "allDates = np.array([re.split(\"[._]\",ele)[1] if (\".\" in ele ) & (\"_\" in ele) else 0 for ele in allFiles]).astype(int)\n",
    "\n",
    "minDate = np.min(dates)\n",
    "maxDate = np.max(dates)\n",
    "\n",
    "if verbose:\n",
    "    print('##### Date range #####\\n\\nDate, Min: %i\\nDate, Max: %i\\n'%(minDate,maxDate))\n",
    "\n",
    "# Locating what files we need.\n",
    "index = np.where((minDate <= allDates) & (allDates <= maxDate))\n",
    "\n",
    "relevantFiles = np.array(allFiles)[index[0]]\n",
    "\n",
    "# Separating the files into trade and quote files.\n",
    "trade = [ele for ele in relevantFiles if 'trade' in ele]\n",
    "quote = [ele for ele in relevantFiles if 'quote' in ele]\n",
    "\n",
    "if verbose:\n",
    "    print('##### Data Extraction begins #####\\n')\n",
    "    \n",
    "    if dataNeeded.lower() == 'both':\n",
    "        print('Both trade and quote data is being extracted..\\n')\n",
    "    else:\n",
    "        print('%s data is being extracted..\\n' % dataNeeded[0:5])\n",
    "        \n",
    "if (dataNeeded == 'both') | (dataNeeded == 'trades'):\n",
    "           \n",
    "# Lets start out by extracting the trade data\n",
    "\n",
    "    for i,file in enumerate(trade):\n",
    "\n",
    "        if (verbose) & (i == 0):\n",
    "            print('### Trade Data ###\\n')\n",
    "\n",
    "        # Reading one file at a time\n",
    "        raw_data = h5py.File(path+'/'+file,'r')\n",
    "\n",
    "        # Store the trade indecies\n",
    "        TI = raw_data['TradeIndex']\n",
    "\n",
    "        if (verbose) & (i==0):\n",
    "            print('The raw H5 trade file contains: ',list(raw_data.keys()),'\\n')\n",
    "\n",
    "        # Extracting just the tickers\n",
    "        TIC = np.array([ele[0].astype(str).strip() for ele in TI])\n",
    "\n",
    "        # Lets get data on each ticker for the file processed at the moment\n",
    "        for j,ticker in enumerate(tickers):\n",
    "\n",
    "            # Getting the specific ticker information\n",
    "            tickerInfo = TI[TIC==ticker][0]\n",
    "\n",
    "            if (verbose) & (i == 0):\n",
    "                    print('Ticker Information: ',tickerInfo,'\\n')\n",
    "\n",
    "            # Raw data\n",
    "            tempData = raw_data['Trades'][np.arange(tickerInfo[1],tickerInfo[1]+tickerInfo[2])]\n",
    "\n",
    "            # For first file and first ticker.\n",
    "            if (i == 0) & (j == 0):    \n",
    "\n",
    "                tradeData = pd.DataFrame(tempData, columns= tempData.dtype.names)\n",
    "\n",
    "                tradeData.loc[:,'ex'] = strList(tradeData.ex)\n",
    "                tradeData.loc[:,'cond'] = strList(tradeData.cond)\n",
    "                tradeData.loc[:,'TradeStopStockIndicator'] = strList(tradeData.TradeStopStockIndicator)\n",
    "                tradeData.loc[:,'corr'] = strList(tradeData['corr'])\n",
    "                tradeData.loc[:,'TradeID'] = strList(tradeData.TradeID)\n",
    "                tradeData.loc[:,'TTE'] = strList(tradeData.TTE)\n",
    "                tradeData.loc[:,'TradeReportingFacility'] = strList(tradeData.TradeReportingFacility)\n",
    "                tradeData.loc[:,'SourceOfTrade'] = strList(tradeData.SourceOfTrade)\n",
    "\n",
    "                # Adding the date of the file to the dataframe.\n",
    "                tradeData['Date'] = re.split('[._]',file)[1]\n",
    "\n",
    "                # Adding a more readable timestamp - TEST IT\n",
    "                tradeData['Timestamp'] = pd.to_datetime(formatDate(re.split('[._]',file)[1],tradeData.utcsec))\n",
    "                tradeData['TSRemainder'] = list(map(lambda x: str(x)[11:], tradeData.utcsec))\n",
    "                tradeData['Hour'] = tradeData.Timestamp.dt.hour\n",
    "                tradeData['Minute'] = tradeData.Timestamp.dt.minute\n",
    "                # Adding the ticker\n",
    "                tradeData['Ticker'] = ticker\n",
    "\n",
    "                if (verbose) & (i==0) & (j==0):\n",
    "                    print('Sneak peak of the data\\n\\n',tradeData.head())\n",
    "\n",
    "            else:\n",
    "\n",
    "                # Storing the data on the following tickers in a temporary variable.\n",
    "\n",
    "                temp = pd.DataFrame(tempData, columns= tempData.dtype.names)\n",
    "\n",
    "                temp.loc[:,'ex'] = strList(temp.ex)\n",
    "                temp.loc[:,'cond'] = strList(temp.cond)\n",
    "                temp.loc[:,'TradeStopStockIndicator'] = strList(temp.TradeStopStockIndicator)\n",
    "                temp.loc[:,'corr'] = strList(temp['corr'])\n",
    "                temp.loc[:,'TradeID'] = strList(temp.TradeID)\n",
    "                temp.loc[:,'TTE'] = strList(temp.TTE)\n",
    "                temp.loc[:,'TradeReportingFacility'] = strList(temp.TradeReportingFacility)\n",
    "                temp.loc[:,'SourceOfTrade'] = strList(temp.SourceOfTrade)\n",
    "\n",
    "                # Adding the date of the file to the dataframe.\n",
    "                temp['Date'] = re.split('[._]',file)[1]\n",
    "\n",
    "                # Adding a more readable timestamp - TEST IT\n",
    "                temp['Timestamp'] = pd.to_datetime(formatDate(re.split('[._]',file)[1],temp.utcsec))\n",
    "                temp['TSRemainder'] = list(map(lambda x: str(x)[11:], temp.utcsec))\n",
    "                temp['Hour'] = temp.Timestamp.dt.hour\n",
    "                temp['Minute'] = temp.Timestamp.dt.minute\n",
    "\n",
    "                # Adding the ticker\n",
    "                temp['Ticker'] = ticker\n",
    "\n",
    "                # Adding the new data \n",
    "                tradeData = pd.concat([tradeData,temp])\n",
    "\n",
    "if (dataNeeded == 'both') | (dataNeeded == 'quotes'):\n",
    "    \n",
    "    # Now to the quote data\n",
    "    for i,file in enumerate(quote):\n",
    "\n",
    "        if (verbose) & (i == 0):\n",
    "            print('### Quote Data ###\\n')\n",
    "\n",
    "        # Reading one file at a time\n",
    "        raw_data = h5py.File(path+'/'+file,'r')\n",
    "\n",
    "        # Store the trade indecies\n",
    "        QI = raw_data['QuoteIndex']\n",
    "\n",
    "        if (verbose) & (i==0):\n",
    "            print('The raw H5 quote file contains: ',list(raw_data.keys()),'\\n')\n",
    "\n",
    "        # Extracting just the tickers\n",
    "        QIC = np.array([ele[0].astype(str).strip() for ele in QI])\n",
    "\n",
    "        # Lets get data on each ticker for the file processed at the moment\n",
    "        for j,ticker in enumerate(tickers):\n",
    "\n",
    "            # Getting the specific ticker information\n",
    "            tickerInfo = QI[QIC==ticker][0]\n",
    "\n",
    "            if (verbose) & (i == 0):\n",
    "                    print('Ticker Information: ',tickerInfo,'\\n')\n",
    "\n",
    "            # Raw data\n",
    "            tempData = raw_data['Quotes'][np.arange(tickerInfo[1],tickerInfo[1]+tickerInfo[2])]\n",
    "\n",
    "            # For first file and first ticker.\n",
    "            if (i == 0) & (j == 0):    \n",
    "\n",
    "                quoteData = pd.DataFrame(tempData, columns= tempData.dtype.names)\n",
    "                # We remove all unnecessary variables\n",
    "                unnecessaryVariables = ['NationalBBOInd',\n",
    "                                        'FinraBBOInd',\n",
    "                                        'FinraQuoteIndicator',\n",
    "                                        'SequenceNumber',\n",
    "                                        'FinraAdfMpidIndicator',\n",
    "                                        'QuoteCancelCorrection',\n",
    "                                        'SourceQuote',\n",
    "                                        'RPI',\n",
    "                                        'ShortSaleRestrictionIndicator',\n",
    "                                        'LuldBBOIndicator',\n",
    "                                        'SIPGeneratedMessageIdent',\n",
    "                                        'NationalBBOLuldIndicator',\n",
    "                                        'ParticipantTimestamp',\n",
    "                                        'FinraTimestamp',\n",
    "                                        'FinraQuoteIndicator',\n",
    "                                        'SecurityStatusIndicator']\n",
    "                \n",
    "                quoteData = quoteData.drop(columns=unnecessaryVariables)\n",
    "\n",
    "                quoteData.loc[:,'ex'] = strList(quoteData.ex)\n",
    "                quoteData.loc[:,'mode'] = strList(quoteData['mode'])\n",
    "                \n",
    "                # Adding the date of the file to the dataframe.\n",
    "                quoteData['Date'] = re.split('[._]',file)[1]\n",
    "\n",
    "                # Adding a more readable timestamp - TEST IT\n",
    "                quoteData['Timestamp'] = pd.to_datetime(formatDate(re.split('[._]',file)[1],quoteData.utcsec))\n",
    "                quoteData['TSRemainder'] = list(map(lambda x: str(x)[11:], quoteData.utcsec))\n",
    "                quoteData['Hour'] = quoteData.Timestamp.dt.hour\n",
    "                quoteData['Minute'] = quoteData.Timestamp.dt.minute\n",
    "                # Adding the ticker\n",
    "                quoteData['Ticker'] = ticker\n",
    "\n",
    "                if (verbose) & (i==0) & (j==0):\n",
    "                    print('Sneak peak of the data\\n\\n',quoteData.head())\n",
    "\n",
    "            else:\n",
    "\n",
    "                # Storing the data on the following tickers in a temporary variable.\n",
    "\n",
    "                temp = pd.DataFrame(tempData, columns= tempData.dtype.names)\n",
    "                # Removing all unnecessary variables\n",
    "                temp = temp.drop(columns=unnecessaryVariables)\n",
    "                \n",
    "                temp.loc[:,'ex'] = strList(temp.ex)\n",
    "                temp.loc[:,'mode'] = strList(temp['mode'])\n",
    "\n",
    "                # Adding the date of the file to the dataframe.\n",
    "                temp['Date'] = re.split('[._]',file)[1]\n",
    "\n",
    "                # Adding a more readable timestamp - TEST IT\n",
    "                temp['Timestamp'] = pd.to_datetime(formatDate(re.split('[._]',file)[1],temp.utcsec))\n",
    "                temp['TSRemainder'] = list(map(lambda x: str(x)[11:], temp.utcsec))\n",
    "                temp['Hour'] = temp.Timestamp.dt.hour\n",
    "                temp['Minute'] = temp.Timestamp.dt.minute\n",
    "\n",
    "                # Adding the ticker\n",
    "                temp['Ticker'] = ticker\n",
    "\n",
    "                # Adding the new data \n",
    "                quoteData = pd.concat([quoteData,temp])\n",
    "                    \n",
    "end = time.time()\n",
    "\n",
    "if verbose:\n",
    "    print('The extraction time was %.3f seconds.' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utcsec</th>\n",
       "      <th>ex</th>\n",
       "      <th>bid</th>\n",
       "      <th>bidsize</th>\n",
       "      <th>ofr</th>\n",
       "      <th>ofrsize</th>\n",
       "      <th>mode</th>\n",
       "      <th>Date</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>TSRemainder</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Minute</th>\n",
       "      <th>Ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14400049177409</td>\n",
       "      <td>P</td>\n",
       "      <td>963.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>R</td>\n",
       "      <td>20200401</td>\n",
       "      <td>2020-04-01 04:00:49.177</td>\n",
       "      <td>409</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>GOOG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14400049177610</td>\n",
       "      <td>P</td>\n",
       "      <td>985.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>R</td>\n",
       "      <td>20200401</td>\n",
       "      <td>2020-04-01 04:00:49.177</td>\n",
       "      <td>610</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>GOOG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14400049181518</td>\n",
       "      <td>P</td>\n",
       "      <td>999.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>R</td>\n",
       "      <td>20200401</td>\n",
       "      <td>2020-04-01 04:00:49.181</td>\n",
       "      <td>518</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>GOOG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14400049181691</td>\n",
       "      <td>P</td>\n",
       "      <td>1018.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>R</td>\n",
       "      <td>20200401</td>\n",
       "      <td>2020-04-01 04:00:49.181</td>\n",
       "      <td>691</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>GOOG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14400049274621</td>\n",
       "      <td>P</td>\n",
       "      <td>1018.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1188.88</td>\n",
       "      <td>3</td>\n",
       "      <td>R</td>\n",
       "      <td>20200401</td>\n",
       "      <td>2020-04-01 04:00:49.274</td>\n",
       "      <td>621</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>GOOG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           utcsec ex      bid  bidsize      ofr  ofrsize mode      Date  \\\n",
       "0  14400049177409  P   963.00        1     0.00        0    R  20200401   \n",
       "1  14400049177610  P   985.65        1     0.00        0    R  20200401   \n",
       "2  14400049181518  P   999.00        1     0.00        0    R  20200401   \n",
       "3  14400049181691  P  1018.00        1     0.00        0    R  20200401   \n",
       "4  14400049274621  P  1018.00        1  1188.88        3    R  20200401   \n",
       "\n",
       "                Timestamp TSRemainder  Hour  Minute Ticker  \n",
       "0 2020-04-01 04:00:49.177         409     4       0   GOOG  \n",
       "1 2020-04-01 04:00:49.177         610     4       0   GOOG  \n",
       "2 2020-04-01 04:00:49.181         518     4       0   GOOG  \n",
       "3 2020-04-01 04:00:49.181         691     4       0   GOOG  \n",
       "4 2020-04-01 04:00:49.274         621     4       0   GOOG  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quoteData.head()\n",
    "#tradeData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utcsec</th>\n",
       "      <th>ex</th>\n",
       "      <th>cond</th>\n",
       "      <th>volume</th>\n",
       "      <th>price</th>\n",
       "      <th>TradeStopStockIndicator</th>\n",
       "      <th>corr</th>\n",
       "      <th>TradeSequenceNumber</th>\n",
       "      <th>TradeID</th>\n",
       "      <th>SourceOfTrade</th>\n",
       "      <th>TradeReportingFacility</th>\n",
       "      <th>ParticipantTime</th>\n",
       "      <th>TRFTime</th>\n",
       "      <th>TTE</th>\n",
       "      <th>Date</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>TSRemainder</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Minute</th>\n",
       "      <th>Ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14400048517953</td>\n",
       "      <td>P</td>\n",
       "      <td>@ TI</td>\n",
       "      <td>67</td>\n",
       "      <td>1139.44</td>\n",
       "      <td></td>\n",
       "      <td>00</td>\n",
       "      <td>1507</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>14400048141056</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>20200401</td>\n",
       "      <td>2020-04-01 04:00:48.517</td>\n",
       "      <td>953</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>GOOG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14422296771981</td>\n",
       "      <td>P</td>\n",
       "      <td>@ TI</td>\n",
       "      <td>20</td>\n",
       "      <td>1138.55</td>\n",
       "      <td></td>\n",
       "      <td>00</td>\n",
       "      <td>1552</td>\n",
       "      <td>2</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>14422296394240</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>20200401</td>\n",
       "      <td>2020-04-01 04:05:18.771</td>\n",
       "      <td>981</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>GOOG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14429472894282</td>\n",
       "      <td>Q</td>\n",
       "      <td>@FTI</td>\n",
       "      <td>1</td>\n",
       "      <td>1138.54</td>\n",
       "      <td></td>\n",
       "      <td>00</td>\n",
       "      <td>1554</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>14429472872353</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>20200401</td>\n",
       "      <td>2020-04-01 04:08:21.894</td>\n",
       "      <td>282</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>GOOG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14506997225243</td>\n",
       "      <td>P</td>\n",
       "      <td>@ TI</td>\n",
       "      <td>31</td>\n",
       "      <td>1143.65</td>\n",
       "      <td></td>\n",
       "      <td>00</td>\n",
       "      <td>1581</td>\n",
       "      <td>3</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>14506996848640</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>20200401</td>\n",
       "      <td>2020-04-01 04:18:23.225</td>\n",
       "      <td>243</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>GOOG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14516526073882</td>\n",
       "      <td>P</td>\n",
       "      <td>@ TI</td>\n",
       "      <td>1</td>\n",
       "      <td>1143.59</td>\n",
       "      <td></td>\n",
       "      <td>00</td>\n",
       "      <td>1587</td>\n",
       "      <td>4</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>14516525699840</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>20200401</td>\n",
       "      <td>2020-04-01 04:10:42.073</td>\n",
       "      <td>882</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>GOOG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           utcsec ex  cond  volume    price TradeStopStockIndicator corr  \\\n",
       "0  14400048517953  P  @ TI      67  1139.44                           00   \n",
       "1  14422296771981  P  @ TI      20  1138.55                           00   \n",
       "2  14429472894282  Q  @FTI       1  1138.54                           00   \n",
       "3  14506997225243  P  @ TI      31  1143.65                           00   \n",
       "4  14516526073882  P  @ TI       1  1143.59                           00   \n",
       "\n",
       "   TradeSequenceNumber TradeID SourceOfTrade TradeReportingFacility  \\\n",
       "0                 1507       1             N                          \n",
       "1                 1552       2             N                          \n",
       "2                 1554       1             N                          \n",
       "3                 1581       3             N                          \n",
       "4                 1587       4             N                          \n",
       "\n",
       "   ParticipantTime  TRFTime TTE      Date               Timestamp TSRemainder  \\\n",
       "0   14400048141056       99   0  20200401 2020-04-01 04:00:48.517         953   \n",
       "1   14422296394240       99   0  20200401 2020-04-01 04:05:18.771         981   \n",
       "2   14429472872353       99   1  20200401 2020-04-01 04:08:21.894         282   \n",
       "3   14506996848640       99   0  20200401 2020-04-01 04:18:23.225         243   \n",
       "4   14516525699840       99   0  20200401 2020-04-01 04:10:42.073         882   \n",
       "\n",
       "   Hour  Minute Ticker  \n",
       "0     4       0   GOOG  \n",
       "1     4       5   GOOG  \n",
       "2     4       8   GOOG  \n",
       "3     4      18   GOOG  \n",
       "4     4      10   GOOG  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tradeData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['utcsec', 'ex', 'bid', 'bidsize', 'ofr', 'ofrsize', 'mode', 'Date',\n",
       "       'Timestamp', 'TSRemainder', 'Hour', 'Minute', 'Ticker'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quoteData.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utcsec</th>\n",
       "      <th>ex</th>\n",
       "      <th>bid</th>\n",
       "      <th>bidsize</th>\n",
       "      <th>ofr</th>\n",
       "      <th>ofrsize</th>\n",
       "      <th>mode</th>\n",
       "      <th>Date</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>TSRemainder</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Minute</th>\n",
       "      <th>Ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14400049177409</td>\n",
       "      <td>P</td>\n",
       "      <td>963.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>R</td>\n",
       "      <td>20200401</td>\n",
       "      <td>2020-04-01 04:00:49.177</td>\n",
       "      <td>409</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>GOOG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14400049177610</td>\n",
       "      <td>P</td>\n",
       "      <td>985.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>R</td>\n",
       "      <td>20200401</td>\n",
       "      <td>2020-04-01 04:00:49.177</td>\n",
       "      <td>610</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>GOOG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14400049181518</td>\n",
       "      <td>P</td>\n",
       "      <td>999.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>R</td>\n",
       "      <td>20200401</td>\n",
       "      <td>2020-04-01 04:00:49.181</td>\n",
       "      <td>518</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>GOOG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14400049181691</td>\n",
       "      <td>P</td>\n",
       "      <td>1018.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>R</td>\n",
       "      <td>20200401</td>\n",
       "      <td>2020-04-01 04:00:49.181</td>\n",
       "      <td>691</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>GOOG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14400049274621</td>\n",
       "      <td>P</td>\n",
       "      <td>1018.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1188.88</td>\n",
       "      <td>3</td>\n",
       "      <td>R</td>\n",
       "      <td>20200401</td>\n",
       "      <td>2020-04-01 04:00:49.274</td>\n",
       "      <td>621</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>GOOG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5607202</th>\n",
       "      <td>71990849475938</td>\n",
       "      <td>K</td>\n",
       "      <td>153.41</td>\n",
       "      <td>2</td>\n",
       "      <td>153.59</td>\n",
       "      <td>2</td>\n",
       "      <td>R</td>\n",
       "      <td>20200401</td>\n",
       "      <td>2020-04-01 20:13:59.475</td>\n",
       "      <td>938</td>\n",
       "      <td>20</td>\n",
       "      <td>13</td>\n",
       "      <td>MSFT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5607203</th>\n",
       "      <td>71993763255970</td>\n",
       "      <td>K</td>\n",
       "      <td>153.41</td>\n",
       "      <td>2</td>\n",
       "      <td>153.59</td>\n",
       "      <td>2</td>\n",
       "      <td>R</td>\n",
       "      <td>20200401</td>\n",
       "      <td>2020-04-01 20:12:36.255</td>\n",
       "      <td>970</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>MSFT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5607204</th>\n",
       "      <td>71996762822526</td>\n",
       "      <td>K</td>\n",
       "      <td>153.58</td>\n",
       "      <td>2</td>\n",
       "      <td>153.59</td>\n",
       "      <td>2</td>\n",
       "      <td>R</td>\n",
       "      <td>20200401</td>\n",
       "      <td>2020-04-01 20:12:38.822</td>\n",
       "      <td>526</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>MSFT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5607205</th>\n",
       "      <td>71998862697002</td>\n",
       "      <td>K</td>\n",
       "      <td>153.58</td>\n",
       "      <td>2</td>\n",
       "      <td>153.59</td>\n",
       "      <td>1</td>\n",
       "      <td>R</td>\n",
       "      <td>20200401</td>\n",
       "      <td>2020-04-01 20:14:20.697</td>\n",
       "      <td>002</td>\n",
       "      <td>20</td>\n",
       "      <td>14</td>\n",
       "      <td>MSFT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5607206</th>\n",
       "      <td>71999986468655</td>\n",
       "      <td>K</td>\n",
       "      <td>153.58</td>\n",
       "      <td>1</td>\n",
       "      <td>153.59</td>\n",
       "      <td>1</td>\n",
       "      <td>R</td>\n",
       "      <td>20200401</td>\n",
       "      <td>2020-04-01 20:16:25.468</td>\n",
       "      <td>655</td>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>MSFT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6207550 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 utcsec ex      bid  bidsize      ofr  ofrsize mode      Date  \\\n",
       "0        14400049177409  P   963.00        1     0.00        0    R  20200401   \n",
       "1        14400049177610  P   985.65        1     0.00        0    R  20200401   \n",
       "2        14400049181518  P   999.00        1     0.00        0    R  20200401   \n",
       "3        14400049181691  P  1018.00        1     0.00        0    R  20200401   \n",
       "4        14400049274621  P  1018.00        1  1188.88        3    R  20200401   \n",
       "...                 ... ..      ...      ...      ...      ...  ...       ...   \n",
       "5607202  71990849475938  K   153.41        2   153.59        2    R  20200401   \n",
       "5607203  71993763255970  K   153.41        2   153.59        2    R  20200401   \n",
       "5607204  71996762822526  K   153.58        2   153.59        2    R  20200401   \n",
       "5607205  71998862697002  K   153.58        2   153.59        1    R  20200401   \n",
       "5607206  71999986468655  K   153.58        1   153.59        1    R  20200401   \n",
       "\n",
       "                      Timestamp TSRemainder  Hour  Minute Ticker  \n",
       "0       2020-04-01 04:00:49.177         409     4       0   GOOG  \n",
       "1       2020-04-01 04:00:49.177         610     4       0   GOOG  \n",
       "2       2020-04-01 04:00:49.181         518     4       0   GOOG  \n",
       "3       2020-04-01 04:00:49.181         691     4       0   GOOG  \n",
       "4       2020-04-01 04:00:49.274         621     4       0   GOOG  \n",
       "...                         ...         ...   ...     ...    ...  \n",
       "5607202 2020-04-01 20:13:59.475         938    20      13   MSFT  \n",
       "5607203 2020-04-01 20:12:36.255         970    20      12   MSFT  \n",
       "5607204 2020-04-01 20:12:38.822         526    20      12   MSFT  \n",
       "5607205 2020-04-01 20:14:20.697         002    20      14   MSFT  \n",
       "5607206 2020-04-01 20:16:25.468         655    20      16   MSFT  \n",
       "\n",
       "[6207550 rows x 13 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quoteData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>utcsec</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th>Ticker</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">20200401</th>\n",
       "      <th>GOOG</th>\n",
       "      <td>71427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSFT</th>\n",
       "      <td>531829</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 utcsec\n",
       "Date     Ticker        \n",
       "20200401 GOOG     71427\n",
       "         MSFT    531829"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['Date','Ticker','utcsec']].groupby(['Date','Ticker']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['@ TI', '@FTI', '@FT ', '@ T ', '@  I', '@   ', '@  Q', '@F I',\n",
       "       '@O X', '@F  ', '@4 I', '@4  ', '@4ZI', '@ ZI', '@ Z ', '@4 W',\n",
       "       'N  I', '@7 V', 'C  I', '@  W', '@  M', '@6 X', '@ TW', 'N T ',\n",
       "       '@ TP'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tradeData.cond.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utcsec</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cond</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>@</th>\n",
       "      <td>6123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@  I</th>\n",
       "      <td>37366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@  M</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@  Q</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@  W</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@ T</th>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@ TI</th>\n",
       "      <td>1263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@ TP</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@ TW</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@ Z</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@ ZI</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@4</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@4 I</th>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@4 W</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@4ZI</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@6 X</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@7 V</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@F</th>\n",
       "      <td>2591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@F I</th>\n",
       "      <td>23409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@FT</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@FTI</th>\n",
       "      <td>413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@O X</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C  I</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N  I</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N T</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      utcsec\n",
       "cond        \n",
       "@       6123\n",
       "@  I   37366\n",
       "@  M       2\n",
       "@  Q       2\n",
       "@  W       1\n",
       "@ T       36\n",
       "@ TI    1263\n",
       "@ TP       2\n",
       "@ TW       1\n",
       "@ Z        1\n",
       "@ ZI      10\n",
       "@4         2\n",
       "@4 I     143\n",
       "@4 W      22\n",
       "@4ZI       7\n",
       "@6 X       1\n",
       "@7 V       7\n",
       "@F      2591\n",
       "@F I   23409\n",
       "@FT       18\n",
       "@FTI     413\n",
       "@O X       1\n",
       "C  I       3\n",
       "N  I       1\n",
       "N T        2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tradeData[['cond','utcsec']].groupby('cond').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utcsec</th>\n",
       "      <th>ex</th>\n",
       "      <th>bid</th>\n",
       "      <th>bidsize</th>\n",
       "      <th>ofr</th>\n",
       "      <th>ofrsize</th>\n",
       "      <th>mode</th>\n",
       "      <th>Date</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>TSRemainder</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Minute</th>\n",
       "      <th>Ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [utcsec, ex, bid, bidsize, ofr, ofrsize, mode, Date, Timestamp, TSRemainder, Hour, Minute, Ticker]\n",
       "Index: []"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tradeData[tradeData.duplicated(['utcsec'])]\n",
    "quoteData[quoteData.duplicated(['utcsec'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(quoteData.utcsec.loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "hej = {ele:0 for ele in quoteData.utcsec}\n",
    "med1 = {ele:0 for ele in tradeData.utcsec}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([True if ele in hej.keys() else False for ele in tradeData.utcsec])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([True if ele in med1.keys() else False for ele in quoteData.utcsec])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
