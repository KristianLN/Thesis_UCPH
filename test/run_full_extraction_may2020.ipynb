{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "import h5py\n",
    "import copy\n",
    "import datetime\n",
    "import ta\n",
    "#import yfinance as yf\n",
    "# import tensorflow as tf\n",
    "# import tensorflow.compat.v2.feature_column as fc\n",
    "from IPython.display import clear_output\n",
    "import pyodbc\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, f1_score, log_loss\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.exceptions import ConvergenceWarning \n",
    "from sklearn import ensemble\n",
    "# ConvergenceWarning('ignore')\n",
    "# Do you wanna see?\n",
    "verbose = True\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from utils.data_extraction import load_data_final,load_data_and_save,strList\n",
    "from utils.data_cleaning import HFDataCleaning\n",
    "from utils.generate_features import candleCreateNP_vect_final,\\\n",
    "                                    generateFeatures_final\n",
    "from utils.preprocessing_features_and_labels import extract_labels,\\\n",
    "                                                    align_features_and_labels,\\\n",
    "                                                    pre_processing_initial,\\\n",
    "                                                    pre_processing_extended,\\\n",
    "                                                    pre_processing\n",
    "# from utils.models import make_input_fn\n",
    "# from utils.models import performanceTesting,scoreFunction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stockInfo = pd.read_csv('../utils/stockInfo.csv',header=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th colspan=\"3\" halign=\"left\">2020-07-05</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>sector</th>\n",
       "      <th>exchange</th>\n",
       "      <th>marketCap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>7671</td>\n",
       "      <td>TCCO</td>\n",
       "      <td>Technology</td>\n",
       "      <td>NMS</td>\n",
       "      <td>5.902776e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2323</td>\n",
       "      <td>EDRY</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>NMS</td>\n",
       "      <td>8.550177e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5016</td>\n",
       "      <td>MDRR</td>\n",
       "      <td>Real Estate</td>\n",
       "      <td>NMS</td>\n",
       "      <td>8.736265e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4262</td>\n",
       "      <td>ISIG</td>\n",
       "      <td>Communication Services</td>\n",
       "      <td>NMS</td>\n",
       "      <td>9.193270e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5644</td>\n",
       "      <td>NSYS</td>\n",
       "      <td>Technology</td>\n",
       "      <td>NMS</td>\n",
       "      <td>1.063012e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4181</td>\n",
       "      <td>INTC</td>\n",
       "      <td>Technology</td>\n",
       "      <td>NMS</td>\n",
       "      <td>2.503564e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2733</td>\n",
       "      <td>FB</td>\n",
       "      <td>Communication Services</td>\n",
       "      <td>NMS</td>\n",
       "      <td>6.650369e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3462</td>\n",
       "      <td>GOOG</td>\n",
       "      <td>Communication Services</td>\n",
       "      <td>NMS</td>\n",
       "      <td>1.001645e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5272</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>Technology</td>\n",
       "      <td>NMS</td>\n",
       "      <td>1.564160e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Technology</td>\n",
       "      <td>NMS</td>\n",
       "      <td>1.578173e+12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1295 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       date              2020-07-05                       \n",
       "     ticker                  sector exchange     marketCap\n",
       "7671   TCCO              Technology      NMS  5.902776e+06\n",
       "2323   EDRY             Industrials      NMS  8.550177e+06\n",
       "5016   MDRR             Real Estate      NMS  8.736265e+06\n",
       "4262   ISIG  Communication Services      NMS  9.193270e+06\n",
       "5644   NSYS              Technology      NMS  1.063012e+07\n",
       "...     ...                     ...      ...           ...\n",
       "4181   INTC              Technology      NMS  2.503564e+11\n",
       "2733     FB  Communication Services      NMS  6.650369e+11\n",
       "3462   GOOG  Communication Services      NMS  1.001645e+12\n",
       "5272   MSFT              Technology      NMS  1.564160e+12\n",
       "12     AAPL              Technology      NMS  1.578173e+12\n",
       "\n",
       "[1295 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stockInfo.dropna()[stockInfo.dropna()[('2020-07-05','exchange')]=='NMS'].sort_values(('2020-07-05','marketCap'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 8850 tickers contained in the file, and there is data on 5306 of them.\n"
     ]
    }
   ],
   "source": [
    "# How many are there contained in the file?\n",
    "print('There are',\n",
    "      stockInfo.shape[0],\n",
    "      'tickers contained in the file, and there is data on',\n",
    "      stockInfo.isnull().sum()[1:].min(),'of them.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sneak peak on the 10 largest companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th colspan=\"3\" halign=\"left\">2020-07-05</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>sector</th>\n",
       "      <th>exchange</th>\n",
       "      <th>marketCap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Technology</td>\n",
       "      <td>NMS</td>\n",
       "      <td>1.578173e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5272</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>Technology</td>\n",
       "      <td>NMS</td>\n",
       "      <td>1.564160e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3462</td>\n",
       "      <td>GOOG</td>\n",
       "      <td>Communication Services</td>\n",
       "      <td>NMS</td>\n",
       "      <td>1.001645e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2733</td>\n",
       "      <td>FB</td>\n",
       "      <td>Communication Services</td>\n",
       "      <td>NMS</td>\n",
       "      <td>6.650369e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>699</td>\n",
       "      <td>BABA</td>\n",
       "      <td>Consumer Cyclical</td>\n",
       "      <td>NYQ</td>\n",
       "      <td>5.936536e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8228</td>\n",
       "      <td>V</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>NYQ</td>\n",
       "      <td>4.298068e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4459</td>\n",
       "      <td>JNJ</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>NYQ</td>\n",
       "      <td>3.716463e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8583</td>\n",
       "      <td>WMT</td>\n",
       "      <td>Consumer Defensive</td>\n",
       "      <td>NYQ</td>\n",
       "      <td>3.375968e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4930</td>\n",
       "      <td>MA</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>NYQ</td>\n",
       "      <td>3.035511e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7950</td>\n",
       "      <td>TSM</td>\n",
       "      <td>Technology</td>\n",
       "      <td>NYQ</td>\n",
       "      <td>2.837483e+11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       date              2020-07-05                       \n",
       "     ticker                  sector exchange     marketCap\n",
       "12     AAPL              Technology      NMS  1.578173e+12\n",
       "5272   MSFT              Technology      NMS  1.564160e+12\n",
       "3462   GOOG  Communication Services      NMS  1.001645e+12\n",
       "2733     FB  Communication Services      NMS  6.650369e+11\n",
       "699    BABA       Consumer Cyclical      NYQ  5.936536e+11\n",
       "8228      V      Financial Services      NYQ  4.298068e+11\n",
       "4459    JNJ              Healthcare      NYQ  3.716463e+11\n",
       "8583    WMT      Consumer Defensive      NYQ  3.375968e+11\n",
       "4930     MA      Financial Services      NYQ  3.035511e+11\n",
       "7950    TSM              Technology      NYQ  2.837483e+11"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "stockInfo.sort_values(('2020-07-05','marketCap'),ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How is the tickers divided in sectors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exchange</th>\n",
       "      <th>marketCap</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sector</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Basic Materials</td>\n",
       "      <td>137</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Communication Services</td>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Consumer Cyclical</td>\n",
       "      <td>318</td>\n",
       "      <td>317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Consumer Defensive</td>\n",
       "      <td>130</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Energy</td>\n",
       "      <td>204</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Financial</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Financial Services</td>\n",
       "      <td>942</td>\n",
       "      <td>942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Healthcare</td>\n",
       "      <td>607</td>\n",
       "      <td>607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Industrials</td>\n",
       "      <td>404</td>\n",
       "      <td>404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Real Estate</td>\n",
       "      <td>175</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Technology</td>\n",
       "      <td>394</td>\n",
       "      <td>394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Utilities</td>\n",
       "      <td>62</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        exchange  marketCap\n",
       "sector                                     \n",
       "Basic Materials              137        137\n",
       "Communication Services       146        146\n",
       "Consumer Cyclical            318        317\n",
       "Consumer Defensive           130        130\n",
       "Energy                       204        204\n",
       "Financial                      3          3\n",
       "Financial Services           942        942\n",
       "Healthcare                   607        607\n",
       "Industrials                  404        404\n",
       "Real Estate                  175        174\n",
       "Technology                   394        394\n",
       "Utilities                     62         62"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stockInfo.loc[:,('2020-07-05')].groupby(['sector']).count()#rename(None,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets get the X largest companies in each sector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sectors = stockInfo.loc[:,('2020-07-05')].dropna(axis=0).sector.unique()\n",
    "\n",
    "X = 5\n",
    "\n",
    "topXsectors = pd.DataFrame(index = np.arange(X),columns = pd.MultiIndex.from_product([['Top {}'.format(X)],sectors]))\n",
    "\n",
    "t1 = pd.DataFrame({'tickers':stockInfo.loc[:,'date'].ticker.values})\n",
    "t1[stockInfo.loc[:,'2020-07-05'].columns] = stockInfo.loc[:,'2020-07-05']\n",
    "\n",
    "for i,sector in enumerate(sectors):\n",
    "    \n",
    "    tempSec = t1[t1.sector==sector].sort_values('marketCap',\n",
    "                                                      ascending=False).dropna(axis=0).values.T\n",
    "    \n",
    "    Y = len(tempSec[0][0:X]) \n",
    "\n",
    "    topXsectors.loc[0:(Y-1),('Top {}'.format(X),sector)] = tempSec[0][0:Y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"12\" halign=\"left\">Top 5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Healthcare</th>\n",
       "      <th>Basic Materials</th>\n",
       "      <th>Consumer Defensive</th>\n",
       "      <th>Industrials</th>\n",
       "      <th>Financial Services</th>\n",
       "      <th>Technology</th>\n",
       "      <th>Consumer Cyclical</th>\n",
       "      <th>Real Estate</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>Communication Services</th>\n",
       "      <th>Energy</th>\n",
       "      <th>Financial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>JNJ</td>\n",
       "      <td>BHP</td>\n",
       "      <td>WMT</td>\n",
       "      <td>UNP</td>\n",
       "      <td>V</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>BABA</td>\n",
       "      <td>AMT</td>\n",
       "      <td>D</td>\n",
       "      <td>GOOG</td>\n",
       "      <td>PTR</td>\n",
       "      <td>IIM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>NVS</td>\n",
       "      <td>LIN</td>\n",
       "      <td>KO</td>\n",
       "      <td>BA</td>\n",
       "      <td>MA</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>CCI</td>\n",
       "      <td>SO</td>\n",
       "      <td>FB</td>\n",
       "      <td>BP</td>\n",
       "      <td>ZTR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>PFE</td>\n",
       "      <td>ECL</td>\n",
       "      <td>PEP</td>\n",
       "      <td>LMT</td>\n",
       "      <td>PYPL</td>\n",
       "      <td>TSM</td>\n",
       "      <td>TM</td>\n",
       "      <td>PLD</td>\n",
       "      <td>AEP</td>\n",
       "      <td>T</td>\n",
       "      <td>SNP</td>\n",
       "      <td>OTTW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ABBV</td>\n",
       "      <td>APD</td>\n",
       "      <td>COST</td>\n",
       "      <td>UPS</td>\n",
       "      <td>BAC</td>\n",
       "      <td>INTC</td>\n",
       "      <td>NKE</td>\n",
       "      <td>PSA</td>\n",
       "      <td>EXC</td>\n",
       "      <td>DIS</td>\n",
       "      <td>ENB</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ABT</td>\n",
       "      <td>SHW</td>\n",
       "      <td>FMX</td>\n",
       "      <td>RTX</td>\n",
       "      <td>LFC</td>\n",
       "      <td>NVDA</td>\n",
       "      <td>MCD</td>\n",
       "      <td>CSGP</td>\n",
       "      <td>SRE</td>\n",
       "      <td>CHL</td>\n",
       "      <td>PBR</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Top 5                                                 \\\n",
       "  Healthcare Basic Materials Consumer Defensive Industrials   \n",
       "0        JNJ             BHP                WMT         UNP   \n",
       "1        NVS             LIN                 KO          BA   \n",
       "2        PFE             ECL                PEP         LMT   \n",
       "3       ABBV             APD               COST         UPS   \n",
       "4        ABT             SHW                FMX         RTX   \n",
       "\n",
       "                                                                         \\\n",
       "  Financial Services Technology Consumer Cyclical Real Estate Utilities   \n",
       "0                  V       AAPL              BABA         AMT         D   \n",
       "1                 MA       MSFT              TSLA         CCI        SO   \n",
       "2               PYPL        TSM                TM         PLD       AEP   \n",
       "3                BAC       INTC               NKE         PSA       EXC   \n",
       "4                LFC       NVDA               MCD        CSGP       SRE   \n",
       "\n",
       "                                           \n",
       "  Communication Services Energy Financial  \n",
       "0                   GOOG    PTR       IIM  \n",
       "1                     FB     BP       ZTR  \n",
       "2                      T    SNP      OTTW  \n",
       "3                    DIS    ENB       NaN  \n",
       "4                    CHL    PBR       NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topXsectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "topXsectors.columns = topXsectors.columns.droplevel(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Healthcare</th>\n",
       "      <th>Basic Materials</th>\n",
       "      <th>Consumer Defensive</th>\n",
       "      <th>Industrials</th>\n",
       "      <th>Financial Services</th>\n",
       "      <th>Technology</th>\n",
       "      <th>Consumer Cyclical</th>\n",
       "      <th>Real Estate</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>Communication Services</th>\n",
       "      <th>Energy</th>\n",
       "      <th>Financial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>JNJ</td>\n",
       "      <td>BHP</td>\n",
       "      <td>WMT</td>\n",
       "      <td>UNP</td>\n",
       "      <td>V</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>BABA</td>\n",
       "      <td>AMT</td>\n",
       "      <td>D</td>\n",
       "      <td>GOOG</td>\n",
       "      <td>PTR</td>\n",
       "      <td>IIM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>NVS</td>\n",
       "      <td>LIN</td>\n",
       "      <td>KO</td>\n",
       "      <td>BA</td>\n",
       "      <td>MA</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>CCI</td>\n",
       "      <td>SO</td>\n",
       "      <td>FB</td>\n",
       "      <td>BP</td>\n",
       "      <td>ZTR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>PFE</td>\n",
       "      <td>ECL</td>\n",
       "      <td>PEP</td>\n",
       "      <td>LMT</td>\n",
       "      <td>PYPL</td>\n",
       "      <td>TSM</td>\n",
       "      <td>TM</td>\n",
       "      <td>PLD</td>\n",
       "      <td>AEP</td>\n",
       "      <td>T</td>\n",
       "      <td>SNP</td>\n",
       "      <td>OTTW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ABBV</td>\n",
       "      <td>APD</td>\n",
       "      <td>COST</td>\n",
       "      <td>UPS</td>\n",
       "      <td>BAC</td>\n",
       "      <td>INTC</td>\n",
       "      <td>NKE</td>\n",
       "      <td>PSA</td>\n",
       "      <td>EXC</td>\n",
       "      <td>DIS</td>\n",
       "      <td>ENB</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ABT</td>\n",
       "      <td>SHW</td>\n",
       "      <td>FMX</td>\n",
       "      <td>RTX</td>\n",
       "      <td>LFC</td>\n",
       "      <td>NVDA</td>\n",
       "      <td>MCD</td>\n",
       "      <td>CSGP</td>\n",
       "      <td>SRE</td>\n",
       "      <td>CHL</td>\n",
       "      <td>PBR</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Healthcare Basic Materials Consumer Defensive Industrials  \\\n",
       "0        JNJ             BHP                WMT         UNP   \n",
       "1        NVS             LIN                 KO          BA   \n",
       "2        PFE             ECL                PEP         LMT   \n",
       "3       ABBV             APD               COST         UPS   \n",
       "4        ABT             SHW                FMX         RTX   \n",
       "\n",
       "  Financial Services Technology Consumer Cyclical Real Estate Utilities  \\\n",
       "0                  V       AAPL              BABA         AMT         D   \n",
       "1                 MA       MSFT              TSLA         CCI        SO   \n",
       "2               PYPL        TSM                TM         PLD       AEP   \n",
       "3                BAC       INTC               NKE         PSA       EXC   \n",
       "4                LFC       NVDA               MCD        CSGP       SRE   \n",
       "\n",
       "  Communication Services Energy Financial  \n",
       "0                   GOOG    PTR       IIM  \n",
       "1                     FB     BP       ZTR  \n",
       "2                      T    SNP      OTTW  \n",
       "3                    DIS    ENB       NaN  \n",
       "4                    CHL    PBR       NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topXsectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True, False])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topXsectors.columns!='Financial'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['JNJ', 'BHP', 'WMT', 'UNP', 'V', 'AAPL', 'BABA', 'AMT', 'D',\n",
       "       'GOOG', 'PTR', 'NVS', 'LIN', 'KO', 'BA', 'MA', 'MSFT', 'TSLA',\n",
       "       'CCI', 'SO', 'FB', 'BP', 'PFE', 'ECL', 'PEP', 'LMT', 'PYPL', 'TSM',\n",
       "       'TM', 'PLD', 'AEP', 'T', 'SNP', 'ABBV', 'APD', 'COST', 'UPS',\n",
       "       'BAC', 'INTC', 'NKE', 'PSA', 'EXC', 'DIS', 'ENB', 'ABT', 'SHW',\n",
       "       'FMX', 'RTX', 'LFC', 'NVDA', 'MCD', 'CSGP', 'SRE', 'CHL', 'PBR'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List for data extraction\n",
    "topXsectors.loc[:,topXsectors.columns != 'Financial'].values.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th colspan=\"3\" halign=\"left\">2020-07-05</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>sector</th>\n",
       "      <th>exchange</th>\n",
       "      <th>marketCap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>NYQ</td>\n",
       "      <td>2.738234e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>AA</td>\n",
       "      <td>Basic Materials</td>\n",
       "      <td>NYQ</td>\n",
       "      <td>2.039532e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>AAAU</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>AACG</td>\n",
       "      <td>Consumer Defensive</td>\n",
       "      <td>NGM</td>\n",
       "      <td>4.157730e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>AADR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    date          2020-07-05                       \n",
       "  ticker              sector exchange     marketCap\n",
       "0      A          Healthcare      NYQ  2.738234e+10\n",
       "1     AA     Basic Materials      NYQ  2.039532e+09\n",
       "2   AAAU                 NaN      NaN           NaN\n",
       "3   AACG  Consumer Defensive      NGM  4.157730e+07\n",
       "4   AADR                 NaN      NaN           NaN"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stockInfo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'IYZ' in stockInfo.loc[:,('date','ticker')].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Healthcare', 'Basic Materials', 'Consumer Defensive',\n",
       "       'Industrials', 'Financial Services', 'Technology',\n",
       "       'Consumer Cyclical', 'Real Estate', 'Utilities',\n",
       "       'Communication Services', 'Energy', 'Financial'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Healthcare</th>\n",
       "      <th>Basic Materials</th>\n",
       "      <th>Consumer Defensive</th>\n",
       "      <th>Industrials</th>\n",
       "      <th>Financial Services</th>\n",
       "      <th>Technology</th>\n",
       "      <th>Consumer Cyclical</th>\n",
       "      <th>Real Estate</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>Communication Services</th>\n",
       "      <th>Energy</th>\n",
       "      <th>Financial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>IYH</td>\n",
       "      <td>IYM</td>\n",
       "      <td>IYK</td>\n",
       "      <td>IYJ</td>\n",
       "      <td>IYG</td>\n",
       "      <td>IYW</td>\n",
       "      <td>IYC</td>\n",
       "      <td>IYR</td>\n",
       "      <td>IDU</td>\n",
       "      <td>IYZ</td>\n",
       "      <td>IYE</td>\n",
       "      <td>IYF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Healthcare Basic Materials Consumer Defensive Industrials  \\\n",
       "0        IYH             IYM                IYK         IYJ   \n",
       "\n",
       "  Financial Services Technology Consumer Cyclical Real Estate Utilities  \\\n",
       "0                IYG        IYW               IYC         IYR       IDU   \n",
       "\n",
       "  Communication Services Energy Financial  \n",
       "0                    IYZ    IYE       IYF  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## IShares Sector ETFS\n",
    "\n",
    "# iShares Dow Jones U.S. Basic Materials Index:     IYM\n",
    "# iShares Dow Jones U.S. Consumer Goods Index:      IYK\n",
    "# iShares Dow Jones U.S. Consumer Services Index:   IYC\n",
    "# iShares Dow Jones U.S. Energy Index:              IYE\n",
    "# iShares Dow Jones U.S. Financial Sector Index:    IYF\n",
    "# iShares Dow Jones U.S. Financial Services Index:  IYG\n",
    "# iShares Dow Jones U.S. Healthcare Index:          IYH\n",
    "# iShares Dow Jones U.S. Industrial Index:          IYJ\n",
    "# iShares Dow Jones U.S. Real Estate Index:         IYR\n",
    "# iShares Dow Jones U.S. Technology Index:          IYW\n",
    "# iShares Dow Jones U.S. Telecommunications Index:  IYZ\n",
    "# iShares Dow Jones Transportation Average Index:   IYT\n",
    "# iShares Dow Jones U.S. Utilities Index:           IDU\n",
    "# iShares Cohen & Steers Realty Majors Index:       ICF\n",
    "\n",
    "etfs = ['IYH','IYM','IYK','IYJ','IYG','IYW','IYC','IYR','IDU','IYZ','IYE','IYF']\n",
    "# {i:j for i,j in zip(sectors,etfs)}\n",
    "pd.DataFrame({i:j for i,j in zip(sectors,etfs)},index=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's extract some data now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tickers = ['JNJ', 'BHP', 'WMT', 'UNP', 'V', 'AAPL', 'BABA', 'AMT', 'D',\n",
    "               'GOOG', 'PTR', 'NVS', 'LIN', 'KO', 'BA', 'MA', 'MSFT', 'TSLA',\n",
    "               'CCI', 'SO', 'FB', 'BP', 'PFE', 'ECL', 'PEP', 'LMT', 'PYPL', 'TSM',\n",
    "               'TM', 'PLD', 'AEP', 'T', 'SNP', 'ABBV', 'APD', 'COST', 'UPS',\n",
    "               'BAC', 'INTC', 'NKE', 'PSA', 'EXC', 'DIS', 'ENB', 'ABT', 'SHW',\n",
    "               'FMX', 'RTX', 'LFC', 'NVDA', 'MCD', 'CSGP', 'SRE', 'CHL', 'PBR',\n",
    "              'IYH','IYM','IYK','IYJ','IYG','IYW','IYC','IYR','IDU','IYZ','IYE'\n",
    "              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 ['taqquote_20200501.h5', 'taqquote_20200504.h5', 'taqquote_20200505.h5', 'taqquote_20200506.h5', 'taqquote_20200507.h5'] ['taqquote_20200522.h5', 'taqquote_20200526.h5', 'taqquote_20200527.h5', 'taqquote_20200528.h5', 'taqquote_20200529.h5']\n",
      "['taqquote_20200515.h5', 'taqquote_20200518.h5', 'taqquote_20200519.h5', 'taqquote_20200520.h5', 'taqquote_20200521.h5', 'taqquote_20200522.h5', 'taqquote_20200526.h5', 'taqquote_20200527.h5', 'taqquote_20200528.h5', 'taqquote_20200529.h5']\n",
      "##### Date range #####\n",
      "\n",
      "Date, Min: 20200501\n",
      "Date, Max: 20200504\n",
      "\n",
      "\n",
      "1 Lap time: 0.001\n",
      "\n",
      "##### Data Extraction begins #####\n",
      "\n",
      "quote data is being extracted..\n",
      "\n",
      "\n",
      "2 Lap time: 0.001\n",
      "\n",
      "### Quote Data ###\n",
      "\n",
      "3 Lap time: 0.002\n",
      "4 Lap time: 0.003\n",
      "The raw H5 quote file contains:  ['QuoteIndex', 'Quotes'] \n",
      "\n",
      "5 Lap time: 0.737\n",
      "6 Lap time: 0.746\n",
      "7 Lap time: 59.099\n",
      "8 Lap time: 76.259\n",
      "9 Lap time: 91.182\n",
      "10 Lap time: 106.068\n",
      "11 Lap time: 106.449\n",
      "12 Lap time: 111.140\n",
      "3 Lap time: 345.773\n",
      "4 Lap time: 345.773\n",
      "5 Lap time: 346.587\n",
      "6 Lap time: 346.601\n",
      "7 Lap time: 402.477\n",
      "8 Lap time: 419.916\n",
      "9 Lap time: 435.088\n",
      "10 Lap time: 450.186\n",
      "11 Lap time: 450.564\n",
      "12 Lap time: 455.474\n",
      "The extraction time was 707.036 seconds.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'list' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-fa45fd361066>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     36\u001b[0m                           \u001b[0mextra_features_from_quotes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m                           \u001b[0mdata_sample\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m                           save_output)\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;31m# quoteData = load_data_final(dates,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\KU Thesis 2020\\Thesis_UCPH\\utils\\data_extraction.py\u001b[0m in \u001b[0;36mload_data_final\u001b[1;34m(dates, tickers, dataNeeded, path, verbose, extract_candles, aggHorizon, extra_features_from_quotes, data_sample, save_output)\u001b[0m\n\u001b[0;32m   1336\u001b[0m                                             \u001b[0msample\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_sample\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1337\u001b[0m                                             \u001b[0mnumpied\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1338\u001b[1;33m                                             return_extended=extra_features_from_quotes)\n\u001b[0m\u001b[0;32m   1339\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1340\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\KU Thesis 2020\\Thesis_UCPH\\utils\\generate_features.py\u001b[0m in \u001b[0;36mcandleCreateNP_vect_final\u001b[1;34m(data, step, verbose, fillHoles, sample, numpied, return_extended)\u001b[0m\n\u001b[0;32m    739\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    740\u001b[0m     \u001b[1;31m# setup time_bins to group each timestamp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 741\u001b[1;33m     \u001b[0mdelta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m60\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    742\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    743\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msample\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'full'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'list' and 'int'"
     ]
    }
   ],
   "source": [
    "# print(os.listdir())\n",
    "try:\n",
    "    path = 'a:/taqhdf5'  #'a:/taqhdf5'\n",
    "    os.listdir(path)\n",
    "except:\n",
    "    path = 'f:/taqhdf5'  #'a:/taqhdf5'\n",
    "    os.listdir(path)    \n",
    "# allFiles = os.listdir(path)\n",
    "# print(len(allFiles), allFiles[:5], allFiles[-5:])\n",
    "# print(allFiles[-10:])\n",
    "\n",
    "#dates = np.array(['2020040' + str(i) if i < 10 else '202004' + str(i) for i in np.arange(1,16)]).astype(int)\n",
    "dates = np.array(['20200501',\n",
    "                  '20200504',\n",
    "                  '20200505',\n",
    "                  '20200506',\n",
    "                  '20200507',\n",
    "                  '20200508',\n",
    "                  '20200511',\n",
    "                  '20200512',\n",
    "                  '20200513',\n",
    "                  '20200514',\n",
    "                  '20200515',\n",
    "                  '20200518',\n",
    "                  '20200519',\n",
    "                  '20200520',\n",
    "                  '20200521',\n",
    "                  '20200522',\n",
    "                  '20200526',\n",
    "                  '20200527',\n",
    "                  '20200528',\n",
    "                  '20200529']).astype(int)#,'20200401','20200402','20200403','20200406','20200407'\n",
    "\n",
    "# Provide a list of tickers of interest\n",
    "tickers = sorted(all_tickers) # ['GOOG']#'MSFT' ['GOOG', 'MSFT'] #\n",
    "\n",
    "# Do we need data on trades, quotes or both?\n",
    "dataNeeded = 'quotes' # 'trades', 'quotes' or 'both'\n",
    "\n",
    "extract_candles = True #False\n",
    "aggHorizon = [1/6, 1/2, 1] # in minutes\n",
    "extra_features_from_quotes = ['spread', 'bidsize', 'ofrsize']\n",
    "\n",
    "data_sample = 'full'\n",
    "save_output = True\n",
    "\n",
    "exchanges = ['q','t']\n",
    "\n",
    "# run load_data()\n",
    "candles = load_data_final(dates,\n",
    "                          tickers,\n",
    "                          dataNeeded,\n",
    "                          path,\n",
    "                          verbose,\n",
    "                          extract_candles,\n",
    "                          aggHorizon,\n",
    "                          extra_features_from_quotes,\n",
    "                          data_sample,\n",
    "                          exchanges,\n",
    "                          save_output)\n",
    "\n",
    "# quoteData = load_data_final(dates,\n",
    "#                           tickers,\n",
    "#                           dataNeeded,\n",
    "#                           path,\n",
    "#                           verbose,\n",
    "#                           extract_candles,\n",
    "#                           aggHorizon,\n",
    "#                           extra_features_from_quotes,\n",
    "#                           data_sample,\n",
    "#                           save_output)\n",
    "\n",
    "# if dataNeeded == 'trades':\n",
    "#     tradeData = load_data(dates, tickers, dataNeeded, path, verbose)\n",
    "# elif dataNeeded == 'quotes':\n",
    "#     quoteData = load_data(dates, tickers, dataNeeded, path, verbose)\n",
    "# elif dataNeeded == 'both':\n",
    "#     tradeData, quoteData = load_data(dates, tickers, dataNeeded, path, verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 ['taqquote_20200501.h5', 'taqquote_20200504.h5', 'taqquote_20200505.h5', 'taqquote_20200506.h5', 'taqquote_20200507.h5'] ['taqquote_20200522.h5', 'taqquote_20200526.h5', 'taqquote_20200527.h5', 'taqquote_20200528.h5', 'taqquote_20200529.h5']\n",
      "['taqquote_20200515.h5', 'taqquote_20200518.h5', 'taqquote_20200519.h5', 'taqquote_20200520.h5', 'taqquote_20200521.h5', 'taqquote_20200522.h5', 'taqquote_20200526.h5', 'taqquote_20200527.h5', 'taqquote_20200528.h5', 'taqquote_20200529.h5']\n",
      "##### Date range #####\n",
      "\n",
      "Date, Min: 20200501\n",
      "Date, Max: 20200529\n",
      "\n",
      "\n",
      "1 Lap time: 0.001\n",
      "\n",
      "##### Data Extraction begins #####\n",
      "\n",
      "quote data is being extracted..\n",
      "\n",
      "\n",
      "2 Lap time: 0.001\n",
      "\n",
      "### Quote Data ###\n",
      "\n",
      "3 Lap time: 0.081\n",
      "4 Lap time: 0.081\n",
      "The raw H5 quote file contains:  ['QuoteIndex', 'Quotes'] \n",
      "\n",
      "5 Lap time: 0.833\n",
      "6 Lap time: 0.842\n",
      "7 Lap time: 0.857\n",
      "8 Lap time: 76.403\n",
      "9 Lap time: 91.095\n",
      "10 Lap time: 105.892\n",
      "11 Lap time: 106.257\n",
      "12 Lap time: 110.702\n",
      "3 Lap time: 421.300\n",
      "4 Lap time: 421.300\n",
      "5 Lap time: 422.080\n",
      "6 Lap time: 422.090\n",
      "7 Lap time: 422.152\n",
      "8 Lap time: 506.470\n",
      "9 Lap time: 521.604\n",
      "10 Lap time: 536.763\n",
      "11 Lap time: 537.133\n",
      "12 Lap time: 541.777\n",
      "3 Lap time: 861.707\n",
      "4 Lap time: 861.707\n",
      "5 Lap time: 862.509\n",
      "6 Lap time: 862.518\n",
      "7 Lap time: 862.616\n",
      "8 Lap time: 975.036\n",
      "9 Lap time: 989.819\n",
      "10 Lap time: 1004.657\n",
      "11 Lap time: 1005.014\n",
      "12 Lap time: 1009.543\n",
      "3 Lap time: 1317.990\n",
      "4 Lap time: 1317.991\n",
      "5 Lap time: 1318.769\n",
      "6 Lap time: 1318.779\n",
      "7 Lap time: 1318.879\n",
      "8 Lap time: 1438.694\n",
      "9 Lap time: 1454.632\n",
      "10 Lap time: 1470.752\n",
      "11 Lap time: 1471.139\n",
      "12 Lap time: 1476.080\n",
      "3 Lap time: 1816.695\n",
      "4 Lap time: 1816.695\n",
      "5 Lap time: 1817.511\n",
      "6 Lap time: 1817.521\n",
      "7 Lap time: 1817.630\n",
      "8 Lap time: 1983.742\n",
      "9 Lap time: 1998.798\n",
      "10 Lap time: 2014.008\n",
      "11 Lap time: 2014.381\n",
      "12 Lap time: 2019.117\n",
      "3 Lap time: 2346.889\n",
      "4 Lap time: 2346.890\n",
      "5 Lap time: 2347.711\n",
      "6 Lap time: 2347.721\n",
      "7 Lap time: 2347.818\n",
      "8 Lap time: 2463.218\n",
      "9 Lap time: 2475.285\n",
      "10 Lap time: 2487.432\n",
      "11 Lap time: 2487.729\n",
      "12 Lap time: 2491.537\n",
      "3 Lap time: 2753.536\n",
      "4 Lap time: 2753.536\n",
      "5 Lap time: 2754.323\n",
      "6 Lap time: 2754.333\n",
      "7 Lap time: 2754.427\n",
      "8 Lap time: 2866.087\n",
      "9 Lap time: 2879.240\n",
      "10 Lap time: 2892.446\n",
      "11 Lap time: 2892.768\n",
      "12 Lap time: 2896.874\n",
      "3 Lap time: 3179.957\n",
      "4 Lap time: 3179.957\n",
      "5 Lap time: 3180.777\n",
      "6 Lap time: 3180.787\n",
      "7 Lap time: 3180.892\n",
      "8 Lap time: 3353.181\n",
      "9 Lap time: 3368.586\n",
      "10 Lap time: 3383.876\n",
      "11 Lap time: 3384.253\n",
      "12 Lap time: 3389.049\n",
      "3 Lap time: 3780.101\n",
      "4 Lap time: 3780.103\n",
      "5 Lap time: 3780.924\n",
      "6 Lap time: 3780.934\n",
      "7 Lap time: 3781.066\n",
      "8 Lap time: 4492.001\n",
      "9 Lap time: 4516.029\n",
      "10 Lap time: 4540.075\n",
      "11 Lap time: 4540.660\n",
      "12 Lap time: 4547.999\n",
      "3 Lap time: 5195.543\n",
      "4 Lap time: 5195.545\n",
      "5 Lap time: 5196.365\n",
      "6 Lap time: 5196.375\n",
      "7 Lap time: 5196.416\n",
      "8 Lap time: 5547.764\n",
      "9 Lap time: 5571.852\n",
      "10 Lap time: 5595.230\n",
      "11 Lap time: 5595.804\n",
      "12 Lap time: 5602.993\n",
      "3 Lap time: 6266.288\n",
      "4 Lap time: 6266.289\n",
      "5 Lap time: 6267.158\n",
      "6 Lap time: 6267.168\n",
      "7 Lap time: 6267.206\n",
      "8 Lap time: 6596.966\n",
      "9 Lap time: 6618.653\n",
      "10 Lap time: 6639.928\n",
      "11 Lap time: 6640.448\n",
      "12 Lap time: 6647.013\n",
      "3 Lap time: 7205.168\n",
      "4 Lap time: 7205.169\n",
      "5 Lap time: 7206.022\n",
      "6 Lap time: 7206.032\n",
      "7 Lap time: 7206.063\n",
      "8 Lap time: 7443.240\n",
      "9 Lap time: 7459.562\n",
      "10 Lap time: 7476.049\n",
      "11 Lap time: 7476.444\n",
      "12 Lap time: 7481.450\n",
      "3 Lap time: 7834.992\n",
      "4 Lap time: 7834.992\n",
      "5 Lap time: 7835.813\n",
      "6 Lap time: 7835.823\n",
      "7 Lap time: 7835.956\n",
      "8 Lap time: 8206.297\n",
      "9 Lap time: 8223.529\n",
      "10 Lap time: 8240.484\n",
      "11 Lap time: 8240.896\n",
      "12 Lap time: 8246.164\n",
      "3 Lap time: 8617.855\n",
      "4 Lap time: 8617.855\n",
      "5 Lap time: 8618.673\n",
      "6 Lap time: 8618.683\n",
      "7 Lap time: 8618.829\n",
      "8 Lap time: 8960.453\n",
      "9 Lap time: 8977.018\n",
      "10 Lap time: 8993.951\n",
      "11 Lap time: 8994.357\n",
      "12 Lap time: 8999.517\n",
      "3 Lap time: 9374.188\n",
      "4 Lap time: 9374.189\n",
      "5 Lap time: 9375.013\n",
      "6 Lap time: 9375.023\n",
      "7 Lap time: 9375.159\n",
      "8 Lap time: 9686.886\n",
      "9 Lap time: 9704.062\n",
      "10 Lap time: 9721.154\n",
      "11 Lap time: 9721.573\n",
      "12 Lap time: 9726.941\n",
      "3 Lap time: 10103.289\n",
      "4 Lap time: 10103.290\n",
      "5 Lap time: 10104.102\n",
      "6 Lap time: 10104.113\n",
      "7 Lap time: 10104.246\n",
      "8 Lap time: 10326.902\n",
      "9 Lap time: 10340.717\n",
      "10 Lap time: 10353.997\n",
      "11 Lap time: 10354.327\n",
      "12 Lap time: 10358.564\n",
      "3 Lap time: 10657.711\n",
      "4 Lap time: 10657.711\n",
      "5 Lap time: 10658.547\n",
      "6 Lap time: 10658.557\n",
      "7 Lap time: 10658.671\n",
      "8 Lap time: 10895.371\n",
      "9 Lap time: 10910.324\n",
      "10 Lap time: 10924.654\n",
      "11 Lap time: 10925.007\n",
      "12 Lap time: 10929.532\n",
      "3 Lap time: 11246.120\n",
      "4 Lap time: 11246.120\n",
      "5 Lap time: 11246.929\n",
      "6 Lap time: 11246.938\n",
      "7 Lap time: 11247.064\n",
      "8 Lap time: 11630.816\n",
      "9 Lap time: 11649.532\n",
      "10 Lap time: 11668.382\n",
      "11 Lap time: 11668.836\n",
      "12 Lap time: 11674.608\n",
      "3 Lap time: 12071.868\n",
      "4 Lap time: 12071.869\n",
      "5 Lap time: 12072.678\n",
      "6 Lap time: 12072.688\n",
      "7 Lap time: 12072.843\n",
      "8 Lap time: 12321.593\n",
      "9 Lap time: 12338.816\n",
      "10 Lap time: 12356.053\n",
      "11 Lap time: 12356.468\n",
      "12 Lap time: 12361.821\n",
      "3 Lap time: 12742.493\n",
      "4 Lap time: 12742.495\n",
      "5 Lap time: 12743.311\n",
      "6 Lap time: 12743.321\n",
      "7 Lap time: 12743.468\n",
      "8 Lap time: 13253.649\n",
      "9 Lap time: 13273.917\n",
      "10 Lap time: 13294.060\n",
      "11 Lap time: 13294.550\n",
      "12 Lap time: 13300.777\n"
     ]
    }
   ],
   "source": [
    "# print(os.listdir())\n",
    "try:\n",
    "    path = 'a:/taqhdf5'  #'a:/taqhdf5'\n",
    "    os.listdir(path)\n",
    "except:\n",
    "    path = 'f:/taqhdf5'  #'a:/taqhdf5'\n",
    "    os.listdir(path)    \n",
    "# allFiles = os.listdir(path)\n",
    "# print(len(allFiles), allFiles[:5], allFiles[-5:])\n",
    "# print(allFiles[-10:])\n",
    "\n",
    "#dates = np.array(['2020040' + str(i) if i < 10 else '202004' + str(i) for i in np.arange(1,16)]).astype(int)\n",
    "dates = np.array(['20200501',\n",
    "                  '20200504',\n",
    "                  '20200505',\n",
    "                  '20200506',\n",
    "                  '20200507',\n",
    "                  '20200508',\n",
    "                  '20200511',\n",
    "                  '20200512',\n",
    "                  '20200513',\n",
    "                  '20200514',\n",
    "                  '20200515',\n",
    "                  '20200518',\n",
    "                  '20200519',\n",
    "                  '20200520',\n",
    "                  '20200521',\n",
    "                  '20200522',\n",
    "                  '20200526',\n",
    "                  '20200527',\n",
    "                  '20200528',\n",
    "                  '20200529']).astype(int)#,'20200401','20200402','20200403','20200406','20200407'\n",
    "\n",
    "# Provide a list of tickers of interest\n",
    "tickers = sorted(all_tickers) # ['GOOG']#'MSFT' ['GOOG', 'MSFT'] #\n",
    "\n",
    "# Do we need data on trades, quotes or both?\n",
    "dataNeeded = 'quotes' # 'trades', 'quotes' or 'both'\n",
    "\n",
    "extract_candles = True #False\n",
    "aggHorizon = [1/6, 1/2, 1] # in minutes\n",
    "extra_features_from_quotes = ['spread', 'bidsize', 'ofrsize']\n",
    "\n",
    "data_sample = 'full'\n",
    "save_output = True\n",
    "\n",
    "exchanges = ['q','t']\n",
    "\n",
    "# run load_data()\n",
    "candles = load_data_and_save(dates,\n",
    "                          tickers,\n",
    "                          dataNeeded,\n",
    "                          path,\n",
    "                          verbose,\n",
    "                          extract_candles,\n",
    "                          aggHorizon,\n",
    "                          extra_features_from_quotes,\n",
    "                          data_sample,\n",
    "                          exchanges,\n",
    "                          save_output)\n",
    "\n",
    "# quoteData = load_data_final(dates,\n",
    "#                           tickers,\n",
    "#                           dataNeeded,\n",
    "#                           path,\n",
    "#                           verbose,\n",
    "#                           extract_candles,\n",
    "#                           aggHorizon,\n",
    "#                           extra_features_from_quotes,\n",
    "#                           data_sample,\n",
    "#                           save_output)\n",
    "\n",
    "# if dataNeeded == 'trades':\n",
    "#     tradeData = load_data(dates, tickers, dataNeeded, path, verbose)\n",
    "# elif dataNeeded == 'quotes':\n",
    "#     quoteData = load_data(dates, tickers, dataNeeded, path, verbose)\n",
    "# elif dataNeeded == 'both':\n",
    "#     tradeData, quoteData = load_data(dates, tickers, dataNeeded, path, verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 ['taqquote_20200501.h5', 'taqquote_20200504.h5', 'taqquote_20200505.h5', 'taqquote_20200506.h5', 'taqquote_20200507.h5'] ['taqquote_20200522.h5', 'taqquote_20200526.h5', 'taqquote_20200527.h5', 'taqquote_20200528.h5', 'taqquote_20200529.h5']\n",
      "['taqquote_20200515.h5', 'taqquote_20200518.h5', 'taqquote_20200519.h5', 'taqquote_20200520.h5', 'taqquote_20200521.h5', 'taqquote_20200522.h5', 'taqquote_20200526.h5', 'taqquote_20200527.h5', 'taqquote_20200528.h5', 'taqquote_20200529.h5']\n",
      "##### Date range #####\n",
      "\n",
      "Date, Min: 20200505\n",
      "Date, Max: 20200529\n",
      "\n",
      "\n",
      "1 Lap time: 0.001\n",
      "\n",
      "##### Data Extraction begins #####\n",
      "\n",
      "quote data is being extracted..\n",
      "\n",
      "\n",
      "2 Lap time: 0.002\n",
      "\n",
      "### Quote Data ###\n",
      "\n",
      "3 Lap time: 0.076\n",
      "4 Lap time: 0.076\n",
      "The raw H5 quote file contains:  ['QuoteIndex', 'Quotes'] \n",
      "\n",
      "5 Lap time: 0.868\n",
      "6 Lap time: 0.878\n",
      "7 Lap time: 62.353\n",
      "8 Lap time: 77.898\n",
      "9 Lap time: 92.528\n",
      "10 Lap time: 107.148\n",
      "11 Lap time: 107.512\n",
      "12 Lap time: 112.094\n",
      "3 Lap time: 353.492\n",
      "4 Lap time: 353.493\n",
      "5 Lap time: 354.299\n",
      "6 Lap time: 354.309\n",
      "7 Lap time: 429.483\n",
      "8 Lap time: 446.593\n",
      "9 Lap time: 462.908\n",
      "10 Lap time: 479.046\n",
      "11 Lap time: 479.445\n",
      "12 Lap time: 484.594\n",
      "3 Lap time: 746.491\n",
      "4 Lap time: 746.495\n",
      "5 Lap time: 747.311\n",
      "6 Lap time: 747.322\n",
      "7 Lap time: 825.434\n",
      "8 Lap time: 842.863\n",
      "9 Lap time: 858.102\n",
      "10 Lap time: 873.229\n",
      "11 Lap time: 873.608\n",
      "12 Lap time: 878.378\n",
      "3 Lap time: 1166.669\n",
      "4 Lap time: 1166.670\n",
      "5 Lap time: 1167.499\n",
      "6 Lap time: 1167.509\n",
      "7 Lap time: 1232.567\n",
      "8 Lap time: 1246.166\n",
      "9 Lap time: 1258.208\n",
      "10 Lap time: 1270.155\n",
      "11 Lap time: 1270.454\n",
      "12 Lap time: 1274.341\n",
      "3 Lap time: 1466.777\n",
      "4 Lap time: 1466.778\n",
      "5 Lap time: 1467.601\n",
      "6 Lap time: 1467.611\n",
      "7 Lap time: 1544.087\n",
      "8 Lap time: 1558.568\n",
      "9 Lap time: 1571.620\n",
      "10 Lap time: 1584.580\n",
      "11 Lap time: 1584.906\n",
      "12 Lap time: 1589.091\n",
      "3 Lap time: 1894.495\n",
      "4 Lap time: 1894.496\n",
      "5 Lap time: 1895.326\n",
      "6 Lap time: 1895.336\n",
      "7 Lap time: 1986.091\n",
      "8 Lap time: 2003.272\n",
      "9 Lap time: 2018.592\n",
      "10 Lap time: 2033.832\n",
      "11 Lap time: 2034.217\n",
      "12 Lap time: 2039.143\n",
      "3 Lap time: 2295.688\n",
      "4 Lap time: 2295.690\n",
      "5 Lap time: 2296.472\n",
      "6 Lap time: 2296.482\n",
      "7 Lap time: 2471.780\n",
      "8 Lap time: 2514.486\n",
      "9 Lap time: 2538.442\n",
      "10 Lap time: 2562.182\n",
      "11 Lap time: 2562.780\n",
      "12 Lap time: 2570.282\n",
      "3 Lap time: 3013.289\n",
      "4 Lap time: 3013.292\n",
      "5 Lap time: 3014.113\n",
      "6 Lap time: 3014.124\n",
      "7 Lap time: 3214.935\n",
      "8 Lap time: 3251.264\n",
      "9 Lap time: 3274.847\n",
      "10 Lap time: 3298.229\n",
      "11 Lap time: 3298.813\n",
      "12 Lap time: 3306.201\n",
      "3 Lap time: 3706.465\n",
      "4 Lap time: 3706.467\n",
      "5 Lap time: 3707.360\n",
      "6 Lap time: 3707.371\n",
      "7 Lap time: 3895.085\n",
      "8 Lap time: 3953.089\n",
      "9 Lap time: 3974.129\n",
      "10 Lap time: 3995.070\n",
      "11 Lap time: 3995.594\n",
      "12 Lap time: 4002.238\n",
      "3 Lap time: 4510.168\n",
      "4 Lap time: 4510.175\n",
      "5 Lap time: 4511.034\n",
      "6 Lap time: 4511.045\n",
      "7 Lap time: 4651.832\n",
      "8 Lap time: 4671.739\n",
      "9 Lap time: 4687.766\n",
      "10 Lap time: 4703.661\n",
      "11 Lap time: 4704.062\n",
      "12 Lap time: 4709.075\n",
      "3 Lap time: 4982.147\n",
      "4 Lap time: 4982.150\n",
      "5 Lap time: 4982.969\n",
      "6 Lap time: 4982.980\n",
      "7 Lap time: 5147.373\n",
      "8 Lap time: 5166.497\n",
      "9 Lap time: 5183.172\n",
      "10 Lap time: 5199.721\n",
      "11 Lap time: 5200.136\n",
      "12 Lap time: 5205.382\n",
      "3 Lap time: 5570.567\n",
      "4 Lap time: 5570.570\n",
      "5 Lap time: 5571.377\n",
      "6 Lap time: 5571.387\n",
      "7 Lap time: 5722.664\n",
      "8 Lap time: 5741.323\n",
      "9 Lap time: 5757.587\n",
      "10 Lap time: 5773.791\n",
      "11 Lap time: 5774.195\n",
      "12 Lap time: 5779.340\n",
      "3 Lap time: 6109.724\n",
      "4 Lap time: 6109.727\n",
      "5 Lap time: 6110.538\n",
      "6 Lap time: 6110.548\n",
      "7 Lap time: 6269.588\n",
      "8 Lap time: 6290.567\n",
      "9 Lap time: 6307.549\n",
      "10 Lap time: 6324.488\n",
      "11 Lap time: 6324.913\n",
      "12 Lap time: 6330.320\n",
      "3 Lap time: 6621.744\n",
      "4 Lap time: 6621.748\n",
      "5 Lap time: 6622.595\n",
      "6 Lap time: 6622.605\n",
      "7 Lap time: 6752.386\n",
      "8 Lap time: 6768.620\n",
      "9 Lap time: 6781.932\n",
      "10 Lap time: 6795.122\n",
      "11 Lap time: 6795.452\n",
      "12 Lap time: 6799.654\n",
      "3 Lap time: 7024.286\n",
      "4 Lap time: 7024.288\n",
      "5 Lap time: 7025.109\n",
      "6 Lap time: 7025.119\n",
      "7 Lap time: 7156.365\n",
      "8 Lap time: 7172.359\n",
      "9 Lap time: 7186.754\n",
      "10 Lap time: 7201.032\n",
      "11 Lap time: 7201.388\n",
      "12 Lap time: 7206.013\n",
      "3 Lap time: 7489.108\n",
      "4 Lap time: 7489.110\n",
      "5 Lap time: 7489.957\n",
      "6 Lap time: 7489.966\n",
      "7 Lap time: 7686.021\n",
      "8 Lap time: 7706.239\n",
      "9 Lap time: 7724.593\n",
      "10 Lap time: 7742.820\n",
      "11 Lap time: 7743.397\n",
      "12 Lap time: 7749.161\n",
      "3 Lap time: 8142.567\n",
      "4 Lap time: 8142.570\n",
      "5 Lap time: 8143.453\n",
      "6 Lap time: 8143.464\n",
      "7 Lap time: 8306.407\n",
      "8 Lap time: 8327.698\n",
      "9 Lap time: 8344.537\n",
      "10 Lap time: 8361.223\n",
      "11 Lap time: 8361.643\n",
      "12 Lap time: 8366.923\n",
      "3 Lap time: 8651.944\n",
      "4 Lap time: 8651.947\n",
      "5 Lap time: 8652.767\n",
      "6 Lap time: 8652.777\n",
      "7 Lap time: 8909.401\n",
      "8 Lap time: 8935.097\n",
      "9 Lap time: 8955.046\n",
      "10 Lap time: 8974.758\n",
      "11 Lap time: 8975.255\n",
      "12 Lap time: 8981.458\n",
      "The extraction time was 9458.545 seconds.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'list' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-8830a522e84e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     56\u001b[0m                           \u001b[0mextra_features_from_quotes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m                           \u001b[0mdata_sample\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m                           save_output)\n\u001b[0m\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;31m# quoteData = load_data_final(dates,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\KU Thesis 2020\\Thesis_UCPH\\utils\\data_extraction.py\u001b[0m in \u001b[0;36mload_data_final\u001b[1;34m(dates, tickers, dataNeeded, path, verbose, extract_candles, aggHorizon, extra_features_from_quotes, data_sample, save_output)\u001b[0m\n\u001b[0;32m   1336\u001b[0m                                             \u001b[0msample\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_sample\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1337\u001b[0m                                             \u001b[0mnumpied\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1338\u001b[1;33m                                             return_extended=extra_features_from_quotes)\n\u001b[0m\u001b[0;32m   1339\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1340\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\KU Thesis 2020\\Thesis_UCPH\\utils\\generate_features.py\u001b[0m in \u001b[0;36mcandleCreateNP_vect_final\u001b[1;34m(data, step, verbose, fillHoles, sample, numpied, return_extended)\u001b[0m\n\u001b[0;32m    739\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    740\u001b[0m     \u001b[1;31m# setup time_bins to group each timestamp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 741\u001b[1;33m     \u001b[0mdelta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m60\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    742\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    743\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msample\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'full'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'list' and 'int'"
     ]
    }
   ],
   "source": [
    "# print(os.listdir())\n",
    "try:\n",
    "    path = 'a:/taqhdf5'  #'a:/taqhdf5'\n",
    "    os.listdir(path)\n",
    "except:\n",
    "    path = 'f:/taqhdf5'  #'a:/taqhdf5'\n",
    "    os.listdir(path)    \n",
    "# allFiles = os.listdir(path)\n",
    "# print(len(allFiles), allFiles[:5], allFiles[-5:])\n",
    "# print(allFiles[-10:])\n",
    "\n",
    "#dates = np.array(['2020040' + str(i) if i < 10 else '202004' + str(i) for i in np.arange(1,16)]).astype(int)\n",
    "dates = np.array(['20200505',\n",
    "                  '20200506',\n",
    "                  '20200507',\n",
    "                  '20200508',\n",
    "                  '20200511',\n",
    "                  '20200512',\n",
    "                  '20200513',\n",
    "                  '20200514',\n",
    "                  '20200515',\n",
    "                  '20200518',\n",
    "                  '20200519',\n",
    "                  '20200520',\n",
    "                  '20200521',\n",
    "                  '20200522',\n",
    "                  '20200526',\n",
    "                  '20200527',\n",
    "                  '20200528',\n",
    "                  '20200529'\n",
    "                  \n",
    "                  \n",
    "                 ]).astype(int)#,'20200401','20200402','20200403','20200406','20200407'\n",
    "\n",
    "# Provide a list of tickers of interest\n",
    "tickers = sorted(all_tickers) # ['GOOG']#'MSFT' ['GOOG', 'MSFT'] #\n",
    "\n",
    "# Do we need data on trades, quotes or both?\n",
    "dataNeeded = 'quotes' # 'trades', 'quotes' or 'both'\n",
    "\n",
    "extract_candles = True #False\n",
    "aggHorizon = [1/6, 1/2, 1] # in minutes\n",
    "extra_features_from_quotes = ['spread', 'bidsize', 'ofrsize']\n",
    "\n",
    "data_sample = 'full'\n",
    "save_output = True\n",
    "\n",
    "# run load_data()\n",
    "candles = load_data_final(dates,\n",
    "                          tickers,\n",
    "                          dataNeeded,\n",
    "                          path,\n",
    "                          verbose,\n",
    "                          extract_candles,\n",
    "                          aggHorizon,\n",
    "                          extra_features_from_quotes,\n",
    "                          data_sample,\n",
    "                          save_output)\n",
    "\n",
    "dates,\n",
    "                    tickers,\n",
    "                    dataNeeded,\n",
    "                    path,\n",
    "                    verbose,\n",
    "                    extract_candles = False,\n",
    "                    aggHorizon = 1,\n",
    "                    extra_features_from_quotes = None,\n",
    "                    data_sample = 'full',\n",
    "                    exchanges = ['q','t'],\n",
    "                    save_output = False):\n",
    "\n",
    "# quoteData = load_data_final(dates,\n",
    "#                           tickers,\n",
    "#                           dataNeeded,\n",
    "#                           path,\n",
    "#                           verbose,\n",
    "#                           extract_candles,\n",
    "#                           aggHorizon,\n",
    "#                           extra_features_from_quotes,\n",
    "#                           data_sample,\n",
    "#                           save_output)\n",
    "\n",
    "# if dataNeeded == 'trades':\n",
    "#     tradeData = load_data(dates, tickers, dataNeeded, path, verbose)\n",
    "# elif dataNeeded == 'quotes':\n",
    "#     quoteData = load_data(dates, tickers, dataNeeded, path, verbose)\n",
    "# elif dataNeeded == 'both':\n",
    "#     tradeData, quoteData = load_data(dates, tickers, dataNeeded, path, verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quoteData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanedData = HFDataCleaning(['P1_2','p2', 'q2', 'p3'],quoteData,'quote',['q'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanedData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanedData.groupby(['Ticker','Date']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanedData[cleanedData['Ticker'] == 'MSFT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candles = candleCreateNP_vect_final(data = cleanedData[cleanedData['Ticker'] == 'MSFT'],\n",
    "                                    step = aggHorizon,\n",
    "                                    verbose=False,\n",
    "                                    fillHoles=True,\n",
    "                                    sample='full',\n",
    "                                    numpied=False,\n",
    "                                    return_extended=extra_features_from_quotes)\n",
    "candles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanedData.loc[cleanedData['Ticker'] == 'MSFT', :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanedData[cleanedData['Ticker'] == 'GOOG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type([5]) == list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quoteData.shape,candles.shape\n",
    "candles.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quoteData.shape, quoteData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning, Feature Engineering & Pre Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implemented technical features\n",
    "\n",
    "A library: https://technical-analysis-library-in-python.readthedocs.io/en/latest/\n",
    "\n",
    "### Features used in the literature:\n",
    "\n",
    "* Stochastic K\n",
    "* Stochastic D\n",
    "* Slow Stochastic D\n",
    "* Momentum/difference\n",
    "* ROC\n",
    "* Williams % R\n",
    "* A/D Oscillator\n",
    "* Disparity 5\n",
    "* Disparity 10\n",
    "* Price Oscillator - (detrended)\n",
    "* Commodity Channel Index\n",
    "* RSI\n",
    "\n",
    "Formulas: https://papers.ssrn.com/sol3/papers.cfm?abstract_id=876544\n",
    "\n",
    "* Moving Average\n",
    "* Exponential Moving Average\n",
    "* True Range - (Average)\n",
    "\n",
    "Formulas: https://www.sciencedirect.com/science/article/pii/S0957417407001819?via%3Dihub\n",
    "\n",
    "#### Other Technical Features\n",
    "* Moving Average Convergence Divergence (MACD)\n",
    "\n",
    "**Non-classical technical features** - **NOT IMPLEMENTED**\n",
    "\n",
    "* Bid/Ask prices of top of book\n",
    "* Spread and mid price based on top og book\n",
    "* Price derivatives\n",
    "\n",
    "Formulas: https://www.tandfonline.com/doi/full/10.1080/14697688.2015.1032546?instName=UCL+%28University+College+London%29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Clean data ###########\n",
    "    \n",
    "DATA_SAMPLE = 'full' # or 'stable'\n",
    "\n",
    "# if DATA_SAMPLE == 'stable':\n",
    "#     # P1 is used for keeping data within [9.5, 16]\n",
    "#     cleanedData = HFDataCleaning(['P1','p2','t1','p3'],tradeData,'trade',['q'])\n",
    "# elif DATA_SAMPLE == 'full':\n",
    "#     # P1_2 is used for keeping data within [9, 16.5]\n",
    "#     cleanedData = HFDataCleaning(['P1_2','p2', 'q2', 'p3'],quoteData,'quote',['q'])#'t1',tradeData # q2, quotedate\n",
    "    \n",
    "# ########### Construct Candles ################\n",
    "# # candles = candleCreateNP_vect_final(cleanedData\n",
    "# #                          ,1)\n",
    "\n",
    "# candles = candleCreateNP_vect_final(data = cleanedData,\n",
    "#                                        step = 1,\n",
    "#                                         verbose=False,\n",
    "#                                         fillHoles=True,\n",
    "#                                         sample='stable',\n",
    "#                                         numpied=True)\n",
    "\n",
    "########### Generate Features ################\n",
    "\n",
    "n_feature_lags = 1\n",
    "features = generateFeatures_final_test(candles, \n",
    "                                       listOfFeatures = [\n",
    "                                           'pastobs',\n",
    "                                            'spread',\n",
    "                                           'bidsize',\n",
    "                                           'ofrsize',\n",
    "                                            'stok',\n",
    "                                            'stod',\n",
    "                                            'sstod',\n",
    "                                            'wilr',\n",
    "                                            'roc',\n",
    "                                            'rsi',\n",
    "                                            'atr',\n",
    "                                            'cci',\n",
    "                                            'dpo',\n",
    "                                            'sma',\n",
    "                                            'ema',\n",
    "                                            'macd',\n",
    "                                            'dis5',\n",
    "                                            'dis10',\n",
    "                                           ], \n",
    "                                    feature_lags = n_feature_lags)\n",
    "\n",
    "########### Generate Labels ################\n",
    "\n",
    "n_classes = 3\n",
    "\n",
    "labels = extract_labels(data = candles['price'].values, classes = n_classes, group_style = 'equal')\n",
    "\n",
    "########### Align Data ################\n",
    "\n",
    "# from imported function (see testing_preprocessing_features_and_labels.ipynb for thorough experimenting with all the cut-offs):    \n",
    "X, y = align_features_and_labels(candles = candles['price'].values, \n",
    "                                 prediction_horizon = 1, \n",
    "                                 features = features, \n",
    "                                 n_feature_lags = n_feature_lags, \n",
    "                                 n_classes = n_classes, # 5,\n",
    "                                 safe_burn_in = False, \n",
    "                                 data_sample = 'full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candles['price'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quoteData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candles[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = pd.DataFrame({'0':np.random.randint(0,10,1000000),\n",
    "                   '1':np.random.randint(0,10,1000000),\n",
    "                   '2':np.random.randint(0,10,1000000)})\n",
    "\n",
    "# t2 = pd.Series({'0':np.random.randint(0,10,10)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#t1.loc[:,['0','1','2']] = t1.loc[:,['0','1','2']] - t1.loc[:,'2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1.loc[:,['0','1','2']] - t1.loc[:,'2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(t1.loc[:,'2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1[['0','1','2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit t1[['0','1','2']].values-t1[['2']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit t1[['0','1','2']].subtract(t1.loc[:,'2'],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's investigate the features a little bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardization, Normalization (MinMax), Norm-Scaling, Quantile and Power Transformation\n",
    "\n",
    "**Inspiration:**\n",
    "\n",
    "* [ScikitLearn Overview](https://scikit-learn.org/stable/auto_examples/preprocessing/plot_all_scaling.html#sphx-glr-auto-examples-preprocessing-plot-all-scaling-py)\n",
    "* [A Note on Feature Scaling and Normalization](http://sebastianraschka.com/Articles/2014_about_feature_scaling.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the Scalers!\n",
    "mm_scaler = MinMaxScaler()\n",
    "scaler = StandardScaler()\n",
    "norm_scaler = Normalizer()\n",
    "pt = PowerTransformer()\n",
    "ptNst = PowerTransformer(standardize=False)\n",
    "qtUni = QuantileTransformer(n_quantiles=100)\n",
    "qtGau = QuantileTransformer(n_quantiles=100,output_distribution='normal')\n",
    "robo = RobustScaler()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.1, random_state=42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "X_train = X_train.reset_index(drop=True) \n",
    "X_test = X_test.reset_index(drop=True)\n",
    "# y_train = y_train.reset_index(drop=True)\n",
    "# y_test = y_test.reset_index(drop=True)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# featurePreProcessing = {'open':'std',\n",
    "#                         'close':'std',\n",
    "#                         'high':'std',\n",
    "#                         'low':'std',\n",
    "                        \n",
    "#                         'stok':'std',\n",
    "#                         'stod':'std',\n",
    "#                         'sstod':'std',\n",
    "#                         'wilr':'std',\n",
    "#                         'ema':'std',\n",
    "#                         'sma':'std',\n",
    "#                         'dis5':'sub',\n",
    "#                         'dis10':'sub',\n",
    "#                         'macd_diff':'act',\n",
    "#                         'roc':'actde',\n",
    "#                         'atr':'actde',\n",
    "#                         'rsi':'std',\n",
    "#                         'cci':'quantgau',\n",
    "#                         'dpo':'quantgau',\n",
    "#                         'macd':'quantgau',\n",
    "#                         'macd_signal':'quantgau'}\n",
    "featurePreProcessing = {col:'quantgau' for col in X.columns}\n",
    "ppX_train,ppX_test = pre_processing(X_train,\n",
    "                                       X_test,\n",
    "                                       featurePreProcessing,\n",
    "                                       100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = ppX_train.corr()\n",
    "corr.style.background_gradient(cmap='coolwarm').set_precision(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[['open','high']].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "## Setting up the model and corresponding parameters\n",
    "\n",
    "rf = ensemble.RandomForestClassifier()\n",
    "param_grid = {'knn': {'n_neighbors': [1,3,5,7,9,11,13,15,17,19]},\n",
    "                  'rf': {'n_estimators': [50,100,200], 'max_features': ['auto', None], 'min_samples_leaf': [1, 5, 10]}}\n",
    "\n",
    "## Setting parameters for grid search\n",
    "cv_folds = 5\n",
    "n_jobs = 1\n",
    "\n",
    "## Performing grid search\n",
    "grid_search = GridSearchCV(rf, param_grid['rf'], cv = cv_folds, n_jobs = n_jobs)\n",
    "grid_search.fit(ppX_train,y_train)\n",
    "\n",
    "# store the best hyperparameters and initialize a separate random forest with those parameters\n",
    "rf_params = grid_search.best_params_\n",
    "rf = ensemble.RandomForestClassifier(**rf_params)\n",
    "\n",
    "# refit the random forest using only the correctly accessible training data\n",
    "# and return feature importances. This is not the perfect solution but it is \n",
    "# better than extracting feature importances from the grid search above which \n",
    "# is refit on all data (also test set) of the inner folds\n",
    "\n",
    "rf.fit(ppX_train, y_train)\n",
    "rf_features =  rf.feature_importances_\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute mean of importances across folds and select those above the mean\n",
    "# rf_features = np.mean(rf_features, axis=0)            \n",
    "threshold_value = np.mean(rf_features) \n",
    "rf_features_w = np.where(rf_features > threshold_value)[0]\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "if verbose:\n",
    "    print(\"RF Feature selection final best features: \" + str(rf_features_w))\n",
    "    print('The model selection took %.3f seconds.' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce data sets using selected features X_train = X_train[:, rf_features]\n",
    "msX_test,msX_train = ppX_test.iloc[:, rf_features_w],ppX_train.iloc[:, rf_features_w]\n",
    "\n",
    "# Refitting\n",
    "\n",
    "rf.fit(msX_train,y_train)\n",
    "\n",
    "# Evaluating\n",
    "rf.score(msX_test,y_test)\n",
    "\n",
    "# store selected features\n",
    "# total_features[counter, :] = str(rf_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = msX_train.corr()\n",
    "corr.style.background_gradient(cmap='coolwarm').set_precision(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression in Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Building a Logistic Regression Model in Tensorflow\n",
    "msX_train = ppX_train.copy(deep=True)\n",
    "msX_test = ppX_test.copy(deep=True)\n",
    "## Setting up data\n",
    "NUMERIC_COLUMNS = msX_train.columns\n",
    "\n",
    "feature_columns = []\n",
    "\n",
    "for feature_name in NUMERIC_COLUMNS:\n",
    "    feature_columns.append(tf.feature_column.numeric_column(feature_name, dtype=tf.float32))\n",
    "    \n",
    "## Arange data correctly\n",
    "train_input_fn = make_input_fn(msX_train, y_train.astype(int))\n",
    "eval_input_fn = make_input_fn(msX_test, y_test.astype(int), num_epochs=1, shuffle=False)\n",
    "\n",
    "## Inspecting the data\n",
    "ds = make_input_fn(msX_train, y_train.astype(int), batch_size=10)()\n",
    "for feature_batch, label_batch in ds.take(1):\n",
    "    print('Some feature keys:', list(feature_batch.keys()))\n",
    "    print()\n",
    "    print('A batch of class:', feature_batch['sstod'].numpy())\n",
    "    print()\n",
    "    print('A batch of Labels:', label_batch.numpy())\n",
    "    \n",
    "linear_est = tf.estimator.LinearClassifier(feature_columns=feature_columns,n_classes=3)\n",
    "linear_est.train(train_input_fn)\n",
    "result = linear_est.evaluate(eval_input_fn)\n",
    "\n",
    "clear_output()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dicts = list(linear_est.predict(eval_input_fn))\n",
    "print(len(pred_dicts))\n",
    "pred_dicts[0]\n",
    "# probs = pd.Series([pred['probabilities'][1] for pred in pred_dicts])\n",
    "\n",
    "# probs.plot(kind='hist', bins=20, title='predicted probabilities')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets test some performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets test different preprocessing methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ppm in ['std','quantgau','quantuni','pow','minmax']:#'act','actde',\n",
    "    print('The preprocessing method tested is: %s\\n' % ppm)\n",
    "    testDict = {col:ppm for col in X.columns}\n",
    "    performanceTesting(X,y,5,2020,testDict,verbose=0)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Process features individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurePreProcessing = {'open':'std',\n",
    "                        'close':'std',\n",
    "                        'high':'std',\n",
    "                        'low':'std',\n",
    "                        'stok':'std',\n",
    "                        'stod':'std',\n",
    "                        'sstod':'std',\n",
    "                        'wilr':'std',\n",
    "                        'ema':'std',\n",
    "                        'sma':'std',\n",
    "                        'dis5':'sub',\n",
    "                        'dis10':'sub',\n",
    "                        'macd_diff':'act',\n",
    "                        'roc':'actde',\n",
    "                        'atr':'actde',\n",
    "                        'rsi':'std',\n",
    "                        'cci':'quantgau',\n",
    "                        'dpo':'quantgau',\n",
    "                        'macd':'quantgau',\n",
    "                        'macd_signal':'quantgau'}\n",
    "performanceTesting(X,y,5,2020,featurePreProcessing,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
