{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\AppData\\Local\\Temp\\tmp2jialnko\\tensorboard_logs\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "import h5py\n",
    "import copy\n",
    "import datetime\n",
    "import ta\n",
    "import pathlib\n",
    "import shutil\n",
    "import tempfile\n",
    "#import vaex\n",
    "from IPython import display\n",
    "from IPython.display import clear_output\n",
    "import pyodbc\n",
    "\n",
    "# Tensorflow related\n",
    "# import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "\n",
    "# from tensorflow.keras import layers\n",
    "# from tensorflow.keras import regularizers\n",
    "# import tensorflow.compat.v2.feature_column as fc\n",
    "\n",
    "# #!pip install -q git+https://github.com/tensorflow/docs\n",
    "\n",
    "# import tensorflow_docs as tfdocs\n",
    "# import tensorflow_docs.modeling\n",
    "# import tensorflow_docs.plots\n",
    "\n",
    "#print(tf.__version__)\n",
    "logdir = pathlib.Path(tempfile.mkdtemp())/\"tensorboard_logs\"\n",
    "shutil.rmtree(logdir, ignore_errors=True)\n",
    "print(logdir)\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, f1_score, log_loss\n",
    "\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.exceptions import ConvergenceWarning \n",
    "from sklearn import ensemble\n",
    "# ConvergenceWarning('ignore')\n",
    "# Do you wanna see?\n",
    "verbose = True\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "#sys.path.append('...../')\n",
    "\n",
    "from utils.data_extraction import load_data_final,load_data_and_save\n",
    "from utils.data_cleaning import HFDataCleaning\n",
    "from utils.generate_features import candleCreateNP_vect_final,\\\n",
    "                                    generateFeatures_final,\\\n",
    "                                    generateFeatures_multi_final\n",
    "\n",
    "from utils.preprocessing_features_and_labels import extract_labels,\\\n",
    "                                                    align_features_and_labels,\\\n",
    "                                                    pre_processing_initial,\\\n",
    "                                                    pre_processing_extended,\\\n",
    "                                                    pre_processing_final,\\\n",
    "                                                    extract_labels_multi_final,\\\n",
    "                                                    align_features_and_labels_multi_final,\\\n",
    "                                                    align_features_and_labels_multi_v5\n",
    "\n",
    "# from utils.models import make_input_fn\n",
    "# from utils.models import performanceTesting,scoreFunction\n",
    "# from utils.plotting import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which one do you want to load? \n",
      "\n",
      "0: aggregateTAQ_May2020_10sec (1).csv\n",
      "1: aggregateTAQ_May2020_30sec (1).csv\n",
      "2: aggregateTAQ_May2020_60sec.csv\n",
      "8: trueAggregateTAQ_60sec.csv\n",
      "\n",
      "\n",
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (19) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>sector</th>\n",
       "      <th>exchange</th>\n",
       "      <th>marketCap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>Technology</td>\n",
       "      <td>NMS</td>\n",
       "      <td>1.578173e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ABBV</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>NYQ</td>\n",
       "      <td>1.742612e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>ABT</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>NYQ</td>\n",
       "      <td>1.631410e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>AEP</td>\n",
       "      <td>Utilities</td>\n",
       "      <td>NYQ</td>\n",
       "      <td>4.089551e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>AMT</td>\n",
       "      <td>Real Estate</td>\n",
       "      <td>NYQ</td>\n",
       "      <td>1.171259e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>APD</td>\n",
       "      <td>Basic Materials</td>\n",
       "      <td>NYQ</td>\n",
       "      <td>5.464395e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>BA</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>NYQ</td>\n",
       "      <td>1.020356e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>BABA</td>\n",
       "      <td>Consumer Cyclical</td>\n",
       "      <td>NYQ</td>\n",
       "      <td>5.936536e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>BAC</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>NYQ</td>\n",
       "      <td>2.020550e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>BHP</td>\n",
       "      <td>Basic Materials</td>\n",
       "      <td>NYQ</td>\n",
       "      <td>1.258194e+11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ticker              sector exchange     marketCap\n",
       "12    AAPL          Technology      NMS  1.578173e+12\n",
       "20    ABBV          Healthcare      NYQ  1.742612e+11\n",
       "34     ABT          Healthcare      NYQ  1.631410e+11\n",
       "126    AEP           Utilities      NYQ  4.089551e+10\n",
       "379    AMT         Real Estate      NYQ  1.171259e+11\n",
       "428    APD     Basic Materials      NYQ  5.464395e+10\n",
       "697     BA         Industrials      NYQ  1.020356e+11\n",
       "699   BABA   Consumer Cyclical      NYQ  5.936536e+11\n",
       "700    BAC  Financial Services      NYQ  2.020550e+11\n",
       "870    BHP     Basic Materials      NYQ  1.258194e+11"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do we extract new data or read in?\n",
    "readIn = True\n",
    "# run load_data()\n",
    "if readIn:\n",
    "    \n",
    "    # Listing the data files \n",
    "    path = '../../../Google Drev/Thesis/Data/TAQ/AggregatedTAQ'\n",
    "#     path = 'F:/AggregatedTAQ/round3'\n",
    "    datafiles = os.listdir(path)\n",
    "    content = np.concatenate([['\\n\\n'],[str(j)+': '+i+'\\n' for j,i in enumerate(datafiles) if 'csv' in i],['\\n\\n']])\n",
    "    \n",
    "    # Asking for user input\n",
    "    file = input('Which one do you want to load? %s'%''.join(content))\n",
    "    if int(file) <= 2:\n",
    "        data = pd.read_csv(path + '/' + datafiles[int(file)],\n",
    "                           header = None,\n",
    "                           names=['open','high','low','close',\n",
    "                                  'spread_open','spread_high','spread_low','spread_close',\n",
    "                                  'bidsize_open','bidsize_high','bidsize_low','bidsize_close',\n",
    "                                  'ofrsize_open','ofrsize_high','ofrsize_low','ofrsize_close',\n",
    "                                  'Ticker'])\n",
    "        # Using the choice of the user to determine the correct market file\n",
    "        key = re.split('[_.]',datafiles[int(file)])[-2]\n",
    "        marketDataFile = [file for file in os.listdir(path+'/round5_market_tickers') if key in file]\n",
    "\n",
    "        # Reading in the market data\n",
    "        tempData = pd.read_csv(path+'/round5_market_tickers/'+marketDataFile[0]\n",
    "                               ,header = None\n",
    "                               ,names=['open','high','low','close',\n",
    "                                      'spread_open','spread_high','spread_low','spread_close',\n",
    "                                      'bidsize_open','bidsize_high','bidsize_low','bidsize_close',\n",
    "                                      'ofrsize_open','ofrsize_high','ofrsize_low','ofrsize_close',\n",
    "                                      'Ticker'])\n",
    "        # Adding the market data to the ticker data\n",
    "        data = pd.concat([data,tempData],axis=0)\n",
    "    else:\n",
    "        data = pd.read_csv(path + '/' + datafiles[int(file)],\n",
    "                           header = 0,\n",
    "                           index_col=[0,1]\n",
    "#                            names=['open','high','low','close',\n",
    "#                                   'spread_open','spread_high','spread_low','spread_close',\n",
    "#                                   'bidsize_open','bidsize_high','bidsize_low','bidsize_close',\n",
    "#                                   'ofrsize_open','ofrsize_high','ofrsize_low','ofrsize_close',\n",
    "#                                   'Ticker']\n",
    "                          )\n",
    "    \n",
    "    # Lower casing all column names\n",
    "#     data.columns = data.columns.str.lower()\n",
    "else:\n",
    "    \n",
    "    # print(os.listdir())\n",
    "    try:\n",
    "        path = 'a:/taqhdf5'  #'a:/taqhdf5'\n",
    "        os.listdir(path)\n",
    "    except:\n",
    "        path = 't:/taqhdf5'  #'a:/taqhdf5'\n",
    "        os.listdir(path)\n",
    "        \n",
    "    # Sample type\n",
    "    data_sample = 'full' # or 'stable'\n",
    "    # allFiles = os.listdir(path)\n",
    "    # print(len(allFiles), allFiles[:5], allFiles[-5:])\n",
    "    # print(allFiles[-10:])\n",
    "\n",
    "    #dates = np.array(['2020040' + str(i) if i < 10 else '202004' + str(i) for i in np.arange(1,16)]).astype(int)\n",
    "    dates = np.array(['20200501']).astype(int)#,'20200402','20200403','20200406','20200407'\n",
    "\n",
    "    # Provide a list of tickers of interest\n",
    "    \n",
    "    tickers = sorted(['TSLA','FB'])#'MSFT'\n",
    "    \n",
    "    # Do we need data on trades, quotes or both?\n",
    "    dataNeeded = 'quotes' # 'trades', 'quotes' or 'both'\n",
    "    \n",
    "    if dataNeeded == 'trades':\n",
    "        tradeData = load_data_final(dates, tickers, dataNeeded, path, verbose)\n",
    "    elif dataNeeded == 'quotes':\n",
    "        quoteData = load_data_final(dates,\n",
    "                                    tickers,\n",
    "                                    dataNeeded,\n",
    "                                    path,\n",
    "                                    verbose,\n",
    "                                    extract_candles = False,\n",
    "                                    aggHorizon = 1,\n",
    "                                    extra_features_from_quotes = None,\n",
    "                                    data_sample = data_sample)\n",
    "    elif dataNeeded == 'both':\n",
    "        tradeData, quoteData = load_data_final(dates, tickers, dataNeeded, path, verbose)\n",
    "\n",
    "# Reading in sector information\n",
    "stockInfo = pd.read_csv('../utils/stockInfo_v1.csv',header=[0,1])\n",
    "stockInfo.columns = ['ticker','sector','exchange','marketCap']\n",
    "\n",
    "# Creating a table with stock information based on the tickers available in the data.\n",
    "uniqueTickers = data.Ticker.unique()\n",
    "stockTable = stockInfo[stockInfo.ticker.isin(uniqueTickers)]\n",
    "stockTable.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hyperparameters.txt',\n",
       " 'hyperparameters_lr_v1.txt',\n",
       " 'hyperparameters_lr_v2.txt',\n",
       " 'hyperparameters_lr_v3.txt',\n",
       " 'hyperparameters_nn.txt',\n",
       " 'hyperparameters_nn_v4.txt',\n",
       " 'metrics.txt',\n",
       " 'metrics_lr_v1.txt',\n",
       " 'metrics_lr_v2.txt',\n",
       " 'metrics_lr_v3.txt',\n",
       " 'metrics_nn.txt',\n",
       " 'metrics_nn_v4.txt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = os.listdir('../AzureML/Output_from_cloud')\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperfiles_nn = [i for i in os.listdir('../AzureML/Output_from_cloud') if ('hyper' in i) & ('nn' in i)]\n",
    "metricfiles_nn = [i for i in os.listdir('../AzureML/Output_from_cloud') if ('metric' in i) & ('nn' in i)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Reading in the file\n",
    "\n",
    "with open('../AzureML/Output_from_cloud/'+hyperfiles_nn[-1],'r') as file:\n",
    "    content = file.readlines()\n",
    "\n",
    "## Containers for the data\n",
    "all_ids = []\n",
    "all_parameters = []\n",
    "\n",
    "## Going over each line in the text file\n",
    "for a in np.arange(len(content[0:-1])):\n",
    "    \n",
    "    ## Split the lines on tabs\n",
    "    temp_parameters = re.split('[\\t]',content[a])[1]\n",
    "    \n",
    "    ## Basic string cleaning, i.e. removing redundant characters\n",
    "#     test = [re.split(': ',i.strip()) for i in re.split(',',temp_parameters.replace('{','')\\\n",
    "#                                                                        .replace('}','')\\\n",
    "#                                                                        .replace('\\n','')\\\n",
    "#                                                                        .replace('\"',''))]\n",
    "    test = [re.split(': ',i.strip()) for i in re.split(',',temp_parameters.replace('{','')\\\n",
    "                                                                       .replace('}','')\\\n",
    "                                                                       .replace('\\n','')\\\n",
    "                                                                       .replace('\"','')\\\n",
    "                                                                       .replace('--','')\n",
    "                                                                       .replace('\\'',''))]\n",
    "    \n",
    "    ## Output of test is a list of lists, where each sublist holds the name of a model variable and its value.\n",
    "    ## We create a dictornary to hold all model variables, making it easy to add the observation to the dataframe.\n",
    "    test = {i[0]:i[1] for i in test}\n",
    "    \n",
    "    # Constructing the dataframe\n",
    "    if a == 0:\n",
    "        parameters = pd.DataFrame(test,index=[re.split('[\\t]',content[a])[0]])\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        parameters.loc[re.split('[\\t]',content[a])[0]] = pd.Series(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"HD_81ace623-e09b-4393-8a5e-131ea8749a35_999\\t{'--activation-inner': 'tanh', '--activation-output': 'softmax', '--batch-norm': '0', '--batch-shuffle': '0', '--batch-size': '21450', '--dropout-ratio': '0.2', '--feature-lags': '0', '--featureset': '1', '--first-layer-neurons': '128', '--label-type': '1', '--learning-rate': '0.0001', '--n-epochs': '150', '--n-layers': '4', '--nn-type': 'lstm', '--pastobs-in-percentage': '1', '--pre-processing': 'quantgau', '--second-layer-neurons': '32'}\\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1001"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['activation-inner', 'sigmoid'],\n",
       " ['activation-output', 'linear'],\n",
       " ['batch-norm', '0'],\n",
       " ['batch-shuffle', '1'],\n",
       " ['batch-size', '21450'],\n",
       " ['dropout-ratio', '0.1'],\n",
       " ['feature-lags', '1'],\n",
       " ['featureset', '1'],\n",
       " ['first-layer-neurons', '64'],\n",
       " ['label-type', '1'],\n",
       " ['learning-rate', '0.1'],\n",
       " ['n-epochs', '150'],\n",
       " ['n-layers', '3'],\n",
       " ['nn-type', 'ffnn'],\n",
       " ['pastobs-in-percentage', '1'],\n",
       " ['pre-processing', 'stacked'],\n",
       " ['second-layer-neurons', '64']]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[re.split(': ',i.strip()) for i in re.split(',',temp_parameters.replace('{','')\\\n",
    "                                                                       .replace('}','')\\\n",
    "                                                                       .replace('\\n','')\\\n",
    "                                                                       .replace('\"','')\\\n",
    "                                                                       .replace('--','')\n",
    "                                                                       .replace('\\'',''))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activation-inner</th>\n",
       "      <th>activation-output</th>\n",
       "      <th>batch-norm</th>\n",
       "      <th>batch-shuffle</th>\n",
       "      <th>batch-size</th>\n",
       "      <th>dropout-ratio</th>\n",
       "      <th>feature-lags</th>\n",
       "      <th>featureset</th>\n",
       "      <th>first-layer-neurons</th>\n",
       "      <th>label-type</th>\n",
       "      <th>learning-rate</th>\n",
       "      <th>n-epochs</th>\n",
       "      <th>n-layers</th>\n",
       "      <th>nn-type</th>\n",
       "      <th>pastobs-in-percentage</th>\n",
       "      <th>pre-processing</th>\n",
       "      <th>second-layer-neurons</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HD_81ace623-e09b-4393-8a5e-131ea8749a35_999</th>\n",
       "      <td>tanh</td>\n",
       "      <td>softmax</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21450</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>150</td>\n",
       "      <td>4</td>\n",
       "      <td>lstm</td>\n",
       "      <td>1</td>\n",
       "      <td>quantgau</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD_81ace623-e09b-4393-8a5e-131ea8749a35_998</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>softmax</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21450</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>150</td>\n",
       "      <td>2</td>\n",
       "      <td>lstm</td>\n",
       "      <td>0</td>\n",
       "      <td>stacked</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD_81ace623-e09b-4393-8a5e-131ea8749a35_997</th>\n",
       "      <td>relu</td>\n",
       "      <td>linear</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10725</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>150</td>\n",
       "      <td>2</td>\n",
       "      <td>lstm</td>\n",
       "      <td>0</td>\n",
       "      <td>pow</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD_81ace623-e09b-4393-8a5e-131ea8749a35_996</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>softmax</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10725</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>150</td>\n",
       "      <td>4</td>\n",
       "      <td>ffnn</td>\n",
       "      <td>1</td>\n",
       "      <td>std</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD_81ace623-e09b-4393-8a5e-131ea8749a35_994</th>\n",
       "      <td>tanh</td>\n",
       "      <td>softmax</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3300</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>150</td>\n",
       "      <td>4</td>\n",
       "      <td>ffnn</td>\n",
       "      <td>1</td>\n",
       "      <td>std</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD_81ace623-e09b-4393-8a5e-131ea8749a35_9</th>\n",
       "      <td>leakyrelu</td>\n",
       "      <td>linear</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3300</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>150</td>\n",
       "      <td>3</td>\n",
       "      <td>ffnn</td>\n",
       "      <td>1</td>\n",
       "      <td>pow</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD_81ace623-e09b-4393-8a5e-131ea8749a35_7</th>\n",
       "      <td>tanh</td>\n",
       "      <td>linear</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10725</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>ffnn</td>\n",
       "      <td>1</td>\n",
       "      <td>minmax</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD_81ace623-e09b-4393-8a5e-131ea8749a35_5</th>\n",
       "      <td>leakyrelu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>21450</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>150</td>\n",
       "      <td>2</td>\n",
       "      <td>lstm</td>\n",
       "      <td>0</td>\n",
       "      <td>quantgau</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD_81ace623-e09b-4393-8a5e-131ea8749a35_6</th>\n",
       "      <td>relu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21450</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>0.001</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>lstm</td>\n",
       "      <td>0</td>\n",
       "      <td>stacked</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD_81ace623-e09b-4393-8a5e-131ea8749a35_1</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>linear</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21450</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>150</td>\n",
       "      <td>3</td>\n",
       "      <td>ffnn</td>\n",
       "      <td>1</td>\n",
       "      <td>stacked</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            activation-inner  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999             tanh   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_998          sigmoid   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_997             relu   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_996          sigmoid   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_994             tanh   \n",
       "...                                                      ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_9          leakyrelu   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_7               tanh   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_5          leakyrelu   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_6               relu   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_1            sigmoid   \n",
       "\n",
       "                                            activation-output batch-norm  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999           softmax          0   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_998           softmax          0   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_997            linear          1   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_996           softmax          1   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_994           softmax          1   \n",
       "...                                                       ...        ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_9              linear          0   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_7              linear          0   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_5             softmax          1   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_6             softmax          0   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_1              linear          0   \n",
       "\n",
       "                                            batch-shuffle batch-size  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999             0      21450   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_998             0      21450   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_997             1      10725   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_996             1      10725   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_994             1       3300   \n",
       "...                                                   ...        ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_9               1       3300   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_7               1      10725   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_5               1      21450   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_6               0      21450   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_1               1      21450   \n",
       "\n",
       "                                            dropout-ratio feature-lags  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999           0.2            0   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_998           0.3            5   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_997           0.5            3   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_996             0            3   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_994           0.2            1   \n",
       "...                                                   ...          ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_9             0.4            0   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_7             0.1            3   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_5             0.5            3   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_6             0.2            1   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_1             0.1            1   \n",
       "\n",
       "                                            featureset first-layer-neurons  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999          1                 128   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_998          3                 128   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_997          2                  64   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_996          0                  64   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_994          0                 128   \n",
       "...                                                ...                 ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_9            3                 128   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_7            0                  64   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_5            3                 128   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_6            1                  32   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_1            1                  64   \n",
       "\n",
       "                                            label-type learning-rate n-epochs  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999          1        0.0001      150   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_998          2         0.001      150   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_997          3        0.0001      150   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_996          1          0.01      150   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_994          1        0.0001      150   \n",
       "...                                                ...           ...      ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_9            2           0.1      150   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_7            0        0.0001      150   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_5            2          0.01      150   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_6            4         0.001      150   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_1            1           0.1      150   \n",
       "\n",
       "                                            n-layers nn-type  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999        4    lstm   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_998        2    lstm   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_997        2    lstm   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_996        4    ffnn   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_994        4    ffnn   \n",
       "...                                              ...     ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_9          3    ffnn   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_7          1    ffnn   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_5          2    lstm   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_6          1    lstm   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_1          3    ffnn   \n",
       "\n",
       "                                            pastobs-in-percentage  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999                     1   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_998                     0   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_997                     0   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_996                     1   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_994                     1   \n",
       "...                                                           ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_9                       1   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_7                       1   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_5                       0   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_6                       0   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_1                       1   \n",
       "\n",
       "                                            pre-processing  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999       quantgau   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_998        stacked   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_997            pow   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_996            std   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_994            std   \n",
       "...                                                    ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_9              pow   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_7           minmax   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_5         quantgau   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_6          stacked   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_1          stacked   \n",
       "\n",
       "                                            second-layer-neurons  \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999                   32  \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_998                   64  \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_997                   64  \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_996                   64  \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_994                  128  \n",
       "...                                                          ...  \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_9                     32  \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_7                    128  \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_5                    128  \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_6                     32  \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_1                     64  \n",
       "\n",
       "[1000 rows x 17 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "activation-inner         sigmoid\n",
       "activation-output        softmax\n",
       "batch-norm                     1\n",
       "batch-shuffle                  1\n",
       "batch-size                 10725\n",
       "dropout-ratio                0.1\n",
       "feature-lags                   3\n",
       "featureset                     3\n",
       "first-layer-neurons          128\n",
       "label-type                     2\n",
       "learning-rate               0.01\n",
       "n-epochs                     150\n",
       "n-layers                       4\n",
       "nn-type                     lstm\n",
       "pastobs-in-percentage          0\n",
       "pre-processing               std\n",
       "second-layer-neurons          32\n",
       "Name: HD_81ace623-e09b-4393-8a5e-131ea8749a35_883, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters.iloc[115,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Readidng in the file\n",
    "with open('../AzureML/Output_from_cloud/'+metricfiles_nn[-1],'r') as file:\n",
    "    content = file.readlines()\n",
    "\n",
    "## Containers\n",
    "t11 = []\n",
    "t12 = []\n",
    "t13 = []\n",
    "\n",
    "t21 = []\n",
    "t22 = []\n",
    "t23 = []\n",
    "\n",
    "## Going over each line\n",
    "for i in np.arange(len(content)):#\n",
    "    \n",
    "    ## Split each line on tabs\n",
    "    temp = re.split('\\t',content[i].replace('\\n',''))\n",
    "    \n",
    "    #print(temp)\n",
    "    \n",
    "    ## There are two types of observations in the text file; 1. final metrics of those models which where not stoppe early\n",
    "    ## and 2. a time series of a metric for each model.\n",
    "    \n",
    "    ## If the length of the last element, in a line, is less than 50 (because it is just a number, i.e. final metric)\n",
    "    ## It stored separately for the time series.\n",
    "    if len(temp[2]) < 50:\n",
    "\n",
    "        t11.append(temp[0])\n",
    "        t12.append(temp[1])\n",
    "        t13.append(temp[2])\n",
    "    \n",
    "    ## Time series\n",
    "    else:\n",
    "    \n",
    "        container = np.zeros(155)\n",
    "        temp1 = [float(j.strip()) if j.strip() !=\"'NaN'\" else 0 for j in re.split(',',temp[2].replace('[','').replace(']',''))]\n",
    "\n",
    "        container[0:len(temp1)] = temp1\n",
    "        container[len(temp1):] = temp1[-1]\n",
    "\n",
    "        t21.append(temp[0])\n",
    "        t22.append(temp[1])\n",
    "        t23.append(container)        \n",
    "\n",
    "## Storing the time series in a dataframe\n",
    "arrays = [t21,t22]\n",
    "tuples = list(zip(*arrays))\n",
    "\n",
    "runningMetrics = pd.DataFrame(np.array(t23),\n",
    "                              index=pd.MultiIndex.from_tuples(tuples),\n",
    "                              columns = [np.arange(155).astype(str)]\n",
    "                             )\n",
    "## Storing the final metrics in a dataframe.\n",
    "arrays = [t11,t12]\n",
    "tuples = list(zip(*arrays))\n",
    "finalMetrics = pd.DataFrame(t13,index = pd.MultiIndex.from_tuples(tuples),columns = ['size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">HD_81ace623-e09b-4393-8a5e-131ea8749a35_998</th>\n",
       "      <th>Final test loss</th>\n",
       "      <td>0.8833522492045336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Final test AUC</th>\n",
       "      <td>0.7648658156394958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Final test accuracy</th>\n",
       "      <td>0.6109746098518372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">HD_81ace623-e09b-4393-8a5e-131ea8749a35_996</th>\n",
       "      <th>Final test loss</th>\n",
       "      <td>1.1133369887535414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Final test AUC</th>\n",
       "      <td>0.640163779258728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">HD_81ace623-e09b-4393-8a5e-131ea8749a35_5</th>\n",
       "      <th>Final test AUC</th>\n",
       "      <td>0.7837895154953003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Final test accuracy</th>\n",
       "      <td>0.602816104888916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">HD_81ace623-e09b-4393-8a5e-131ea8749a35_6</th>\n",
       "      <th>Final test loss</th>\n",
       "      <td>1.3713646207894699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Final test AUC</th>\n",
       "      <td>0.7241190671920776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Final test accuracy</th>\n",
       "      <td>0.4148908853530884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1170 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                               size\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_998 Final test loss      0.8833522492045336\n",
       "                                            Final test AUC       0.7648658156394958\n",
       "                                            Final test accuracy  0.6109746098518372\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_996 Final test loss      1.1133369887535414\n",
       "                                            Final test AUC        0.640163779258728\n",
       "...                                                                             ...\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_5   Final test AUC       0.7837895154953003\n",
       "                                            Final test accuracy   0.602816104888916\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_6   Final test loss      1.3713646207894699\n",
       "                                            Final test AUC       0.7241190671920776\n",
       "                                            Final test accuracy  0.4148908853530884\n",
       "\n",
       "[1170 rows x 1 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">HD_81ace623-e09b-4393-8a5e-131ea8749a35_116</th>\n",
       "      <th>Final test loss</th>\n",
       "      <td>0.6772750117269136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Final test AUC</th>\n",
       "      <td>0.5715229511260986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Final test accuracy</th>\n",
       "      <td>0.5456066727638245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">HD_81ace623-e09b-4393-8a5e-131ea8749a35_115</th>\n",
       "      <th>Final test loss</th>\n",
       "      <td>1.052469070279928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Final test AUC</th>\n",
       "      <td>0.6014689207077026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Final test accuracy</th>\n",
       "      <td>0.42372506856918335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                size\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_116 Final test loss       0.6772750117269136\n",
       "                                            Final test AUC        0.5715229511260986\n",
       "                                            Final test accuracy   0.5456066727638245\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_115 Final test loss        1.052469070279928\n",
       "                                            Final test AUC        0.6014689207077026\n",
       "                                            Final test accuracy  0.42372506856918335"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalMetrics.iloc[957:963,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1170, 1)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalMetrics.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "      <th>150</th>\n",
       "      <th>151</th>\n",
       "      <th>152</th>\n",
       "      <th>153</th>\n",
       "      <th>154</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">HD_81ace623-e09b-4393-8a5e-131ea8749a35_999</th>\n",
       "      <th>Loss</th>\n",
       "      <td>1.098537</td>\n",
       "      <td>1.098504</td>\n",
       "      <td>1.098467</td>\n",
       "      <td>1.098423</td>\n",
       "      <td>1.098371</td>\n",
       "      <td>1.098309</td>\n",
       "      <td>1.098233</td>\n",
       "      <td>1.098140</td>\n",
       "      <td>1.098026</td>\n",
       "      <td>1.097886</td>\n",
       "      <td>...</td>\n",
       "      <td>1.066601</td>\n",
       "      <td>1.066601</td>\n",
       "      <td>1.066601</td>\n",
       "      <td>1.066601</td>\n",
       "      <td>1.066601</td>\n",
       "      <td>1.066601</td>\n",
       "      <td>1.066601</td>\n",
       "      <td>1.066601</td>\n",
       "      <td>1.066601</td>\n",
       "      <td>1.066601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.354843</td>\n",
       "      <td>0.358482</td>\n",
       "      <td>0.362843</td>\n",
       "      <td>0.365199</td>\n",
       "      <td>0.366960</td>\n",
       "      <td>0.367240</td>\n",
       "      <td>0.368826</td>\n",
       "      <td>0.370377</td>\n",
       "      <td>0.371579</td>\n",
       "      <td>0.372220</td>\n",
       "      <td>...</td>\n",
       "      <td>0.412316</td>\n",
       "      <td>0.412316</td>\n",
       "      <td>0.412316</td>\n",
       "      <td>0.412316</td>\n",
       "      <td>0.412316</td>\n",
       "      <td>0.412316</td>\n",
       "      <td>0.412316</td>\n",
       "      <td>0.412316</td>\n",
       "      <td>0.412316</td>\n",
       "      <td>0.412316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC</th>\n",
       "      <td>0.500120</td>\n",
       "      <td>0.500277</td>\n",
       "      <td>0.500545</td>\n",
       "      <td>0.501018</td>\n",
       "      <td>0.501737</td>\n",
       "      <td>0.502806</td>\n",
       "      <td>0.504301</td>\n",
       "      <td>0.506150</td>\n",
       "      <td>0.508213</td>\n",
       "      <td>0.510308</td>\n",
       "      <td>...</td>\n",
       "      <td>0.575838</td>\n",
       "      <td>0.575838</td>\n",
       "      <td>0.575838</td>\n",
       "      <td>0.575838</td>\n",
       "      <td>0.575838</td>\n",
       "      <td>0.575838</td>\n",
       "      <td>0.575838</td>\n",
       "      <td>0.575838</td>\n",
       "      <td>0.575838</td>\n",
       "      <td>0.575838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Loss</th>\n",
       "      <td>1.098558</td>\n",
       "      <td>1.098524</td>\n",
       "      <td>1.098487</td>\n",
       "      <td>1.098442</td>\n",
       "      <td>1.098396</td>\n",
       "      <td>1.098339</td>\n",
       "      <td>1.098267</td>\n",
       "      <td>1.098180</td>\n",
       "      <td>1.098077</td>\n",
       "      <td>1.097955</td>\n",
       "      <td>...</td>\n",
       "      <td>1.068791</td>\n",
       "      <td>1.068791</td>\n",
       "      <td>1.068791</td>\n",
       "      <td>1.068791</td>\n",
       "      <td>1.068791</td>\n",
       "      <td>1.068791</td>\n",
       "      <td>1.068791</td>\n",
       "      <td>1.068791</td>\n",
       "      <td>1.068791</td>\n",
       "      <td>1.068791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Accuracy</th>\n",
       "      <td>0.344181</td>\n",
       "      <td>0.350251</td>\n",
       "      <td>0.353537</td>\n",
       "      <td>0.358348</td>\n",
       "      <td>0.360740</td>\n",
       "      <td>0.363537</td>\n",
       "      <td>0.365985</td>\n",
       "      <td>0.368336</td>\n",
       "      <td>0.368998</td>\n",
       "      <td>0.369959</td>\n",
       "      <td>...</td>\n",
       "      <td>0.412060</td>\n",
       "      <td>0.412060</td>\n",
       "      <td>0.412060</td>\n",
       "      <td>0.412060</td>\n",
       "      <td>0.412060</td>\n",
       "      <td>0.412060</td>\n",
       "      <td>0.412060</td>\n",
       "      <td>0.412060</td>\n",
       "      <td>0.412060</td>\n",
       "      <td>0.412060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">HD_81ace623-e09b-4393-8a5e-131ea8749a35_1</th>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>...</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC</th>\n",
       "      <td>0.006679</td>\n",
       "      <td>0.003153</td>\n",
       "      <td>0.002064</td>\n",
       "      <td>0.001534</td>\n",
       "      <td>0.001221</td>\n",
       "      <td>0.001014</td>\n",
       "      <td>0.000867</td>\n",
       "      <td>0.000757</td>\n",
       "      <td>0.000672</td>\n",
       "      <td>0.000604</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.000113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Loss</th>\n",
       "      <td>5.383223</td>\n",
       "      <td>5.355752</td>\n",
       "      <td>5.355751</td>\n",
       "      <td>5.355751</td>\n",
       "      <td>5.355751</td>\n",
       "      <td>5.355750</td>\n",
       "      <td>5.355750</td>\n",
       "      <td>5.355750</td>\n",
       "      <td>5.355750</td>\n",
       "      <td>5.355750</td>\n",
       "      <td>...</td>\n",
       "      <td>5.355750</td>\n",
       "      <td>5.355750</td>\n",
       "      <td>5.355750</td>\n",
       "      <td>5.355750</td>\n",
       "      <td>5.355750</td>\n",
       "      <td>5.355750</td>\n",
       "      <td>5.355750</td>\n",
       "      <td>5.355750</td>\n",
       "      <td>5.355750</td>\n",
       "      <td>5.355750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Accuracy</th>\n",
       "      <td>0.333057</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>...</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>0.332281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train AUC</th>\n",
       "      <td>0.030584</td>\n",
       "      <td>0.004384</td>\n",
       "      <td>0.002511</td>\n",
       "      <td>0.001766</td>\n",
       "      <td>0.001362</td>\n",
       "      <td>0.001109</td>\n",
       "      <td>0.000935</td>\n",
       "      <td>0.000809</td>\n",
       "      <td>0.000712</td>\n",
       "      <td>0.000636</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6000 rows × 155 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   0  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999 Loss            1.098537   \n",
       "                                            Accuracy        0.354843   \n",
       "                                            AUC             0.500120   \n",
       "                                            Train Loss      1.098558   \n",
       "                                            Train Accuracy  0.344181   \n",
       "...                                                              ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_1   Accuracy        0.337729   \n",
       "                                            AUC             0.006679   \n",
       "                                            Train Loss      5.383223   \n",
       "                                            Train Accuracy  0.333057   \n",
       "                                            Train AUC       0.030584   \n",
       "\n",
       "                                                                   1  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999 Loss            1.098504   \n",
       "                                            Accuracy        0.358482   \n",
       "                                            AUC             0.500277   \n",
       "                                            Train Loss      1.098524   \n",
       "                                            Train Accuracy  0.350251   \n",
       "...                                                              ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_1   Accuracy        0.337729   \n",
       "                                            AUC             0.003153   \n",
       "                                            Train Loss      5.355752   \n",
       "                                            Train Accuracy  0.332281   \n",
       "                                            Train AUC       0.004384   \n",
       "\n",
       "                                                                   2  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999 Loss            1.098467   \n",
       "                                            Accuracy        0.362843   \n",
       "                                            AUC             0.500545   \n",
       "                                            Train Loss      1.098487   \n",
       "                                            Train Accuracy  0.353537   \n",
       "...                                                              ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_1   Accuracy        0.337729   \n",
       "                                            AUC             0.002064   \n",
       "                                            Train Loss      5.355751   \n",
       "                                            Train Accuracy  0.332281   \n",
       "                                            Train AUC       0.002511   \n",
       "\n",
       "                                                                   3  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999 Loss            1.098423   \n",
       "                                            Accuracy        0.365199   \n",
       "                                            AUC             0.501018   \n",
       "                                            Train Loss      1.098442   \n",
       "                                            Train Accuracy  0.358348   \n",
       "...                                                              ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_1   Accuracy        0.337729   \n",
       "                                            AUC             0.001534   \n",
       "                                            Train Loss      5.355751   \n",
       "                                            Train Accuracy  0.332281   \n",
       "                                            Train AUC       0.001766   \n",
       "\n",
       "                                                                   4  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999 Loss            1.098371   \n",
       "                                            Accuracy        0.366960   \n",
       "                                            AUC             0.501737   \n",
       "                                            Train Loss      1.098396   \n",
       "                                            Train Accuracy  0.360740   \n",
       "...                                                              ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_1   Accuracy        0.337729   \n",
       "                                            AUC             0.001221   \n",
       "                                            Train Loss      5.355751   \n",
       "                                            Train Accuracy  0.332281   \n",
       "                                            Train AUC       0.001362   \n",
       "\n",
       "                                                                   5  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999 Loss            1.098309   \n",
       "                                            Accuracy        0.367240   \n",
       "                                            AUC             0.502806   \n",
       "                                            Train Loss      1.098339   \n",
       "                                            Train Accuracy  0.363537   \n",
       "...                                                              ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_1   Accuracy        0.337729   \n",
       "                                            AUC             0.001014   \n",
       "                                            Train Loss      5.355750   \n",
       "                                            Train Accuracy  0.332281   \n",
       "                                            Train AUC       0.001109   \n",
       "\n",
       "                                                                   6  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999 Loss            1.098233   \n",
       "                                            Accuracy        0.368826   \n",
       "                                            AUC             0.504301   \n",
       "                                            Train Loss      1.098267   \n",
       "                                            Train Accuracy  0.365985   \n",
       "...                                                              ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_1   Accuracy        0.337729   \n",
       "                                            AUC             0.000867   \n",
       "                                            Train Loss      5.355750   \n",
       "                                            Train Accuracy  0.332281   \n",
       "                                            Train AUC       0.000935   \n",
       "\n",
       "                                                                   7  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999 Loss            1.098140   \n",
       "                                            Accuracy        0.370377   \n",
       "                                            AUC             0.506150   \n",
       "                                            Train Loss      1.098180   \n",
       "                                            Train Accuracy  0.368336   \n",
       "...                                                              ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_1   Accuracy        0.337729   \n",
       "                                            AUC             0.000757   \n",
       "                                            Train Loss      5.355750   \n",
       "                                            Train Accuracy  0.332281   \n",
       "                                            Train AUC       0.000809   \n",
       "\n",
       "                                                                   8  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999 Loss            1.098026   \n",
       "                                            Accuracy        0.371579   \n",
       "                                            AUC             0.508213   \n",
       "                                            Train Loss      1.098077   \n",
       "                                            Train Accuracy  0.368998   \n",
       "...                                                              ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_1   Accuracy        0.337729   \n",
       "                                            AUC             0.000672   \n",
       "                                            Train Loss      5.355750   \n",
       "                                            Train Accuracy  0.332281   \n",
       "                                            Train AUC       0.000712   \n",
       "\n",
       "                                                                   9  ...  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999 Loss            1.097886  ...   \n",
       "                                            Accuracy        0.372220  ...   \n",
       "                                            AUC             0.510308  ...   \n",
       "                                            Train Loss      1.097955  ...   \n",
       "                                            Train Accuracy  0.369959  ...   \n",
       "...                                                              ...  ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_1   Accuracy        0.337729  ...   \n",
       "                                            AUC             0.000604  ...   \n",
       "                                            Train Loss      5.355750  ...   \n",
       "                                            Train Accuracy  0.332281  ...   \n",
       "                                            Train AUC       0.000636  ...   \n",
       "\n",
       "                                                                 145  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999 Loss            1.066601   \n",
       "                                            Accuracy        0.412316   \n",
       "                                            AUC             0.575838   \n",
       "                                            Train Loss      1.068791   \n",
       "                                            Train Accuracy  0.412060   \n",
       "...                                                              ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_1   Accuracy        0.337729   \n",
       "                                            AUC             0.000113   \n",
       "                                            Train Loss      5.355750   \n",
       "                                            Train Accuracy  0.332281   \n",
       "                                            Train AUC       0.000114   \n",
       "\n",
       "                                                                 146  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999 Loss            1.066601   \n",
       "                                            Accuracy        0.412316   \n",
       "                                            AUC             0.575838   \n",
       "                                            Train Loss      1.068791   \n",
       "                                            Train Accuracy  0.412060   \n",
       "...                                                              ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_1   Accuracy        0.337729   \n",
       "                                            AUC             0.000113   \n",
       "                                            Train Loss      5.355750   \n",
       "                                            Train Accuracy  0.332281   \n",
       "                                            Train AUC       0.000114   \n",
       "\n",
       "                                                                 147  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999 Loss            1.066601   \n",
       "                                            Accuracy        0.412316   \n",
       "                                            AUC             0.575838   \n",
       "                                            Train Loss      1.068791   \n",
       "                                            Train Accuracy  0.412060   \n",
       "...                                                              ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_1   Accuracy        0.337729   \n",
       "                                            AUC             0.000113   \n",
       "                                            Train Loss      5.355750   \n",
       "                                            Train Accuracy  0.332281   \n",
       "                                            Train AUC       0.000114   \n",
       "\n",
       "                                                                 148  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999 Loss            1.066601   \n",
       "                                            Accuracy        0.412316   \n",
       "                                            AUC             0.575838   \n",
       "                                            Train Loss      1.068791   \n",
       "                                            Train Accuracy  0.412060   \n",
       "...                                                              ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_1   Accuracy        0.337729   \n",
       "                                            AUC             0.000113   \n",
       "                                            Train Loss      5.355750   \n",
       "                                            Train Accuracy  0.332281   \n",
       "                                            Train AUC       0.000114   \n",
       "\n",
       "                                                                 149  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999 Loss            1.066601   \n",
       "                                            Accuracy        0.412316   \n",
       "                                            AUC             0.575838   \n",
       "                                            Train Loss      1.068791   \n",
       "                                            Train Accuracy  0.412060   \n",
       "...                                                              ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_1   Accuracy        0.337729   \n",
       "                                            AUC             0.000113   \n",
       "                                            Train Loss      5.355750   \n",
       "                                            Train Accuracy  0.332281   \n",
       "                                            Train AUC       0.000114   \n",
       "\n",
       "                                                                 150  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999 Loss            1.066601   \n",
       "                                            Accuracy        0.412316   \n",
       "                                            AUC             0.575838   \n",
       "                                            Train Loss      1.068791   \n",
       "                                            Train Accuracy  0.412060   \n",
       "...                                                              ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_1   Accuracy        0.337729   \n",
       "                                            AUC             0.000113   \n",
       "                                            Train Loss      5.355750   \n",
       "                                            Train Accuracy  0.332281   \n",
       "                                            Train AUC       0.000114   \n",
       "\n",
       "                                                                 151  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999 Loss            1.066601   \n",
       "                                            Accuracy        0.412316   \n",
       "                                            AUC             0.575838   \n",
       "                                            Train Loss      1.068791   \n",
       "                                            Train Accuracy  0.412060   \n",
       "...                                                              ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_1   Accuracy        0.337729   \n",
       "                                            AUC             0.000113   \n",
       "                                            Train Loss      5.355750   \n",
       "                                            Train Accuracy  0.332281   \n",
       "                                            Train AUC       0.000114   \n",
       "\n",
       "                                                                 152  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999 Loss            1.066601   \n",
       "                                            Accuracy        0.412316   \n",
       "                                            AUC             0.575838   \n",
       "                                            Train Loss      1.068791   \n",
       "                                            Train Accuracy  0.412060   \n",
       "...                                                              ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_1   Accuracy        0.337729   \n",
       "                                            AUC             0.000113   \n",
       "                                            Train Loss      5.355750   \n",
       "                                            Train Accuracy  0.332281   \n",
       "                                            Train AUC       0.000114   \n",
       "\n",
       "                                                                 153       154  \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999 Loss            1.066601  1.066601  \n",
       "                                            Accuracy        0.412316  0.412316  \n",
       "                                            AUC             0.575838  0.575838  \n",
       "                                            Train Loss      1.068791  1.068791  \n",
       "                                            Train Accuracy  0.412060  0.412060  \n",
       "...                                                              ...       ...  \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_1   Accuracy        0.337729  0.337729  \n",
       "                                            AUC             0.000113  0.000113  \n",
       "                                            Train Loss      5.355750  5.355750  \n",
       "                                            Train Accuracy  0.332281  0.332281  \n",
       "                                            Train AUC       0.000114  0.000114  \n",
       "\n",
       "[6000 rows x 155 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runningMetrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attaching the last observation of each model, for each metric, to the parameters of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>activation-inner</th>\n",
       "      <th>activation-output</th>\n",
       "      <th>batch-norm</th>\n",
       "      <th>batch-shuffle</th>\n",
       "      <th>batch-size</th>\n",
       "      <th>dropout-ratio</th>\n",
       "      <th>feature-lags</th>\n",
       "      <th>featureset</th>\n",
       "      <th>first-layer-neurons</th>\n",
       "      <th>...</th>\n",
       "      <th>pastobs-in-percentage</th>\n",
       "      <th>pre-processing</th>\n",
       "      <th>second-layer-neurons</th>\n",
       "      <th>id</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Train AUC</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Train Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_883</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>softmax</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10725</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>std</td>\n",
       "      <td>32</td>\n",
       "      <td>883</td>\n",
       "      <td>0.80363</td>\n",
       "      <td>0.58075</td>\n",
       "      <td>0.98257</td>\n",
       "      <td>0.80358</td>\n",
       "      <td>0.66548</td>\n",
       "      <td>0.77074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_218</td>\n",
       "      <td>tanh</td>\n",
       "      <td>softmax</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>21450</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>pow</td>\n",
       "      <td>32</td>\n",
       "      <td>218</td>\n",
       "      <td>0.79064</td>\n",
       "      <td>0.57710</td>\n",
       "      <td>0.99908</td>\n",
       "      <td>0.79060</td>\n",
       "      <td>0.65135</td>\n",
       "      <td>0.80627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_5</td>\n",
       "      <td>leakyrelu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>21450</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>quantgau</td>\n",
       "      <td>128</td>\n",
       "      <td>5</td>\n",
       "      <td>0.78380</td>\n",
       "      <td>0.60282</td>\n",
       "      <td>0.90322</td>\n",
       "      <td>0.78376</td>\n",
       "      <td>0.62677</td>\n",
       "      <td>0.84667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_72</td>\n",
       "      <td>tanh</td>\n",
       "      <td>softmax</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3300</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>stacked</td>\n",
       "      <td>64</td>\n",
       "      <td>72</td>\n",
       "      <td>0.78185</td>\n",
       "      <td>0.61228</td>\n",
       "      <td>0.89609</td>\n",
       "      <td>0.78181</td>\n",
       "      <td>0.62734</td>\n",
       "      <td>0.84895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_871</td>\n",
       "      <td>tanh</td>\n",
       "      <td>softmax</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10725</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>quantgau</td>\n",
       "      <td>32</td>\n",
       "      <td>871</td>\n",
       "      <td>0.78175</td>\n",
       "      <td>0.60582</td>\n",
       "      <td>0.92492</td>\n",
       "      <td>0.78172</td>\n",
       "      <td>0.62636</td>\n",
       "      <td>0.85098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_185</td>\n",
       "      <td>relu</td>\n",
       "      <td>linear</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3300</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>128</td>\n",
       "      <td>185</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.19641</td>\n",
       "      <td>0.94736</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.19952</td>\n",
       "      <td>0.95143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_695</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>linear</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3300</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>quantgau</td>\n",
       "      <td>128</td>\n",
       "      <td>695</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.19329</td>\n",
       "      <td>0.89643</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.18706</td>\n",
       "      <td>0.91432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_803</td>\n",
       "      <td>tanh</td>\n",
       "      <td>linear</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21450</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>minmax</td>\n",
       "      <td>32</td>\n",
       "      <td>803</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.45457</td>\n",
       "      <td>0.68465</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.45333</td>\n",
       "      <td>0.68717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_137</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>linear</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10725</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>stacked</td>\n",
       "      <td>64</td>\n",
       "      <td>137</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.16547</td>\n",
       "      <td>1.59072</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.17433</td>\n",
       "      <td>1.59977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_677</td>\n",
       "      <td>relu</td>\n",
       "      <td>linear</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10725</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>64</td>\n",
       "      <td>677</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.19750</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.19989</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          run_id activation-inner  \\\n",
       "115  HD_81ace623-e09b-4393-8a5e-131ea8749a35_883          sigmoid   \n",
       "781  HD_81ace623-e09b-4393-8a5e-131ea8749a35_218             tanh   \n",
       "997    HD_81ace623-e09b-4393-8a5e-131ea8749a35_5        leakyrelu   \n",
       "928   HD_81ace623-e09b-4393-8a5e-131ea8749a35_72             tanh   \n",
       "128  HD_81ace623-e09b-4393-8a5e-131ea8749a35_871             tanh   \n",
       "..                                           ...              ...   \n",
       "814  HD_81ace623-e09b-4393-8a5e-131ea8749a35_185             relu   \n",
       "304  HD_81ace623-e09b-4393-8a5e-131ea8749a35_695          sigmoid   \n",
       "195  HD_81ace623-e09b-4393-8a5e-131ea8749a35_803             tanh   \n",
       "861  HD_81ace623-e09b-4393-8a5e-131ea8749a35_137          sigmoid   \n",
       "321  HD_81ace623-e09b-4393-8a5e-131ea8749a35_677             relu   \n",
       "\n",
       "    activation-output batch-norm batch-shuffle batch-size dropout-ratio  \\\n",
       "115           softmax          1             1      10725           0.1   \n",
       "781           softmax          1             0      21450             0   \n",
       "997           softmax          1             1      21450           0.5   \n",
       "928           softmax          1             1       3300           0.2   \n",
       "128           softmax          1             1      10725             0   \n",
       "..                ...        ...           ...        ...           ...   \n",
       "814            linear          0             1       3300           0.3   \n",
       "304            linear          0             0       3300           0.1   \n",
       "195            linear          0             0      21450           0.3   \n",
       "861            linear          0             1      10725           0.5   \n",
       "321            linear          0             1      10725           0.5   \n",
       "\n",
       "    feature-lags featureset first-layer-neurons  ... pastobs-in-percentage  \\\n",
       "115            3          3                 128  ...                     0   \n",
       "781            5          1                  64  ...                     0   \n",
       "997            3          3                 128  ...                     0   \n",
       "928            3          3                 128  ...                     1   \n",
       "128            3          0                 128  ...                     0   \n",
       "..           ...        ...                 ...  ...                   ...   \n",
       "814            5          3                 128  ...                     1   \n",
       "304            1          3                  64  ...                     1   \n",
       "195            3          0                  32  ...                     1   \n",
       "861            5          3                 128  ...                     0   \n",
       "321            3          2                  64  ...                     0   \n",
       "\n",
       "    pre-processing second-layer-neurons   id      AUC Accuracy     Loss  \\\n",
       "115            std                   32  883  0.80363  0.58075  0.98257   \n",
       "781            pow                   32  218  0.79064  0.57710  0.99908   \n",
       "997       quantgau                  128    5  0.78380  0.60282  0.90322   \n",
       "928        stacked                   64   72  0.78185  0.61228  0.89609   \n",
       "128       quantgau                   32  871  0.78175  0.60582  0.92492   \n",
       "..             ...                  ...  ...      ...      ...      ...   \n",
       "814           None                  128  185  0.00000  0.19641  0.94736   \n",
       "304       quantgau                  128  695  0.00000  0.19329  0.89643   \n",
       "195         minmax                   32  803  0.00000  0.45457  0.68465   \n",
       "861        stacked                   64  137  0.00000  0.16547  1.59072   \n",
       "321           None                   64  677  0.00000  0.19750  0.00000   \n",
       "\n",
       "    Train AUC Train Accuracy  Train Loss  \n",
       "115   0.80358        0.66548     0.77074  \n",
       "781   0.79060        0.65135     0.80627  \n",
       "997   0.78376        0.62677     0.84667  \n",
       "928   0.78181        0.62734     0.84895  \n",
       "128   0.78172        0.62636     0.85098  \n",
       "..        ...            ...         ...  \n",
       "814   0.00000        0.19952     0.95143  \n",
       "304   0.00000        0.18706     0.91432  \n",
       "195   0.00000        0.45333     0.68717  \n",
       "861   0.00000        0.17433     1.59977  \n",
       "321   0.00000        0.19989     0.00000  \n",
       "\n",
       "[1000 rows x 25 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Resetting indcies and rename columns\n",
    "runningMetrics = runningMetrics.reset_index().rename(columns={'level_0':'run_id','level_1':'metric'})\n",
    "runningMetrics.columns = runningMetrics.columns.get_level_values(0)\n",
    "\n",
    "## Adding a column of short ids, to merge on.\n",
    "runningMetrics['id'] = [re.split('_',i)[-1] for i in runningMetrics.run_id]\n",
    "\n",
    "## Creating a table, having the short id in the rows and the last observation for each metric in the columns. \n",
    "table = pd.pivot_table(runningMetrics[['run_id','metric','154','id']],index='id',columns=['metric'])\n",
    "table.columns = table.columns.get_level_values(1)\n",
    "table = table.round(5).reset_index()\n",
    "\n",
    "## Preparing the parameter dataframe.\n",
    "parameters = parameters.reset_index().rename(columns={'index':'run_id'})\n",
    "\n",
    "## Setting short ID\n",
    "parameters['id'] = [re.split('_',i)[-1] for i in parameters.run_id]\n",
    "\n",
    "## Creating the combined table\n",
    "combined_table = parameters.merge(table,\n",
    "                                     on = 'id',\n",
    "                                     how='left').sort_values('AUC',ascending=False)\n",
    "combined_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2099f20abc8>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "runningMetrics[(runningMetrics.metric=='Accuracy')&\\\n",
    "               (np.isin(runningMetrics.id,parameters[parameters['label-type']=='2'].id.values))].sort_values('154')['154'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating a top-X table for each label-type of a given metric, here AUC.\n",
    "temp_auc = pd.pivot_table(combined_table[['label-type','AUC','id']],index='id',columns='label-type')\n",
    "temp_acc = pd.pivot_table(combined_table[['label-type','Accuracy','id']],index='id',columns='label-type')\n",
    "\n",
    "## Final output - AUC\n",
    "final_output_auc = pd.DataFrame(np.sort(temp_auc.fillna(0).values,\n",
    "                             axis=0)[::-1],\n",
    "                             columns=temp_auc.columns.get_level_values(1)).loc[0:10]\n",
    "## Final output - Accuracy\n",
    "final_output_acc = pd.DataFrame(np.sort(temp_acc.fillna(0).values,\n",
    "                             axis=0)[::-1],\n",
    "                             columns=temp_acc.columns.get_level_values(1))#.loc[0:10]\n",
    "# final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['run_id',\n",
       " 'activation-inner',\n",
       " 'activation-output',\n",
       " 'batch-norm',\n",
       " 'batch-shuffle',\n",
       " 'batch-size',\n",
       " 'dropout-ratio',\n",
       " 'feature-lags',\n",
       " 'featureset',\n",
       " 'first-layer-neurons',\n",
       " 'label-type',\n",
       " 'learning-rate',\n",
       " 'n-epochs',\n",
       " 'n-layers',\n",
       " 'nn-type',\n",
       " 'pastobs-in-percentage',\n",
       " 'pre-processing',\n",
       " 'second-layer-neurons',\n",
       " 'id',\n",
       " 'AUC',\n",
       " 'Accuracy',\n",
       " 'Loss',\n",
       " 'Train AUC',\n",
       " 'Train Accuracy',\n",
       " 'Train Loss']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(combined_table.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>activation-inner</th>\n",
       "      <th>activation-output</th>\n",
       "      <th>batch-norm</th>\n",
       "      <th>batch-shuffle</th>\n",
       "      <th>batch-size</th>\n",
       "      <th>dropout-ratio</th>\n",
       "      <th>feature-lags</th>\n",
       "      <th>featureset</th>\n",
       "      <th>first-layer-neurons</th>\n",
       "      <th>...</th>\n",
       "      <th>pastobs-in-percentage</th>\n",
       "      <th>pre-processing</th>\n",
       "      <th>second-layer-neurons</th>\n",
       "      <th>id</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Train AUC</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Train Loss</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label-type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_883</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>softmax</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10725</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>std</td>\n",
       "      <td>32</td>\n",
       "      <td>883</td>\n",
       "      <td>0.80363</td>\n",
       "      <td>0.58075</td>\n",
       "      <td>0.98257</td>\n",
       "      <td>0.80358</td>\n",
       "      <td>0.66548</td>\n",
       "      <td>0.77074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_743</td>\n",
       "      <td>relu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10725</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>std</td>\n",
       "      <td>32</td>\n",
       "      <td>743</td>\n",
       "      <td>0.75291</td>\n",
       "      <td>0.39708</td>\n",
       "      <td>1.49211</td>\n",
       "      <td>0.75284</td>\n",
       "      <td>0.46585</td>\n",
       "      <td>1.25437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_65</td>\n",
       "      <td>leakyrelu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10725</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>std</td>\n",
       "      <td>64</td>\n",
       "      <td>65</td>\n",
       "      <td>0.74085</td>\n",
       "      <td>0.38183</td>\n",
       "      <td>1.54324</td>\n",
       "      <td>0.74076</td>\n",
       "      <td>0.63645</td>\n",
       "      <td>0.77408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_818</td>\n",
       "      <td>relu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10725</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>pow</td>\n",
       "      <td>128</td>\n",
       "      <td>818</td>\n",
       "      <td>0.71117</td>\n",
       "      <td>0.53313</td>\n",
       "      <td>0.97092</td>\n",
       "      <td>0.71096</td>\n",
       "      <td>0.74884</td>\n",
       "      <td>0.49957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_737</td>\n",
       "      <td>tanh</td>\n",
       "      <td>softmax</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3300</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>pow</td>\n",
       "      <td>128</td>\n",
       "      <td>737</td>\n",
       "      <td>0.68440</td>\n",
       "      <td>0.27445</td>\n",
       "      <td>1.66672</td>\n",
       "      <td>0.68431</td>\n",
       "      <td>0.41546</td>\n",
       "      <td>1.36253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 run_id activation-inner  \\\n",
       "label-type                                                                 \n",
       "2           HD_81ace623-e09b-4393-8a5e-131ea8749a35_883          sigmoid   \n",
       "4           HD_81ace623-e09b-4393-8a5e-131ea8749a35_743             relu   \n",
       "1            HD_81ace623-e09b-4393-8a5e-131ea8749a35_65        leakyrelu   \n",
       "0           HD_81ace623-e09b-4393-8a5e-131ea8749a35_818             relu   \n",
       "3           HD_81ace623-e09b-4393-8a5e-131ea8749a35_737             tanh   \n",
       "\n",
       "           activation-output batch-norm batch-shuffle batch-size  \\\n",
       "label-type                                                         \n",
       "2                    softmax          1             1      10725   \n",
       "4                    softmax          1             0      10725   \n",
       "1                    softmax          0             1      10725   \n",
       "0                    softmax          1             1      10725   \n",
       "3                    softmax          1             1       3300   \n",
       "\n",
       "           dropout-ratio feature-lags featureset first-layer-neurons  ...  \\\n",
       "label-type                                                            ...   \n",
       "2                    0.1            3          3                 128  ...   \n",
       "4                      0            3          3                 128  ...   \n",
       "1                      0            5          1                 128  ...   \n",
       "0                      0            5          1                 128  ...   \n",
       "3                      0            5          0                  32  ...   \n",
       "\n",
       "           pastobs-in-percentage pre-processing second-layer-neurons   id  \\\n",
       "label-type                                                                  \n",
       "2                              0            std                   32  883   \n",
       "4                              1            std                   32  743   \n",
       "1                              0            std                   64   65   \n",
       "0                              1            pow                  128  818   \n",
       "3                              0            pow                  128  737   \n",
       "\n",
       "                AUC Accuracy     Loss Train AUC Train Accuracy  Train Loss  \n",
       "label-type                                                                  \n",
       "2           0.80363  0.58075  0.98257   0.80358        0.66548     0.77074  \n",
       "4           0.75291  0.39708  1.49211   0.75284        0.46585     1.25437  \n",
       "1           0.74085  0.38183  1.54324   0.74076        0.63645     0.77408  \n",
       "0           0.71117  0.53313  0.97092   0.71096        0.74884     0.49957  \n",
       "3           0.68440  0.27445  1.66672   0.68431        0.41546     1.36253  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tempFinal_v0 = combined_table[np.isin(combined_table.AUC,final_output_auc.loc[0].values.flatten())]\n",
    "tempFinal_v0.index = tempFinal_v0.loc[:,'label-type']\n",
    "tempFinal_v0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "run_id                   HD_81ace623-e09b-4393-8a5e-131ea8749a35_65\n",
       "activation-inner                                          leakyrelu\n",
       "activation-output                                           softmax\n",
       "batch-norm                                                        0\n",
       "batch-shuffle                                                     1\n",
       "batch-size                                                    10725\n",
       "dropout-ratio                                                     0\n",
       "feature-lags                                                      5\n",
       "featureset                                                        1\n",
       "first-layer-neurons                                             128\n",
       "label-type                                                        1\n",
       "learning-rate                                                  0.01\n",
       "n-epochs                                                        150\n",
       "n-layers                                                          4\n",
       "nn-type                                                        lstm\n",
       "pastobs-in-percentage                                             0\n",
       "pre-processing                                                  std\n",
       "second-layer-neurons                                             64\n",
       "id                                                               65\n",
       "AUC                                                         0.74085\n",
       "Accuracy                                                    0.38183\n",
       "Loss                                                        1.54324\n",
       "Train AUC                                                   0.74076\n",
       "Train Accuracy                                              0.63645\n",
       "Train Loss                                                  0.77408\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tempFinal_v0.loc['1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>activation-inner</th>\n",
       "      <th>activation-output</th>\n",
       "      <th>batch-norm</th>\n",
       "      <th>batch-shuffle</th>\n",
       "      <th>batch-size</th>\n",
       "      <th>dropout-ratio</th>\n",
       "      <th>feature-lags</th>\n",
       "      <th>featureset</th>\n",
       "      <th>first-layer-neurons</th>\n",
       "      <th>...</th>\n",
       "      <th>pastobs-in-percentage</th>\n",
       "      <th>pre-processing</th>\n",
       "      <th>second-layer-neurons</th>\n",
       "      <th>id</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Train AUC</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Train Loss</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label-type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_706</td>\n",
       "      <td>leakyrelu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10725</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>quantgau</td>\n",
       "      <td>128</td>\n",
       "      <td>706</td>\n",
       "      <td>0.57765</td>\n",
       "      <td>0.55382</td>\n",
       "      <td>0.67447</td>\n",
       "      <td>0.57746</td>\n",
       "      <td>0.55565</td>\n",
       "      <td>0.67536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_390</td>\n",
       "      <td>leakyrelu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10725</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>pow</td>\n",
       "      <td>64</td>\n",
       "      <td>390</td>\n",
       "      <td>0.62001</td>\n",
       "      <td>0.43072</td>\n",
       "      <td>1.04843</td>\n",
       "      <td>0.61998</td>\n",
       "      <td>0.44065</td>\n",
       "      <td>1.04593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_283</td>\n",
       "      <td>tanh</td>\n",
       "      <td>softmax</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3300</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>stacked</td>\n",
       "      <td>128</td>\n",
       "      <td>283</td>\n",
       "      <td>0.76304</td>\n",
       "      <td>0.61409</td>\n",
       "      <td>0.87683</td>\n",
       "      <td>0.76298</td>\n",
       "      <td>0.61164</td>\n",
       "      <td>0.87896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_213</td>\n",
       "      <td>tanh</td>\n",
       "      <td>softmax</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21450</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>pow</td>\n",
       "      <td>64</td>\n",
       "      <td>213</td>\n",
       "      <td>0.64187</td>\n",
       "      <td>0.30243</td>\n",
       "      <td>1.51325</td>\n",
       "      <td>0.64186</td>\n",
       "      <td>0.30381</td>\n",
       "      <td>1.51441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_528</td>\n",
       "      <td>tanh</td>\n",
       "      <td>softmax</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10725</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>std</td>\n",
       "      <td>32</td>\n",
       "      <td>528</td>\n",
       "      <td>0.73196</td>\n",
       "      <td>0.42030</td>\n",
       "      <td>1.35104</td>\n",
       "      <td>0.73192</td>\n",
       "      <td>0.41582</td>\n",
       "      <td>1.35792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 run_id activation-inner  \\\n",
       "label-type                                                                 \n",
       "0           HD_81ace623-e09b-4393-8a5e-131ea8749a35_706        leakyrelu   \n",
       "1           HD_81ace623-e09b-4393-8a5e-131ea8749a35_390        leakyrelu   \n",
       "2           HD_81ace623-e09b-4393-8a5e-131ea8749a35_283             tanh   \n",
       "3           HD_81ace623-e09b-4393-8a5e-131ea8749a35_213             tanh   \n",
       "4           HD_81ace623-e09b-4393-8a5e-131ea8749a35_528             tanh   \n",
       "\n",
       "           activation-output batch-norm batch-shuffle batch-size  \\\n",
       "label-type                                                         \n",
       "0                    softmax          0             0      10725   \n",
       "1                    softmax          1             0      10725   \n",
       "2                    softmax          1             1       3300   \n",
       "3                    softmax          0             1      21450   \n",
       "4                    softmax          1             1      10725   \n",
       "\n",
       "           dropout-ratio feature-lags featureset first-layer-neurons  ...  \\\n",
       "label-type                                                            ...   \n",
       "0                    0.4            1          3                  64  ...   \n",
       "1                    0.5            0          3                 128  ...   \n",
       "2                    0.1            3          2                  32  ...   \n",
       "3                    0.5            5          0                 128  ...   \n",
       "4                    0.1            3          0                 128  ...   \n",
       "\n",
       "           pastobs-in-percentage pre-processing second-layer-neurons   id  \\\n",
       "label-type                                                                  \n",
       "0                              0       quantgau                  128  706   \n",
       "1                              1            pow                   64  390   \n",
       "2                              0        stacked                  128  283   \n",
       "3                              1            pow                   64  213   \n",
       "4                              0            std                   32  528   \n",
       "\n",
       "                AUC Accuracy     Loss Train AUC Train Accuracy  Train Loss  \n",
       "label-type                                                                  \n",
       "0           0.57765  0.55382  0.67447   0.57746        0.55565     0.67536  \n",
       "1           0.62001  0.43072  1.04843   0.61998        0.44065     1.04593  \n",
       "2           0.76304  0.61409  0.87683   0.76298        0.61164     0.87896  \n",
       "3           0.64187  0.30243  1.51325   0.64186        0.30381     1.51441  \n",
       "4           0.73196  0.42030  1.35104   0.73192        0.41582     1.35792  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tempFinal_v1 = combined_table[np.isin(combined_table.Accuracy,final_output_acc.loc[0].values.flatten())].sort_values('label-type').copy(deep=True)\n",
    "tempFinal_v1.index = tempFinal_v1.loc[:,'label-type']\n",
    "tempFinal_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['run_id',\n",
       " 'activation-inner',\n",
       " 'activation-output',\n",
       " 'batch-norm',\n",
       " 'batch-shuffle',\n",
       " 'batch-size',\n",
       " 'dropout-ratio',\n",
       " 'feature-lags',\n",
       " 'featureset',\n",
       " 'first-layer-neurons',\n",
       " 'label-type',\n",
       " 'learning-rate',\n",
       " 'n-epochs',\n",
       " 'n-layers',\n",
       " 'nn-type',\n",
       " 'pastobs-in-percentage',\n",
       " 'pre-processing',\n",
       " 'second-layer-neurons',\n",
       " 'id',\n",
       " 'AUC',\n",
       " 'Accuracy',\n",
       " 'Loss',\n",
       " 'Train AUC',\n",
       " 'Train Accuracy',\n",
       " 'Train Loss']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(combined_table.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An example of a box-plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp = combined_table[(combined_table.loc[:,'label-type']=='0')&(combined_table.loc[:,'nn-type']=='lstm')&(combined_table.AUC>0.5)]\n",
    "temp_2 = pd.pivot_table(temp,values='AUC',columns='dropout-ratio',index='run_id').reset_index()\n",
    "temp_2.boxplot(list(temp_2.columns[1:]),figsize=(7,7))#temp_2.columns[2:]\n",
    "plt.grid(b=None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation-inner :  ['tanh' 'sigmoid' 'relu' 'leakyrelu'] \n",
      "\n",
      "activation-output :  ['softmax' 'linear'] \n",
      "\n",
      "batch-norm :  ['1' '0'] \n",
      "\n",
      "batch-shuffle :  ['1' '0'] \n",
      "\n",
      "batch-size :  ['21450' '10725' '3300'] \n",
      "\n",
      "dropout-ratio :  ['0' '0.2' '0.3' '0.4' '0.5' '0.1'] \n",
      "\n",
      "feature-lags :  ['5' '3' '0' '1'] \n",
      "\n",
      "featureset :  ['0' '3' '2' '1'] \n",
      "\n",
      "first-layer-neurons :  ['128' '64' '32'] \n",
      "\n",
      "learning-rate :  ['0.01' '0.1' '0.001' '0.0001'] \n",
      "\n",
      "n-layers :  ['4' '1' '2' '3'] \n",
      "\n",
      "pastobs-in-percentage :  ['1' '0'] \n",
      "\n",
      "pre-processing :  ['pow' 'quantgau' 'minmax' 'std' 'None' 'stacked'] \n",
      "\n",
      "second-layer-neurons :  ['32' '64' '128'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "cols_not_plot = []\n",
    "cols_to_plot = []\n",
    "\n",
    "for i,col in enumerate(temp.columns):\n",
    "    if (temp.loc[:,col].unique().shape[0]>1)&(temp.loc[:,col].unique().shape[0]<7):\n",
    "        cols_to_plot.append(col)\n",
    "        print(col,': ',temp.loc[:,col].unique(),'\\n')\n",
    "    else:\n",
    "        cols_not_plot.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cols_to_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1224x2880 with 15 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "temp = combined_table[(combined_table.loc[:,'label-type']=='4')&(combined_table.loc[:,'nn-type']=='ffnn')&(combined_table.AUC>0.5)]\n",
    "\n",
    "fig,ax = plt.subplots(5,3,figsize=(17,40))\n",
    "font = {'family' : 'normal',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 12}\n",
    "\n",
    "plt.rc('font', **font)\n",
    "# plt.rcParams.update({'font.size': 12})\n",
    "# plt.rcParams.update({'font.weight': 'normal'})\n",
    "k = 0\n",
    "\n",
    "for i in np.arange(5):\n",
    "    for j in np.arange(3):\n",
    "        \n",
    "\n",
    "\n",
    "        if k < len(cols_to_plot):\n",
    "            temp_2 = pd.pivot_table(temp,values='AUC',columns=cols_to_plot[k],index='run_id').reset_index()\n",
    "\n",
    "            # sns.set_theme(style=\"whitegrid\")\n",
    "            # tips = sns.load_dataset(\"tips\")\n",
    "            # ax = sns.violinplot(x=tips[\"total_bill\"])\n",
    "            sns.boxplot(data=temp_2,ax=ax[i,j],color='gray')#,bw='scott'\n",
    "#             ax[i,j].set_xticks(fontsize=12)\n",
    "#             ax[i,j].set_yticks(fontsize=12)\n",
    "            # plt.legend(fontsize=14)\n",
    "            ax[i,j].set_xlabel(temp_2.columns.name,fontsize=12,fontweight='bold')\n",
    "\n",
    "\n",
    "            k +=1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hyperparameters.txt',\n",
       " 'hyperparameters_lr_v1.txt',\n",
       " 'hyperparameters_lr_v2.txt',\n",
       " 'hyperparameters_lr_v3.txt',\n",
       " 'metrics.txt',\n",
       " 'metrics_lr_v1.txt',\n",
       " 'metrics_lr_v2.txt',\n",
       " 'metrics_lr_v3.txt']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('../AzureML/Output_from_cloud')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperfiles = [i for i in os.listdir('../AzureML/Output_from_cloud') if 'hyper' in i]\n",
    "metricfiles = [i for i in os.listdir('../AzureML/Output_from_cloud') if 'metric' in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hyperparameters.txt',\n",
       " 'hyperparameters_lr_v1.txt',\n",
       " 'hyperparameters_lr_v2.txt',\n",
       " 'hyperparameters_lr_v3.txt']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j,file in enumerate(hyperfiles):\n",
    "    \n",
    "    if j > 0:\n",
    "        \n",
    "        ### Reading in the file\n",
    "\n",
    "        with open('../AzureML/Output_from_cloud/'+hyperfiles[j],'r') as file:\n",
    "            content = file.readlines()\n",
    "\n",
    "        ## Going over each line in the text file\n",
    "        for a in np.arange(len(content)):\n",
    "\n",
    "            ## Split the lines on tabs\n",
    "            temp_parameters = re.split('[\\t]',content[a])[1]\n",
    "\n",
    "            ## Basic string cleaning, i.e. removing redundant characters\n",
    "            test = [re.split(': ',i.strip()) for i in re.split(',',temp_parameters.replace('{','')\\\n",
    "                                                                               .replace('}','')\\\n",
    "                                                                               .replace('\\n','')\\\n",
    "                                                                               .replace('\"',''))]\n",
    "\n",
    "            ## Output of test is a list of lists, where each sublist holds the name of a model variable and its value.\n",
    "            ## We create a dictornary to hold all model variables, making it easy to add the observation to the dataframe.\n",
    "            test = {i[0]:i[1] for i in test}\n",
    "\n",
    "            # Constructing the dataframe\n",
    "            if (a == 0)&(j==1):\n",
    "                parameters_lr = pd.DataFrame(test,index=[re.split('[\\t]',content[a])[0]])\n",
    "\n",
    "            else:\n",
    "\n",
    "                parameters_lr.loc[re.split('[\\t]',content[a])[0]] = pd.Series(test)\n",
    "        \n",
    "#         lastone = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch-shuffle</th>\n",
       "      <th>batch-size</th>\n",
       "      <th>feature-lags</th>\n",
       "      <th>featureset</th>\n",
       "      <th>l2-penalty</th>\n",
       "      <th>l2-type</th>\n",
       "      <th>label-type</th>\n",
       "      <th>learning-rate</th>\n",
       "      <th>loss-from-logits</th>\n",
       "      <th>n-epochs</th>\n",
       "      <th>pastobs-in-percentage</th>\n",
       "      <th>pre-processing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0</th>\n",
       "      <td>1</td>\n",
       "      <td>21450</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>stacked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_1</th>\n",
       "      <td>0</td>\n",
       "      <td>3300</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>quantgau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_2</th>\n",
       "      <td>1</td>\n",
       "      <td>10725</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>pow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_3</th>\n",
       "      <td>1</td>\n",
       "      <td>3300</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>minmax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_4</th>\n",
       "      <td>0</td>\n",
       "      <td>21450</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>std</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_166</th>\n",
       "      <td>0</td>\n",
       "      <td>3300</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>quantgau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_167</th>\n",
       "      <td>1</td>\n",
       "      <td>3300</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_168</th>\n",
       "      <td>1</td>\n",
       "      <td>21450</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>pow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169</th>\n",
       "      <td>0</td>\n",
       "      <td>3300</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>pow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_170</th>\n",
       "      <td>1</td>\n",
       "      <td>10725</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>std</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>655 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            batch-shuffle batch-size  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0               1      21450   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_1               0       3300   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_2               1      10725   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_3               1       3300   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_4               0      21450   \n",
       "...                                                   ...        ...   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_166             0       3300   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_167             1       3300   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_168             1      21450   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169             0       3300   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_170             1      10725   \n",
       "\n",
       "                                            feature-lags featureset  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0              5          1   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_1              1          2   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_2              5          2   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_3              5          1   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_4              5          3   \n",
       "...                                                  ...        ...   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_166            3          2   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_167            1          3   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_168            5          0   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169            1          1   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_170            1          3   \n",
       "\n",
       "                                            l2-penalty l2-type label-type  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0          1.0       6          2   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_1         10.0       1          2   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_2          0.1       1          0   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_3        100.0       4          0   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_4         0.01       5          2   \n",
       "...                                                ...     ...        ...   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_166     0.0001       2          1   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_167        1.0       5          0   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_168        1.0       1          2   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169     1000.0       4          1   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_170      0.001       5          1   \n",
       "\n",
       "                                            learning-rate loss-from-logits  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0           0.001                0   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_1             0.1                0   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_2           0.001                0   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_3           0.001                1   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_4          0.0001                1   \n",
       "...                                                   ...              ...   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_166        0.0001                1   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_167           0.1                0   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_168         0.001                0   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169        0.0001                1   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_170        0.0001                0   \n",
       "\n",
       "                                            n-epochs pastobs-in-percentage  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0        150                     1   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_1        150                     1   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_2        150                     1   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_3        150                     1   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_4        150                     1   \n",
       "...                                              ...                   ...   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_166      150                     0   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_167      150                     0   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_168      150                     1   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169      150                     1   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_170      150                     0   \n",
       "\n",
       "                                            pre-processing  \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0          stacked  \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_1         quantgau  \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_2              pow  \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_3           minmax  \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_4              std  \n",
       "...                                                    ...  \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_166       quantgau  \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_167           None  \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_168            pow  \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169            pow  \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_170            std  \n",
       "\n",
       "[655 rows x 12 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j,file in enumerate(metricfiles):\n",
    "    \n",
    "    if j > 0:\n",
    "        \n",
    "        ## Readidng in the file\n",
    "        with open('../AzureML/Output_from_cloud/'+metricfiles[j],'r') as file:\n",
    "            content = file.readlines()\n",
    "\n",
    "        ## Containers\n",
    "        t11 = []\n",
    "        t12 = []\n",
    "        t13 = []\n",
    "\n",
    "        t21 = []\n",
    "        t22 = []\n",
    "        t23 = []\n",
    "\n",
    "        ## Going over each line\n",
    "        for i in np.arange(len(content)):#\n",
    "\n",
    "            ## Split each line on tabs\n",
    "            temp = re.split('\\t',content[i].replace('\\n',''))\n",
    "\n",
    "            ## There are two types of observations in the text file; 1. final metrics of those models which where not stoppe early\n",
    "            ## and 2. a time series of a metric for each model.\n",
    "\n",
    "            ## If the length of the last element, in a line, is less than 50 (because it is just a number, i.e. final metric)\n",
    "            ## It stored separately for the time series.\n",
    "            if len(temp[2]) < 50:\n",
    "\n",
    "                t11.append(temp[0])\n",
    "                t12.append(temp[1])\n",
    "                t13.append(temp[2])\n",
    "\n",
    "            ## Time series\n",
    "            else:\n",
    "\n",
    "                container = np.zeros(155)\n",
    "                temp1 = [float(j.strip()) if j.strip() !=\"'NaN'\" else 0 for j in re.split(',',temp[2].replace('[','').replace(']',''))]\n",
    "\n",
    "                container[0:len(temp1)] = temp1\n",
    "                container[len(temp1):] = temp1[-1]\n",
    "\n",
    "                t21.append(temp[0])\n",
    "                t22.append(temp[1])\n",
    "                t23.append(container)        \n",
    "\n",
    "        ## Storing the time series in a dataframe\n",
    "        arrays = [t21,t22]\n",
    "        tuples = list(zip(*arrays))\n",
    "        if j == 1:\n",
    "            \n",
    "            runningMetrics_lr = pd.DataFrame(np.array(t23),\n",
    "                                              index=pd.MultiIndex.from_tuples(tuples),\n",
    "                                              columns = [np.arange(155).astype(str)]\n",
    "                                             )\n",
    "        else:\n",
    "            temp_1 = pd.DataFrame(np.array(t23),\n",
    "                                  index=pd.MultiIndex.from_tuples(tuples),\n",
    "                                  columns = [np.arange(155).astype(str)])\n",
    "            runningMetrics_lr = pd.concat([runningMetrics_lr,temp_1])\n",
    "        ## Storing the final metrics in a dataframe.\n",
    "        arrays = [t11,t12]\n",
    "        tuples = list(zip(*arrays))\n",
    "        if j == 1:\n",
    "            \n",
    "            finalMetrics_lr = pd.DataFrame(t13,index = pd.MultiIndex.from_tuples(tuples),columns = ['size'])\n",
    "        else:\n",
    "            \n",
    "            temp = pd.DataFrame(t13,index = pd.MultiIndex.from_tuples(tuples),columns = ['size'])\n",
    "            finalMetrics_lr = pd.concat([finalMetrics_lr,temp],axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "      <th>150</th>\n",
       "      <th>151</th>\n",
       "      <th>152</th>\n",
       "      <th>153</th>\n",
       "      <th>154</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0</th>\n",
       "      <th>Loss</th>\n",
       "      <td>1.097134</td>\n",
       "      <td>1.089486</td>\n",
       "      <td>1.084925</td>\n",
       "      <td>1.082050</td>\n",
       "      <td>1.080157</td>\n",
       "      <td>1.078848</td>\n",
       "      <td>1.077901</td>\n",
       "      <td>1.077183</td>\n",
       "      <td>1.076617</td>\n",
       "      <td>1.076155</td>\n",
       "      <td>...</td>\n",
       "      <td>1.070333</td>\n",
       "      <td>1.070329</td>\n",
       "      <td>1.070325</td>\n",
       "      <td>1.070321</td>\n",
       "      <td>1.070317</td>\n",
       "      <td>1.070317</td>\n",
       "      <td>1.070317</td>\n",
       "      <td>1.070317</td>\n",
       "      <td>1.070317</td>\n",
       "      <td>1.070317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.357927</td>\n",
       "      <td>0.372786</td>\n",
       "      <td>0.380087</td>\n",
       "      <td>0.386206</td>\n",
       "      <td>0.388733</td>\n",
       "      <td>0.389996</td>\n",
       "      <td>0.391295</td>\n",
       "      <td>0.392629</td>\n",
       "      <td>0.393904</td>\n",
       "      <td>0.394478</td>\n",
       "      <td>...</td>\n",
       "      <td>0.401299</td>\n",
       "      <td>0.401381</td>\n",
       "      <td>0.401322</td>\n",
       "      <td>0.401275</td>\n",
       "      <td>0.401299</td>\n",
       "      <td>0.401299</td>\n",
       "      <td>0.401299</td>\n",
       "      <td>0.401299</td>\n",
       "      <td>0.401299</td>\n",
       "      <td>0.401299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC</th>\n",
       "      <td>0.520483</td>\n",
       "      <td>0.533294</td>\n",
       "      <td>0.543315</td>\n",
       "      <td>0.550682</td>\n",
       "      <td>0.556136</td>\n",
       "      <td>0.560248</td>\n",
       "      <td>0.563450</td>\n",
       "      <td>0.566000</td>\n",
       "      <td>0.568082</td>\n",
       "      <td>0.569817</td>\n",
       "      <td>...</td>\n",
       "      <td>0.592322</td>\n",
       "      <td>0.592349</td>\n",
       "      <td>0.592375</td>\n",
       "      <td>0.592401</td>\n",
       "      <td>0.592426</td>\n",
       "      <td>0.592426</td>\n",
       "      <td>0.592426</td>\n",
       "      <td>0.592426</td>\n",
       "      <td>0.592426</td>\n",
       "      <td>0.592426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Loss</th>\n",
       "      <td>1.103421</td>\n",
       "      <td>1.092251</td>\n",
       "      <td>1.085799</td>\n",
       "      <td>1.081776</td>\n",
       "      <td>1.079140</td>\n",
       "      <td>1.077343</td>\n",
       "      <td>1.076068</td>\n",
       "      <td>1.075129</td>\n",
       "      <td>1.074413</td>\n",
       "      <td>1.073847</td>\n",
       "      <td>...</td>\n",
       "      <td>1.067931</td>\n",
       "      <td>1.067927</td>\n",
       "      <td>1.067922</td>\n",
       "      <td>1.067918</td>\n",
       "      <td>1.067913</td>\n",
       "      <td>1.067913</td>\n",
       "      <td>1.067913</td>\n",
       "      <td>1.067913</td>\n",
       "      <td>1.067913</td>\n",
       "      <td>1.067913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Accuracy</th>\n",
       "      <td>0.348293</td>\n",
       "      <td>0.370394</td>\n",
       "      <td>0.381516</td>\n",
       "      <td>0.386821</td>\n",
       "      <td>0.390184</td>\n",
       "      <td>0.392238</td>\n",
       "      <td>0.393292</td>\n",
       "      <td>0.394232</td>\n",
       "      <td>0.395504</td>\n",
       "      <td>0.396163</td>\n",
       "      <td>...</td>\n",
       "      <td>0.407098</td>\n",
       "      <td>0.407139</td>\n",
       "      <td>0.407136</td>\n",
       "      <td>0.407177</td>\n",
       "      <td>0.407191</td>\n",
       "      <td>0.407191</td>\n",
       "      <td>0.407191</td>\n",
       "      <td>0.407191</td>\n",
       "      <td>0.407191</td>\n",
       "      <td>0.407191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169</th>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.196420</td>\n",
       "      <td>0.195965</td>\n",
       "      <td>0.195393</td>\n",
       "      <td>0.194752</td>\n",
       "      <td>0.194052</td>\n",
       "      <td>0.193772</td>\n",
       "      <td>0.194320</td>\n",
       "      <td>0.194624</td>\n",
       "      <td>0.194764</td>\n",
       "      <td>0.195335</td>\n",
       "      <td>...</td>\n",
       "      <td>0.195592</td>\n",
       "      <td>0.195673</td>\n",
       "      <td>0.195673</td>\n",
       "      <td>0.195533</td>\n",
       "      <td>0.195533</td>\n",
       "      <td>0.195533</td>\n",
       "      <td>0.195533</td>\n",
       "      <td>0.195533</td>\n",
       "      <td>0.195533</td>\n",
       "      <td>0.195533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC</th>\n",
       "      <td>0.498032</td>\n",
       "      <td>0.498719</td>\n",
       "      <td>0.498959</td>\n",
       "      <td>0.499100</td>\n",
       "      <td>0.499201</td>\n",
       "      <td>0.499279</td>\n",
       "      <td>0.499350</td>\n",
       "      <td>0.499412</td>\n",
       "      <td>0.499474</td>\n",
       "      <td>0.499528</td>\n",
       "      <td>...</td>\n",
       "      <td>0.499037</td>\n",
       "      <td>0.499022</td>\n",
       "      <td>0.499007</td>\n",
       "      <td>0.498993</td>\n",
       "      <td>0.498978</td>\n",
       "      <td>0.498978</td>\n",
       "      <td>0.498978</td>\n",
       "      <td>0.498978</td>\n",
       "      <td>0.498978</td>\n",
       "      <td>0.498978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Loss</th>\n",
       "      <td>27.245023</td>\n",
       "      <td>24.507504</td>\n",
       "      <td>22.095238</td>\n",
       "      <td>19.988227</td>\n",
       "      <td>18.149702</td>\n",
       "      <td>16.543524</td>\n",
       "      <td>15.139264</td>\n",
       "      <td>13.911686</td>\n",
       "      <td>12.839479</td>\n",
       "      <td>11.904266</td>\n",
       "      <td>...</td>\n",
       "      <td>2.535947</td>\n",
       "      <td>2.523146</td>\n",
       "      <td>2.510520</td>\n",
       "      <td>2.498068</td>\n",
       "      <td>2.485785</td>\n",
       "      <td>2.485785</td>\n",
       "      <td>2.485785</td>\n",
       "      <td>2.485785</td>\n",
       "      <td>2.485785</td>\n",
       "      <td>2.485785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Accuracy</th>\n",
       "      <td>0.196710</td>\n",
       "      <td>0.196640</td>\n",
       "      <td>0.196341</td>\n",
       "      <td>0.196336</td>\n",
       "      <td>0.196248</td>\n",
       "      <td>0.196330</td>\n",
       "      <td>0.196661</td>\n",
       "      <td>0.197103</td>\n",
       "      <td>0.197493</td>\n",
       "      <td>0.197821</td>\n",
       "      <td>...</td>\n",
       "      <td>0.199241</td>\n",
       "      <td>0.199253</td>\n",
       "      <td>0.199227</td>\n",
       "      <td>0.199297</td>\n",
       "      <td>0.199192</td>\n",
       "      <td>0.199192</td>\n",
       "      <td>0.199192</td>\n",
       "      <td>0.199192</td>\n",
       "      <td>0.199192</td>\n",
       "      <td>0.199192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train AUC</th>\n",
       "      <td>0.505100</td>\n",
       "      <td>0.500372</td>\n",
       "      <td>0.499929</td>\n",
       "      <td>0.499766</td>\n",
       "      <td>0.499693</td>\n",
       "      <td>0.499662</td>\n",
       "      <td>0.499652</td>\n",
       "      <td>0.499658</td>\n",
       "      <td>0.499674</td>\n",
       "      <td>0.499695</td>\n",
       "      <td>...</td>\n",
       "      <td>0.499045</td>\n",
       "      <td>0.499030</td>\n",
       "      <td>0.499015</td>\n",
       "      <td>0.499001</td>\n",
       "      <td>0.498986</td>\n",
       "      <td>0.498986</td>\n",
       "      <td>0.498986</td>\n",
       "      <td>0.498986</td>\n",
       "      <td>0.498986</td>\n",
       "      <td>0.498986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3846 rows × 155 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                    0  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss             1.097134   \n",
       "                                            Accuracy         0.357927   \n",
       "                                            AUC              0.520483   \n",
       "                                            Train Loss       1.103421   \n",
       "                                            Train Accuracy   0.348293   \n",
       "...                                                               ...   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169 Accuracy         0.196420   \n",
       "                                            AUC              0.498032   \n",
       "                                            Train Loss      27.245023   \n",
       "                                            Train Accuracy   0.196710   \n",
       "                                            Train AUC        0.505100   \n",
       "\n",
       "                                                                    1  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss             1.089486   \n",
       "                                            Accuracy         0.372786   \n",
       "                                            AUC              0.533294   \n",
       "                                            Train Loss       1.092251   \n",
       "                                            Train Accuracy   0.370394   \n",
       "...                                                               ...   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169 Accuracy         0.195965   \n",
       "                                            AUC              0.498719   \n",
       "                                            Train Loss      24.507504   \n",
       "                                            Train Accuracy   0.196640   \n",
       "                                            Train AUC        0.500372   \n",
       "\n",
       "                                                                    2  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss             1.084925   \n",
       "                                            Accuracy         0.380087   \n",
       "                                            AUC              0.543315   \n",
       "                                            Train Loss       1.085799   \n",
       "                                            Train Accuracy   0.381516   \n",
       "...                                                               ...   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169 Accuracy         0.195393   \n",
       "                                            AUC              0.498959   \n",
       "                                            Train Loss      22.095238   \n",
       "                                            Train Accuracy   0.196341   \n",
       "                                            Train AUC        0.499929   \n",
       "\n",
       "                                                                    3  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss             1.082050   \n",
       "                                            Accuracy         0.386206   \n",
       "                                            AUC              0.550682   \n",
       "                                            Train Loss       1.081776   \n",
       "                                            Train Accuracy   0.386821   \n",
       "...                                                               ...   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169 Accuracy         0.194752   \n",
       "                                            AUC              0.499100   \n",
       "                                            Train Loss      19.988227   \n",
       "                                            Train Accuracy   0.196336   \n",
       "                                            Train AUC        0.499766   \n",
       "\n",
       "                                                                    4  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss             1.080157   \n",
       "                                            Accuracy         0.388733   \n",
       "                                            AUC              0.556136   \n",
       "                                            Train Loss       1.079140   \n",
       "                                            Train Accuracy   0.390184   \n",
       "...                                                               ...   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169 Accuracy         0.194052   \n",
       "                                            AUC              0.499201   \n",
       "                                            Train Loss      18.149702   \n",
       "                                            Train Accuracy   0.196248   \n",
       "                                            Train AUC        0.499693   \n",
       "\n",
       "                                                                    5  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss             1.078848   \n",
       "                                            Accuracy         0.389996   \n",
       "                                            AUC              0.560248   \n",
       "                                            Train Loss       1.077343   \n",
       "                                            Train Accuracy   0.392238   \n",
       "...                                                               ...   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169 Accuracy         0.193772   \n",
       "                                            AUC              0.499279   \n",
       "                                            Train Loss      16.543524   \n",
       "                                            Train Accuracy   0.196330   \n",
       "                                            Train AUC        0.499662   \n",
       "\n",
       "                                                                    6  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss             1.077901   \n",
       "                                            Accuracy         0.391295   \n",
       "                                            AUC              0.563450   \n",
       "                                            Train Loss       1.076068   \n",
       "                                            Train Accuracy   0.393292   \n",
       "...                                                               ...   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169 Accuracy         0.194320   \n",
       "                                            AUC              0.499350   \n",
       "                                            Train Loss      15.139264   \n",
       "                                            Train Accuracy   0.196661   \n",
       "                                            Train AUC        0.499652   \n",
       "\n",
       "                                                                    7  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss             1.077183   \n",
       "                                            Accuracy         0.392629   \n",
       "                                            AUC              0.566000   \n",
       "                                            Train Loss       1.075129   \n",
       "                                            Train Accuracy   0.394232   \n",
       "...                                                               ...   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169 Accuracy         0.194624   \n",
       "                                            AUC              0.499412   \n",
       "                                            Train Loss      13.911686   \n",
       "                                            Train Accuracy   0.197103   \n",
       "                                            Train AUC        0.499658   \n",
       "\n",
       "                                                                    8  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss             1.076617   \n",
       "                                            Accuracy         0.393904   \n",
       "                                            AUC              0.568082   \n",
       "                                            Train Loss       1.074413   \n",
       "                                            Train Accuracy   0.395504   \n",
       "...                                                               ...   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169 Accuracy         0.194764   \n",
       "                                            AUC              0.499474   \n",
       "                                            Train Loss      12.839479   \n",
       "                                            Train Accuracy   0.197493   \n",
       "                                            Train AUC        0.499674   \n",
       "\n",
       "                                                                    9  ...  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss             1.076155  ...   \n",
       "                                            Accuracy         0.394478  ...   \n",
       "                                            AUC              0.569817  ...   \n",
       "                                            Train Loss       1.073847  ...   \n",
       "                                            Train Accuracy   0.396163  ...   \n",
       "...                                                               ...  ...   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169 Accuracy         0.195335  ...   \n",
       "                                            AUC              0.499528  ...   \n",
       "                                            Train Loss      11.904266  ...   \n",
       "                                            Train Accuracy   0.197821  ...   \n",
       "                                            Train AUC        0.499695  ...   \n",
       "\n",
       "                                                                 145  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss            1.070333   \n",
       "                                            Accuracy        0.401299   \n",
       "                                            AUC             0.592322   \n",
       "                                            Train Loss      1.067931   \n",
       "                                            Train Accuracy  0.407098   \n",
       "...                                                              ...   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169 Accuracy        0.195592   \n",
       "                                            AUC             0.499037   \n",
       "                                            Train Loss      2.535947   \n",
       "                                            Train Accuracy  0.199241   \n",
       "                                            Train AUC       0.499045   \n",
       "\n",
       "                                                                 146  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss            1.070329   \n",
       "                                            Accuracy        0.401381   \n",
       "                                            AUC             0.592349   \n",
       "                                            Train Loss      1.067927   \n",
       "                                            Train Accuracy  0.407139   \n",
       "...                                                              ...   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169 Accuracy        0.195673   \n",
       "                                            AUC             0.499022   \n",
       "                                            Train Loss      2.523146   \n",
       "                                            Train Accuracy  0.199253   \n",
       "                                            Train AUC       0.499030   \n",
       "\n",
       "                                                                 147  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss            1.070325   \n",
       "                                            Accuracy        0.401322   \n",
       "                                            AUC             0.592375   \n",
       "                                            Train Loss      1.067922   \n",
       "                                            Train Accuracy  0.407136   \n",
       "...                                                              ...   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169 Accuracy        0.195673   \n",
       "                                            AUC             0.499007   \n",
       "                                            Train Loss      2.510520   \n",
       "                                            Train Accuracy  0.199227   \n",
       "                                            Train AUC       0.499015   \n",
       "\n",
       "                                                                 148  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss            1.070321   \n",
       "                                            Accuracy        0.401275   \n",
       "                                            AUC             0.592401   \n",
       "                                            Train Loss      1.067918   \n",
       "                                            Train Accuracy  0.407177   \n",
       "...                                                              ...   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169 Accuracy        0.195533   \n",
       "                                            AUC             0.498993   \n",
       "                                            Train Loss      2.498068   \n",
       "                                            Train Accuracy  0.199297   \n",
       "                                            Train AUC       0.499001   \n",
       "\n",
       "                                                                 149  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss            1.070317   \n",
       "                                            Accuracy        0.401299   \n",
       "                                            AUC             0.592426   \n",
       "                                            Train Loss      1.067913   \n",
       "                                            Train Accuracy  0.407191   \n",
       "...                                                              ...   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169 Accuracy        0.195533   \n",
       "                                            AUC             0.498978   \n",
       "                                            Train Loss      2.485785   \n",
       "                                            Train Accuracy  0.199192   \n",
       "                                            Train AUC       0.498986   \n",
       "\n",
       "                                                                 150  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss            1.070317   \n",
       "                                            Accuracy        0.401299   \n",
       "                                            AUC             0.592426   \n",
       "                                            Train Loss      1.067913   \n",
       "                                            Train Accuracy  0.407191   \n",
       "...                                                              ...   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169 Accuracy        0.195533   \n",
       "                                            AUC             0.498978   \n",
       "                                            Train Loss      2.485785   \n",
       "                                            Train Accuracy  0.199192   \n",
       "                                            Train AUC       0.498986   \n",
       "\n",
       "                                                                 151  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss            1.070317   \n",
       "                                            Accuracy        0.401299   \n",
       "                                            AUC             0.592426   \n",
       "                                            Train Loss      1.067913   \n",
       "                                            Train Accuracy  0.407191   \n",
       "...                                                              ...   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169 Accuracy        0.195533   \n",
       "                                            AUC             0.498978   \n",
       "                                            Train Loss      2.485785   \n",
       "                                            Train Accuracy  0.199192   \n",
       "                                            Train AUC       0.498986   \n",
       "\n",
       "                                                                 152  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss            1.070317   \n",
       "                                            Accuracy        0.401299   \n",
       "                                            AUC             0.592426   \n",
       "                                            Train Loss      1.067913   \n",
       "                                            Train Accuracy  0.407191   \n",
       "...                                                              ...   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169 Accuracy        0.195533   \n",
       "                                            AUC             0.498978   \n",
       "                                            Train Loss      2.485785   \n",
       "                                            Train Accuracy  0.199192   \n",
       "                                            Train AUC       0.498986   \n",
       "\n",
       "                                                                 153       154  \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss            1.070317  1.070317  \n",
       "                                            Accuracy        0.401299  0.401299  \n",
       "                                            AUC             0.592426  0.592426  \n",
       "                                            Train Loss      1.067913  1.067913  \n",
       "                                            Train Accuracy  0.407191  0.407191  \n",
       "...                                                              ...       ...  \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169 Accuracy        0.195533  0.195533  \n",
       "                                            AUC             0.498978  0.498978  \n",
       "                                            Train Loss      2.485785  2.485785  \n",
       "                                            Train Accuracy  0.199192  0.199192  \n",
       "                                            Train AUC       0.498986  0.498986  \n",
       "\n",
       "[3846 rows x 155 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runningMetrics_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['run_id',\n",
       " 'metric',\n",
       " '0',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " '10',\n",
       " '11',\n",
       " '12',\n",
       " '13',\n",
       " '14',\n",
       " '15',\n",
       " '16',\n",
       " '17',\n",
       " '18',\n",
       " '19',\n",
       " '20',\n",
       " '21',\n",
       " '22',\n",
       " '23',\n",
       " '24',\n",
       " '25',\n",
       " '26',\n",
       " '27',\n",
       " '28',\n",
       " '29',\n",
       " '30',\n",
       " '31',\n",
       " '32',\n",
       " '33',\n",
       " '34',\n",
       " '35',\n",
       " '36',\n",
       " '37',\n",
       " '38',\n",
       " '39',\n",
       " '40',\n",
       " '41',\n",
       " '42',\n",
       " '43',\n",
       " '44',\n",
       " '45',\n",
       " '46',\n",
       " '47',\n",
       " '48',\n",
       " '49',\n",
       " '50',\n",
       " '51',\n",
       " '52',\n",
       " '53',\n",
       " '54',\n",
       " '55',\n",
       " '56',\n",
       " '57',\n",
       " '58',\n",
       " '59',\n",
       " '60',\n",
       " '61',\n",
       " '62',\n",
       " '63',\n",
       " '64',\n",
       " '65',\n",
       " '66',\n",
       " '67',\n",
       " '68',\n",
       " '69',\n",
       " '70',\n",
       " '71',\n",
       " '72',\n",
       " '73',\n",
       " '74',\n",
       " '75',\n",
       " '76',\n",
       " '77',\n",
       " '78',\n",
       " '79',\n",
       " '80',\n",
       " '81',\n",
       " '82',\n",
       " '83',\n",
       " '84',\n",
       " '85',\n",
       " '86',\n",
       " '87',\n",
       " '88',\n",
       " '89',\n",
       " '90',\n",
       " '91',\n",
       " '92',\n",
       " '93',\n",
       " '94',\n",
       " '95',\n",
       " '96',\n",
       " '97',\n",
       " '98',\n",
       " '99',\n",
       " '100',\n",
       " '101',\n",
       " '102',\n",
       " '103',\n",
       " '104',\n",
       " '105',\n",
       " '106',\n",
       " '107',\n",
       " '108',\n",
       " '109',\n",
       " '110',\n",
       " '111',\n",
       " '112',\n",
       " '113',\n",
       " '114',\n",
       " '115',\n",
       " '116',\n",
       " '117',\n",
       " '118',\n",
       " '119',\n",
       " '120',\n",
       " '121',\n",
       " '122',\n",
       " '123',\n",
       " '124',\n",
       " '125',\n",
       " '126',\n",
       " '127',\n",
       " '128',\n",
       " '129',\n",
       " '130',\n",
       " '131',\n",
       " '132',\n",
       " '133',\n",
       " '134',\n",
       " '135',\n",
       " '136',\n",
       " '137',\n",
       " '138',\n",
       " '139',\n",
       " '140',\n",
       " '141',\n",
       " '142',\n",
       " '143',\n",
       " '144',\n",
       " '145',\n",
       " '146',\n",
       " '147',\n",
       " '148',\n",
       " '149',\n",
       " '150',\n",
       " '151',\n",
       " '152',\n",
       " '153',\n",
       " '154',\n",
       " 'id']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(runningMetrics.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hyperparameters.txt',\n",
       " 'hyperparameters_lr_v1.txt',\n",
       " 'hyperparameters_lr_v2.txt',\n",
       " 'hyperparameters_lr_v3.txt',\n",
       " 'metrics.txt',\n",
       " 'metrics_lr_v1.txt',\n",
       " 'metrics_lr_v2.txt',\n",
       " 'metrics_lr_v3.txt']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('../AzureML/Output_from_cloud/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('../AzureML/Output_from_cloud/'+metricfiles[1],'r') as file:\n",
    "#     content = file.readlines()\n",
    "        \n",
    "# ## Containers\n",
    "# t11 = []\n",
    "# t12 = []\n",
    "# t13 = []\n",
    "\n",
    "# t21 = []\n",
    "# t22 = []\n",
    "# t23 = []\n",
    "\n",
    "# ## Going over each line\n",
    "# for i in np.arange(len(content)):#\n",
    "\n",
    "#     ## Split each line on tabs\n",
    "#     temp = re.split('\\t',content[i].replace('\\n',''))\n",
    "\n",
    "#     ## There are two types of observations in the text file; 1. final metrics of those models which where not stoppe early\n",
    "#     ## and 2. a time series of a metric for each model.\n",
    "\n",
    "#     ## If the length of the last element, in a line, is less than 50 (because it is just a number, i.e. final metric)\n",
    "#     ## It stored separately for the time series.\n",
    "#     if len(temp[2]) < 50:\n",
    "\n",
    "#         t11.append(temp[0])\n",
    "#         t12.append(temp[1])\n",
    "#         t13.append(temp[2])\n",
    "\n",
    "#     ## Time series\n",
    "#     else:\n",
    "\n",
    "#         container = np.zeros(155)\n",
    "#         temp1 = [float(j.strip()) if j.strip() !=\"'NaN'\" else 0 for j in re.split(',',temp[2].replace('[','').replace(']',''))]\n",
    "\n",
    "#         container[0:len(temp1)] = temp1\n",
    "#         container[len(temp1):] = temp1[-1]\n",
    "\n",
    "#         t21.append(temp[0])\n",
    "#         t22.append(temp[1])\n",
    "#         t23.append(container)    \n",
    "        \n",
    "# print([i for i,j in enumerate(t11) if j == 'HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_1'])\n",
    "# print([i for i,j in enumerate(t21) if j == 'HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(t12[5],t13[5])\n",
    "# print(t22[10],t23[10][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('../AzureML/Output_from_cloud/'+metricfiles[2],'r') as file:\n",
    "#     content = file.readlines()\n",
    "        \n",
    "# ## Containers\n",
    "# t11 = []\n",
    "# t12 = []\n",
    "# t13 = []\n",
    "\n",
    "# t21 = []\n",
    "# t22 = []\n",
    "# t23 = []\n",
    "\n",
    "# ## Going over each line\n",
    "# for i in np.arange(len(content)):#\n",
    "\n",
    "#     ## Split each line on tabs\n",
    "#     temp = re.split('\\t',content[i].replace('\\n',''))\n",
    "\n",
    "#     ## There are two types of observations in the text file; 1. final metrics of those models which where not stoppe early\n",
    "#     ## and 2. a time series of a metric for each model.\n",
    "\n",
    "#     ## If the length of the last element, in a line, is less than 50 (because it is just a number, i.e. final metric)\n",
    "#     ## It stored separately for the time series.\n",
    "#     if len(temp[2]) < 50:\n",
    "\n",
    "#         t11.append(temp[0])\n",
    "#         t12.append(temp[1])\n",
    "#         t13.append(temp[2])\n",
    "\n",
    "#     ## Time series\n",
    "#     else:\n",
    "\n",
    "#         container = np.zeros(155)\n",
    "#         temp1 = [float(j.strip()) if j.strip() !=\"'NaN'\" else 0 for j in re.split(',',temp[2].replace('[','').replace(']',''))]\n",
    "\n",
    "#         container[0:len(temp1)] = temp1\n",
    "#         container[len(temp1):] = temp1[-1]\n",
    "\n",
    "#         t21.append(temp[0])\n",
    "#         t22.append(temp[1])\n",
    "#         t23.append(container)   \n",
    "\n",
    "# print([i for i,j in enumerate(t11) if j == 'HD_914f915c-2cac-473e-bea5-c26e4c83673c_1'])\n",
    "# print([i for i,j in enumerate(t21) if j == 'HD_914f915c-2cac-473e-bea5-c26e4c83673c_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(t12[5],t13[5])\n",
    "# print(t22[10],t23[10][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0</th>\n",
       "      <th>Final test loss</th>\n",
       "      <td>1.0703172176779956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Final test AUC</th>\n",
       "      <td>0.5924146175384521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Final test accuracy</th>\n",
       "      <td>0.4012987017631531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_1</th>\n",
       "      <th>Final test loss</th>\n",
       "      <td>0.9833228082609005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Final test AUC</th>\n",
       "      <td>0.7488732933998108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_168</th>\n",
       "      <th>Final test AUC</th>\n",
       "      <td>0.5023971796035767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Final test accuracy</th>\n",
       "      <td>0.5048107504844666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169</th>\n",
       "      <th>Final test loss</th>\n",
       "      <td>1.6155616476873773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Final test AUC</th>\n",
       "      <td>0.4989795684814453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Final test accuracy</th>\n",
       "      <td>0.19553326070308685</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1923 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                size\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Final test loss       1.0703172176779956\n",
       "                                            Final test AUC        0.5924146175384521\n",
       "                                            Final test accuracy   0.4012987017631531\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_1   Final test loss       0.9833228082609005\n",
       "                                            Final test AUC        0.7488732933998108\n",
       "...                                                                              ...\n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_168 Final test AUC        0.5023971796035767\n",
       "                                            Final test accuracy   0.5048107504844666\n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169 Final test loss       1.6155616476873773\n",
       "                                            Final test AUC        0.4989795684814453\n",
       "                                            Final test accuracy  0.19553326070308685\n",
       "\n",
       "[1923 rows x 1 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalMetrics_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "      <th>150</th>\n",
       "      <th>151</th>\n",
       "      <th>152</th>\n",
       "      <th>153</th>\n",
       "      <th>154</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0</th>\n",
       "      <th>Loss</th>\n",
       "      <td>1.097134</td>\n",
       "      <td>1.089486</td>\n",
       "      <td>1.084925</td>\n",
       "      <td>1.082050</td>\n",
       "      <td>1.080157</td>\n",
       "      <td>1.078848</td>\n",
       "      <td>1.077901</td>\n",
       "      <td>1.077183</td>\n",
       "      <td>1.076617</td>\n",
       "      <td>1.076155</td>\n",
       "      <td>...</td>\n",
       "      <td>1.070333</td>\n",
       "      <td>1.070329</td>\n",
       "      <td>1.070325</td>\n",
       "      <td>1.070321</td>\n",
       "      <td>1.070317</td>\n",
       "      <td>1.070317</td>\n",
       "      <td>1.070317</td>\n",
       "      <td>1.070317</td>\n",
       "      <td>1.070317</td>\n",
       "      <td>1.070317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.357927</td>\n",
       "      <td>0.372786</td>\n",
       "      <td>0.380087</td>\n",
       "      <td>0.386206</td>\n",
       "      <td>0.388733</td>\n",
       "      <td>0.389996</td>\n",
       "      <td>0.391295</td>\n",
       "      <td>0.392629</td>\n",
       "      <td>0.393904</td>\n",
       "      <td>0.394478</td>\n",
       "      <td>...</td>\n",
       "      <td>0.401299</td>\n",
       "      <td>0.401381</td>\n",
       "      <td>0.401322</td>\n",
       "      <td>0.401275</td>\n",
       "      <td>0.401299</td>\n",
       "      <td>0.401299</td>\n",
       "      <td>0.401299</td>\n",
       "      <td>0.401299</td>\n",
       "      <td>0.401299</td>\n",
       "      <td>0.401299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC</th>\n",
       "      <td>0.520483</td>\n",
       "      <td>0.533294</td>\n",
       "      <td>0.543315</td>\n",
       "      <td>0.550682</td>\n",
       "      <td>0.556136</td>\n",
       "      <td>0.560248</td>\n",
       "      <td>0.563450</td>\n",
       "      <td>0.566000</td>\n",
       "      <td>0.568082</td>\n",
       "      <td>0.569817</td>\n",
       "      <td>...</td>\n",
       "      <td>0.592322</td>\n",
       "      <td>0.592349</td>\n",
       "      <td>0.592375</td>\n",
       "      <td>0.592401</td>\n",
       "      <td>0.592426</td>\n",
       "      <td>0.592426</td>\n",
       "      <td>0.592426</td>\n",
       "      <td>0.592426</td>\n",
       "      <td>0.592426</td>\n",
       "      <td>0.592426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Loss</th>\n",
       "      <td>1.103421</td>\n",
       "      <td>1.092251</td>\n",
       "      <td>1.085799</td>\n",
       "      <td>1.081776</td>\n",
       "      <td>1.079140</td>\n",
       "      <td>1.077343</td>\n",
       "      <td>1.076068</td>\n",
       "      <td>1.075129</td>\n",
       "      <td>1.074413</td>\n",
       "      <td>1.073847</td>\n",
       "      <td>...</td>\n",
       "      <td>1.067931</td>\n",
       "      <td>1.067927</td>\n",
       "      <td>1.067922</td>\n",
       "      <td>1.067918</td>\n",
       "      <td>1.067913</td>\n",
       "      <td>1.067913</td>\n",
       "      <td>1.067913</td>\n",
       "      <td>1.067913</td>\n",
       "      <td>1.067913</td>\n",
       "      <td>1.067913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Accuracy</th>\n",
       "      <td>0.348293</td>\n",
       "      <td>0.370394</td>\n",
       "      <td>0.381516</td>\n",
       "      <td>0.386821</td>\n",
       "      <td>0.390184</td>\n",
       "      <td>0.392238</td>\n",
       "      <td>0.393292</td>\n",
       "      <td>0.394232</td>\n",
       "      <td>0.395504</td>\n",
       "      <td>0.396163</td>\n",
       "      <td>...</td>\n",
       "      <td>0.407098</td>\n",
       "      <td>0.407139</td>\n",
       "      <td>0.407136</td>\n",
       "      <td>0.407177</td>\n",
       "      <td>0.407191</td>\n",
       "      <td>0.407191</td>\n",
       "      <td>0.407191</td>\n",
       "      <td>0.407191</td>\n",
       "      <td>0.407191</td>\n",
       "      <td>0.407191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169</th>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.196420</td>\n",
       "      <td>0.195965</td>\n",
       "      <td>0.195393</td>\n",
       "      <td>0.194752</td>\n",
       "      <td>0.194052</td>\n",
       "      <td>0.193772</td>\n",
       "      <td>0.194320</td>\n",
       "      <td>0.194624</td>\n",
       "      <td>0.194764</td>\n",
       "      <td>0.195335</td>\n",
       "      <td>...</td>\n",
       "      <td>0.195592</td>\n",
       "      <td>0.195673</td>\n",
       "      <td>0.195673</td>\n",
       "      <td>0.195533</td>\n",
       "      <td>0.195533</td>\n",
       "      <td>0.195533</td>\n",
       "      <td>0.195533</td>\n",
       "      <td>0.195533</td>\n",
       "      <td>0.195533</td>\n",
       "      <td>0.195533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC</th>\n",
       "      <td>0.498032</td>\n",
       "      <td>0.498719</td>\n",
       "      <td>0.498959</td>\n",
       "      <td>0.499100</td>\n",
       "      <td>0.499201</td>\n",
       "      <td>0.499279</td>\n",
       "      <td>0.499350</td>\n",
       "      <td>0.499412</td>\n",
       "      <td>0.499474</td>\n",
       "      <td>0.499528</td>\n",
       "      <td>...</td>\n",
       "      <td>0.499037</td>\n",
       "      <td>0.499022</td>\n",
       "      <td>0.499007</td>\n",
       "      <td>0.498993</td>\n",
       "      <td>0.498978</td>\n",
       "      <td>0.498978</td>\n",
       "      <td>0.498978</td>\n",
       "      <td>0.498978</td>\n",
       "      <td>0.498978</td>\n",
       "      <td>0.498978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Loss</th>\n",
       "      <td>27.245023</td>\n",
       "      <td>24.507504</td>\n",
       "      <td>22.095238</td>\n",
       "      <td>19.988227</td>\n",
       "      <td>18.149702</td>\n",
       "      <td>16.543524</td>\n",
       "      <td>15.139264</td>\n",
       "      <td>13.911686</td>\n",
       "      <td>12.839479</td>\n",
       "      <td>11.904266</td>\n",
       "      <td>...</td>\n",
       "      <td>2.535947</td>\n",
       "      <td>2.523146</td>\n",
       "      <td>2.510520</td>\n",
       "      <td>2.498068</td>\n",
       "      <td>2.485785</td>\n",
       "      <td>2.485785</td>\n",
       "      <td>2.485785</td>\n",
       "      <td>2.485785</td>\n",
       "      <td>2.485785</td>\n",
       "      <td>2.485785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Accuracy</th>\n",
       "      <td>0.196710</td>\n",
       "      <td>0.196640</td>\n",
       "      <td>0.196341</td>\n",
       "      <td>0.196336</td>\n",
       "      <td>0.196248</td>\n",
       "      <td>0.196330</td>\n",
       "      <td>0.196661</td>\n",
       "      <td>0.197103</td>\n",
       "      <td>0.197493</td>\n",
       "      <td>0.197821</td>\n",
       "      <td>...</td>\n",
       "      <td>0.199241</td>\n",
       "      <td>0.199253</td>\n",
       "      <td>0.199227</td>\n",
       "      <td>0.199297</td>\n",
       "      <td>0.199192</td>\n",
       "      <td>0.199192</td>\n",
       "      <td>0.199192</td>\n",
       "      <td>0.199192</td>\n",
       "      <td>0.199192</td>\n",
       "      <td>0.199192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train AUC</th>\n",
       "      <td>0.505100</td>\n",
       "      <td>0.500372</td>\n",
       "      <td>0.499929</td>\n",
       "      <td>0.499766</td>\n",
       "      <td>0.499693</td>\n",
       "      <td>0.499662</td>\n",
       "      <td>0.499652</td>\n",
       "      <td>0.499658</td>\n",
       "      <td>0.499674</td>\n",
       "      <td>0.499695</td>\n",
       "      <td>...</td>\n",
       "      <td>0.499045</td>\n",
       "      <td>0.499030</td>\n",
       "      <td>0.499015</td>\n",
       "      <td>0.499001</td>\n",
       "      <td>0.498986</td>\n",
       "      <td>0.498986</td>\n",
       "      <td>0.498986</td>\n",
       "      <td>0.498986</td>\n",
       "      <td>0.498986</td>\n",
       "      <td>0.498986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3846 rows × 155 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                    0  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss             1.097134   \n",
       "                                            Accuracy         0.357927   \n",
       "                                            AUC              0.520483   \n",
       "                                            Train Loss       1.103421   \n",
       "                                            Train Accuracy   0.348293   \n",
       "...                                                               ...   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169 Accuracy         0.196420   \n",
       "                                            AUC              0.498032   \n",
       "                                            Train Loss      27.245023   \n",
       "                                            Train Accuracy   0.196710   \n",
       "                                            Train AUC        0.505100   \n",
       "\n",
       "                                                                    1  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss             1.089486   \n",
       "                                            Accuracy         0.372786   \n",
       "                                            AUC              0.533294   \n",
       "                                            Train Loss       1.092251   \n",
       "                                            Train Accuracy   0.370394   \n",
       "...                                                               ...   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169 Accuracy         0.195965   \n",
       "                                            AUC              0.498719   \n",
       "                                            Train Loss      24.507504   \n",
       "                                            Train Accuracy   0.196640   \n",
       "                                            Train AUC        0.500372   \n",
       "\n",
       "                                                                    2  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss             1.084925   \n",
       "                                            Accuracy         0.380087   \n",
       "                                            AUC              0.543315   \n",
       "                                            Train Loss       1.085799   \n",
       "                                            Train Accuracy   0.381516   \n",
       "...                                                               ...   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169 Accuracy         0.195393   \n",
       "                                            AUC              0.498959   \n",
       "                                            Train Loss      22.095238   \n",
       "                                            Train Accuracy   0.196341   \n",
       "                                            Train AUC        0.499929   \n",
       "\n",
       "                                                                    3  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss             1.082050   \n",
       "                                            Accuracy         0.386206   \n",
       "                                            AUC              0.550682   \n",
       "                                            Train Loss       1.081776   \n",
       "                                            Train Accuracy   0.386821   \n",
       "...                                                               ...   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169 Accuracy         0.194752   \n",
       "                                            AUC              0.499100   \n",
       "                                            Train Loss      19.988227   \n",
       "                                            Train Accuracy   0.196336   \n",
       "                                            Train AUC        0.499766   \n",
       "\n",
       "                                                                    4  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss             1.080157   \n",
       "                                            Accuracy         0.388733   \n",
       "                                            AUC              0.556136   \n",
       "                                            Train Loss       1.079140   \n",
       "                                            Train Accuracy   0.390184   \n",
       "...                                                               ...   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169 Accuracy         0.194052   \n",
       "                                            AUC              0.499201   \n",
       "                                            Train Loss      18.149702   \n",
       "                                            Train Accuracy   0.196248   \n",
       "                                            Train AUC        0.499693   \n",
       "\n",
       "                                                                    5  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss             1.078848   \n",
       "                                            Accuracy         0.389996   \n",
       "                                            AUC              0.560248   \n",
       "                                            Train Loss       1.077343   \n",
       "                                            Train Accuracy   0.392238   \n",
       "...                                                               ...   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169 Accuracy         0.193772   \n",
       "                                            AUC              0.499279   \n",
       "                                            Train Loss      16.543524   \n",
       "                                            Train Accuracy   0.196330   \n",
       "                                            Train AUC        0.499662   \n",
       "\n",
       "                                                                    6  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss             1.077901   \n",
       "                                            Accuracy         0.391295   \n",
       "                                            AUC              0.563450   \n",
       "                                            Train Loss       1.076068   \n",
       "                                            Train Accuracy   0.393292   \n",
       "...                                                               ...   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169 Accuracy         0.194320   \n",
       "                                            AUC              0.499350   \n",
       "                                            Train Loss      15.139264   \n",
       "                                            Train Accuracy   0.196661   \n",
       "                                            Train AUC        0.499652   \n",
       "\n",
       "                                                                    7  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss             1.077183   \n",
       "                                            Accuracy         0.392629   \n",
       "                                            AUC              0.566000   \n",
       "                                            Train Loss       1.075129   \n",
       "                                            Train Accuracy   0.394232   \n",
       "...                                                               ...   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169 Accuracy         0.194624   \n",
       "                                            AUC              0.499412   \n",
       "                                            Train Loss      13.911686   \n",
       "                                            Train Accuracy   0.197103   \n",
       "                                            Train AUC        0.499658   \n",
       "\n",
       "                                                                    8  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss             1.076617   \n",
       "                                            Accuracy         0.393904   \n",
       "                                            AUC              0.568082   \n",
       "                                            Train Loss       1.074413   \n",
       "                                            Train Accuracy   0.395504   \n",
       "...                                                               ...   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169 Accuracy         0.194764   \n",
       "                                            AUC              0.499474   \n",
       "                                            Train Loss      12.839479   \n",
       "                                            Train Accuracy   0.197493   \n",
       "                                            Train AUC        0.499674   \n",
       "\n",
       "                                                                    9  ...  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss             1.076155  ...   \n",
       "                                            Accuracy         0.394478  ...   \n",
       "                                            AUC              0.569817  ...   \n",
       "                                            Train Loss       1.073847  ...   \n",
       "                                            Train Accuracy   0.396163  ...   \n",
       "...                                                               ...  ...   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169 Accuracy         0.195335  ...   \n",
       "                                            AUC              0.499528  ...   \n",
       "                                            Train Loss      11.904266  ...   \n",
       "                                            Train Accuracy   0.197821  ...   \n",
       "                                            Train AUC        0.499695  ...   \n",
       "\n",
       "                                                                 145  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss            1.070333   \n",
       "                                            Accuracy        0.401299   \n",
       "                                            AUC             0.592322   \n",
       "                                            Train Loss      1.067931   \n",
       "                                            Train Accuracy  0.407098   \n",
       "...                                                              ...   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169 Accuracy        0.195592   \n",
       "                                            AUC             0.499037   \n",
       "                                            Train Loss      2.535947   \n",
       "                                            Train Accuracy  0.199241   \n",
       "                                            Train AUC       0.499045   \n",
       "\n",
       "                                                                 146  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss            1.070329   \n",
       "                                            Accuracy        0.401381   \n",
       "                                            AUC             0.592349   \n",
       "                                            Train Loss      1.067927   \n",
       "                                            Train Accuracy  0.407139   \n",
       "...                                                              ...   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169 Accuracy        0.195673   \n",
       "                                            AUC             0.499022   \n",
       "                                            Train Loss      2.523146   \n",
       "                                            Train Accuracy  0.199253   \n",
       "                                            Train AUC       0.499030   \n",
       "\n",
       "                                                                 147  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss            1.070325   \n",
       "                                            Accuracy        0.401322   \n",
       "                                            AUC             0.592375   \n",
       "                                            Train Loss      1.067922   \n",
       "                                            Train Accuracy  0.407136   \n",
       "...                                                              ...   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169 Accuracy        0.195673   \n",
       "                                            AUC             0.499007   \n",
       "                                            Train Loss      2.510520   \n",
       "                                            Train Accuracy  0.199227   \n",
       "                                            Train AUC       0.499015   \n",
       "\n",
       "                                                                 148  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss            1.070321   \n",
       "                                            Accuracy        0.401275   \n",
       "                                            AUC             0.592401   \n",
       "                                            Train Loss      1.067918   \n",
       "                                            Train Accuracy  0.407177   \n",
       "...                                                              ...   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169 Accuracy        0.195533   \n",
       "                                            AUC             0.498993   \n",
       "                                            Train Loss      2.498068   \n",
       "                                            Train Accuracy  0.199297   \n",
       "                                            Train AUC       0.499001   \n",
       "\n",
       "                                                                 149  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss            1.070317   \n",
       "                                            Accuracy        0.401299   \n",
       "                                            AUC             0.592426   \n",
       "                                            Train Loss      1.067913   \n",
       "                                            Train Accuracy  0.407191   \n",
       "...                                                              ...   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169 Accuracy        0.195533   \n",
       "                                            AUC             0.498978   \n",
       "                                            Train Loss      2.485785   \n",
       "                                            Train Accuracy  0.199192   \n",
       "                                            Train AUC       0.498986   \n",
       "\n",
       "                                                                 150  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss            1.070317   \n",
       "                                            Accuracy        0.401299   \n",
       "                                            AUC             0.592426   \n",
       "                                            Train Loss      1.067913   \n",
       "                                            Train Accuracy  0.407191   \n",
       "...                                                              ...   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169 Accuracy        0.195533   \n",
       "                                            AUC             0.498978   \n",
       "                                            Train Loss      2.485785   \n",
       "                                            Train Accuracy  0.199192   \n",
       "                                            Train AUC       0.498986   \n",
       "\n",
       "                                                                 151  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss            1.070317   \n",
       "                                            Accuracy        0.401299   \n",
       "                                            AUC             0.592426   \n",
       "                                            Train Loss      1.067913   \n",
       "                                            Train Accuracy  0.407191   \n",
       "...                                                              ...   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169 Accuracy        0.195533   \n",
       "                                            AUC             0.498978   \n",
       "                                            Train Loss      2.485785   \n",
       "                                            Train Accuracy  0.199192   \n",
       "                                            Train AUC       0.498986   \n",
       "\n",
       "                                                                 152  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss            1.070317   \n",
       "                                            Accuracy        0.401299   \n",
       "                                            AUC             0.592426   \n",
       "                                            Train Loss      1.067913   \n",
       "                                            Train Accuracy  0.407191   \n",
       "...                                                              ...   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169 Accuracy        0.195533   \n",
       "                                            AUC             0.498978   \n",
       "                                            Train Loss      2.485785   \n",
       "                                            Train Accuracy  0.199192   \n",
       "                                            Train AUC       0.498986   \n",
       "\n",
       "                                                                 153       154  \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss            1.070317  1.070317  \n",
       "                                            Accuracy        0.401299  0.401299  \n",
       "                                            AUC             0.592426  0.592426  \n",
       "                                            Train Loss      1.067913  1.067913  \n",
       "                                            Train Accuracy  0.407191  0.407191  \n",
       "...                                                              ...       ...  \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169 Accuracy        0.195533  0.195533  \n",
       "                                            AUC             0.498978  0.498978  \n",
       "                                            Train Loss      2.485785  2.485785  \n",
       "                                            Train Accuracy  0.199192  0.199192  \n",
       "                                            Train AUC       0.498986  0.498986  \n",
       "\n",
       "[3846 rows x 155 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runningMetrics_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attaching the last observation of each model, for each metric, to the parameters of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>batch-shuffle</th>\n",
       "      <th>batch-size</th>\n",
       "      <th>feature-lags</th>\n",
       "      <th>featureset</th>\n",
       "      <th>l2-penalty</th>\n",
       "      <th>l2-type</th>\n",
       "      <th>label-type</th>\n",
       "      <th>learning-rate</th>\n",
       "      <th>loss-from-logits</th>\n",
       "      <th>n-epochs</th>\n",
       "      <th>pastobs-in-percentage</th>\n",
       "      <th>pre-processing</th>\n",
       "      <th>id</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Train AUC</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Train Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_321</td>\n",
       "      <td>0</td>\n",
       "      <td>3300</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>quantgau</td>\n",
       "      <td>d62b1e6b8d95_321</td>\n",
       "      <td>0.770243</td>\n",
       "      <td>0.609699</td>\n",
       "      <td>0.899017</td>\n",
       "      <td>0.770233</td>\n",
       "      <td>0.607270</td>\n",
       "      <td>0.892077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_57</td>\n",
       "      <td>1</td>\n",
       "      <td>3300</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>d62b1e6b8d95_57</td>\n",
       "      <td>0.769295</td>\n",
       "      <td>0.609793</td>\n",
       "      <td>1.025276</td>\n",
       "      <td>0.769279</td>\n",
       "      <td>0.607994</td>\n",
       "      <td>1.026104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_269</td>\n",
       "      <td>1</td>\n",
       "      <td>21450</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>quantgau</td>\n",
       "      <td>d62b1e6b8d95_269</td>\n",
       "      <td>0.765728</td>\n",
       "      <td>0.609536</td>\n",
       "      <td>0.899042</td>\n",
       "      <td>0.765704</td>\n",
       "      <td>0.607570</td>\n",
       "      <td>0.898071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_281</td>\n",
       "      <td>0</td>\n",
       "      <td>21450</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>pow</td>\n",
       "      <td>d62b1e6b8d95_281</td>\n",
       "      <td>0.758545</td>\n",
       "      <td>0.609978</td>\n",
       "      <td>0.906770</td>\n",
       "      <td>0.758532</td>\n",
       "      <td>0.605583</td>\n",
       "      <td>0.908269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_16</td>\n",
       "      <td>1</td>\n",
       "      <td>21450</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>quantgau</td>\n",
       "      <td>b36f03f5d186_16</td>\n",
       "      <td>0.757047</td>\n",
       "      <td>0.608576</td>\n",
       "      <td>1.034854</td>\n",
       "      <td>0.757034</td>\n",
       "      <td>0.606462</td>\n",
       "      <td>1.032217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>HD_914f915c-2cac-473e-bea5-c26e4c83673c_25</td>\n",
       "      <td>0</td>\n",
       "      <td>10725</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>minmax</td>\n",
       "      <td>c26e4c83673c_25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>HD_914f915c-2cac-473e-bea5-c26e4c83673c_53</td>\n",
       "      <td>1</td>\n",
       "      <td>3300</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>c26e4c83673c_53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>HD_914f915c-2cac-473e-bea5-c26e4c83673c_68</td>\n",
       "      <td>1</td>\n",
       "      <td>10725</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>quantgau</td>\n",
       "      <td>c26e4c83673c_68</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>HD_914f915c-2cac-473e-bea5-c26e4c83673c_102</td>\n",
       "      <td>0</td>\n",
       "      <td>21450</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>minmax</td>\n",
       "      <td>c26e4c83673c_102</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_170</td>\n",
       "      <td>1</td>\n",
       "      <td>10725</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>std</td>\n",
       "      <td>b36f03f5d186_170</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>655 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          run_id batch-shuffle batch-size  \\\n",
       "321  HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_321             0       3300   \n",
       "57    HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_57             1       3300   \n",
       "269  HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_269             1      21450   \n",
       "281  HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_281             0      21450   \n",
       "500   HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_16             1      21450   \n",
       "..                                           ...           ...        ...   \n",
       "406   HD_914f915c-2cac-473e-bea5-c26e4c83673c_25             0      10725   \n",
       "434   HD_914f915c-2cac-473e-bea5-c26e4c83673c_53             1       3300   \n",
       "449   HD_914f915c-2cac-473e-bea5-c26e4c83673c_68             1      10725   \n",
       "483  HD_914f915c-2cac-473e-bea5-c26e4c83673c_102             0      21450   \n",
       "654  HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_170             1      10725   \n",
       "\n",
       "    feature-lags featureset l2-penalty l2-type label-type learning-rate  \\\n",
       "321            1          1       10.0       1          1        0.0001   \n",
       "57             3          2       0.01       0          3        0.0001   \n",
       "269            1          3    10000.0       2          2           0.1   \n",
       "281            1          3     1000.0       4          1          0.01   \n",
       "500            3          1        0.1       5          2           0.1   \n",
       "..           ...        ...        ...     ...        ...           ...   \n",
       "406            0          0       0.01       3          1         0.001   \n",
       "434            5          1      0.001       0          3        0.0001   \n",
       "449            5          2        0.1       0          3         0.001   \n",
       "483            3          0       10.0       6          3         0.001   \n",
       "654            1          3      0.001       5          1        0.0001   \n",
       "\n",
       "    loss-from-logits n-epochs pastobs-in-percentage pre-processing  \\\n",
       "321                0      150                     1       quantgau   \n",
       "57                 0      150                     0           None   \n",
       "269                0      150                     0       quantgau   \n",
       "281                0      150                     0            pow   \n",
       "500                1      150                     0       quantgau   \n",
       "..               ...      ...                   ...            ...   \n",
       "406                1      150                     1         minmax   \n",
       "434                1      150                     1           None   \n",
       "449                1      150                     0       quantgau   \n",
       "483                0      150                     0         minmax   \n",
       "654                0      150                     0            std   \n",
       "\n",
       "                   id       AUC  Accuracy      Loss  Train AUC  \\\n",
       "321  d62b1e6b8d95_321  0.770243  0.609699  0.899017   0.770233   \n",
       "57    d62b1e6b8d95_57  0.769295  0.609793  1.025276   0.769279   \n",
       "269  d62b1e6b8d95_269  0.765728  0.609536  0.899042   0.765704   \n",
       "281  d62b1e6b8d95_281  0.758545  0.609978  0.906770   0.758532   \n",
       "500   b36f03f5d186_16  0.757047  0.608576  1.034854   0.757034   \n",
       "..                ...       ...       ...       ...        ...   \n",
       "406   c26e4c83673c_25       NaN       NaN       NaN        NaN   \n",
       "434   c26e4c83673c_53       NaN       NaN       NaN        NaN   \n",
       "449   c26e4c83673c_68       NaN       NaN       NaN        NaN   \n",
       "483  c26e4c83673c_102       NaN       NaN       NaN        NaN   \n",
       "654  b36f03f5d186_170       NaN       NaN       NaN        NaN   \n",
       "\n",
       "     Train Accuracy  Train Loss  \n",
       "321        0.607270    0.892077  \n",
       "57         0.607994    1.026104  \n",
       "269        0.607570    0.898071  \n",
       "281        0.605583    0.908269  \n",
       "500        0.606462    1.032217  \n",
       "..              ...         ...  \n",
       "406             NaN         NaN  \n",
       "434             NaN         NaN  \n",
       "449             NaN         NaN  \n",
       "483             NaN         NaN  \n",
       "654             NaN         NaN  \n",
       "\n",
       "[655 rows x 20 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Resetting indcies and rename columns\n",
    "runningMetrics_lr2 = runningMetrics_lr.reset_index().rename(columns={'level_0':'run_id','level_1':'metric'})\n",
    "runningMetrics_lr2.columns = runningMetrics_lr2.columns.get_level_values(0)\n",
    "\n",
    "## Adding a column of short ids, to merge on.\n",
    "runningMetrics_lr2['id'] = [re.split('-',i)[-1] for i in runningMetrics_lr2.run_id] #np.arange(runningMetrics_lr2.shape[0]).astype(str)#\n",
    "runningMetrics_lr2\n",
    "\n",
    "# ## Creating a table, having the short id in the rows and the last observation for each metric in the columns. \n",
    "table_lr = pd.pivot_table(runningMetrics_lr2[['run_id','metric','154','id']],index='id',columns=['metric'])\n",
    "table_lr.columns = table_lr.columns.get_level_values(1)\n",
    "table_lr = table_lr.round(7).reset_index()\n",
    "table_lr\n",
    "\n",
    "## Preparing the parameter dataframe.\n",
    "parameters_lr2 = parameters_lr.reset_index().rename(columns={'index':'run_id'})\n",
    "\n",
    "## Setting short ID\n",
    "parameters_lr2['id'] = [re.split('-',i)[-1] for i in parameters_lr2.run_id] #np.arange(parameters_lr2.shape[0]).astype(str) #[re.split('_',i)[-1] for i in parameters_lr.run_id]\n",
    "\n",
    "## Creating the combined table\n",
    "combined_table_lr = parameters_lr2.merge(table_lr,\n",
    "                                     on = 'id',\n",
    "                                     how='left').sort_values('AUC',ascending=False)\n",
    "combined_table_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = [re.split('-',i)[-1] for i in runningMetrics_lr2.run_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'b36f03f5d186_169'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d62b1e6b8d95_0'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3846"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "641"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>metric</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "      <th>150</th>\n",
       "      <th>151</th>\n",
       "      <th>152</th>\n",
       "      <th>153</th>\n",
       "      <th>154</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_0</td>\n",
       "      <td>Loss</td>\n",
       "      <td>1.098537</td>\n",
       "      <td>1.098504</td>\n",
       "      <td>1.098467</td>\n",
       "      <td>1.098423</td>\n",
       "      <td>1.098371</td>\n",
       "      <td>1.098309</td>\n",
       "      <td>1.098233</td>\n",
       "      <td>1.098140</td>\n",
       "      <td>...</td>\n",
       "      <td>1.066601</td>\n",
       "      <td>1.066601</td>\n",
       "      <td>1.066601</td>\n",
       "      <td>1.066601</td>\n",
       "      <td>1.066601</td>\n",
       "      <td>1.066601</td>\n",
       "      <td>1.066601</td>\n",
       "      <td>1.066601</td>\n",
       "      <td>1.066601</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_0</td>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.354843</td>\n",
       "      <td>0.358482</td>\n",
       "      <td>0.362843</td>\n",
       "      <td>0.365199</td>\n",
       "      <td>0.366960</td>\n",
       "      <td>0.367240</td>\n",
       "      <td>0.368826</td>\n",
       "      <td>0.370377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.412316</td>\n",
       "      <td>0.412316</td>\n",
       "      <td>0.412316</td>\n",
       "      <td>0.412316</td>\n",
       "      <td>0.412316</td>\n",
       "      <td>0.412316</td>\n",
       "      <td>0.412316</td>\n",
       "      <td>0.412316</td>\n",
       "      <td>0.412316</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_0</td>\n",
       "      <td>AUC</td>\n",
       "      <td>0.500120</td>\n",
       "      <td>0.500277</td>\n",
       "      <td>0.500545</td>\n",
       "      <td>0.501018</td>\n",
       "      <td>0.501737</td>\n",
       "      <td>0.502806</td>\n",
       "      <td>0.504301</td>\n",
       "      <td>0.506150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.575838</td>\n",
       "      <td>0.575838</td>\n",
       "      <td>0.575838</td>\n",
       "      <td>0.575838</td>\n",
       "      <td>0.575838</td>\n",
       "      <td>0.575838</td>\n",
       "      <td>0.575838</td>\n",
       "      <td>0.575838</td>\n",
       "      <td>0.575838</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_0</td>\n",
       "      <td>Train Loss</td>\n",
       "      <td>1.098558</td>\n",
       "      <td>1.098524</td>\n",
       "      <td>1.098487</td>\n",
       "      <td>1.098442</td>\n",
       "      <td>1.098396</td>\n",
       "      <td>1.098339</td>\n",
       "      <td>1.098267</td>\n",
       "      <td>1.098180</td>\n",
       "      <td>...</td>\n",
       "      <td>1.068791</td>\n",
       "      <td>1.068791</td>\n",
       "      <td>1.068791</td>\n",
       "      <td>1.068791</td>\n",
       "      <td>1.068791</td>\n",
       "      <td>1.068791</td>\n",
       "      <td>1.068791</td>\n",
       "      <td>1.068791</td>\n",
       "      <td>1.068791</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_0</td>\n",
       "      <td>Train Accuracy</td>\n",
       "      <td>0.344181</td>\n",
       "      <td>0.350251</td>\n",
       "      <td>0.353537</td>\n",
       "      <td>0.358348</td>\n",
       "      <td>0.360740</td>\n",
       "      <td>0.363537</td>\n",
       "      <td>0.365985</td>\n",
       "      <td>0.368336</td>\n",
       "      <td>...</td>\n",
       "      <td>0.412060</td>\n",
       "      <td>0.412060</td>\n",
       "      <td>0.412060</td>\n",
       "      <td>0.412060</td>\n",
       "      <td>0.412060</td>\n",
       "      <td>0.412060</td>\n",
       "      <td>0.412060</td>\n",
       "      <td>0.412060</td>\n",
       "      <td>0.412060</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5995</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_999</td>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>...</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_999</td>\n",
       "      <td>AUC</td>\n",
       "      <td>0.006679</td>\n",
       "      <td>0.003153</td>\n",
       "      <td>0.002064</td>\n",
       "      <td>0.001534</td>\n",
       "      <td>0.001221</td>\n",
       "      <td>0.001014</td>\n",
       "      <td>0.000867</td>\n",
       "      <td>0.000757</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5997</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_999</td>\n",
       "      <td>Train Loss</td>\n",
       "      <td>5.383223</td>\n",
       "      <td>5.355752</td>\n",
       "      <td>5.355751</td>\n",
       "      <td>5.355751</td>\n",
       "      <td>5.355751</td>\n",
       "      <td>5.355750</td>\n",
       "      <td>5.355750</td>\n",
       "      <td>5.355750</td>\n",
       "      <td>...</td>\n",
       "      <td>5.355750</td>\n",
       "      <td>5.355750</td>\n",
       "      <td>5.355750</td>\n",
       "      <td>5.355750</td>\n",
       "      <td>5.355750</td>\n",
       "      <td>5.355750</td>\n",
       "      <td>5.355750</td>\n",
       "      <td>5.355750</td>\n",
       "      <td>5.355750</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5998</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_999</td>\n",
       "      <td>Train Accuracy</td>\n",
       "      <td>0.333057</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>...</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5999</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_999</td>\n",
       "      <td>Train AUC</td>\n",
       "      <td>0.030584</td>\n",
       "      <td>0.004384</td>\n",
       "      <td>0.002511</td>\n",
       "      <td>0.001766</td>\n",
       "      <td>0.001362</td>\n",
       "      <td>0.001109</td>\n",
       "      <td>0.000935</td>\n",
       "      <td>0.000809</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6000 rows × 158 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           run_id          metric         0  \\\n",
       "0       HD_81ace623-e09b-4393-8a5e-131ea8749a35_0            Loss  1.098537   \n",
       "1       HD_81ace623-e09b-4393-8a5e-131ea8749a35_0        Accuracy  0.354843   \n",
       "2       HD_81ace623-e09b-4393-8a5e-131ea8749a35_0             AUC  0.500120   \n",
       "3       HD_81ace623-e09b-4393-8a5e-131ea8749a35_0      Train Loss  1.098558   \n",
       "4       HD_81ace623-e09b-4393-8a5e-131ea8749a35_0  Train Accuracy  0.344181   \n",
       "...                                           ...             ...       ...   \n",
       "5995  HD_81ace623-e09b-4393-8a5e-131ea8749a35_999        Accuracy  0.337729   \n",
       "5996  HD_81ace623-e09b-4393-8a5e-131ea8749a35_999             AUC  0.006679   \n",
       "5997  HD_81ace623-e09b-4393-8a5e-131ea8749a35_999      Train Loss  5.383223   \n",
       "5998  HD_81ace623-e09b-4393-8a5e-131ea8749a35_999  Train Accuracy  0.333057   \n",
       "5999  HD_81ace623-e09b-4393-8a5e-131ea8749a35_999       Train AUC  0.030584   \n",
       "\n",
       "             1         2         3         4         5         6         7  \\\n",
       "0     1.098504  1.098467  1.098423  1.098371  1.098309  1.098233  1.098140   \n",
       "1     0.358482  0.362843  0.365199  0.366960  0.367240  0.368826  0.370377   \n",
       "2     0.500277  0.500545  0.501018  0.501737  0.502806  0.504301  0.506150   \n",
       "3     1.098524  1.098487  1.098442  1.098396  1.098339  1.098267  1.098180   \n",
       "4     0.350251  0.353537  0.358348  0.360740  0.363537  0.365985  0.368336   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "5995  0.337729  0.337729  0.337729  0.337729  0.337729  0.337729  0.337729   \n",
       "5996  0.003153  0.002064  0.001534  0.001221  0.001014  0.000867  0.000757   \n",
       "5997  5.355752  5.355751  5.355751  5.355751  5.355750  5.355750  5.355750   \n",
       "5998  0.332281  0.332281  0.332281  0.332281  0.332281  0.332281  0.332281   \n",
       "5999  0.004384  0.002511  0.001766  0.001362  0.001109  0.000935  0.000809   \n",
       "\n",
       "      ...       146       147       148       149       150       151  \\\n",
       "0     ...  1.066601  1.066601  1.066601  1.066601  1.066601  1.066601   \n",
       "1     ...  0.412316  0.412316  0.412316  0.412316  0.412316  0.412316   \n",
       "2     ...  0.575838  0.575838  0.575838  0.575838  0.575838  0.575838   \n",
       "3     ...  1.068791  1.068791  1.068791  1.068791  1.068791  1.068791   \n",
       "4     ...  0.412060  0.412060  0.412060  0.412060  0.412060  0.412060   \n",
       "...   ...       ...       ...       ...       ...       ...       ...   \n",
       "5995  ...  0.337729  0.337729  0.337729  0.337729  0.337729  0.337729   \n",
       "5996  ...  0.000113  0.000113  0.000113  0.000113  0.000113  0.000113   \n",
       "5997  ...  5.355750  5.355750  5.355750  5.355750  5.355750  5.355750   \n",
       "5998  ...  0.332281  0.332281  0.332281  0.332281  0.332281  0.332281   \n",
       "5999  ...  0.000114  0.000114  0.000114  0.000114  0.000114  0.000114   \n",
       "\n",
       "           152       153       154   id  \n",
       "0     1.066601  1.066601  1.066601    0  \n",
       "1     0.412316  0.412316  0.412316    0  \n",
       "2     0.575838  0.575838  0.575838    0  \n",
       "3     1.068791  1.068791  1.068791    0  \n",
       "4     0.412060  0.412060  0.412060    0  \n",
       "...        ...       ...       ...  ...  \n",
       "5995  0.337729  0.337729  0.337729  999  \n",
       "5996  0.000113  0.000113  0.000113  999  \n",
       "5997  5.355750  5.355750  5.355750  999  \n",
       "5998  0.332281  0.332281  0.332281  999  \n",
       "5999  0.000114  0.000114  0.000114  999  \n",
       "\n",
       "[6000 rows x 158 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runningMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>batch-shuffle</th>\n",
       "      <th>batch-size</th>\n",
       "      <th>feature-lags</th>\n",
       "      <th>featureset</th>\n",
       "      <th>l2-penalty</th>\n",
       "      <th>l2-type</th>\n",
       "      <th>label-type</th>\n",
       "      <th>learning-rate</th>\n",
       "      <th>loss-from-logits</th>\n",
       "      <th>n-epochs</th>\n",
       "      <th>pastobs-in-percentage</th>\n",
       "      <th>pre-processing</th>\n",
       "      <th>id</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Train AUC</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Train Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_380</td>\n",
       "      <td>1</td>\n",
       "      <td>3300</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>std</td>\n",
       "      <td>d62b1e6b8d95_380</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>HD_914f915c-2cac-473e-bea5-c26e4c83673c_5</td>\n",
       "      <td>1</td>\n",
       "      <td>21450</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>quantgau</td>\n",
       "      <td>c26e4c83673c_5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>HD_914f915c-2cac-473e-bea5-c26e4c83673c_8</td>\n",
       "      <td>1</td>\n",
       "      <td>3300</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>quantgau</td>\n",
       "      <td>c26e4c83673c_8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>HD_914f915c-2cac-473e-bea5-c26e4c83673c_9</td>\n",
       "      <td>0</td>\n",
       "      <td>21450</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>minmax</td>\n",
       "      <td>c26e4c83673c_9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>HD_914f915c-2cac-473e-bea5-c26e4c83673c_11</td>\n",
       "      <td>1</td>\n",
       "      <td>3300</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10000000000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>stacked</td>\n",
       "      <td>c26e4c83673c_11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>HD_914f915c-2cac-473e-bea5-c26e4c83673c_12</td>\n",
       "      <td>1</td>\n",
       "      <td>10725</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>stacked</td>\n",
       "      <td>c26e4c83673c_12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>HD_914f915c-2cac-473e-bea5-c26e4c83673c_15</td>\n",
       "      <td>0</td>\n",
       "      <td>10725</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>pow</td>\n",
       "      <td>c26e4c83673c_15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>HD_914f915c-2cac-473e-bea5-c26e4c83673c_16</td>\n",
       "      <td>1</td>\n",
       "      <td>3300</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>pow</td>\n",
       "      <td>c26e4c83673c_16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>HD_914f915c-2cac-473e-bea5-c26e4c83673c_19</td>\n",
       "      <td>1</td>\n",
       "      <td>3300</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>quantgau</td>\n",
       "      <td>c26e4c83673c_19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>HD_914f915c-2cac-473e-bea5-c26e4c83673c_25</td>\n",
       "      <td>0</td>\n",
       "      <td>10725</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>minmax</td>\n",
       "      <td>c26e4c83673c_25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>HD_914f915c-2cac-473e-bea5-c26e4c83673c_53</td>\n",
       "      <td>1</td>\n",
       "      <td>3300</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>c26e4c83673c_53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>HD_914f915c-2cac-473e-bea5-c26e4c83673c_68</td>\n",
       "      <td>1</td>\n",
       "      <td>10725</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>quantgau</td>\n",
       "      <td>c26e4c83673c_68</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>HD_914f915c-2cac-473e-bea5-c26e4c83673c_102</td>\n",
       "      <td>0</td>\n",
       "      <td>21450</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>minmax</td>\n",
       "      <td>c26e4c83673c_102</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_170</td>\n",
       "      <td>1</td>\n",
       "      <td>10725</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>std</td>\n",
       "      <td>b36f03f5d186_170</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          run_id batch-shuffle batch-size  \\\n",
       "380  HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_380             1       3300   \n",
       "386    HD_914f915c-2cac-473e-bea5-c26e4c83673c_5             1      21450   \n",
       "389    HD_914f915c-2cac-473e-bea5-c26e4c83673c_8             1       3300   \n",
       "390    HD_914f915c-2cac-473e-bea5-c26e4c83673c_9             0      21450   \n",
       "392   HD_914f915c-2cac-473e-bea5-c26e4c83673c_11             1       3300   \n",
       "393   HD_914f915c-2cac-473e-bea5-c26e4c83673c_12             1      10725   \n",
       "396   HD_914f915c-2cac-473e-bea5-c26e4c83673c_15             0      10725   \n",
       "397   HD_914f915c-2cac-473e-bea5-c26e4c83673c_16             1       3300   \n",
       "400   HD_914f915c-2cac-473e-bea5-c26e4c83673c_19             1       3300   \n",
       "406   HD_914f915c-2cac-473e-bea5-c26e4c83673c_25             0      10725   \n",
       "434   HD_914f915c-2cac-473e-bea5-c26e4c83673c_53             1       3300   \n",
       "449   HD_914f915c-2cac-473e-bea5-c26e4c83673c_68             1      10725   \n",
       "483  HD_914f915c-2cac-473e-bea5-c26e4c83673c_102             0      21450   \n",
       "654  HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_170             1      10725   \n",
       "\n",
       "    feature-lags featureset     l2-penalty l2-type label-type learning-rate  \\\n",
       "380            1          1          100.0       3          3        0.0001   \n",
       "386            1          3           0.01       1          0          0.01   \n",
       "389            3          2        10000.0       1          2           0.1   \n",
       "390            1          2           10.0       0          0          0.01   \n",
       "392            1          0  10000000000.0       1          1         0.001   \n",
       "393            3          2          100.0       2          1           0.1   \n",
       "396            3          3        10000.0       5          2        0.0001   \n",
       "397            1          3        10000.0       4          2         0.001   \n",
       "400            5          0         1000.0       5          1         0.001   \n",
       "406            0          0           0.01       3          1         0.001   \n",
       "434            5          1          0.001       0          3        0.0001   \n",
       "449            5          2            0.1       0          3         0.001   \n",
       "483            3          0           10.0       6          3         0.001   \n",
       "654            1          3          0.001       5          1        0.0001   \n",
       "\n",
       "    loss-from-logits n-epochs pastobs-in-percentage pre-processing  \\\n",
       "380                0      150                     0            std   \n",
       "386                0      150                     0       quantgau   \n",
       "389                1      150                     0       quantgau   \n",
       "390                1      150                     1         minmax   \n",
       "392                0      150                     1        stacked   \n",
       "393                0      150                     0        stacked   \n",
       "396                1      150                     1            pow   \n",
       "397                0      150                     0            pow   \n",
       "400                0      150                     0       quantgau   \n",
       "406                1      150                     1         minmax   \n",
       "434                1      150                     1           None   \n",
       "449                1      150                     0       quantgau   \n",
       "483                0      150                     0         minmax   \n",
       "654                0      150                     0            std   \n",
       "\n",
       "                   id  AUC  Accuracy  Loss  Train AUC  Train Accuracy  \\\n",
       "380  d62b1e6b8d95_380  NaN       NaN   NaN        NaN             NaN   \n",
       "386    c26e4c83673c_5  NaN       NaN   NaN        NaN             NaN   \n",
       "389    c26e4c83673c_8  NaN       NaN   NaN        NaN             NaN   \n",
       "390    c26e4c83673c_9  NaN       NaN   NaN        NaN             NaN   \n",
       "392   c26e4c83673c_11  NaN       NaN   NaN        NaN             NaN   \n",
       "393   c26e4c83673c_12  NaN       NaN   NaN        NaN             NaN   \n",
       "396   c26e4c83673c_15  NaN       NaN   NaN        NaN             NaN   \n",
       "397   c26e4c83673c_16  NaN       NaN   NaN        NaN             NaN   \n",
       "400   c26e4c83673c_19  NaN       NaN   NaN        NaN             NaN   \n",
       "406   c26e4c83673c_25  NaN       NaN   NaN        NaN             NaN   \n",
       "434   c26e4c83673c_53  NaN       NaN   NaN        NaN             NaN   \n",
       "449   c26e4c83673c_68  NaN       NaN   NaN        NaN             NaN   \n",
       "483  c26e4c83673c_102  NaN       NaN   NaN        NaN             NaN   \n",
       "654  b36f03f5d186_170  NaN       NaN   NaN        NaN             NaN   \n",
       "\n",
       "     Train Loss  \n",
       "380         NaN  \n",
       "386         NaN  \n",
       "389         NaN  \n",
       "390         NaN  \n",
       "392         NaN  \n",
       "393         NaN  \n",
       "396         NaN  \n",
       "397         NaN  \n",
       "400         NaN  \n",
       "406         NaN  \n",
       "434         NaN  \n",
       "449         NaN  \n",
       "483         NaN  \n",
       "654         NaN  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## How many NaN rows?\n",
    "print(len(combined_table_lr[combined_table_lr.isnull().any(axis=1)]))\n",
    "# 14 in total: 12 from run 881, 1 (last child run) from run 985 , 1 (last child run) from run 453\n",
    "# HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_380 doesn't exist in the experiment window in Azure, looks like it was initialised but not run (hyperparams file has it, metrics file does not)\n",
    "# HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_170 doesn't exist in the experiment window in Azure, looks like it was initialised but not run (hyperparams file has it, metrics file does not)\n",
    "# HD_914f915c-2cac-473e-bea5-c26e4c83673c has 11x NaNs because they failed (but metrics file does have all except _84! so they are included)\n",
    "# the 12 missed runs seems to be an error\n",
    "combined_table_lr[combined_table_lr.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating a top-X table for each label-type of a given metric, here AUC.\n",
    "temp_auc_lr = pd.pivot_table(combined_table_lr[['label-type','AUC','id']],index='id',columns='label-type')\n",
    "temp_acc_lr = pd.pivot_table(combined_table_lr[['label-type','Accuracy','id']],index='id',columns='label-type')\n",
    "\n",
    "## Final output - AUC\n",
    "final_output_auc_lr = pd.DataFrame(np.sort(temp_auc_lr.fillna(0).values,\n",
    "                             axis=0)[::-1],\n",
    "                             columns=temp_auc_lr.columns.get_level_values(1)).loc[0:10]\n",
    "## Final output - Accuracy\n",
    "final_output_acc_lr = pd.DataFrame(np.sort(temp_acc_lr.fillna(0).values,\n",
    "                             axis=0)[::-1],\n",
    "                             columns=temp_acc_lr.columns.get_level_values(1))#.loc[0:10]\n",
    "# final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>batch-shuffle</th>\n",
       "      <th>batch-size</th>\n",
       "      <th>feature-lags</th>\n",
       "      <th>featureset</th>\n",
       "      <th>l2-penalty</th>\n",
       "      <th>l2-type</th>\n",
       "      <th>label-type</th>\n",
       "      <th>learning-rate</th>\n",
       "      <th>loss-from-logits</th>\n",
       "      <th>n-epochs</th>\n",
       "      <th>pastobs-in-percentage</th>\n",
       "      <th>pre-processing</th>\n",
       "      <th>id</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Train AUC</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Train Loss</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label-type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_321</td>\n",
       "      <td>0</td>\n",
       "      <td>3300</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>quantgau</td>\n",
       "      <td>d62b1e6b8d95_321</td>\n",
       "      <td>0.770243</td>\n",
       "      <td>0.609699</td>\n",
       "      <td>0.899017</td>\n",
       "      <td>0.770233</td>\n",
       "      <td>0.607270</td>\n",
       "      <td>0.892077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_57</td>\n",
       "      <td>1</td>\n",
       "      <td>3300</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>d62b1e6b8d95_57</td>\n",
       "      <td>0.769295</td>\n",
       "      <td>0.609793</td>\n",
       "      <td>1.025276</td>\n",
       "      <td>0.769279</td>\n",
       "      <td>0.607994</td>\n",
       "      <td>1.026104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_269</td>\n",
       "      <td>1</td>\n",
       "      <td>21450</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>quantgau</td>\n",
       "      <td>d62b1e6b8d95_269</td>\n",
       "      <td>0.765728</td>\n",
       "      <td>0.609536</td>\n",
       "      <td>0.899042</td>\n",
       "      <td>0.765704</td>\n",
       "      <td>0.607570</td>\n",
       "      <td>0.898071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_330</td>\n",
       "      <td>0</td>\n",
       "      <td>10725</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>d62b1e6b8d95_330</td>\n",
       "      <td>0.743810</td>\n",
       "      <td>0.605753</td>\n",
       "      <td>0.923442</td>\n",
       "      <td>0.743768</td>\n",
       "      <td>0.601687</td>\n",
       "      <td>0.919710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_54</td>\n",
       "      <td>0</td>\n",
       "      <td>21450</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>std</td>\n",
       "      <td>d62b1e6b8d95_54</td>\n",
       "      <td>0.736580</td>\n",
       "      <td>0.605878</td>\n",
       "      <td>0.998291</td>\n",
       "      <td>0.736546</td>\n",
       "      <td>0.599142</td>\n",
       "      <td>0.948503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 run_id batch-shuffle  \\\n",
       "label-type                                                              \n",
       "1           HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_321             0   \n",
       "3            HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_57             1   \n",
       "2           HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_269             1   \n",
       "0           HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_330             0   \n",
       "4            HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_54             0   \n",
       "\n",
       "           batch-size feature-lags featureset l2-penalty l2-type label-type  \\\n",
       "label-type                                                                    \n",
       "1                3300            1          1       10.0       1          1   \n",
       "3                3300            3          2       0.01       0          3   \n",
       "2               21450            1          3    10000.0       2          2   \n",
       "0               10725            5          3       10.0       2          0   \n",
       "4               21450            0          3    10000.0       1          4   \n",
       "\n",
       "           learning-rate loss-from-logits n-epochs pastobs-in-percentage  \\\n",
       "label-type                                                                 \n",
       "1                 0.0001                0      150                     1   \n",
       "3                 0.0001                0      150                     0   \n",
       "2                    0.1                0      150                     0   \n",
       "0                  0.001                1      150                     1   \n",
       "4                   0.01                1      150                     1   \n",
       "\n",
       "           pre-processing                id       AUC  Accuracy      Loss  \\\n",
       "label-type                                                                  \n",
       "1                quantgau  d62b1e6b8d95_321  0.770243  0.609699  0.899017   \n",
       "3                    None   d62b1e6b8d95_57  0.769295  0.609793  1.025276   \n",
       "2                quantgau  d62b1e6b8d95_269  0.765728  0.609536  0.899042   \n",
       "0                    None  d62b1e6b8d95_330  0.743810  0.605753  0.923442   \n",
       "4                     std   d62b1e6b8d95_54  0.736580  0.605878  0.998291   \n",
       "\n",
       "            Train AUC  Train Accuracy  Train Loss  \n",
       "label-type                                         \n",
       "1            0.770233        0.607270    0.892077  \n",
       "3            0.769279        0.607994    1.026104  \n",
       "2            0.765704        0.607570    0.898071  \n",
       "0            0.743768        0.601687    0.919710  \n",
       "4            0.736546        0.599142    0.948503  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tempFinal_v0_lr = combined_table_lr[np.isin(combined_table_lr.AUC,final_output_auc_lr.loc[0].values.flatten())]\n",
    "tempFinal_v0_lr.index = tempFinal_v0_lr.loc[:,'label-type']\n",
    "tempFinal_v0_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "run_id                   HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_321\n",
       "batch-shuffle                                                      0\n",
       "batch-size                                                      3300\n",
       "feature-lags                                                       1\n",
       "featureset                                                         1\n",
       "l2-penalty                                                      10.0\n",
       "l2-type                                                            1\n",
       "label-type                                                         1\n",
       "learning-rate                                                 0.0001\n",
       "loss-from-logits                                                   0\n",
       "n-epochs                                                         150\n",
       "pastobs-in-percentage                                              1\n",
       "pre-processing                                              quantgau\n",
       "id                                                  d62b1e6b8d95_321\n",
       "AUC                                                         0.770243\n",
       "Accuracy                                                    0.609699\n",
       "Loss                                                        0.899017\n",
       "Train AUC                                                   0.770233\n",
       "Train Accuracy                                               0.60727\n",
       "Train Loss                                                  0.892077\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tempFinal_v0_lr.loc['1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>label-type</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.743810</td>\n",
       "      <td>0.770243</td>\n",
       "      <td>0.765728</td>\n",
       "      <td>0.769295</td>\n",
       "      <td>0.736580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.721774</td>\n",
       "      <td>0.758545</td>\n",
       "      <td>0.757047</td>\n",
       "      <td>0.744937</td>\n",
       "      <td>0.724654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.714000</td>\n",
       "      <td>0.750477</td>\n",
       "      <td>0.748841</td>\n",
       "      <td>0.698706</td>\n",
       "      <td>0.724517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.679195</td>\n",
       "      <td>0.743498</td>\n",
       "      <td>0.746708</td>\n",
       "      <td>0.694823</td>\n",
       "      <td>0.711150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.671642</td>\n",
       "      <td>0.734464</td>\n",
       "      <td>0.730215</td>\n",
       "      <td>0.671782</td>\n",
       "      <td>0.711061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.640807</td>\n",
       "      <td>0.715505</td>\n",
       "      <td>0.724101</td>\n",
       "      <td>0.654014</td>\n",
       "      <td>0.710338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.638079</td>\n",
       "      <td>0.713154</td>\n",
       "      <td>0.721513</td>\n",
       "      <td>0.639567</td>\n",
       "      <td>0.702422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.630913</td>\n",
       "      <td>0.709437</td>\n",
       "      <td>0.719707</td>\n",
       "      <td>0.572875</td>\n",
       "      <td>0.698800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.630850</td>\n",
       "      <td>0.684589</td>\n",
       "      <td>0.711174</td>\n",
       "      <td>0.547524</td>\n",
       "      <td>0.684616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.625526</td>\n",
       "      <td>0.675148</td>\n",
       "      <td>0.700884</td>\n",
       "      <td>0.547256</td>\n",
       "      <td>0.679712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.624141</td>\n",
       "      <td>0.669039</td>\n",
       "      <td>0.698419</td>\n",
       "      <td>0.544227</td>\n",
       "      <td>0.673169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "label-type         0         1         2         3         4\n",
       "0           0.743810  0.770243  0.765728  0.769295  0.736580\n",
       "1           0.721774  0.758545  0.757047  0.744937  0.724654\n",
       "2           0.714000  0.750477  0.748841  0.698706  0.724517\n",
       "3           0.679195  0.743498  0.746708  0.694823  0.711150\n",
       "4           0.671642  0.734464  0.730215  0.671782  0.711061\n",
       "5           0.640807  0.715505  0.724101  0.654014  0.710338\n",
       "6           0.638079  0.713154  0.721513  0.639567  0.702422\n",
       "7           0.630913  0.709437  0.719707  0.572875  0.698800\n",
       "8           0.630850  0.684589  0.711174  0.547524  0.684616\n",
       "9           0.625526  0.675148  0.700884  0.547256  0.679712\n",
       "10          0.624141  0.669039  0.698419  0.544227  0.673169"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_output_auc_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label-type\n",
       "0    0.609582\n",
       "1    0.609978\n",
       "2    0.610655\n",
       "3    0.609793\n",
       "4    0.606345\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_output_acc_lr.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>batch-shuffle</th>\n",
       "      <th>batch-size</th>\n",
       "      <th>feature-lags</th>\n",
       "      <th>featureset</th>\n",
       "      <th>l2-penalty</th>\n",
       "      <th>l2-type</th>\n",
       "      <th>label-type</th>\n",
       "      <th>learning-rate</th>\n",
       "      <th>loss-from-logits</th>\n",
       "      <th>n-epochs</th>\n",
       "      <th>pastobs-in-percentage</th>\n",
       "      <th>pre-processing</th>\n",
       "      <th>id</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Train AUC</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Train Loss</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label-type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_73</td>\n",
       "      <td>0</td>\n",
       "      <td>21450</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>std</td>\n",
       "      <td>d62b1e6b8d95_73</td>\n",
       "      <td>0.104320</td>\n",
       "      <td>0.609582</td>\n",
       "      <td>0.896365</td>\n",
       "      <td>0.104317</td>\n",
       "      <td>0.606454</td>\n",
       "      <td>0.900158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_281</td>\n",
       "      <td>0</td>\n",
       "      <td>21450</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>pow</td>\n",
       "      <td>d62b1e6b8d95_281</td>\n",
       "      <td>0.758545</td>\n",
       "      <td>0.609978</td>\n",
       "      <td>0.906770</td>\n",
       "      <td>0.758532</td>\n",
       "      <td>0.605583</td>\n",
       "      <td>0.908269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_1</td>\n",
       "      <td>0</td>\n",
       "      <td>3300</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>quantgau</td>\n",
       "      <td>d62b1e6b8d95_1</td>\n",
       "      <td>0.748841</td>\n",
       "      <td>0.610655</td>\n",
       "      <td>1.028220</td>\n",
       "      <td>0.748771</td>\n",
       "      <td>0.608715</td>\n",
       "      <td>1.028798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_57</td>\n",
       "      <td>1</td>\n",
       "      <td>3300</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>d62b1e6b8d95_57</td>\n",
       "      <td>0.769295</td>\n",
       "      <td>0.609793</td>\n",
       "      <td>1.025276</td>\n",
       "      <td>0.769279</td>\n",
       "      <td>0.607994</td>\n",
       "      <td>1.026104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_43</td>\n",
       "      <td>1</td>\n",
       "      <td>21450</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10000000000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>quantgau</td>\n",
       "      <td>d62b1e6b8d95_43</td>\n",
       "      <td>0.679712</td>\n",
       "      <td>0.606345</td>\n",
       "      <td>1.030533</td>\n",
       "      <td>0.679452</td>\n",
       "      <td>0.602908</td>\n",
       "      <td>1.031799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 run_id batch-shuffle  \\\n",
       "label-type                                                              \n",
       "0            HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_73             0   \n",
       "1           HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_281             0   \n",
       "2             HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_1             0   \n",
       "3            HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_57             1   \n",
       "4            HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_43             1   \n",
       "\n",
       "           batch-size feature-lags featureset     l2-penalty l2-type  \\\n",
       "label-type                                                             \n",
       "0               21450            0          0          0.001       5   \n",
       "1               21450            1          3         1000.0       4   \n",
       "2                3300            1          2           10.0       1   \n",
       "3                3300            3          2           0.01       0   \n",
       "4               21450            1          3  10000000000.0       4   \n",
       "\n",
       "           label-type learning-rate loss-from-logits n-epochs  \\\n",
       "label-type                                                      \n",
       "0                   0         0.001                0      150   \n",
       "1                   1          0.01                0      150   \n",
       "2                   2           0.1                0      150   \n",
       "3                   3        0.0001                0      150   \n",
       "4                   4        0.0001                0      150   \n",
       "\n",
       "           pastobs-in-percentage pre-processing                id       AUC  \\\n",
       "label-type                                                                    \n",
       "0                              1            std   d62b1e6b8d95_73  0.104320   \n",
       "1                              0            pow  d62b1e6b8d95_281  0.758545   \n",
       "2                              1       quantgau    d62b1e6b8d95_1  0.748841   \n",
       "3                              0           None   d62b1e6b8d95_57  0.769295   \n",
       "4                              0       quantgau   d62b1e6b8d95_43  0.679712   \n",
       "\n",
       "            Accuracy      Loss  Train AUC  Train Accuracy  Train Loss  \n",
       "label-type                                                             \n",
       "0           0.609582  0.896365   0.104317        0.606454    0.900158  \n",
       "1           0.609978  0.906770   0.758532        0.605583    0.908269  \n",
       "2           0.610655  1.028220   0.748771        0.608715    1.028798  \n",
       "3           0.609793  1.025276   0.769279        0.607994    1.026104  \n",
       "4           0.606345  1.030533   0.679452        0.602908    1.031799  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tempFinal_v1_lr = combined_table_lr[np.isin(combined_table_lr.Accuracy,final_output_acc_lr.loc[0].values.flatten())].sort_values('label-type').copy(deep=True)\n",
    "tempFinal_v1_lr.index = tempFinal_v1_lr.loc[:,'label-type']\n",
    "tempFinal_v1_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['run_id',\n",
       " 'batch-shuffle',\n",
       " 'batch-size',\n",
       " 'feature-lags',\n",
       " 'featureset',\n",
       " 'l2-penalty',\n",
       " 'l2-type',\n",
       " 'label-type',\n",
       " 'learning-rate',\n",
       " 'loss-from-logits',\n",
       " 'n-epochs',\n",
       " 'pastobs-in-percentage',\n",
       " 'pre-processing',\n",
       " 'id',\n",
       " 'AUC',\n",
       " 'Accuracy',\n",
       " 'Loss',\n",
       " 'Train AUC',\n",
       " 'Train Accuracy',\n",
       " 'Train Loss']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(combined_table_lr.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp_lr = combined_table_lr[(combined_table_lr.loc[:,'label-type']=='0')&\\\n",
    "                            (combined_table_lr.loc[:,'loss-from-logits']=='1')&\\\n",
    "                            (combined_table_lr.AUC>0.5)]\n",
    "temp_2_lr = pd.pivot_table(temp_lr,\n",
    "                        values='AUC',\n",
    "                        columns='learning-rate',\n",
    "                        index='run_id').reset_index()\n",
    "temp_2_lr.boxplot(list(temp_2_lr.columns[1:]),\n",
    "                  figsize=(7,7))#temp_2.columns[2:]\n",
    "plt.grid(b=None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-4f76a9dad686>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mstop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'stop' is not defined"
     ]
    }
   ],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reading in the market data (done automatically atm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping ETFS and market indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Ticker.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the XNTK ticker\n",
    "data = data[~data.Ticker.isin(['XNTK'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Ticker.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the XNTK ticker\n",
    "data = data[~data.Ticker.isin(['XNTK'])]\n",
    "\n",
    "etfs = ['IYH','IYM','IYK','IYJ','IYG','IYW','IYC','IYR','IDU','IYZ','IYE','IYF','SPY','DIA','QQQ']\n",
    "\n",
    "# Extracting the sector ETFs to a separate variable\n",
    "sectorETFS = data[data.Ticker.isin(etfs)]\n",
    "\n",
    "# Removing the ETFs\n",
    "data = data[~data.Ticker.isin(etfs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Generate Features ################\n",
    "\n",
    "n_feature_lags = 1\n",
    "\n",
    "# features = generateFeatures_multi_final(data = data, \n",
    "#                                   listOfFeatures = [\n",
    "#                                                     'pastobs',\n",
    "#                                                     'spread',\n",
    "#                                                     'bidsize',\n",
    "#                                                     'ofrsize',\n",
    "# #                                                     'stok',\n",
    "# #                                                     'stod',\n",
    "# #                                                     'sstod',\n",
    "# #                                                     'wilr',\n",
    "# #                                                     'roc',\n",
    "# #                                                     'rsi',\n",
    "# #                                                     'atr',\n",
    "# #                                                     'cci',\n",
    "# #                                                     'dpo',\n",
    "# #                                                     'sma',\n",
    "# #                                                     'ema',\n",
    "# #                                                     'macd',\n",
    "# #                                                       'macd_diff',\n",
    "# #                                                       'macd_signal',\n",
    "# #                                                     'dis5',\n",
    "# #                                                     'dis10',\n",
    "#                                                       'sector'\n",
    "#                                                    ], \n",
    "#                                    feature_lags = n_feature_lags\n",
    "#                                      ,stockTable=stockTable)\n",
    "features = generateFeatures_multi_final(data = data, \n",
    "                                  listOfFeatures = [\n",
    "                                                    'pastobs',\n",
    "                                                    'spread',\n",
    "                                                    'bidsize',\n",
    "                                                    'ofrsize',\n",
    "                                                    'stok',\n",
    "                                                    'stod',\n",
    "                                                    'sstod',\n",
    "#                                                     'wilr',\n",
    "                                                    'roc',\n",
    "                                                    'rsi',\n",
    "                                                    'atr',\n",
    "                                                    'cci',\n",
    "                                                    'dpo',\n",
    "                                                    'sma',\n",
    "                                                    'ema',\n",
    "                                                    'macd',\n",
    "                                                      'macd_diff',\n",
    "                                                      'macd_signal',\n",
    "                                                    'dis5',\n",
    "                                                    'dis10',\n",
    "                                                      'sector'\n",
    "                                                   ], \n",
    "                                   feature_lags = n_feature_lags\n",
    "                                     ,sectorETFS=sectorETFS)\n",
    "\n",
    "########### Generate Labels ################\n",
    "\n",
    "n_classes = 2\n",
    "# extract first 4 columns as the lag0 or raw OHLC prices (used for labelling)\n",
    "price_candles = data[['open','high','low','close','Ticker']]\n",
    "\n",
    "########### Align Data ################\n",
    "\n",
    "# from imported function (see testing_preprocessing_features_and_labels.ipynb for thorough experimenting with all the cut-offs):    \n",
    "X, y,indices = align_features_and_labels_multi_final(price_candles = price_candles, \n",
    "                                                 all_features = features,\n",
    "                                                 prediction_horizon = 1, \n",
    "                                                 n_feature_lags = n_feature_lags, \n",
    "                                                 n_classes = n_classes, # 5,\n",
    "                                                 safe_burn_in = False, \n",
    "                                                 data_sample = 'full',\n",
    "                                                 splitType='global',\n",
    "                                                 noise=False,ticker_dummies=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding ticker dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Adding ticker dummies\n",
    "tickers = X.pop('ticker')\n",
    "X = pd.concat([X, pd.get_dummies(tickers, prefix='ticker', drop_first=False)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing our final train/validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ds = pd.concat([X.iloc[start:end, :] for (start, end) in train_ranges]).reset_index(drop=True)\n",
    "# train_y = pd.concat([y.iloc[start:end] for (start, end) in train_ranges]).reset_index(drop=True)\n",
    "\n",
    "# validate_ds = pd.concat([X.iloc[start:end, :] for (start, end) in val_ranges]).reset_index(drop=True)\n",
    "# val_y = pd.concat([y.iloc[start:end] for (start, end) in val_ranges]).reset_index(drop=True)\n",
    "\n",
    "# train_ds.shape, train_y.shape, validate_ds.shape, val_y.shape, train_y.shape[0] + val_y.shape[0]\n",
    "\n",
    "# Let's have a proper split (along tickers & dates)\n",
    "train_size = 0.8\n",
    "\n",
    "# Sort the indices\n",
    "tempIndices = indices.sort_values(['days','timestamps','ticker'])\n",
    "\n",
    "# Sorting the data\n",
    "X = X.loc[tempIndices.index,:]#.head(66)\n",
    "y = y.loc[tempIndices.index,:]\n",
    "\n",
    "# extracting the first date for the validation data.\n",
    "first_val_day = int(np.floor(indices.days.unique().shape[0]*0.8))\n",
    "\n",
    "# Splitting the data\n",
    "X_train = X[tempIndices.days<tempIndices.days.unique()[first_val_day]].reset_index(drop=True)\n",
    "y_train = y[tempIndices.days<tempIndices.days.unique()[first_val_day]].reset_index(drop=True)\n",
    "\n",
    "X_test = X[tempIndices.days>=tempIndices.days.unique()[first_val_day]].reset_index(drop=True)\n",
    "y_test = y[tempIndices.days>=tempIndices.days.unique()[first_val_day]].reset_index(drop=True)\n",
    "\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where((np.sum(np.isinf(X_train.values), axis=1) == 0) == False),\n",
    "np.where((np.sum(np.isnan(X_train.values), axis=1) == 0) == False)#X_train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{i:colname for i,colname in enumerate(train_ds.columns)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating one ppdict for individual preprocessings\n",
    "# ppdict1 = {'open':'minmax',\n",
    "#           'high':'log',\n",
    "#           'low':'log',\n",
    "#           'close':'std'}\n",
    "# splitpoint = 32\n",
    "\n",
    "# # Standardize some features\n",
    "# ppdict1 = {i:'std' for i in train_ds.columns[0:splitpoint]} \n",
    "# # Keep some in actual levels (Dummies in this case).\n",
    "# ppdict2 = {i:'act' for i in train_ds.columns[splitpoint:]}\n",
    "\n",
    "pre_procesing_applied = 'std'\n",
    "\n",
    "# Merging the two\n",
    "# ppdict = {**ppdict1,**ppdict2}\n",
    "\n",
    "if  pre_procesing_applied == 'None':\n",
    "    # do nothing here\n",
    "    pass\n",
    "\n",
    "elif  pre_procesing_applied == 'std':\n",
    "\n",
    "    # splitpoint = int((args.feature-lags+1)*16)#32\n",
    "    # columns_to_pre_process = [col for col in X_train.columns if 'd_' != col[0:2]]\n",
    "\n",
    "    # Standardize some features\n",
    "    ppdict1 = {i:'std' for i in X_train.columns if 'd_' != i[0:2]} \n",
    "    # Keep some in actual levels (Dummies in this case).\n",
    "    ppdict2 = {i:'act' for i in X_train.columns if 'd_' == i[0:2]} \n",
    "\n",
    "    # Merging the two\n",
    "    ppdict = {**ppdict1,**ppdict2}\n",
    "\n",
    "    # x_train,x_test = pre_processing(x_train,x_test,pp_dict)\n",
    "\n",
    "elif pre_procesing_applied == 'minmax':\n",
    "\n",
    "    # splitpoint = int((args.feature-lags+1)*16)#32\n",
    "    # columns_to_pre_process = [col for col in X_train.columns if 'd_' != col[0:2]]\n",
    "\n",
    "    # Standardize some features\n",
    "    ppdict1 = {i:'minmax' for i in X_train.columns if 'd_' != i[0:2]} \n",
    "    # Keep some in actual levels (Dummies in this case).\n",
    "    ppdict2 = {i:'act' for i in X_train.columns if 'd_' == i[0:2]} \n",
    "\n",
    "    # Merging the two\n",
    "    ppdict = {**ppdict1,**ppdict2}\n",
    "\n",
    "    # x_train,x_test = pre_processing(X_train,X_test,pp_dict)\n",
    "\n",
    "elif pre_procesing_applied == 'pow':\n",
    "\n",
    "    # splitpoint = int((args.feature-lags+1)*16)#32\n",
    "    # columns_to_pre_process = [col for col in X_train.columns if 'd_' != col[0:2]]\n",
    "\n",
    "    # Standardize some features\n",
    "    ppdict1 = {i:'pow' for i in X_train.columns if 'd_' != i[0:2]} \n",
    "    # Keep some in actual levels (Dummies in this case).\n",
    "    ppdict2 = {i:'act' for i in X_train.columns if 'd_' == i[0:2]} \n",
    "\n",
    "    # Merging the two\n",
    "    ppdict = {**ppdict1,**ppdict2}\n",
    "\n",
    "    # x_train,x_test = pre_processing(x_train,x_test,pp_dict)\n",
    "\n",
    "elif pre_procesing_applied == 'quantgau':\n",
    "\n",
    "    # splitpoint = int((args.feature-lags+1)*16)#32\n",
    "    # columns_to_pre_process = [col for col in X_train.columns if 'd_' != col[0:2]]\n",
    "\n",
    "    # Standardize some features\n",
    "    ppdict1 = {i:'quantgau' for i in X_train.columns if 'd_' != i[0:2]} \n",
    "    # Keep some in actual levels (Dummies in this case).\n",
    "    ppdict2 = {i:'act' for i in X_train.columns if 'd_' == i[0:2]} \n",
    "\n",
    "    # Merging the two\n",
    "    ppdict = {**ppdict1,**ppdict2}\n",
    "\n",
    "    # x_train,x_test = pre_processing(x_train,x_test,pp_dict)\n",
    "\n",
    "elif pre_procesing_applied == 'individual':\n",
    "\n",
    "    # splitpoint = int((args.feature-lags+1)*16)#32\n",
    "    # columns_to_pre_process = [col for col in X_train.columns if 'd_' != col[0:2]]\n",
    "\n",
    "    # Standardize some features\n",
    "    \n",
    "    # ppdict1 = {i:'power' for i in X_train.columns if 'd_' != i[0:2]}\n",
    "\n",
    "\n",
    "    # Keep some in actual levels (Dummies in this case).\n",
    "    ppdict2 = {i:'act' for i in X_train.columns if 'd_' == i[0:2]} \n",
    "\n",
    "    # Merging the two\n",
    "    ppdict = {**ppdict1,**ppdict2}\n",
    "\n",
    "    # x_train,x_test = pre_processing(x_train,x_test,pp_dict)\n",
    "\n",
    "elif pre_procesing_applied == 'stacked':\n",
    "\n",
    "    # splitpoint = int((args.feature-lags+1)*16)#32\n",
    "    # columns_to_pre_process = [col for col in X_train.columns if 'd_' != col[0:2]]\n",
    "\n",
    "    # Standardize some features\n",
    "    \n",
    "    for j in ['pow','std','minmax']:\n",
    "\n",
    "        ppdict1 = {i:j for i in X_train.columns if 'd_' != i[0:2]}\n",
    "\n",
    "        # Keep some in actual levels (Dummies in this case).\n",
    "        ppdict2 = {i:'act' for i in X_train.columns if 'd_' == i[0:2]} \n",
    "\n",
    "        # Merging the two\n",
    "        ppdict = {**ppdict1,**ppdict2}\n",
    "\n",
    "        X_train,X_test = pre_processing(X_train,X_test,ppdict)\n",
    "\n",
    "if pre_procesing_applied not in ['None','stacked']:\n",
    "    X_train,X_test = pre_processing(X_train,X_test,ppdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppX_train.iloc[:,0].mean(),ppX_train.iloc[:,0].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepping for models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_VALIDATION = val_y.shape[0] #int(1e3)\n",
    "N_TRAIN = train_y.shape[0] #int(1e4)\n",
    "# BUFFER_SIZE = int(1e4)\n",
    "BATCH_SIZE = 256 #512 #32\n",
    "MAX_EPOCHS = 500\n",
    "\n",
    "STEPS_PER_EPOCH = N_TRAIN//BATCH_SIZE\n",
    "\n",
    "N_REPEAT = int(N_TRAIN / ((STEPS_PER_EPOCH * MAX_EPOCHS) / BATCH_SIZE))\n",
    "FEATURES = X.shape[1]\n",
    "\n",
    "N_TRAIN, N_VALIDATION, N_TRAIN + N_VALIDATION, STEPS_PER_EPOCH, N_REPEAT, STEPS_PER_EPOCH * MAX_EPOCHS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Logistic Regression model in TF/Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "      #keras.metrics.TruePositives(name='tp'),\n",
    "      #keras.metrics.FalsePositives(name='fp'),\n",
    "      #keras.metrics.TrueNegatives(name='tn'),\n",
    "      #keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      #keras.metrics.Precision(name='precision'),\n",
    "      #keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "]\n",
    "\n",
    "# def make_model(metrics = METRICS, output_bias=None):\n",
    "#   if output_bias is not None:\n",
    "#     output_bias = tf.keras.initializers.Constant(output_bias)\n",
    "#   model = keras.Sequential([\n",
    "#       keras.layers.Dense(\n",
    "#           16, activation='relu',\n",
    "#           input_shape=(train_features.shape[-1],)),\n",
    "#       keras.layers.Dropout(0.5),\n",
    "#       keras.layers.Dense(1, activation='sigmoid',\n",
    "#                          bias_initializer=output_bias),\n",
    "#   ])\n",
    "\n",
    "#   model.compile(\n",
    "#       optimizer=keras.optimizers.Adam(lr=1e-3),\n",
    "#       loss=keras.losses.BinaryCrossentropy(),\n",
    "#       metrics=metrics)\n",
    "\n",
    "#   return model\n",
    "\n",
    "# model = keras.Sequential({\n",
    "#   keras.layers.Dense(1, input_shape=(FEATURES,))\n",
    "# })\n",
    "\n",
    "model = keras.Sequential([\n",
    "#     keras.layers.Flatten(input_shape=(28, 28)),\n",
    "#     keras.layers.Dense(128, activation='relu'),\n",
    "#     keras.layers.Dense(10)\n",
    "    keras.layers.Dense(1,\n",
    "                       input_shape=(FEATURES,),\n",
    "                       activation='sigmoid',\n",
    "                       kernel_regularizer=regularizers.l2(1))\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# with final activation (Keras/TF tutorial advises against this practice, but they also use it later in the tutorial)\n",
    "# model = keras.Sequential({\n",
    "#   keras.layers.Dense(1, input_shape=(FEATURES,), activation='sigmoid')\n",
    "# })\n",
    "\n",
    "#model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['binary_accuracy', ])\n",
    "model.compile(\n",
    "              optimizer=keras.optimizers.Adam(), #lr=1e-3\n",
    "              loss=keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "              metrics=METRICS)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "                                                monitor='val_auc', \n",
    "                                                verbose=1,\n",
    "                                                patience=100,\n",
    "                                                mode='max',\n",
    "                                                restore_best_weights=True)\n",
    "\n",
    "def get_callbacks(run_id):\n",
    "      return [\n",
    "             tfdocs.modeling.EpochDots(),\n",
    "             early_stopping,\n",
    "             tf.keras.callbacks.TensorBoard(logdir), #/run_id),\n",
    "      ]\n",
    "\n",
    "baseline_history = model.fit(\n",
    "                            train_ds, #train_features,\n",
    "                            train_y, #train_labels,\n",
    "                            batch_size=512, #BATCH_SIZE,\n",
    "                            epochs=1000, #EPOCHS,\n",
    "                            callbacks = get_callbacks(run_id = 'first'), #[early_stopping],\n",
    "                            validation_data=(validate_ds, val_y),\n",
    "                            verbose=0) #(val_features, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(validate_ds,  val_y, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
