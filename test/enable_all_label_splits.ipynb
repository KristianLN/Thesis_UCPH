{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The aim of this notebook is to implement the work presented in the article [here](https://towardsdatascience.com/how-to-train-multiple-machine-learning-models-and-run-other-data-tasks-in-parallel-by-combining-2fa9670dd579)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n",
      "C:\\Users\\fstri\\AppData\\Local\\Temp\\tmpshdx2d3y\\tensorboard_logs\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "import h5py\n",
    "import copy\n",
    "import datetime\n",
    "import ta\n",
    "import pathlib\n",
    "import shutil\n",
    "import tempfile\n",
    "# import vaex\n",
    "from IPython import display\n",
    "from IPython.display import clear_output\n",
    "import pyodbc\n",
    "\n",
    "# Tensorflow related\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "import tensorflow.compat.v2.feature_column as fc\n",
    "\n",
    "#!pip install -q git+https://github.com/tensorflow/docs\n",
    "\n",
    "import tensorflow_docs as tfdocs\n",
    "import tensorflow_docs.modeling\n",
    "import tensorflow_docs.plots\n",
    "\n",
    "print(tf.__version__)\n",
    "logdir = pathlib.Path(tempfile.mkdtemp())/\"tensorboard_logs\"\n",
    "shutil.rmtree(logdir, ignore_errors=True)\n",
    "print(logdir)\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, f1_score, log_loss\n",
    "\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.exceptions import ConvergenceWarning \n",
    "from sklearn import ensemble\n",
    "# ConvergenceWarning('ignore')\n",
    "# Do you wanna see?\n",
    "verbose = True\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "#sys.path.append('...../')\n",
    "\n",
    "from utils.data_extraction import load_data_final,load_data_and_save\n",
    "from utils.data_cleaning import HFDataCleaning\n",
    "from utils.generate_features import candleCreateNP_vect_final,\\\n",
    "                                    generateFeatures_final,\\\n",
    "                                    generateFeatures_multi_v2\n",
    "\n",
    "from utils.preprocessing_features_and_labels import extract_labels,\\\n",
    "                                                    align_features_and_labels,\\\n",
    "                                                    pre_processing_initial,\\\n",
    "                                                    pre_processing_extended,\\\n",
    "                                                    pre_processing,\\\n",
    "                                                    extract_labels_multi_final,\\\n",
    "                                                    align_features_and_labels_multi_final,\\\n",
    "                                                    align_features_and_labels_multi_v5\n",
    "\n",
    "from utils.models import make_input_fn\n",
    "from utils.models import performanceTesting,scoreFunction\n",
    "from utils.plotting import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 1 2 2 2 2 3 3 4] [ 0  1  3  7  9 10]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1.,  1.,  2.,  2.,  2.,  2.,  3.,  3.,  4., nan])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = list(range(11))\n",
    "test_data\n",
    "\n",
    "#pd.cut(test_data, bins=5)\n",
    "#.qcut(test_data, )\n",
    "\n",
    "# xyz, splits = pd.qcut(test_data, q=[0, 0.2, 0.8, 1], labels=False, retbins=True)\n",
    "xyz, splits = pd.qcut(test_data, q=[0, 0.1, 0.3, 0.7, 0.9, 1], labels=False, retbins=True)\n",
    "\n",
    "print(xyz, splits)\n",
    "\n",
    "labels = pd.cut(test_data, bins=splits, labels=False, right=False, include_lowest=True)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2], dtype=int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " pd.qcut(test_data, q=[0, 0.2, 0.8, 1], labels=False) #, retbins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which one do you want to load? \n",
      "\n",
      "0: aggregateTAQ_10sec.csv\n",
      "1: aggregateTAQ_30sec.csv\n",
      "2: aggregateTAQ_60sec.csv\n",
      "\n",
      "\n",
      "2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>sector</th>\n",
       "      <th>exchange</th>\n",
       "      <th>marketCap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Technology</td>\n",
       "      <td>NMS</td>\n",
       "      <td>1.578173e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>ABBV</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>NYQ</td>\n",
       "      <td>1.742612e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>ABT</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>NYQ</td>\n",
       "      <td>1.631410e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>126</td>\n",
       "      <td>AEP</td>\n",
       "      <td>Utilities</td>\n",
       "      <td>NYQ</td>\n",
       "      <td>4.089551e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>379</td>\n",
       "      <td>AMT</td>\n",
       "      <td>Real Estate</td>\n",
       "      <td>NYQ</td>\n",
       "      <td>1.171259e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>428</td>\n",
       "      <td>APD</td>\n",
       "      <td>Basic Materials</td>\n",
       "      <td>NYQ</td>\n",
       "      <td>5.464395e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>697</td>\n",
       "      <td>BA</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>NYQ</td>\n",
       "      <td>1.020356e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>699</td>\n",
       "      <td>BABA</td>\n",
       "      <td>Consumer Cyclical</td>\n",
       "      <td>NYQ</td>\n",
       "      <td>5.936536e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>BAC</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>NYQ</td>\n",
       "      <td>2.020550e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>BHP</td>\n",
       "      <td>Basic Materials</td>\n",
       "      <td>NYQ</td>\n",
       "      <td>1.258194e+11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ticker              sector exchange     marketCap\n",
       "12    AAPL          Technology      NMS  1.578173e+12\n",
       "20    ABBV          Healthcare      NYQ  1.742612e+11\n",
       "34     ABT          Healthcare      NYQ  1.631410e+11\n",
       "126    AEP           Utilities      NYQ  4.089551e+10\n",
       "379    AMT         Real Estate      NYQ  1.171259e+11\n",
       "428    APD     Basic Materials      NYQ  5.464395e+10\n",
       "697     BA         Industrials      NYQ  1.020356e+11\n",
       "699   BABA   Consumer Cyclical      NYQ  5.936536e+11\n",
       "700    BAC  Financial Services      NYQ  2.020550e+11\n",
       "870    BHP     Basic Materials      NYQ  1.258194e+11"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do we extract new data or read in?\n",
    "readIn = True\n",
    "# run load_data()\n",
    "if readIn:\n",
    "    \n",
    "    # Listing the data files \n",
    "    #path = '../../../Google Drev/Thesis/Data/TAQ/AggregatedTAQ'\n",
    "    path = 'F:/AggregatedTAQ/round3'\n",
    "    datafiles = os.listdir(path)\n",
    "    content = np.concatenate([['\\n\\n'],[str(j)+': '+i+'\\n' for j,i in enumerate(datafiles) if 'csv' in i],['\\n\\n']])\n",
    "    \n",
    "    # Asking for user input\n",
    "    file = input('Which one do you want to load? %s'%''.join(content))\n",
    "    data = pd.read_csv(path + '/' + datafiles[int(file)],\n",
    "                       header = None,\n",
    "                       names=['open','high','low','close',\n",
    "                              'spread_open','spread_high','spread_low','spread_close',\n",
    "                              'bidsize_open','bidsize_high','bidsize_low','bidsize_close',\n",
    "                              'ofrsize_open','ofrsize_high','ofrsize_low','ofrsize_close',\n",
    "                              'Ticker'])\n",
    "    # Lower casing all column names\n",
    "#     data.columns = data.columns.str.lower()\n",
    "else:\n",
    "    \n",
    "    # print(os.listdir())\n",
    "    try:\n",
    "        path = 'a:/taqhdf5'  #'a:/taqhdf5'\n",
    "        os.listdir(path)\n",
    "    except:\n",
    "        path = 't:/taqhdf5'  #'a:/taqhdf5'\n",
    "        os.listdir(path)\n",
    "        \n",
    "    # Sample type\n",
    "    data_sample = 'full' # or 'stable'\n",
    "    # allFiles = os.listdir(path)\n",
    "    # print(len(allFiles), allFiles[:5], allFiles[-5:])\n",
    "    # print(allFiles[-10:])\n",
    "\n",
    "    #dates = np.array(['2020040' + str(i) if i < 10 else '202004' + str(i) for i in np.arange(1,16)]).astype(int)\n",
    "    dates = np.array(['20200501']).astype(int)#,'20200402','20200403','20200406','20200407'\n",
    "\n",
    "    # Provide a list of tickers of interest\n",
    "    \n",
    "    tickers = sorted(['TSLA','FB'])#'MSFT'\n",
    "    \n",
    "    # Do we need data on trades, quotes or both?\n",
    "    dataNeeded = 'quotes' # 'trades', 'quotes' or 'both'\n",
    "    \n",
    "    if dataNeeded == 'trades':\n",
    "        tradeData = load_data_final(dates, tickers, dataNeeded, path, verbose)\n",
    "    elif dataNeeded == 'quotes':\n",
    "        quoteData = load_data_final(dates,\n",
    "                                    tickers,\n",
    "                                    dataNeeded,\n",
    "                                    path,\n",
    "                                    verbose,\n",
    "                                    extract_candles = False,\n",
    "                                    aggHorizon = 1,\n",
    "                                    extra_features_from_quotes = None,\n",
    "                                    data_sample = data_sample)\n",
    "    elif dataNeeded == 'both':\n",
    "        tradeData, quoteData = load_data_final(dates, tickers, dataNeeded, path, verbose)\n",
    "\n",
    "# Reading in sector information\n",
    "stockInfo = pd.read_csv('../utils/stockInfo_v1.csv',header=[0,1])\n",
    "stockInfo.columns = ['ticker','sector','exchange','marketCap']\n",
    "\n",
    "# Creating a table with stock information based on the tickers available in the data.\n",
    "uniqueTickers = data.Ticker.unique()\n",
    "stockTable = stockInfo[stockInfo.ticker.isin(uniqueTickers)]\n",
    "stockTable.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping ETFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "etfs = ['IYH','IYM','IYK','IYJ','IYG','IYW','IYC','IYR','IDU','IYZ','IYE','IYF']\n",
    "\n",
    "# Extracting the sector ETFs to a separate variable\n",
    "sectorETFS = data[data.Ticker.isin(etfs)]\n",
    "\n",
    "# Removing the ETFs\n",
    "data = data[~data.Ticker.isin(etfs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAPL done\n",
      "ABBV done\n",
      "ABT done\n",
      "AEP done\n",
      "AMT done\n",
      "APD done\n",
      "BA done\n",
      "BABA done\n",
      "BAC done\n",
      "BHP done\n",
      "BP done\n",
      "CCI done\n",
      "CHL done\n",
      "COST done\n",
      "CSGP done\n",
      "D done\n",
      "DIS done\n",
      "ECL done\n",
      "ENB done\n",
      "EXC done\n",
      "FB done\n",
      "FMX done\n",
      "GOOG done\n",
      "INTC done\n",
      "JNJ done\n",
      "KO done\n",
      "LFC done\n",
      "LIN done\n",
      "LMT done\n",
      "MA done\n",
      "MCD done\n",
      "MSFT done\n",
      "NKE done\n",
      "NVDA done\n",
      "NVS done\n",
      "Number of NaNs in label: 1. 1 is expected\n",
      "Returns that lead to NaNs in label: [0.0907158]\n",
      "PBR done\n",
      "PEP done\n",
      "PFE done\n",
      "PLD done\n",
      "PSA done\n",
      "PTR done\n",
      "PYPL done\n",
      "RTX done\n",
      "SHW done\n",
      "SNP done\n",
      "SO done\n",
      "SRE done\n",
      "T done\n",
      "TM done\n",
      "TSLA done\n",
      "TSM done\n",
      "UNP done\n",
      "UPS done\n",
      "V done\n",
      "WMT done\n"
     ]
    }
   ],
   "source": [
    "########### Generate Features ################\n",
    "\n",
    "n_feature_lags = 1\n",
    "\n",
    "features = generateFeatures_multi_v2(data = data, \n",
    "                                  listOfFeatures = [\n",
    "                                                    'pastobs',\n",
    "                                                    'spread',\n",
    "                                                    'bidsize',\n",
    "                                                    'ofrsize',\n",
    "#                                                     'stok',\n",
    "#                                                     'stod',\n",
    "#                                                     'sstod',\n",
    "#                                                     'wilr',\n",
    "#                                                     'roc',\n",
    "#                                                     'rsi',\n",
    "#                                                     'atr',\n",
    "#                                                     'cci',\n",
    "#                                                     'dpo',\n",
    "#                                                     'sma',\n",
    "#                                                     'ema',\n",
    "#                                                     'macd',\n",
    "#                                                       'macd_diff',\n",
    "#                                                       'macd_signal',\n",
    "#                                                     'dis5',\n",
    "#                                                     'dis10',\n",
    "                                                      'sector'\n",
    "                                                   ], \n",
    "                                   feature_lags = n_feature_lags\n",
    "                                     ,stockTable=stockTable)\n",
    "\n",
    "########### Generate Labels ################\n",
    "\n",
    "n_classes = 2\n",
    "# extract first 4 columns as the lag0 or raw OHLC prices (used for labelling)\n",
    "price_candles = data[['open','high','low','close','Ticker']]\n",
    "\n",
    "########### Align Data ################\n",
    "\n",
    "# from imported function (see testing_preprocessing_features_and_labels.ipynb for thorough experimenting with all the cut-offs):    \n",
    "X, y = align_features_and_labels_multi_final(price_candles = price_candles, \n",
    "                                             all_features = features,\n",
    "                                             prediction_horizon = 1, \n",
    "                                             n_feature_lags = n_feature_lags, \n",
    "                                             n_classes = n_classes, # 5,\n",
    "                                             safe_burn_in = False, \n",
    "                                             data_sample = 'full',\n",
    "                                             splitType='global',\n",
    "                                             noise=False,ticker_dummies=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expanding functions:\n",
    "\n",
    "- extract_labels_multi \n",
    "- align_features_and_labels_multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Works only for two classes (by using median)\n",
    "# def extract_labels_multi(data = None,\n",
    "#                         classes = 5,\n",
    "#                         group_style = 'equal',\n",
    "#                         splits=None):\n",
    "    \n",
    "#     # this version takes data in a direct returns for a specific ticker\n",
    "\n",
    "#     if group_style == 'equal':\n",
    "#         # if splits is None:\n",
    "#             # splits = np.array_split(np.sort(returns),classes)\n",
    "\n",
    "#         # for i in np.arange(classes):\n",
    "\n",
    "#         #labels[returns > global_median] = 1\n",
    "#         #labels[returns <= global_median] = 0\n",
    "        \n",
    "#         labels = pd.cut(data, bins=splits, labels=False, right=False, include_lowest=True)\n",
    "        \n",
    "#         # we need right=False (open right-handside in split interval) to get median into the positive class\n",
    "\n",
    "#     elif group_style != 'equal':\n",
    "#         raise ValueError(f'group_style {group_style} not implemented')\n",
    "\n",
    "#     return labels #, returns, [thresholdsMin, thresholdsMax]\n",
    "\n",
    "# per version 6 we no longer use group_style, as the \"splits\" fully describes splits for both equal and non-equal\n",
    "def extract_labels_multi_v6(data = None,\n",
    "                            classes = 5,\n",
    "                            splits=None):\n",
    "\n",
    "    # this version takes data in a direct returns for a specific ticker\n",
    "    # per version 6 we no longer use group_style, as the \"splits\" fully describes splits for both equal and non-equal\n",
    "\n",
    "    labels = pd.cut(data, bins=splits, labels=False, right=False, include_lowest=True)\n",
    "\n",
    "    # we need right=False (open right-handside in split interval) to get median into the positive class\n",
    "    # this makes the last point nan, we fix it here\n",
    "    if sum(np.isnan(labels)) > 0:\n",
    "        print(f'Number of NaNs in label: {sum(np.isnan(labels))}. 1 is expected')\n",
    "        print(f'Returns that lead to NaNs in label: {data[np.where(np.isnan(labels))]}')\n",
    "        assert sum(np.isnan(labels)) <= 1, \"There should be max 1 NaN\"\n",
    "\n",
    "        if data[np.where(np.isnan(labels))] >= splits[-1]:\n",
    "            labels[np.where(np.isnan(labels))] = classes - 1 # assign last label id\n",
    "        else:\n",
    "            print(data[np.where(np.isnan(labels))], splits[-1])\n",
    "            raise ValueError('There is a label NaN where its underlying return is not max of dataset, which it should be')\n",
    "\n",
    "    return labels\n",
    "\n",
    "\n",
    "# def align_features_and_labels_multi(price_candles,\n",
    "#                                     all_features,\n",
    "#                                     prediction_horizon,\n",
    "#                                     n_feature_lags,\n",
    "#                                     n_classes,\n",
    "#                                     safe_burn_in = False,\n",
    "#                                     data_sample = 'full',\n",
    "#                                     splitType='global',\n",
    "#                                     noise = True):\n",
    "\n",
    "#     all_burned_in_features = pd.DataFrame()\n",
    "#     all_labels = pd.DataFrame()\n",
    "    \n",
    "#     if splitType.lower() == 'global':\n",
    "#         # Making the splits for the labels based on all tickers\n",
    "#         # returns = ((price_candles['close'].values[1:] / price_candles['close'].values[:-1]) -1) * 100\n",
    "# #         returns = np.concatenate([((price_candles[price_candles.Ticker==ticker]['close'].values[1:]/\\\n",
    "# #                          price_candles[price_candles.Ticker==ticker]['close'].values[:-1])-1) for ticker\\\n",
    "# #                           in price_candles.Ticker.unique()])\n",
    "\n",
    "#         returns = []\n",
    "#         tickers = []\n",
    "#         for ticker in price_candles.Ticker.unique():\n",
    "\n",
    "#             ticker_returns = (price_candles[price_candles.Ticker==ticker]['close'].values[1:]/\\\n",
    "#                                  price_candles[price_candles.Ticker==ticker]['close'].values[:-1]) - 1\n",
    "#             ticker_names = [ticker for i in range(len(ticker_returns))]\n",
    "\n",
    "#             returns.append(ticker_returns)\n",
    "#             tickers.append(ticker_names)\n",
    "\n",
    "#         # concatenate returns and add noise    \n",
    "#         returns = np.concatenate(returns)\n",
    "#         if noise:\n",
    "#             returns[returns==0] = np.random.normal(0,1,sum(returns==0))/1000000\n",
    "\n",
    "#         tickers = np.concatenate(tickers)\n",
    "\n",
    "#         _, splits = pd.qcut(returns, q=n_classes, labels=False, retbins=True)\n",
    "#         print(splits)\n",
    "        \n",
    "#         returns = pd.DataFrame({'returns': returns, 'Ticker': tickers})\n",
    "        \n",
    "        \n",
    "        \n",
    "#     for ticker_iter, ticker_name in enumerate(all_features.ticker.unique()):\n",
    "#         ticker_features = all_features[all_features.ticker==ticker_name].copy(deep=True)\n",
    "#         # removing the \"ticker\" variable from ticker_features as np.isnan() does not like non-numericals\n",
    "#         #ticker_features = ticker_features.iloc[:, ticker_features.columns != 'ticker']\n",
    "#         ticker_features.drop('ticker', axis=1, inplace=True)\n",
    "#         # extract first 4 columns as the lag0 or raw OHLC prices (used for labelling)\n",
    "#         #ticker_prices = price_candles[price_candles.Ticker==ticker_name]['close'].values # candles.iloc[:, :4].values\n",
    "#         ticker_returns = returns[returns.Ticker==ticker_name]['returns'].values\n",
    "\n",
    "#         if not safe_burn_in:\n",
    "#             assert data_sample == 'full'\n",
    "#             # we assume data_sample is full and that we can continue features from yesterday's values.\n",
    "#             # that we have a single burn-in at the beginning and that's it\n",
    "\n",
    "#             # get first index that has no NaNs (the sum checks for True across columns, we look for sum == 0 and where that is first True)\n",
    "#             burned_in_idx = np.where((np.sum(np.isnan(ticker_features.values), axis=1) == 0) == True)[0][0]\n",
    "\n",
    "#             # calculate end-point cut-off to match with labels\n",
    "#             end_point_cut = max(prediction_horizon, n_feature_lags + 1)\n",
    "\n",
    "#             # slice away the observations used for burn-in (taking off 1 at the end to match with labels [slice off \"prediction_horizon\"])\n",
    "#             burned_in_features = ticker_features.iloc[burned_in_idx : -end_point_cut, :] #.reset_index(drop=True) # features[burned_in_idx:] latter is sligthly faster but maybe not as precise\n",
    "\n",
    "#             # slice away the burned-in indices from labels\n",
    "#             labels = extract_labels_multi(data = ticker_returns[(burned_in_idx+n_feature_lags):],\n",
    "#                                           classes = n_classes,\n",
    "#                                           group_style = 'equal',\n",
    "#                                           splits = splits)\n",
    "#             # labels, returns, thresholds = extract_labels(data = candles[burned_in_idx + n_feature_lags : , :],\n",
    "#             #                                             classes = n_classes, group_style = 'equal')\n",
    "\n",
    "#             # check if there are remaining NaNs are burn-in (means error)\n",
    "#             remaining_nans = np.where(np.isnan(burned_in_features.values))[0].size\n",
    "#             if remaining_nans > 0:\n",
    "#                 raise ValueError('Had NaN in burned_in_features after burn-in')\n",
    "\n",
    "#         burned_in_features['ticker'] = ticker_name\n",
    "#         all_burned_in_features = pd.concat([all_burned_in_features, burned_in_features])\n",
    "#         all_labels = pd.concat([all_labels, pd.Series(labels)])\n",
    "#         print(ticker_name + \" done\")\n",
    "\n",
    "#     return all_burned_in_features, all_labels.reset_index(drop=True) # call the function as X, y = align_features_and_labels(.) if you like\n",
    "\n",
    "\n",
    "# adding custom label splitting (label_split) for multi-class\n",
    "def align_features_and_labels_multi_v8(price_candles,\n",
    "                                        all_features,\n",
    "                                        prediction_horizon,\n",
    "                                        n_feature_lags,\n",
    "                                        n_classes,\n",
    "                                        label_split = [],\n",
    "                                        safe_burn_in = False,\n",
    "                                        data_sample = 'full',\n",
    "                                        splitType='global',\n",
    "                                        noise = False,\n",
    "                                        ticker_dummies = False):\n",
    "\n",
    "    all_burned_in_features = pd.DataFrame()\n",
    "    all_burned_in_indices = pd.DataFrame()\n",
    "    all_labels = pd.DataFrame()\n",
    "\n",
    "    dailyIndices = pd.DataFrame({'days':price_candles.index.get_level_values(0),\n",
    "                                  'timestamps':price_candles.index.get_level_values(1),\n",
    "                                  'ticker':price_candles.Ticker})\n",
    "\n",
    "    if splitType.lower() == 'global':\n",
    "        # Making the splits for the labels based on all tickers\n",
    "        # returns = ((price_candles['close'].values[1:] / price_candles['close'].values[:-1]) -1) * 100\n",
    "#         returns = np.concatenate([((price_candles[price_candles.Ticker==ticker]['close'].values[1:]/\\\n",
    "#                          price_candles[price_candles.Ticker==ticker]['close'].values[:-1])-1) for ticker\\\n",
    "#                           in price_candles.Ticker.unique()])\n",
    "\n",
    "        returns = []\n",
    "        tickers = []\n",
    "\n",
    "        for ticker in price_candles.Ticker.unique():\n",
    "\n",
    "            ticker_returns = (price_candles[price_candles.Ticker==ticker]['close'].values[1:]/\\\n",
    "                                 price_candles[price_candles.Ticker==ticker]['close'].values[:-1]) - 1\n",
    "            ticker_names = [ticker for i in range(len(ticker_returns))]\n",
    "\n",
    "            returns.append(ticker_returns)\n",
    "            tickers.append(ticker_names)\n",
    "\n",
    "        # concatenate returns and add noise\n",
    "        returns = np.concatenate(returns)\n",
    "        if noise:\n",
    "            returns[returns==0] = np.random.normal(0,1,sum(returns==0))/1000000\n",
    "\n",
    "        tickers = np.concatenate(tickers)\n",
    "        \n",
    "        if label_split == []:\n",
    "            # equal-sized bins according to n_classes\n",
    "            _, splits = pd.qcut(returns, q=n_classes, labels=False, retbins=True)\n",
    "        elif label_split != []:\n",
    "            _, splits = pd.qcut(returns, q=label_split, labels=False, retbins=True)\n",
    "            \n",
    "        #print(splits)\n",
    "\n",
    "        returns = pd.DataFrame({'returns': returns, 'Ticker': tickers})\n",
    "\n",
    "    keepCheck = []\n",
    "\n",
    "    for ticker_iter, ticker_name in enumerate(all_features.ticker.unique()):\n",
    "        ticker_features = all_features[all_features.ticker==ticker_name].copy(deep=True)\n",
    "        ticker_indices = dailyIndices[dailyIndices.ticker==ticker_name].copy(deep=True)\n",
    "        # removing the \"ticker\" variable from ticker_features as np.isnan() does not like non-numericals\n",
    "        #ticker_features = ticker_features.iloc[:, ticker_features.columns != 'ticker']\n",
    "        ticker_features.drop('ticker', axis=1, inplace=True)\n",
    "        # extract first 4 columns as the lag0 or raw OHLC prices (used for labelling)\n",
    "        #ticker_prices = price_candles[price_candles.Ticker==ticker_name]['close'].values # candles.iloc[:, :4].values\n",
    "        ticker_returns = returns[returns.Ticker==ticker_name]['returns'].values\n",
    "\n",
    "        if not safe_burn_in:\n",
    "            assert data_sample == 'full'\n",
    "            # we assume data_sample is full and that we can continue features from yesterday's values.\n",
    "            # that we have a single burn-in at the beginning and that's it\n",
    "\n",
    "            # get first index that has no NaNs (the sum checks for True across columns, we look for sum == 0 and where that is first True)\n",
    "            burned_in_idx = np.where((np.sum(np.isnan(ticker_features.values), axis=1) == 0) == True)[0][0]\n",
    "            keepCheck.append(burned_in_idx)\n",
    "            # calculate end-point cut-off to match with labels\n",
    "            end_point_cut = max(prediction_horizon, n_feature_lags + 1)\n",
    "\n",
    "            # slice away the observations used for burn-in (taking off 1 at the end to match with labels [slice off \"prediction_horizon\"])\n",
    "            burned_in_features = ticker_features.iloc[burned_in_idx : -end_point_cut, :] #.reset_index(drop=True) # features[burned_in_idx:] latter is sligthly faster but maybe not as precise\n",
    "            burned_in_indices = ticker_indices.iloc[burned_in_idx : -end_point_cut, :]\n",
    "            # slice away the burned-in indices from labels\n",
    "            labels = extract_labels_multi_v6(data = ticker_returns[(burned_in_idx+n_feature_lags):],\n",
    "                                                classes = n_classes,\n",
    "                                                splits = splits)\n",
    "            # labels, returns, thresholds = extract_labels(data = candles[burned_in_idx + n_feature_lags : , :],\n",
    "            #                                             classes = n_classes, group_style = 'equal')\n",
    "\n",
    "            # check if there are remaining NaNs are burn-in (means error)\n",
    "            remaining_nans = np.where(np.isnan(burned_in_features.values))[0].size\n",
    "            if remaining_nans > 0:\n",
    "                raise ValueError('Had NaN in burned_in_features after burn-in')\n",
    "\n",
    "        # Adding the ticker\n",
    "        burned_in_features.loc[:,'ticker'] = ticker_name\n",
    "\n",
    "        # Adding the burned in data\n",
    "        all_burned_in_features = pd.concat([all_burned_in_features, burned_in_features.reset_index(drop=True)])\n",
    "        all_burned_in_indices = pd.concat([all_burned_in_indices, burned_in_indices.reset_index(drop=True)])\n",
    "        all_labels = pd.concat([all_labels, pd.Series(labels)])\n",
    "        print(ticker_name + \" done\")\n",
    "\n",
    "    # Returning the ticker as dummies\n",
    "    if ticker_dummies:\n",
    "\n",
    "        tickers = all_burned_in_features.pop('ticker')\n",
    "        all_burned_in_features = pd.concat([all_burned_in_features, pd.get_dummies(tickers, prefix='d_ticker', drop_first=False)], axis=1)\n",
    "#     print('Are all burned_in_idx the same?', all(keepCheck==keepCheck[0]))\n",
    "#     print(dailyIndicies.head(50))\n",
    "    return all_burned_in_features.reset_index(drop=True),\\\n",
    "            all_labels.reset_index(drop=True),\\\n",
    "            all_burned_in_indices.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAPL done\n",
      "ABBV done\n",
      "ABT done\n",
      "AEP done\n",
      "AMT done\n",
      "APD done\n",
      "BA done\n",
      "BABA done\n",
      "BAC done\n",
      "BHP done\n",
      "BP done\n",
      "CCI done\n",
      "CHL done\n",
      "COST done\n",
      "CSGP done\n",
      "D done\n",
      "DIS done\n",
      "ECL done\n",
      "ENB done\n",
      "EXC done\n",
      "FB done\n",
      "FMX done\n",
      "GOOG done\n",
      "INTC done\n",
      "JNJ done\n",
      "KO done\n",
      "LFC done\n",
      "LIN done\n",
      "LMT done\n",
      "MA done\n",
      "MCD done\n",
      "MSFT done\n",
      "NKE done\n",
      "NVDA done\n",
      "NVS done\n",
      "Number of NaNs in label: 1. 1 is expected\n",
      "Returns that lead to NaNs in label: [0.0907158]\n",
      "PBR done\n",
      "PEP done\n",
      "PFE done\n",
      "PLD done\n",
      "PSA done\n",
      "PTR done\n",
      "PYPL done\n",
      "RTX done\n",
      "SHW done\n",
      "SNP done\n",
      "SO done\n",
      "SRE done\n",
      "T done\n",
      "TM done\n",
      "TSLA done\n",
      "TSM done\n",
      "UNP done\n",
      "UPS done\n",
      "V done\n",
      "WMT done\n"
     ]
    }
   ],
   "source": [
    "########### Generate Labels ################\n",
    "\n",
    "n_classes = 5\n",
    "# extract first 4 columns as the lag0 or raw OHLC prices (used for labelling)\n",
    "price_candles = data[['open','high','low','close','Ticker']]\n",
    "\n",
    "########### Align Data ################\n",
    "\n",
    "# from imported function (see testing_preprocessing_features_and_labels.ipynb for thorough experimenting with all the cut-offs):    \n",
    "X_new, y_new, indices = align_features_and_labels_multi_v8(price_candles = price_candles, \n",
    "                                                         all_features = features,\n",
    "                                                         prediction_horizon = 1, \n",
    "                                                         n_feature_lags = n_feature_lags, \n",
    "                                                         n_classes = n_classes, # 5,\n",
    "                                                         label_split = [0,0.1,0.3,0.7,0.9,1], # empty means equal, otherwise specify sorted quantile splits including 0 and 1\n",
    "                                                         safe_burn_in = False, \n",
    "                                                         data_sample = 'full',\n",
    "                                                         splitType='global',\n",
    "                                                         noise=False,\n",
    "                                                         ticker_dummies=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    234696\n",
       "0.0    194194\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    234696\n",
       "0.0    194194\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_new[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    142979\n",
       "0.0    142957\n",
       "2.0    142954\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test 3 class equal splits:\n",
    "y_new[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    257354\n",
       "0.0     85772\n",
       "2.0     85764\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test 3 class 20-60-20 splits:\n",
    "y_new[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    85788\n",
       "3.0    85783\n",
       "2.0    85783\n",
       "0.0    85772\n",
       "4.0    85764\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test 5 class equal splits:\n",
    "y_new[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0    171567\n",
       "1.0     85785\n",
       "3.0     85783\n",
       "0.0     42882\n",
       "4.0     42873\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test 5 class 10-20-40-20-10 splits:\n",
    "y_new[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open_lag0</th>\n",
       "      <th>high_lag0</th>\n",
       "      <th>low_lag0</th>\n",
       "      <th>close_lag0</th>\n",
       "      <th>spread_open_lag0</th>\n",
       "      <th>spread_high_lag0</th>\n",
       "      <th>spread_low_lag0</th>\n",
       "      <th>spread_close_lag0</th>\n",
       "      <th>bidsize_open_lag0</th>\n",
       "      <th>bidsize_high_lag0</th>\n",
       "      <th>...</th>\n",
       "      <th>sector_Consumer Cyclical</th>\n",
       "      <th>sector_Consumer Defensive</th>\n",
       "      <th>sector_Energy</th>\n",
       "      <th>sector_Financial Services</th>\n",
       "      <th>sector_Healthcare</th>\n",
       "      <th>sector_Industrials</th>\n",
       "      <th>sector_Real Estate</th>\n",
       "      <th>sector_Technology</th>\n",
       "      <th>sector_Utilities</th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.330</td>\n",
       "      <td>-0.655</td>\n",
       "      <td>289.020</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.10</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.455</td>\n",
       "      <td>1.125</td>\n",
       "      <td>-0.300</td>\n",
       "      <td>288.580</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-0.610</td>\n",
       "      <td>0.220</td>\n",
       "      <td>-0.815</td>\n",
       "      <td>289.095</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-1.220</td>\n",
       "      <td>0.115</td>\n",
       "      <td>-1.380</td>\n",
       "      <td>290.320</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.10</td>\n",
       "      <td>13.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.355</td>\n",
       "      <td>-0.565</td>\n",
       "      <td>290.085</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>428885</td>\n",
       "      <td>-0.110</td>\n",
       "      <td>0.010</td>\n",
       "      <td>-0.175</td>\n",
       "      <td>123.950</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>WMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>428886</td>\n",
       "      <td>-0.150</td>\n",
       "      <td>0.010</td>\n",
       "      <td>-0.190</td>\n",
       "      <td>124.100</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>WMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>428887</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.090</td>\n",
       "      <td>-0.075</td>\n",
       "      <td>123.995</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>WMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>428888</td>\n",
       "      <td>-0.340</td>\n",
       "      <td>0.020</td>\n",
       "      <td>-0.350</td>\n",
       "      <td>124.335</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.05</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>WMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>428889</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.280</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>124.075</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>WMT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>428890 rows  44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        open_lag0  high_lag0  low_lag0  close_lag0  spread_open_lag0  \\\n",
       "0           0.240      0.330    -0.655     289.020              0.24   \n",
       "1           0.455      1.125    -0.300     288.580              0.07   \n",
       "2          -0.610      0.220    -0.815     289.095              0.49   \n",
       "3          -1.220      0.115    -1.380     290.320              0.16   \n",
       "4           0.235      0.355    -0.565     290.085              0.10   \n",
       "...           ...        ...       ...         ...               ...   \n",
       "428885     -0.110      0.010    -0.175     123.950              0.02   \n",
       "428886     -0.150      0.010    -0.190     124.100              0.02   \n",
       "428887      0.090      0.090    -0.075     123.995              0.01   \n",
       "428888     -0.340      0.020    -0.350     124.335              0.01   \n",
       "428889      0.260      0.280    -0.015     124.075              0.05   \n",
       "\n",
       "        spread_high_lag0  spread_low_lag0  spread_close_lag0  \\\n",
       "0                   0.45             0.01               0.10   \n",
       "1                   0.49             0.01               0.30   \n",
       "2                   0.49             0.01               0.17   \n",
       "3                   0.33             0.01               0.10   \n",
       "4                   0.42             0.01               0.05   \n",
       "...                  ...              ...                ...   \n",
       "428885              0.07             0.01               0.02   \n",
       "428886              0.07             0.01               0.04   \n",
       "428887              0.06             0.01               0.01   \n",
       "428888              0.07             0.01               0.05   \n",
       "428889              0.12             0.01               0.01   \n",
       "\n",
       "        bidsize_open_lag0  bidsize_high_lag0  ...  sector_Consumer Cyclical  \\\n",
       "0                     9.0               20.0  ...                         0   \n",
       "1                     1.0               50.0  ...                         0   \n",
       "2                     1.0               25.0  ...                         0   \n",
       "3                    13.0               71.0  ...                         0   \n",
       "4                     2.0               86.0  ...                         0   \n",
       "...                   ...                ...  ...                       ...   \n",
       "428885                3.0                6.0  ...                         0   \n",
       "428886                1.0               11.0  ...                         0   \n",
       "428887                1.0                8.0  ...                         0   \n",
       "428888                4.0               16.0  ...                         0   \n",
       "428889                3.0                6.0  ...                         0   \n",
       "\n",
       "        sector_Consumer Defensive  sector_Energy  sector_Financial Services  \\\n",
       "0                               0              0                          0   \n",
       "1                               0              0                          0   \n",
       "2                               0              0                          0   \n",
       "3                               0              0                          0   \n",
       "4                               0              0                          0   \n",
       "...                           ...            ...                        ...   \n",
       "428885                          1              0                          0   \n",
       "428886                          1              0                          0   \n",
       "428887                          1              0                          0   \n",
       "428888                          1              0                          0   \n",
       "428889                          1              0                          0   \n",
       "\n",
       "        sector_Healthcare  sector_Industrials  sector_Real Estate  \\\n",
       "0                       0                   0                   0   \n",
       "1                       0                   0                   0   \n",
       "2                       0                   0                   0   \n",
       "3                       0                   0                   0   \n",
       "4                       0                   0                   0   \n",
       "...                   ...                 ...                 ...   \n",
       "428885                  0                   0                   0   \n",
       "428886                  0                   0                   0   \n",
       "428887                  0                   0                   0   \n",
       "428888                  0                   0                   0   \n",
       "428889                  0                   0                   0   \n",
       "\n",
       "        sector_Technology  sector_Utilities  ticker  \n",
       "0                       1                 0    AAPL  \n",
       "1                       1                 0    AAPL  \n",
       "2                       1                 0    AAPL  \n",
       "3                       1                 0    AAPL  \n",
       "4                       1                 0    AAPL  \n",
       "...                   ...               ...     ...  \n",
       "428885                  0                 0     WMT  \n",
       "428886                  0                 0     WMT  \n",
       "428887                  0                 0     WMT  \n",
       "428888                  0                 0     WMT  \n",
       "428889                  0                 0     WMT  \n",
       "\n",
       "[428890 rows x 44 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open_lag0</th>\n",
       "      <th>high_lag0</th>\n",
       "      <th>low_lag0</th>\n",
       "      <th>close_lag0</th>\n",
       "      <th>spread_open_lag0</th>\n",
       "      <th>spread_high_lag0</th>\n",
       "      <th>spread_low_lag0</th>\n",
       "      <th>spread_close_lag0</th>\n",
       "      <th>bidsize_open_lag0</th>\n",
       "      <th>bidsize_high_lag0</th>\n",
       "      <th>...</th>\n",
       "      <th>sector_Consumer Cyclical</th>\n",
       "      <th>sector_Consumer Defensive</th>\n",
       "      <th>sector_Energy</th>\n",
       "      <th>sector_Financial Services</th>\n",
       "      <th>sector_Healthcare</th>\n",
       "      <th>sector_Industrials</th>\n",
       "      <th>sector_Real Estate</th>\n",
       "      <th>sector_Technology</th>\n",
       "      <th>sector_Utilities</th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.330</td>\n",
       "      <td>-0.655</td>\n",
       "      <td>289.020</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.10</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.455</td>\n",
       "      <td>1.125</td>\n",
       "      <td>-0.300</td>\n",
       "      <td>288.580</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-0.610</td>\n",
       "      <td>0.220</td>\n",
       "      <td>-0.815</td>\n",
       "      <td>289.095</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-1.220</td>\n",
       "      <td>0.115</td>\n",
       "      <td>-1.380</td>\n",
       "      <td>290.320</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.10</td>\n",
       "      <td>13.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.355</td>\n",
       "      <td>-0.565</td>\n",
       "      <td>290.085</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>428885</td>\n",
       "      <td>-0.110</td>\n",
       "      <td>0.010</td>\n",
       "      <td>-0.175</td>\n",
       "      <td>123.950</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>WMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>428886</td>\n",
       "      <td>-0.150</td>\n",
       "      <td>0.010</td>\n",
       "      <td>-0.190</td>\n",
       "      <td>124.100</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>WMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>428887</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.090</td>\n",
       "      <td>-0.075</td>\n",
       "      <td>123.995</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>WMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>428888</td>\n",
       "      <td>-0.340</td>\n",
       "      <td>0.020</td>\n",
       "      <td>-0.350</td>\n",
       "      <td>124.335</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.05</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>WMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>428889</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.280</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>124.075</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>WMT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>428890 rows  44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        open_lag0  high_lag0  low_lag0  close_lag0  spread_open_lag0  \\\n",
       "0           0.240      0.330    -0.655     289.020              0.24   \n",
       "1           0.455      1.125    -0.300     288.580              0.07   \n",
       "2          -0.610      0.220    -0.815     289.095              0.49   \n",
       "3          -1.220      0.115    -1.380     290.320              0.16   \n",
       "4           0.235      0.355    -0.565     290.085              0.10   \n",
       "...           ...        ...       ...         ...               ...   \n",
       "428885     -0.110      0.010    -0.175     123.950              0.02   \n",
       "428886     -0.150      0.010    -0.190     124.100              0.02   \n",
       "428887      0.090      0.090    -0.075     123.995              0.01   \n",
       "428888     -0.340      0.020    -0.350     124.335              0.01   \n",
       "428889      0.260      0.280    -0.015     124.075              0.05   \n",
       "\n",
       "        spread_high_lag0  spread_low_lag0  spread_close_lag0  \\\n",
       "0                   0.45             0.01               0.10   \n",
       "1                   0.49             0.01               0.30   \n",
       "2                   0.49             0.01               0.17   \n",
       "3                   0.33             0.01               0.10   \n",
       "4                   0.42             0.01               0.05   \n",
       "...                  ...              ...                ...   \n",
       "428885              0.07             0.01               0.02   \n",
       "428886              0.07             0.01               0.04   \n",
       "428887              0.06             0.01               0.01   \n",
       "428888              0.07             0.01               0.05   \n",
       "428889              0.12             0.01               0.01   \n",
       "\n",
       "        bidsize_open_lag0  bidsize_high_lag0  ...  sector_Consumer Cyclical  \\\n",
       "0                     9.0               20.0  ...                         0   \n",
       "1                     1.0               50.0  ...                         0   \n",
       "2                     1.0               25.0  ...                         0   \n",
       "3                    13.0               71.0  ...                         0   \n",
       "4                     2.0               86.0  ...                         0   \n",
       "...                   ...                ...  ...                       ...   \n",
       "428885                3.0                6.0  ...                         0   \n",
       "428886                1.0               11.0  ...                         0   \n",
       "428887                1.0                8.0  ...                         0   \n",
       "428888                4.0               16.0  ...                         0   \n",
       "428889                3.0                6.0  ...                         0   \n",
       "\n",
       "        sector_Consumer Defensive  sector_Energy  sector_Financial Services  \\\n",
       "0                               0              0                          0   \n",
       "1                               0              0                          0   \n",
       "2                               0              0                          0   \n",
       "3                               0              0                          0   \n",
       "4                               0              0                          0   \n",
       "...                           ...            ...                        ...   \n",
       "428885                          1              0                          0   \n",
       "428886                          1              0                          0   \n",
       "428887                          1              0                          0   \n",
       "428888                          1              0                          0   \n",
       "428889                          1              0                          0   \n",
       "\n",
       "        sector_Healthcare  sector_Industrials  sector_Real Estate  \\\n",
       "0                       0                   0                   0   \n",
       "1                       0                   0                   0   \n",
       "2                       0                   0                   0   \n",
       "3                       0                   0                   0   \n",
       "4                       0                   0                   0   \n",
       "...                   ...                 ...                 ...   \n",
       "428885                  0                   0                   0   \n",
       "428886                  0                   0                   0   \n",
       "428887                  0                   0                   0   \n",
       "428888                  0                   0                   0   \n",
       "428889                  0                   0                   0   \n",
       "\n",
       "        sector_Technology  sector_Utilities  ticker  \n",
       "0                       1                 0    AAPL  \n",
       "1                       1                 0    AAPL  \n",
       "2                       1                 0    AAPL  \n",
       "3                       1                 0    AAPL  \n",
       "4                       1                 0    AAPL  \n",
       "...                   ...               ...     ...  \n",
       "428885                  0                 0     WMT  \n",
       "428886                  0                 0     WMT  \n",
       "428887                  0                 0     WMT  \n",
       "428888                  0                 0     WMT  \n",
       "428889                  0                 0     WMT  \n",
       "\n",
       "[428890 rows x 44 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:MainThread:numexpr.utils:NumExpr defaulting to 4 threads.\n"
     ]
    }
   ],
   "source": [
    "# Let's have a proper split (along tickers & dates)\n",
    "train_size = 0.8\n",
    "data_splits = pd.DataFrame()\n",
    "data_splits = X.index.to_series().groupby(X['ticker']).agg(['first','last']).reset_index()\n",
    "\n",
    "data_splits['val_size'] = ((1-train_size) * (data_splits['last'] - data_splits['first'])).astype(int)\n",
    "data_splits['val_start_idx'] = data_splits['last'] - data_splits['val_size']\n",
    "data_splits['val_end_idx'] = data_splits['last'] + 1 # to get the last observation included\n",
    "\n",
    "data_splits['train_start_idx'] =  data_splits['first']\n",
    "data_splits['train_end_idx'] = data_splits['val_start_idx']\n",
    "\n",
    "# Store ranges\n",
    "\n",
    "train_ranges = [list(x) for x in zip(data_splits['train_start_idx'], data_splits['train_end_idx'])]\n",
    "val_ranges = [list(x) for x in zip(data_splits['val_start_idx'], data_splits['val_end_idx'])]\n",
    "\n",
    "\n",
    "if verbose:\n",
    "    data_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding ticker dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Adding ticker dummies\n",
    "tickers = X.pop('ticker')\n",
    "X = pd.concat([X, pd.get_dummies(tickers, prefix='ticker', drop_first=False)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['open_lag0', 'high_lag0', 'low_lag0', 'close_lag0', 'spread_open_lag0',\n",
       "       'spread_high_lag0', 'spread_low_lag0', 'spread_close_lag0',\n",
       "       'bidsize_open_lag0', 'bidsize_high_lag0', 'bidsize_low_lag0',\n",
       "       'bidsize_close_lag0', 'ofrsize_open_lag0', 'ofrsize_high_lag0',\n",
       "       'ofrsize_low_lag0', 'ofrsize_close_lag0', 'open_lag1', 'high_lag1',\n",
       "       'low_lag1', 'close_lag1', 'spread_open_lag1', 'spread_high_lag1',\n",
       "       'spread_low_lag1', 'spread_close_lag1', 'bidsize_open_lag1',\n",
       "       'bidsize_high_lag1', 'bidsize_low_lag1', 'bidsize_close_lag1',\n",
       "       'ofrsize_open_lag1', 'ofrsize_high_lag1', 'ofrsize_low_lag1',\n",
       "       'ofrsize_close_lag1', 'sector_Basic Materials',\n",
       "       'sector_Communication Services', 'sector_Consumer Cyclical',\n",
       "       'sector_Consumer Defensive', 'sector_Energy',\n",
       "       'sector_Financial Services', 'sector_Healthcare', 'sector_Industrials',\n",
       "       'sector_Real Estate', 'sector_Technology', 'sector_Utilities',\n",
       "       'ticker_AAPL', 'ticker_ABBV', 'ticker_ABT', 'ticker_AEP', 'ticker_AMT',\n",
       "       'ticker_APD', 'ticker_BA', 'ticker_BABA', 'ticker_BAC', 'ticker_BHP',\n",
       "       'ticker_BP', 'ticker_CCI', 'ticker_CHL', 'ticker_COST', 'ticker_CSGP',\n",
       "       'ticker_D', 'ticker_DIS', 'ticker_ECL', 'ticker_ENB', 'ticker_EXC',\n",
       "       'ticker_FB', 'ticker_FMX', 'ticker_GOOG', 'ticker_INTC', 'ticker_JNJ',\n",
       "       'ticker_KO', 'ticker_LFC', 'ticker_LIN', 'ticker_LMT', 'ticker_MA',\n",
       "       'ticker_MCD', 'ticker_MSFT', 'ticker_NKE', 'ticker_NVDA', 'ticker_NVS',\n",
       "       'ticker_PBR', 'ticker_PEP', 'ticker_PFE', 'ticker_PLD', 'ticker_PSA',\n",
       "       'ticker_PTR', 'ticker_PYPL', 'ticker_RTX', 'ticker_SHW', 'ticker_SNP',\n",
       "       'ticker_SO', 'ticker_SRE', 'ticker_T', 'ticker_TM', 'ticker_TSLA',\n",
       "       'ticker_TSM', 'ticker_UNP', 'ticker_UPS', 'ticker_V', 'ticker_WMT'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 6238]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ranges[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing our final train/validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((343090, 98), (343090, 1), (85800, 98), (85800, 1), 428890)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = pd.concat([X.iloc[start:end, :] for (start, end) in train_ranges]).reset_index(drop=True)\n",
    "train_y = pd.concat([y.iloc[start:end] for (start, end) in train_ranges]).reset_index(drop=True)\n",
    "\n",
    "validate_ds = pd.concat([X.iloc[start:end, :] for (start, end) in val_ranges]).reset_index(drop=True)\n",
    "val_y = pd.concat([y.iloc[start:end] for (start, end) in val_ranges]).reset_index(drop=True)\n",
    "\n",
    "train_ds.shape, train_y.shape, validate_ds.shape, val_y.shape, train_y.shape[0] + val_y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 6238]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ranges[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6248"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ranges[0][1]+10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'open_lag0',\n",
       " 1: 'high_lag0',\n",
       " 2: 'low_lag0',\n",
       " 3: 'close_lag0',\n",
       " 4: 'spread_open_lag0',\n",
       " 5: 'spread_high_lag0',\n",
       " 6: 'spread_low_lag0',\n",
       " 7: 'spread_close_lag0',\n",
       " 8: 'bidsize_open_lag0',\n",
       " 9: 'bidsize_high_lag0',\n",
       " 10: 'bidsize_low_lag0',\n",
       " 11: 'bidsize_close_lag0',\n",
       " 12: 'ofrsize_open_lag0',\n",
       " 13: 'ofrsize_high_lag0',\n",
       " 14: 'ofrsize_low_lag0',\n",
       " 15: 'ofrsize_close_lag0',\n",
       " 16: 'open_lag1',\n",
       " 17: 'high_lag1',\n",
       " 18: 'low_lag1',\n",
       " 19: 'close_lag1',\n",
       " 20: 'spread_open_lag1',\n",
       " 21: 'spread_high_lag1',\n",
       " 22: 'spread_low_lag1',\n",
       " 23: 'spread_close_lag1',\n",
       " 24: 'bidsize_open_lag1',\n",
       " 25: 'bidsize_high_lag1',\n",
       " 26: 'bidsize_low_lag1',\n",
       " 27: 'bidsize_close_lag1',\n",
       " 28: 'ofrsize_open_lag1',\n",
       " 29: 'ofrsize_high_lag1',\n",
       " 30: 'ofrsize_low_lag1',\n",
       " 31: 'ofrsize_close_lag1',\n",
       " 32: 'sector_Basic Materials',\n",
       " 33: 'sector_Communication Services',\n",
       " 34: 'sector_Consumer Cyclical',\n",
       " 35: 'sector_Consumer Defensive',\n",
       " 36: 'sector_Energy',\n",
       " 37: 'sector_Financial Services',\n",
       " 38: 'sector_Healthcare',\n",
       " 39: 'sector_Industrials',\n",
       " 40: 'sector_Real Estate',\n",
       " 41: 'sector_Technology',\n",
       " 42: 'sector_Utilities',\n",
       " 43: 'ticker_AAPL',\n",
       " 44: 'ticker_ABBV',\n",
       " 45: 'ticker_ABT',\n",
       " 46: 'ticker_AEP',\n",
       " 47: 'ticker_AMT',\n",
       " 48: 'ticker_APD',\n",
       " 49: 'ticker_BA',\n",
       " 50: 'ticker_BABA',\n",
       " 51: 'ticker_BAC',\n",
       " 52: 'ticker_BHP',\n",
       " 53: 'ticker_BP',\n",
       " 54: 'ticker_CCI',\n",
       " 55: 'ticker_CHL',\n",
       " 56: 'ticker_COST',\n",
       " 57: 'ticker_CSGP',\n",
       " 58: 'ticker_D',\n",
       " 59: 'ticker_DIS',\n",
       " 60: 'ticker_ECL',\n",
       " 61: 'ticker_ENB',\n",
       " 62: 'ticker_EXC',\n",
       " 63: 'ticker_FB',\n",
       " 64: 'ticker_FMX',\n",
       " 65: 'ticker_GOOG',\n",
       " 66: 'ticker_INTC',\n",
       " 67: 'ticker_JNJ',\n",
       " 68: 'ticker_KO',\n",
       " 69: 'ticker_LFC',\n",
       " 70: 'ticker_LIN',\n",
       " 71: 'ticker_LMT',\n",
       " 72: 'ticker_MA',\n",
       " 73: 'ticker_MCD',\n",
       " 74: 'ticker_MSFT',\n",
       " 75: 'ticker_NKE',\n",
       " 76: 'ticker_NVDA',\n",
       " 77: 'ticker_NVS',\n",
       " 78: 'ticker_PBR',\n",
       " 79: 'ticker_PEP',\n",
       " 80: 'ticker_PFE',\n",
       " 81: 'ticker_PLD',\n",
       " 82: 'ticker_PSA',\n",
       " 83: 'ticker_PTR',\n",
       " 84: 'ticker_PYPL',\n",
       " 85: 'ticker_RTX',\n",
       " 86: 'ticker_SHW',\n",
       " 87: 'ticker_SNP',\n",
       " 88: 'ticker_SO',\n",
       " 89: 'ticker_SRE',\n",
       " 90: 'ticker_T',\n",
       " 91: 'ticker_TM',\n",
       " 92: 'ticker_TSLA',\n",
       " 93: 'ticker_TSM',\n",
       " 94: 'ticker_UNP',\n",
       " 95: 'ticker_UPS',\n",
       " 96: 'ticker_V',\n",
       " 97: 'ticker_WMT'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{i:colname for i,colname in enumerate(train_ds.columns)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating one ppdict for individual preprocessings\n",
    "# ppdict1 = {'open':'minmax',\n",
    "#           'high':'log',\n",
    "#           'low':'log',\n",
    "#           'close':'std'}\n",
    "splitpoint = 32\n",
    "\n",
    "# Standardize some features\n",
    "ppdict1 = {i:'std' for i in train_ds.columns[0:splitpoint]} \n",
    "# Keep some in actual levels (Dummies in this case).\n",
    "ppdict2 = {i:'act' for i in train_ds.columns[splitpoint:]} \n",
    "\n",
    "# Merging the two\n",
    "ppdict = {**ppdict1,**ppdict2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-Processing Procedure:  act\n",
      "Columns Processed: ['sector_Basic Materials' 'sector_Communication Services'\n",
      " 'sector_Consumer Cyclical' 'sector_Consumer Defensive' 'sector_Energy'\n",
      " 'sector_Financial Services' 'sector_Healthcare' 'sector_Industrials'\n",
      " 'sector_Real Estate' 'sector_Technology' 'sector_Utilities' 'ticker_AAPL'\n",
      " 'ticker_ABBV' 'ticker_ABT' 'ticker_AEP' 'ticker_AMT' 'ticker_APD'\n",
      " 'ticker_BA' 'ticker_BABA' 'ticker_BAC' 'ticker_BHP' 'ticker_BP'\n",
      " 'ticker_CCI' 'ticker_CHL' 'ticker_COST' 'ticker_CSGP' 'ticker_D'\n",
      " 'ticker_DIS' 'ticker_ECL' 'ticker_ENB' 'ticker_EXC' 'ticker_FB'\n",
      " 'ticker_FMX' 'ticker_GOOG' 'ticker_INTC' 'ticker_JNJ' 'ticker_KO'\n",
      " 'ticker_LFC' 'ticker_LIN' 'ticker_LMT' 'ticker_MA' 'ticker_MCD'\n",
      " 'ticker_MSFT' 'ticker_NKE' 'ticker_NVDA' 'ticker_NVS' 'ticker_PBR'\n",
      " 'ticker_PEP' 'ticker_PFE' 'ticker_PLD' 'ticker_PSA' 'ticker_PTR'\n",
      " 'ticker_PYPL' 'ticker_RTX' 'ticker_SHW' 'ticker_SNP' 'ticker_SO'\n",
      " 'ticker_SRE' 'ticker_T' 'ticker_TM' 'ticker_TSLA' 'ticker_TSM'\n",
      " 'ticker_UNP' 'ticker_UPS' 'ticker_V' 'ticker_WMT'] \n",
      "\n",
      "Pre-Processing Procedure:  std\n",
      "Columns Processed: ['open_lag0' 'high_lag0' 'low_lag0' 'close_lag0' 'spread_open_lag0'\n",
      " 'spread_high_lag0' 'spread_low_lag0' 'spread_close_lag0'\n",
      " 'bidsize_open_lag0' 'bidsize_high_lag0' 'bidsize_low_lag0'\n",
      " 'bidsize_close_lag0' 'ofrsize_open_lag0' 'ofrsize_high_lag0'\n",
      " 'ofrsize_low_lag0' 'ofrsize_close_lag0' 'open_lag1' 'high_lag1'\n",
      " 'low_lag1' 'close_lag1' 'spread_open_lag1' 'spread_high_lag1'\n",
      " 'spread_low_lag1' 'spread_close_lag1' 'bidsize_open_lag1'\n",
      " 'bidsize_high_lag1' 'bidsize_low_lag1' 'bidsize_close_lag1'\n",
      " 'ofrsize_open_lag1' 'ofrsize_high_lag1' 'ofrsize_low_lag1'\n",
      " 'ofrsize_close_lag1'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_ds,validate_ds = pre_processing(train_ds,\n",
    "                                    validate_ds,\n",
    "                                    ppdict,\n",
    "                                    100,\n",
    "                                    verbose =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1.8927265537610815e-16, 1.000001457346533)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppX_train.iloc[:,0].mean(),ppX_train.iloc[:,0].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepping for models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(343090, 85800, 428890, 1340, 131, 670000)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_VALIDATION = val_y.shape[0] #int(1e3)\n",
    "N_TRAIN = train_y.shape[0] #int(1e4)\n",
    "# BUFFER_SIZE = int(1e4)\n",
    "BATCH_SIZE = 256 #512 #32\n",
    "MAX_EPOCHS = 500\n",
    "\n",
    "STEPS_PER_EPOCH = N_TRAIN//BATCH_SIZE\n",
    "\n",
    "N_REPEAT = int(N_TRAIN / ((STEPS_PER_EPOCH * MAX_EPOCHS) / BATCH_SIZE))\n",
    "FEATURES = X.shape[1]\n",
    "\n",
    "N_TRAIN, N_VALIDATION, N_TRAIN + N_VALIDATION, STEPS_PER_EPOCH, N_REPEAT, STEPS_PER_EPOCH * MAX_EPOCHS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Logistic Regression model in TF/Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 1)                 99        \n",
      "=================================================================\n",
      "Total params: 99\n",
      "Trainable params: 99\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:MainThread:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.390774). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0, accuracy:0.5352,  auc:0.5034,  loss:0.8996,  val_accuracy:0.5456,  val_auc:0.5453,  val_loss:0.6876,  \n",
      "....................................................................................................\n",
      "Epoch: 100, accuracy:0.5480,  auc:0.5440,  loss:0.6873,  val_accuracy:0.5454,  val_auc:0.5459,  val_loss:0.6879,  \n",
      "..................Restoring model weights from the end of the best epoch.\n",
      "Epoch 00118: early stopping\n"
     ]
    }
   ],
   "source": [
    "METRICS = [\n",
    "      #keras.metrics.TruePositives(name='tp'),\n",
    "      #keras.metrics.FalsePositives(name='fp'),\n",
    "      #keras.metrics.TrueNegatives(name='tn'),\n",
    "      #keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      #keras.metrics.Precision(name='precision'),\n",
    "      #keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "]\n",
    "\n",
    "# def make_model(metrics = METRICS, output_bias=None):\n",
    "#   if output_bias is not None:\n",
    "#     output_bias = tf.keras.initializers.Constant(output_bias)\n",
    "#   model = keras.Sequential([\n",
    "#       keras.layers.Dense(\n",
    "#           16, activation='relu',\n",
    "#           input_shape=(train_features.shape[-1],)),\n",
    "#       keras.layers.Dropout(0.5),\n",
    "#       keras.layers.Dense(1, activation='sigmoid',\n",
    "#                          bias_initializer=output_bias),\n",
    "#   ])\n",
    "\n",
    "#   model.compile(\n",
    "#       optimizer=keras.optimizers.Adam(lr=1e-3),\n",
    "#       loss=keras.losses.BinaryCrossentropy(),\n",
    "#       metrics=metrics)\n",
    "\n",
    "#   return model\n",
    "\n",
    "# model = keras.Sequential({\n",
    "#   keras.layers.Dense(1, input_shape=(FEATURES,))\n",
    "# })\n",
    "\n",
    "model = keras.Sequential([\n",
    "#     keras.layers.Flatten(input_shape=(28, 28)),\n",
    "#     keras.layers.Dense(128, activation='relu'),\n",
    "#     keras.layers.Dense(10)\n",
    "    keras.layers.Dense(1,\n",
    "                       input_shape=(FEATURES,),\n",
    "                       activation='sigmoid',\n",
    "                       kernel_regularizer=regularizers.l2(1))\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# with final activation (Keras/TF tutorial advises against this practice, but they also use it later in the tutorial)\n",
    "# model = keras.Sequential({\n",
    "#   keras.layers.Dense(1, input_shape=(FEATURES,), activation='sigmoid')\n",
    "# })\n",
    "\n",
    "#model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['binary_accuracy', ])\n",
    "model.compile(\n",
    "              optimizer=keras.optimizers.Adam(), #lr=1e-3\n",
    "              loss=keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "              metrics=METRICS)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "                                                monitor='val_auc', \n",
    "                                                verbose=1,\n",
    "                                                patience=100,\n",
    "                                                mode='max',\n",
    "                                                restore_best_weights=True)\n",
    "\n",
    "def get_callbacks(run_id):\n",
    "      return [\n",
    "             tfdocs.modeling.EpochDots(),\n",
    "             early_stopping,\n",
    "             tf.keras.callbacks.TensorBoard(logdir), #/run_id),\n",
    "      ]\n",
    "\n",
    "baseline_history = model.fit(\n",
    "                            train_ds, #train_features,\n",
    "                            train_y, #train_labels,\n",
    "                            batch_size=512, #BATCH_SIZE,\n",
    "                            epochs=1000, #EPOCHS,\n",
    "                            callbacks = get_callbacks(run_id = 'first'), #[early_stopping],\n",
    "                            validation_data=(validate_ds, val_y),\n",
    "                            verbose=0) #(val_features, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2682/2682 - 6s - loss: 0.6879 - accuracy: 0.5457 - auc: 0.5513\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6878659725189209, 0.5456876754760742, 0.5513222217559814]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(validate_ds,  val_y, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Timed out waiting for TensorBoard to start. It may still be running as pid 9296."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datetime\n",
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
