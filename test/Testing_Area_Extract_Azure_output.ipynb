{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\tmpp8q4dk02\\tensorboard_logs\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "import h5py\n",
    "import copy\n",
    "import datetime\n",
    "import ta\n",
    "import pathlib\n",
    "import shutil\n",
    "import tempfile\n",
    "import vaex\n",
    "from IPython import display\n",
    "from IPython.display import clear_output\n",
    "import pyodbc\n",
    "\n",
    "# Tensorflow related\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "import tensorflow.compat.v2.feature_column as fc\n",
    "\n",
    "#!pip install -q git+https://github.com/tensorflow/docs\n",
    "\n",
    "import tensorflow_docs as tfdocs\n",
    "import tensorflow_docs.modeling\n",
    "import tensorflow_docs.plots\n",
    "\n",
    "print(tf.__version__)\n",
    "logdir = pathlib.Path(tempfile.mkdtemp())/\"tensorboard_logs\"\n",
    "shutil.rmtree(logdir, ignore_errors=True)\n",
    "print(logdir)\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, f1_score, log_loss\n",
    "\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.exceptions import ConvergenceWarning \n",
    "from sklearn import ensemble\n",
    "# ConvergenceWarning('ignore')\n",
    "# Do you wanna see?\n",
    "verbose = True\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "#sys.path.append('...../')\n",
    "\n",
    "from utils.data_extraction import load_data_final,load_data_and_save\n",
    "from utils.data_cleaning import HFDataCleaning\n",
    "from utils.generate_features import candleCreateNP_vect_final,\\\n",
    "                                    generateFeatures_final,\\\n",
    "                                    generateFeatures_multi_final\n",
    "\n",
    "from utils.preprocessing_features_and_labels import extract_labels,\\\n",
    "                                                    align_features_and_labels,\\\n",
    "                                                    pre_processing_initial,\\\n",
    "                                                    pre_processing_extended,\\\n",
    "                                                    pre_processing_final,\\\n",
    "                                                    extract_labels_multi_final,\\\n",
    "                                                    align_features_and_labels_multi_final,\\\n",
    "                                                    align_features_and_labels_multi_v5\n",
    "\n",
    "from utils.models import make_input_fn\n",
    "from utils.models import performanceTesting,scoreFunction\n",
    "from utils.plotting import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which one do you want to load? \n",
      "\n",
      "0: aggregateTAQ_May2020_10sec (1).csv\n",
      "1: aggregateTAQ_May2020_30sec (1).csv\n",
      "2: aggregateTAQ_May2020_60sec.csv\n",
      "8: trueAggregateTAQ_60sec.csv\n",
      "\n",
      "\n",
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (19) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>sector</th>\n",
       "      <th>exchange</th>\n",
       "      <th>marketCap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>Technology</td>\n",
       "      <td>NMS</td>\n",
       "      <td>1.578173e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ABBV</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>NYQ</td>\n",
       "      <td>1.742612e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>ABT</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>NYQ</td>\n",
       "      <td>1.631410e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>AEP</td>\n",
       "      <td>Utilities</td>\n",
       "      <td>NYQ</td>\n",
       "      <td>4.089551e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>AMT</td>\n",
       "      <td>Real Estate</td>\n",
       "      <td>NYQ</td>\n",
       "      <td>1.171259e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>APD</td>\n",
       "      <td>Basic Materials</td>\n",
       "      <td>NYQ</td>\n",
       "      <td>5.464395e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>BA</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>NYQ</td>\n",
       "      <td>1.020356e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>BABA</td>\n",
       "      <td>Consumer Cyclical</td>\n",
       "      <td>NYQ</td>\n",
       "      <td>5.936536e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>BAC</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>NYQ</td>\n",
       "      <td>2.020550e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>BHP</td>\n",
       "      <td>Basic Materials</td>\n",
       "      <td>NYQ</td>\n",
       "      <td>1.258194e+11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ticker              sector exchange     marketCap\n",
       "12    AAPL          Technology      NMS  1.578173e+12\n",
       "20    ABBV          Healthcare      NYQ  1.742612e+11\n",
       "34     ABT          Healthcare      NYQ  1.631410e+11\n",
       "126    AEP           Utilities      NYQ  4.089551e+10\n",
       "379    AMT         Real Estate      NYQ  1.171259e+11\n",
       "428    APD     Basic Materials      NYQ  5.464395e+10\n",
       "697     BA         Industrials      NYQ  1.020356e+11\n",
       "699   BABA   Consumer Cyclical      NYQ  5.936536e+11\n",
       "700    BAC  Financial Services      NYQ  2.020550e+11\n",
       "870    BHP     Basic Materials      NYQ  1.258194e+11"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do we extract new data or read in?\n",
    "readIn = True\n",
    "# run load_data()\n",
    "if readIn:\n",
    "    \n",
    "    # Listing the data files \n",
    "    path = '../../../Google Drev/Thesis/Data/TAQ/AggregatedTAQ'\n",
    "#     path = 'F:/AggregatedTAQ/round3'\n",
    "    datafiles = os.listdir(path)\n",
    "    content = np.concatenate([['\\n\\n'],[str(j)+': '+i+'\\n' for j,i in enumerate(datafiles) if 'csv' in i],['\\n\\n']])\n",
    "    \n",
    "    # Asking for user input\n",
    "    file = input('Which one do you want to load? %s'%''.join(content))\n",
    "    if int(file) <= 2:\n",
    "        data = pd.read_csv(path + '/' + datafiles[int(file)],\n",
    "                           header = None,\n",
    "                           names=['open','high','low','close',\n",
    "                                  'spread_open','spread_high','spread_low','spread_close',\n",
    "                                  'bidsize_open','bidsize_high','bidsize_low','bidsize_close',\n",
    "                                  'ofrsize_open','ofrsize_high','ofrsize_low','ofrsize_close',\n",
    "                                  'Ticker'])\n",
    "        # Using the choice of the user to determine the correct market file\n",
    "        key = re.split('[_.]',datafiles[int(file)])[-2]\n",
    "        marketDataFile = [file for file in os.listdir(path+'/round5_market_tickers') if key in file]\n",
    "\n",
    "        # Reading in the market data\n",
    "        tempData = pd.read_csv(path+'/round5_market_tickers/'+marketDataFile[0]\n",
    "                               ,header = None\n",
    "                               ,names=['open','high','low','close',\n",
    "                                      'spread_open','spread_high','spread_low','spread_close',\n",
    "                                      'bidsize_open','bidsize_high','bidsize_low','bidsize_close',\n",
    "                                      'ofrsize_open','ofrsize_high','ofrsize_low','ofrsize_close',\n",
    "                                      'Ticker'])\n",
    "        # Adding the market data to the ticker data\n",
    "        data = pd.concat([data,tempData],axis=0)\n",
    "    else:\n",
    "        data = pd.read_csv(path + '/' + datafiles[int(file)],\n",
    "                           header = 0,\n",
    "                           index_col=[0,1]\n",
    "#                            names=['open','high','low','close',\n",
    "#                                   'spread_open','spread_high','spread_low','spread_close',\n",
    "#                                   'bidsize_open','bidsize_high','bidsize_low','bidsize_close',\n",
    "#                                   'ofrsize_open','ofrsize_high','ofrsize_low','ofrsize_close',\n",
    "#                                   'Ticker']\n",
    "                          )\n",
    "    \n",
    "    # Lower casing all column names\n",
    "#     data.columns = data.columns.str.lower()\n",
    "else:\n",
    "    \n",
    "    # print(os.listdir())\n",
    "    try:\n",
    "        path = 'a:/taqhdf5'  #'a:/taqhdf5'\n",
    "        os.listdir(path)\n",
    "    except:\n",
    "        path = 't:/taqhdf5'  #'a:/taqhdf5'\n",
    "        os.listdir(path)\n",
    "        \n",
    "    # Sample type\n",
    "    data_sample = 'full' # or 'stable'\n",
    "    # allFiles = os.listdir(path)\n",
    "    # print(len(allFiles), allFiles[:5], allFiles[-5:])\n",
    "    # print(allFiles[-10:])\n",
    "\n",
    "    #dates = np.array(['2020040' + str(i) if i < 10 else '202004' + str(i) for i in np.arange(1,16)]).astype(int)\n",
    "    dates = np.array(['20200501']).astype(int)#,'20200402','20200403','20200406','20200407'\n",
    "\n",
    "    # Provide a list of tickers of interest\n",
    "    \n",
    "    tickers = sorted(['TSLA','FB'])#'MSFT'\n",
    "    \n",
    "    # Do we need data on trades, quotes or both?\n",
    "    dataNeeded = 'quotes' # 'trades', 'quotes' or 'both'\n",
    "    \n",
    "    if dataNeeded == 'trades':\n",
    "        tradeData = load_data_final(dates, tickers, dataNeeded, path, verbose)\n",
    "    elif dataNeeded == 'quotes':\n",
    "        quoteData = load_data_final(dates,\n",
    "                                    tickers,\n",
    "                                    dataNeeded,\n",
    "                                    path,\n",
    "                                    verbose,\n",
    "                                    extract_candles = False,\n",
    "                                    aggHorizon = 1,\n",
    "                                    extra_features_from_quotes = None,\n",
    "                                    data_sample = data_sample)\n",
    "    elif dataNeeded == 'both':\n",
    "        tradeData, quoteData = load_data_final(dates, tickers, dataNeeded, path, verbose)\n",
    "\n",
    "# Reading in sector information\n",
    "stockInfo = pd.read_csv('../utils/stockInfo_v1.csv',header=[0,1])\n",
    "stockInfo.columns = ['ticker','sector','exchange','marketCap']\n",
    "\n",
    "# Creating a table with stock information based on the tickers available in the data.\n",
    "uniqueTickers = data.Ticker.unique()\n",
    "stockTable = stockInfo[stockInfo.ticker.isin(uniqueTickers)]\n",
    "stockTable.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hyperparameters.txt', 'metrics.txt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = os.listdir('../AzureML/Output_from_cloud')\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Reading in the file\n",
    "\n",
    "with open('../AzureML/Output_from_cloud/'+files[0],'r') as file:\n",
    "    content = file.readlines()\n",
    "\n",
    "## Containers for the data\n",
    "all_ids = []\n",
    "all_parameters = []\n",
    "\n",
    "## Going over each line in the text file\n",
    "for a in np.arange(len(content)):\n",
    "    \n",
    "    ## Split the lines on tabs\n",
    "    temp_parameters = re.split('[\\t]',content[a])[1]\n",
    "    \n",
    "    ## Basic string cleaning, i.e. removing redundant characters\n",
    "    test = [re.split(': ',i.strip()) for i in re.split(',',temp_parameters.replace('{','')\\\n",
    "                                                                       .replace('}','')\\\n",
    "                                                                       .replace('\\n','')\\\n",
    "                                                                       .replace('\"',''))]\n",
    "    \n",
    "    ## Output of test is a list of lists, where each sublist holds the name of a model variable and its value.\n",
    "    ## We create a dictornary to hold all model variables, making it easy to add the observation to the dataframe.\n",
    "    test = {i[0]:i[1] for i in test}\n",
    "    \n",
    "    # Constructing the dataframe\n",
    "    if a == 0:\n",
    "        parameters = pd.DataFrame(test,index=[re.split('[\\t]',content[a])[0]])\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        parameters.loc[re.split('[\\t]',content[a])[0]] = pd.Series(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activation-inner</th>\n",
       "      <th>activation-output</th>\n",
       "      <th>batch-norm</th>\n",
       "      <th>batch-shuffle</th>\n",
       "      <th>batch-size</th>\n",
       "      <th>dropout-ratio</th>\n",
       "      <th>feature-lags</th>\n",
       "      <th>featureset</th>\n",
       "      <th>first-layer-neurons</th>\n",
       "      <th>label-type</th>\n",
       "      <th>learning-rate</th>\n",
       "      <th>n-epochs</th>\n",
       "      <th>n-layers</th>\n",
       "      <th>nn-type</th>\n",
       "      <th>pastobs-in-percentage</th>\n",
       "      <th>pre-processing</th>\n",
       "      <th>second-layer-neurons</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HD_81ace623-e09b-4393-8a5e-131ea8749a35_0</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>linear</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3300</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>150</td>\n",
       "      <td>3</td>\n",
       "      <td>ffnn</td>\n",
       "      <td>1</td>\n",
       "      <td>stacked</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD_81ace623-e09b-4393-8a5e-131ea8749a35_1</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>linear</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21450</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>150</td>\n",
       "      <td>3</td>\n",
       "      <td>ffnn</td>\n",
       "      <td>1</td>\n",
       "      <td>stacked</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD_81ace623-e09b-4393-8a5e-131ea8749a35_2</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>softmax</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3300</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>150</td>\n",
       "      <td>2</td>\n",
       "      <td>ffnn</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD_81ace623-e09b-4393-8a5e-131ea8749a35_3</th>\n",
       "      <td>tanh</td>\n",
       "      <td>linear</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10725</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>150</td>\n",
       "      <td>2</td>\n",
       "      <td>ffnn</td>\n",
       "      <td>0</td>\n",
       "      <td>quantgau</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD_81ace623-e09b-4393-8a5e-131ea8749a35_4</th>\n",
       "      <td>leakyrelu</td>\n",
       "      <td>linear</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21450</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>150</td>\n",
       "      <td>2</td>\n",
       "      <td>lstm</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD_81ace623-e09b-4393-8a5e-131ea8749a35_995</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>linear</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>21450</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>150</td>\n",
       "      <td>4</td>\n",
       "      <td>ffnn</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD_81ace623-e09b-4393-8a5e-131ea8749a35_996</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>softmax</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10725</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>150</td>\n",
       "      <td>4</td>\n",
       "      <td>ffnn</td>\n",
       "      <td>1</td>\n",
       "      <td>std</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD_81ace623-e09b-4393-8a5e-131ea8749a35_997</th>\n",
       "      <td>relu</td>\n",
       "      <td>linear</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10725</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>150</td>\n",
       "      <td>2</td>\n",
       "      <td>lstm</td>\n",
       "      <td>0</td>\n",
       "      <td>pow</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD_81ace623-e09b-4393-8a5e-131ea8749a35_998</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>softmax</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21450</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>150</td>\n",
       "      <td>2</td>\n",
       "      <td>lstm</td>\n",
       "      <td>0</td>\n",
       "      <td>stacked</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD_81ace623-e09b-4393-8a5e-131ea8749a35_999</th>\n",
       "      <td>tanh</td>\n",
       "      <td>softmax</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21450</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>150</td>\n",
       "      <td>4</td>\n",
       "      <td>lstm</td>\n",
       "      <td>1</td>\n",
       "      <td>quantgau</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            activation-inner  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_0            sigmoid   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_1            sigmoid   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_2            sigmoid   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_3               tanh   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_4          leakyrelu   \n",
       "...                                                      ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_995          sigmoid   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_996          sigmoid   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_997             relu   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_998          sigmoid   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999             tanh   \n",
       "\n",
       "                                            activation-output batch-norm  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_0              linear          0   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_1              linear          0   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_2             softmax          0   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_3              linear          0   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_4              linear          0   \n",
       "...                                                       ...        ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_995            linear          1   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_996           softmax          1   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_997            linear          1   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_998           softmax          0   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999           softmax          0   \n",
       "\n",
       "                                            batch-shuffle batch-size  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_0               1       3300   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_1               1      21450   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_2               0       3300   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_3               0      10725   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_4               1      21450   \n",
       "...                                                   ...        ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_995             0      21450   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_996             1      10725   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_997             1      10725   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_998             0      21450   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999             0      21450   \n",
       "\n",
       "                                            dropout-ratio feature-lags  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_0             0.1            3   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_1             0.1            1   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_2             0.4            0   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_3             0.5            0   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_4             0.4            1   \n",
       "...                                                   ...          ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_995           0.0            3   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_996           0.0            3   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_997           0.5            3   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_998           0.3            5   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999           0.2            0   \n",
       "\n",
       "                                            featureset first-layer-neurons  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_0            2                  32   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_1            1                  64   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_2            2                  32   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_3            1                  64   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_4            2                 128   \n",
       "...                                                ...                 ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_995          3                  64   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_996          0                  64   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_997          2                  64   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_998          3                 128   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999          1                 128   \n",
       "\n",
       "                                            label-type learning-rate n-epochs  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_0            0          0.01      150   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_1            1           0.1      150   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_2            4           0.1      150   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_3            0          0.01      150   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_4            0         0.001      150   \n",
       "...                                                ...           ...      ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_995          2        0.0001      150   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_996          1          0.01      150   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_997          3        0.0001      150   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_998          2         0.001      150   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999          1        0.0001      150   \n",
       "\n",
       "                                            n-layers nn-type  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_0          3    ffnn   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_1          3    ffnn   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_2          2    ffnn   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_3          2    ffnn   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_4          2    lstm   \n",
       "...                                              ...     ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_995        4    ffnn   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_996        4    ffnn   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_997        2    lstm   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_998        2    lstm   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999        4    lstm   \n",
       "\n",
       "                                            pastobs-in-percentage  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_0                       1   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_1                       1   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_2                       0   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_3                       0   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_4                       1   \n",
       "...                                                           ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_995                     0   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_996                     1   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_997                     0   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_998                     0   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999                     1   \n",
       "\n",
       "                                            pre-processing  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_0          stacked   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_1          stacked   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_2             None   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_3         quantgau   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_4             None   \n",
       "...                                                    ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_995           None   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_996            std   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_997            pow   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_998        stacked   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999       quantgau   \n",
       "\n",
       "                                            second-layer-neurons  \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_0                     64  \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_1                     64  \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_2                     64  \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_3                    128  \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_4                     64  \n",
       "...                                                          ...  \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_995                   64  \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_996                   64  \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_997                   64  \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_998                   64  \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999                   32  \n",
       "\n",
       "[1000 rows x 17 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Readidng in the file\n",
    "with open('../AzureML/Output_from_cloud/'+files[1],'r') as file:\n",
    "    content = file.readlines()\n",
    "\n",
    "## Containers\n",
    "t11 = []\n",
    "t12 = []\n",
    "t13 = []\n",
    "\n",
    "t21 = []\n",
    "t22 = []\n",
    "t23 = []\n",
    "\n",
    "## Going over each line\n",
    "for i in np.arange(len(content)):#\n",
    "    \n",
    "    ## Split each line on tabs\n",
    "    temp = re.split('\\t',content[i].replace('\\n',''))\n",
    "    \n",
    "    ## There are two types of observations in the text file; 1. final metrics of those models which where not stoppe early\n",
    "    ## and 2. a time series of a metric for each model.\n",
    "    \n",
    "    ## If the length of the last element, in a line, is less than 50 (because it is just a number, i.e. final metric)\n",
    "    ## It stored separately for the time series.\n",
    "    if len(temp[2]) < 50:\n",
    "\n",
    "        t11.append(temp[0])\n",
    "        t12.append(temp[1])\n",
    "        t13.append(temp[2])\n",
    "    \n",
    "    ## Time series\n",
    "    else:\n",
    "    \n",
    "        container = np.zeros(155)\n",
    "        temp1 = [float(j.strip()) if j.strip() !=\"'NaN'\" else 0 for j in re.split(',',temp[2].replace('[','').replace(']',''))]\n",
    "\n",
    "        container[0:len(temp1)] = temp1\n",
    "        container[len(temp1):] = temp1[-1]\n",
    "\n",
    "        t21.append(temp[0])\n",
    "        t22.append(temp[1])\n",
    "        t23.append(container)        \n",
    "\n",
    "## Storing the time series in a dataframe\n",
    "arrays = [t21,t22]\n",
    "tuples = list(zip(*arrays))\n",
    "\n",
    "runningMetrics = pd.DataFrame(np.array(t23),\n",
    "                              index=pd.MultiIndex.from_tuples(tuples),\n",
    "                              columns = [np.arange(155).astype(str)]\n",
    "                             )\n",
    "## Storing the final metrics in a dataframe.\n",
    "arrays = [t11,t12]\n",
    "tuples = list(zip(*arrays))\n",
    "finalMetrics = pd.DataFrame(t13,index = pd.MultiIndex.from_tuples(tuples),columns = ['size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1d784b9dbc8>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "runningMetrics[(runningMetrics.metric=='Accuracy')&\\\n",
    "               (np.isin(runningMetrics.id,parameters[parameters['label-type']=='2'].id.values))].sort_values('154')['154'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">HD_81ace623-e09b-4393-8a5e-131ea8749a35_1</th>\n",
       "      <th>Final test loss</th>\n",
       "      <td>0.8833522492045336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Final test AUC</th>\n",
       "      <td>0.7648658156394958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Final test accuracy</th>\n",
       "      <td>0.6109746098518372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">HD_81ace623-e09b-4393-8a5e-131ea8749a35_3</th>\n",
       "      <th>Final test loss</th>\n",
       "      <td>1.1133369887535414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Final test AUC</th>\n",
       "      <td>0.640163779258728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">HD_81ace623-e09b-4393-8a5e-131ea8749a35_997</th>\n",
       "      <th>Final test AUC</th>\n",
       "      <td>0.7837895154953003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Final test accuracy</th>\n",
       "      <td>0.602816104888916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">HD_81ace623-e09b-4393-8a5e-131ea8749a35_998</th>\n",
       "      <th>Final test loss</th>\n",
       "      <td>1.3713646207894699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Final test AUC</th>\n",
       "      <td>0.7241190671920776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Final test accuracy</th>\n",
       "      <td>0.4148908853530884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1170 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                               size\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_1   Final test loss      0.8833522492045336\n",
       "                                            Final test AUC       0.7648658156394958\n",
       "                                            Final test accuracy  0.6109746098518372\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_3   Final test loss      1.1133369887535414\n",
       "                                            Final test AUC        0.640163779258728\n",
       "...                                                                             ...\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_997 Final test AUC       0.7837895154953003\n",
       "                                            Final test accuracy   0.602816104888916\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_998 Final test loss      1.3713646207894699\n",
       "                                            Final test AUC       0.7241190671920776\n",
       "                                            Final test accuracy  0.4148908853530884\n",
       "\n",
       "[1170 rows x 1 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "      <th>150</th>\n",
       "      <th>151</th>\n",
       "      <th>152</th>\n",
       "      <th>153</th>\n",
       "      <th>154</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">HD_81ace623-e09b-4393-8a5e-131ea8749a35_0</th>\n",
       "      <th>Loss</th>\n",
       "      <td>1.098537</td>\n",
       "      <td>1.098504</td>\n",
       "      <td>1.098467</td>\n",
       "      <td>1.098423</td>\n",
       "      <td>1.098371</td>\n",
       "      <td>1.098309</td>\n",
       "      <td>1.098233</td>\n",
       "      <td>1.098140</td>\n",
       "      <td>1.098026</td>\n",
       "      <td>1.097886</td>\n",
       "      <td>...</td>\n",
       "      <td>1.066601</td>\n",
       "      <td>1.066601</td>\n",
       "      <td>1.066601</td>\n",
       "      <td>1.066601</td>\n",
       "      <td>1.066601</td>\n",
       "      <td>1.066601</td>\n",
       "      <td>1.066601</td>\n",
       "      <td>1.066601</td>\n",
       "      <td>1.066601</td>\n",
       "      <td>1.066601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.354843</td>\n",
       "      <td>0.358482</td>\n",
       "      <td>0.362843</td>\n",
       "      <td>0.365199</td>\n",
       "      <td>0.366960</td>\n",
       "      <td>0.367240</td>\n",
       "      <td>0.368826</td>\n",
       "      <td>0.370377</td>\n",
       "      <td>0.371579</td>\n",
       "      <td>0.372220</td>\n",
       "      <td>...</td>\n",
       "      <td>0.412316</td>\n",
       "      <td>0.412316</td>\n",
       "      <td>0.412316</td>\n",
       "      <td>0.412316</td>\n",
       "      <td>0.412316</td>\n",
       "      <td>0.412316</td>\n",
       "      <td>0.412316</td>\n",
       "      <td>0.412316</td>\n",
       "      <td>0.412316</td>\n",
       "      <td>0.412316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC</th>\n",
       "      <td>0.500120</td>\n",
       "      <td>0.500277</td>\n",
       "      <td>0.500545</td>\n",
       "      <td>0.501018</td>\n",
       "      <td>0.501737</td>\n",
       "      <td>0.502806</td>\n",
       "      <td>0.504301</td>\n",
       "      <td>0.506150</td>\n",
       "      <td>0.508213</td>\n",
       "      <td>0.510308</td>\n",
       "      <td>...</td>\n",
       "      <td>0.575838</td>\n",
       "      <td>0.575838</td>\n",
       "      <td>0.575838</td>\n",
       "      <td>0.575838</td>\n",
       "      <td>0.575838</td>\n",
       "      <td>0.575838</td>\n",
       "      <td>0.575838</td>\n",
       "      <td>0.575838</td>\n",
       "      <td>0.575838</td>\n",
       "      <td>0.575838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Loss</th>\n",
       "      <td>1.098558</td>\n",
       "      <td>1.098524</td>\n",
       "      <td>1.098487</td>\n",
       "      <td>1.098442</td>\n",
       "      <td>1.098396</td>\n",
       "      <td>1.098339</td>\n",
       "      <td>1.098267</td>\n",
       "      <td>1.098180</td>\n",
       "      <td>1.098077</td>\n",
       "      <td>1.097955</td>\n",
       "      <td>...</td>\n",
       "      <td>1.068791</td>\n",
       "      <td>1.068791</td>\n",
       "      <td>1.068791</td>\n",
       "      <td>1.068791</td>\n",
       "      <td>1.068791</td>\n",
       "      <td>1.068791</td>\n",
       "      <td>1.068791</td>\n",
       "      <td>1.068791</td>\n",
       "      <td>1.068791</td>\n",
       "      <td>1.068791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Accuracy</th>\n",
       "      <td>0.344181</td>\n",
       "      <td>0.350251</td>\n",
       "      <td>0.353537</td>\n",
       "      <td>0.358348</td>\n",
       "      <td>0.360740</td>\n",
       "      <td>0.363537</td>\n",
       "      <td>0.365985</td>\n",
       "      <td>0.368336</td>\n",
       "      <td>0.368998</td>\n",
       "      <td>0.369959</td>\n",
       "      <td>...</td>\n",
       "      <td>0.412060</td>\n",
       "      <td>0.412060</td>\n",
       "      <td>0.412060</td>\n",
       "      <td>0.412060</td>\n",
       "      <td>0.412060</td>\n",
       "      <td>0.412060</td>\n",
       "      <td>0.412060</td>\n",
       "      <td>0.412060</td>\n",
       "      <td>0.412060</td>\n",
       "      <td>0.412060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">HD_81ace623-e09b-4393-8a5e-131ea8749a35_999</th>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>...</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC</th>\n",
       "      <td>0.006679</td>\n",
       "      <td>0.003153</td>\n",
       "      <td>0.002064</td>\n",
       "      <td>0.001534</td>\n",
       "      <td>0.001221</td>\n",
       "      <td>0.001014</td>\n",
       "      <td>0.000867</td>\n",
       "      <td>0.000757</td>\n",
       "      <td>0.000672</td>\n",
       "      <td>0.000604</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.000113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Loss</th>\n",
       "      <td>5.383223</td>\n",
       "      <td>5.355752</td>\n",
       "      <td>5.355751</td>\n",
       "      <td>5.355751</td>\n",
       "      <td>5.355751</td>\n",
       "      <td>5.355750</td>\n",
       "      <td>5.355750</td>\n",
       "      <td>5.355750</td>\n",
       "      <td>5.355750</td>\n",
       "      <td>5.355750</td>\n",
       "      <td>...</td>\n",
       "      <td>5.355750</td>\n",
       "      <td>5.355750</td>\n",
       "      <td>5.355750</td>\n",
       "      <td>5.355750</td>\n",
       "      <td>5.355750</td>\n",
       "      <td>5.355750</td>\n",
       "      <td>5.355750</td>\n",
       "      <td>5.355750</td>\n",
       "      <td>5.355750</td>\n",
       "      <td>5.355750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Accuracy</th>\n",
       "      <td>0.333057</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>...</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>0.332281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train AUC</th>\n",
       "      <td>0.030584</td>\n",
       "      <td>0.004384</td>\n",
       "      <td>0.002511</td>\n",
       "      <td>0.001766</td>\n",
       "      <td>0.001362</td>\n",
       "      <td>0.001109</td>\n",
       "      <td>0.000935</td>\n",
       "      <td>0.000809</td>\n",
       "      <td>0.000712</td>\n",
       "      <td>0.000636</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6000 rows × 155 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   0  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_0   Loss            1.098537   \n",
       "                                            Accuracy        0.354843   \n",
       "                                            AUC             0.500120   \n",
       "                                            Train Loss      1.098558   \n",
       "                                            Train Accuracy  0.344181   \n",
       "...                                                              ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999 Accuracy        0.337729   \n",
       "                                            AUC             0.006679   \n",
       "                                            Train Loss      5.383223   \n",
       "                                            Train Accuracy  0.333057   \n",
       "                                            Train AUC       0.030584   \n",
       "\n",
       "                                                                   1  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_0   Loss            1.098504   \n",
       "                                            Accuracy        0.358482   \n",
       "                                            AUC             0.500277   \n",
       "                                            Train Loss      1.098524   \n",
       "                                            Train Accuracy  0.350251   \n",
       "...                                                              ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999 Accuracy        0.337729   \n",
       "                                            AUC             0.003153   \n",
       "                                            Train Loss      5.355752   \n",
       "                                            Train Accuracy  0.332281   \n",
       "                                            Train AUC       0.004384   \n",
       "\n",
       "                                                                   2  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_0   Loss            1.098467   \n",
       "                                            Accuracy        0.362843   \n",
       "                                            AUC             0.500545   \n",
       "                                            Train Loss      1.098487   \n",
       "                                            Train Accuracy  0.353537   \n",
       "...                                                              ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999 Accuracy        0.337729   \n",
       "                                            AUC             0.002064   \n",
       "                                            Train Loss      5.355751   \n",
       "                                            Train Accuracy  0.332281   \n",
       "                                            Train AUC       0.002511   \n",
       "\n",
       "                                                                   3  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_0   Loss            1.098423   \n",
       "                                            Accuracy        0.365199   \n",
       "                                            AUC             0.501018   \n",
       "                                            Train Loss      1.098442   \n",
       "                                            Train Accuracy  0.358348   \n",
       "...                                                              ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999 Accuracy        0.337729   \n",
       "                                            AUC             0.001534   \n",
       "                                            Train Loss      5.355751   \n",
       "                                            Train Accuracy  0.332281   \n",
       "                                            Train AUC       0.001766   \n",
       "\n",
       "                                                                   4  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_0   Loss            1.098371   \n",
       "                                            Accuracy        0.366960   \n",
       "                                            AUC             0.501737   \n",
       "                                            Train Loss      1.098396   \n",
       "                                            Train Accuracy  0.360740   \n",
       "...                                                              ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999 Accuracy        0.337729   \n",
       "                                            AUC             0.001221   \n",
       "                                            Train Loss      5.355751   \n",
       "                                            Train Accuracy  0.332281   \n",
       "                                            Train AUC       0.001362   \n",
       "\n",
       "                                                                   5  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_0   Loss            1.098309   \n",
       "                                            Accuracy        0.367240   \n",
       "                                            AUC             0.502806   \n",
       "                                            Train Loss      1.098339   \n",
       "                                            Train Accuracy  0.363537   \n",
       "...                                                              ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999 Accuracy        0.337729   \n",
       "                                            AUC             0.001014   \n",
       "                                            Train Loss      5.355750   \n",
       "                                            Train Accuracy  0.332281   \n",
       "                                            Train AUC       0.001109   \n",
       "\n",
       "                                                                   6  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_0   Loss            1.098233   \n",
       "                                            Accuracy        0.368826   \n",
       "                                            AUC             0.504301   \n",
       "                                            Train Loss      1.098267   \n",
       "                                            Train Accuracy  0.365985   \n",
       "...                                                              ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999 Accuracy        0.337729   \n",
       "                                            AUC             0.000867   \n",
       "                                            Train Loss      5.355750   \n",
       "                                            Train Accuracy  0.332281   \n",
       "                                            Train AUC       0.000935   \n",
       "\n",
       "                                                                   7  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_0   Loss            1.098140   \n",
       "                                            Accuracy        0.370377   \n",
       "                                            AUC             0.506150   \n",
       "                                            Train Loss      1.098180   \n",
       "                                            Train Accuracy  0.368336   \n",
       "...                                                              ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999 Accuracy        0.337729   \n",
       "                                            AUC             0.000757   \n",
       "                                            Train Loss      5.355750   \n",
       "                                            Train Accuracy  0.332281   \n",
       "                                            Train AUC       0.000809   \n",
       "\n",
       "                                                                   8  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_0   Loss            1.098026   \n",
       "                                            Accuracy        0.371579   \n",
       "                                            AUC             0.508213   \n",
       "                                            Train Loss      1.098077   \n",
       "                                            Train Accuracy  0.368998   \n",
       "...                                                              ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999 Accuracy        0.337729   \n",
       "                                            AUC             0.000672   \n",
       "                                            Train Loss      5.355750   \n",
       "                                            Train Accuracy  0.332281   \n",
       "                                            Train AUC       0.000712   \n",
       "\n",
       "                                                                   9  ...  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_0   Loss            1.097886  ...   \n",
       "                                            Accuracy        0.372220  ...   \n",
       "                                            AUC             0.510308  ...   \n",
       "                                            Train Loss      1.097955  ...   \n",
       "                                            Train Accuracy  0.369959  ...   \n",
       "...                                                              ...  ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999 Accuracy        0.337729  ...   \n",
       "                                            AUC             0.000604  ...   \n",
       "                                            Train Loss      5.355750  ...   \n",
       "                                            Train Accuracy  0.332281  ...   \n",
       "                                            Train AUC       0.000636  ...   \n",
       "\n",
       "                                                                 145  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_0   Loss            1.066601   \n",
       "                                            Accuracy        0.412316   \n",
       "                                            AUC             0.575838   \n",
       "                                            Train Loss      1.068791   \n",
       "                                            Train Accuracy  0.412060   \n",
       "...                                                              ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999 Accuracy        0.337729   \n",
       "                                            AUC             0.000113   \n",
       "                                            Train Loss      5.355750   \n",
       "                                            Train Accuracy  0.332281   \n",
       "                                            Train AUC       0.000114   \n",
       "\n",
       "                                                                 146  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_0   Loss            1.066601   \n",
       "                                            Accuracy        0.412316   \n",
       "                                            AUC             0.575838   \n",
       "                                            Train Loss      1.068791   \n",
       "                                            Train Accuracy  0.412060   \n",
       "...                                                              ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999 Accuracy        0.337729   \n",
       "                                            AUC             0.000113   \n",
       "                                            Train Loss      5.355750   \n",
       "                                            Train Accuracy  0.332281   \n",
       "                                            Train AUC       0.000114   \n",
       "\n",
       "                                                                 147  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_0   Loss            1.066601   \n",
       "                                            Accuracy        0.412316   \n",
       "                                            AUC             0.575838   \n",
       "                                            Train Loss      1.068791   \n",
       "                                            Train Accuracy  0.412060   \n",
       "...                                                              ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999 Accuracy        0.337729   \n",
       "                                            AUC             0.000113   \n",
       "                                            Train Loss      5.355750   \n",
       "                                            Train Accuracy  0.332281   \n",
       "                                            Train AUC       0.000114   \n",
       "\n",
       "                                                                 148  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_0   Loss            1.066601   \n",
       "                                            Accuracy        0.412316   \n",
       "                                            AUC             0.575838   \n",
       "                                            Train Loss      1.068791   \n",
       "                                            Train Accuracy  0.412060   \n",
       "...                                                              ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999 Accuracy        0.337729   \n",
       "                                            AUC             0.000113   \n",
       "                                            Train Loss      5.355750   \n",
       "                                            Train Accuracy  0.332281   \n",
       "                                            Train AUC       0.000114   \n",
       "\n",
       "                                                                 149  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_0   Loss            1.066601   \n",
       "                                            Accuracy        0.412316   \n",
       "                                            AUC             0.575838   \n",
       "                                            Train Loss      1.068791   \n",
       "                                            Train Accuracy  0.412060   \n",
       "...                                                              ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999 Accuracy        0.337729   \n",
       "                                            AUC             0.000113   \n",
       "                                            Train Loss      5.355750   \n",
       "                                            Train Accuracy  0.332281   \n",
       "                                            Train AUC       0.000114   \n",
       "\n",
       "                                                                 150  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_0   Loss            1.066601   \n",
       "                                            Accuracy        0.412316   \n",
       "                                            AUC             0.575838   \n",
       "                                            Train Loss      1.068791   \n",
       "                                            Train Accuracy  0.412060   \n",
       "...                                                              ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999 Accuracy        0.337729   \n",
       "                                            AUC             0.000113   \n",
       "                                            Train Loss      5.355750   \n",
       "                                            Train Accuracy  0.332281   \n",
       "                                            Train AUC       0.000114   \n",
       "\n",
       "                                                                 151  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_0   Loss            1.066601   \n",
       "                                            Accuracy        0.412316   \n",
       "                                            AUC             0.575838   \n",
       "                                            Train Loss      1.068791   \n",
       "                                            Train Accuracy  0.412060   \n",
       "...                                                              ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999 Accuracy        0.337729   \n",
       "                                            AUC             0.000113   \n",
       "                                            Train Loss      5.355750   \n",
       "                                            Train Accuracy  0.332281   \n",
       "                                            Train AUC       0.000114   \n",
       "\n",
       "                                                                 152  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_0   Loss            1.066601   \n",
       "                                            Accuracy        0.412316   \n",
       "                                            AUC             0.575838   \n",
       "                                            Train Loss      1.068791   \n",
       "                                            Train Accuracy  0.412060   \n",
       "...                                                              ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999 Accuracy        0.337729   \n",
       "                                            AUC             0.000113   \n",
       "                                            Train Loss      5.355750   \n",
       "                                            Train Accuracy  0.332281   \n",
       "                                            Train AUC       0.000114   \n",
       "\n",
       "                                                                 153       154  \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_0   Loss            1.066601  1.066601  \n",
       "                                            Accuracy        0.412316  0.412316  \n",
       "                                            AUC             0.575838  0.575838  \n",
       "                                            Train Loss      1.068791  1.068791  \n",
       "                                            Train Accuracy  0.412060  0.412060  \n",
       "...                                                              ...       ...  \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999 Accuracy        0.337729  0.337729  \n",
       "                                            AUC             0.000113  0.000113  \n",
       "                                            Train Loss      5.355750  5.355750  \n",
       "                                            Train Accuracy  0.332281  0.332281  \n",
       "                                            Train AUC       0.000114  0.000114  \n",
       "\n",
       "[6000 rows x 155 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runningMetrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attaching the last observation of each model, for each metric, to the parameters of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>activation-inner</th>\n",
       "      <th>activation-output</th>\n",
       "      <th>batch-norm</th>\n",
       "      <th>batch-shuffle</th>\n",
       "      <th>batch-size</th>\n",
       "      <th>dropout-ratio</th>\n",
       "      <th>feature-lags</th>\n",
       "      <th>featureset</th>\n",
       "      <th>first-layer-neurons</th>\n",
       "      <th>...</th>\n",
       "      <th>pastobs-in-percentage</th>\n",
       "      <th>pre-processing</th>\n",
       "      <th>second-layer-neurons</th>\n",
       "      <th>id</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Train AUC</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Train Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_115</td>\n",
       "      <td>relu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3300</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>quantgau</td>\n",
       "      <td>128</td>\n",
       "      <td>115</td>\n",
       "      <td>0.80363</td>\n",
       "      <td>0.58075</td>\n",
       "      <td>0.98257</td>\n",
       "      <td>0.80358</td>\n",
       "      <td>0.66548</td>\n",
       "      <td>0.77074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_781</td>\n",
       "      <td>tanh</td>\n",
       "      <td>linear</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>21450</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>minmax</td>\n",
       "      <td>32</td>\n",
       "      <td>781</td>\n",
       "      <td>0.79064</td>\n",
       "      <td>0.57710</td>\n",
       "      <td>0.99908</td>\n",
       "      <td>0.79060</td>\n",
       "      <td>0.65135</td>\n",
       "      <td>0.80627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_997</td>\n",
       "      <td>relu</td>\n",
       "      <td>linear</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10725</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>pow</td>\n",
       "      <td>64</td>\n",
       "      <td>997</td>\n",
       "      <td>0.78380</td>\n",
       "      <td>0.60282</td>\n",
       "      <td>0.90322</td>\n",
       "      <td>0.78376</td>\n",
       "      <td>0.62677</td>\n",
       "      <td>0.84667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_928</td>\n",
       "      <td>relu</td>\n",
       "      <td>linear</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21450</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>std</td>\n",
       "      <td>32</td>\n",
       "      <td>928</td>\n",
       "      <td>0.78185</td>\n",
       "      <td>0.61228</td>\n",
       "      <td>0.89609</td>\n",
       "      <td>0.78181</td>\n",
       "      <td>0.62734</td>\n",
       "      <td>0.84895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_128</td>\n",
       "      <td>tanh</td>\n",
       "      <td>linear</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>21450</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>0.78175</td>\n",
       "      <td>0.60582</td>\n",
       "      <td>0.92492</td>\n",
       "      <td>0.78172</td>\n",
       "      <td>0.62636</td>\n",
       "      <td>0.85098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_814</td>\n",
       "      <td>tanh</td>\n",
       "      <td>linear</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3300</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>32</td>\n",
       "      <td>814</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.19641</td>\n",
       "      <td>0.94736</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.19952</td>\n",
       "      <td>0.95143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_304</td>\n",
       "      <td>leakyrelu</td>\n",
       "      <td>linear</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10725</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>minmax</td>\n",
       "      <td>32</td>\n",
       "      <td>304</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.19329</td>\n",
       "      <td>0.89643</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.18706</td>\n",
       "      <td>0.91432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_195</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>linear</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10725</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>128</td>\n",
       "      <td>195</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.45457</td>\n",
       "      <td>0.68465</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.45333</td>\n",
       "      <td>0.68717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_861</td>\n",
       "      <td>relu</td>\n",
       "      <td>linear</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3300</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>128</td>\n",
       "      <td>861</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.16547</td>\n",
       "      <td>1.59072</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.17433</td>\n",
       "      <td>1.59977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_321</td>\n",
       "      <td>leakyrelu</td>\n",
       "      <td>linear</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>std</td>\n",
       "      <td>64</td>\n",
       "      <td>321</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.19750</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.19989</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          run_id activation-inner  \\\n",
       "115  HD_81ace623-e09b-4393-8a5e-131ea8749a35_115             relu   \n",
       "781  HD_81ace623-e09b-4393-8a5e-131ea8749a35_781             tanh   \n",
       "997  HD_81ace623-e09b-4393-8a5e-131ea8749a35_997             relu   \n",
       "928  HD_81ace623-e09b-4393-8a5e-131ea8749a35_928             relu   \n",
       "128  HD_81ace623-e09b-4393-8a5e-131ea8749a35_128             tanh   \n",
       "..                                           ...              ...   \n",
       "814  HD_81ace623-e09b-4393-8a5e-131ea8749a35_814             tanh   \n",
       "304  HD_81ace623-e09b-4393-8a5e-131ea8749a35_304        leakyrelu   \n",
       "195  HD_81ace623-e09b-4393-8a5e-131ea8749a35_195          sigmoid   \n",
       "861  HD_81ace623-e09b-4393-8a5e-131ea8749a35_861             relu   \n",
       "321  HD_81ace623-e09b-4393-8a5e-131ea8749a35_321        leakyrelu   \n",
       "\n",
       "    activation-output batch-norm batch-shuffle batch-size dropout-ratio  \\\n",
       "115           softmax          1             0       3300           0.2   \n",
       "781            linear          1             1      21450           0.3   \n",
       "997            linear          1             1      10725           0.5   \n",
       "928            linear          0             1      21450           0.4   \n",
       "128            linear          1             1      21450           0.3   \n",
       "..                ...        ...           ...        ...           ...   \n",
       "814            linear          0             0       3300           0.1   \n",
       "304            linear          0             1      10725           0.1   \n",
       "195            linear          1             1      10725           0.5   \n",
       "861            linear          1             1       3300           0.2   \n",
       "321            linear          0             0       3300           0.0   \n",
       "\n",
       "    feature-lags featureset first-layer-neurons  ... pastobs-in-percentage  \\\n",
       "115            1          3                 128  ...                     1   \n",
       "781            3          0                  64  ...                     1   \n",
       "997            3          2                  64  ...                     0   \n",
       "928            1          0                  64  ...                     0   \n",
       "128            0          2                  64  ...                     1   \n",
       "..           ...        ...                 ...  ...                   ...   \n",
       "814            5          2                  32  ...                     1   \n",
       "304            0          1                  32  ...                     1   \n",
       "195            5          3                  64  ...                     0   \n",
       "861            1          0                 128  ...                     1   \n",
       "321            5          0                  32  ...                     0   \n",
       "\n",
       "    pre-processing second-layer-neurons   id      AUC Accuracy     Loss  \\\n",
       "115       quantgau                  128  115  0.80363  0.58075  0.98257   \n",
       "781         minmax                   32  781  0.79064  0.57710  0.99908   \n",
       "997            pow                   64  997  0.78380  0.60282  0.90322   \n",
       "928            std                   32  928  0.78185  0.61228  0.89609   \n",
       "128           None                  128  128  0.78175  0.60582  0.92492   \n",
       "..             ...                  ...  ...      ...      ...      ...   \n",
       "814           None                   32  814  0.00000  0.19641  0.94736   \n",
       "304         minmax                   32  304  0.00000  0.19329  0.89643   \n",
       "195           None                  128  195  0.00000  0.45457  0.68465   \n",
       "861           None                  128  861  0.00000  0.16547  1.59072   \n",
       "321            std                   64  321  0.00000  0.19750  0.00000   \n",
       "\n",
       "    Train AUC Train Accuracy  Train Loss  \n",
       "115   0.80358        0.66548     0.77074  \n",
       "781   0.79060        0.65135     0.80627  \n",
       "997   0.78376        0.62677     0.84667  \n",
       "928   0.78181        0.62734     0.84895  \n",
       "128   0.78172        0.62636     0.85098  \n",
       "..        ...            ...         ...  \n",
       "814   0.00000        0.19952     0.95143  \n",
       "304   0.00000        0.18706     0.91432  \n",
       "195   0.00000        0.45333     0.68717  \n",
       "861   0.00000        0.17433     1.59977  \n",
       "321   0.00000        0.19989     0.00000  \n",
       "\n",
       "[1000 rows x 25 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Resetting indcies and rename columns\n",
    "runningMetrics = runningMetrics.reset_index().rename(columns={'level_0':'run_id','level_1':'metric'})\n",
    "runningMetrics.columns = runningMetrics.columns.get_level_values(0)\n",
    "\n",
    "## Adding a column of short ids, to merge on.\n",
    "runningMetrics['id'] = [re.split('_',i)[-1] for i in runningMetrics.run_id]\n",
    "\n",
    "## Creating a table, having the short id in the rows and the last observation for each metric in the columns. \n",
    "table = pd.pivot_table(runningMetrics[['run_id','metric','154','id']],index='id',columns=['metric'])\n",
    "table.columns = table.columns.get_level_values(1)\n",
    "table = table.round(5).reset_index()\n",
    "\n",
    "## Preparing the parameter dataframe.\n",
    "parameters = parameters.reset_index().rename(columns={'index':'run_id'})\n",
    "\n",
    "## Setting short ID\n",
    "parameters['id'] = [re.split('_',i)[-1] for i in parameters.run_id]\n",
    "\n",
    "## Creating the combined table\n",
    "combined_table = parameters.merge(table,\n",
    "                                     on = 'id',\n",
    "                                     how='left').sort_values('AUC',ascending=False)\n",
    "combined_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating a top-X table for each label-type of a given metric, here AUC.\n",
    "temp_auc = pd.pivot_table(combined_table[['label-type','AUC','id']],index='id',columns='label-type')\n",
    "temp_acc = pd.pivot_table(combined_table[['label-type','Accuracy','id']],index='id',columns='label-type')\n",
    "\n",
    "## Final output - AUC\n",
    "final_output_auc = pd.DataFrame(np.sort(temp_auc.fillna(0).values,\n",
    "                             axis=0)[::-1],\n",
    "                             columns=temp_auc.columns.get_level_values(1)).loc[0:10]\n",
    "## Final output - Accuracy\n",
    "final_output_acc = pd.DataFrame(np.sort(temp_acc.fillna(0).values,\n",
    "                             axis=0)[::-1],\n",
    "                             columns=temp_acc.columns.get_level_values(1))#.loc[0:10]\n",
    "# final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>activation-inner</th>\n",
       "      <th>activation-output</th>\n",
       "      <th>batch-norm</th>\n",
       "      <th>batch-shuffle</th>\n",
       "      <th>batch-size</th>\n",
       "      <th>dropout-ratio</th>\n",
       "      <th>feature-lags</th>\n",
       "      <th>featureset</th>\n",
       "      <th>first-layer-neurons</th>\n",
       "      <th>...</th>\n",
       "      <th>pastobs-in-percentage</th>\n",
       "      <th>pre-processing</th>\n",
       "      <th>second-layer-neurons</th>\n",
       "      <th>id</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Train AUC</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Train Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_115</td>\n",
       "      <td>relu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3300</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>quantgau</td>\n",
       "      <td>128</td>\n",
       "      <td>115</td>\n",
       "      <td>0.80363</td>\n",
       "      <td>0.58075</td>\n",
       "      <td>0.98257</td>\n",
       "      <td>0.80358</td>\n",
       "      <td>0.66548</td>\n",
       "      <td>0.77074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_781</td>\n",
       "      <td>tanh</td>\n",
       "      <td>linear</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>21450</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>minmax</td>\n",
       "      <td>32</td>\n",
       "      <td>781</td>\n",
       "      <td>0.79064</td>\n",
       "      <td>0.57710</td>\n",
       "      <td>0.99908</td>\n",
       "      <td>0.79060</td>\n",
       "      <td>0.65135</td>\n",
       "      <td>0.80627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_997</td>\n",
       "      <td>relu</td>\n",
       "      <td>linear</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10725</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>pow</td>\n",
       "      <td>64</td>\n",
       "      <td>997</td>\n",
       "      <td>0.78380</td>\n",
       "      <td>0.60282</td>\n",
       "      <td>0.90322</td>\n",
       "      <td>0.78376</td>\n",
       "      <td>0.62677</td>\n",
       "      <td>0.84667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_338</td>\n",
       "      <td>relu</td>\n",
       "      <td>linear</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21450</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>quantgau</td>\n",
       "      <td>64</td>\n",
       "      <td>338</td>\n",
       "      <td>0.78078</td>\n",
       "      <td>0.60986</td>\n",
       "      <td>0.88815</td>\n",
       "      <td>0.78075</td>\n",
       "      <td>0.62015</td>\n",
       "      <td>0.86651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_537</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>linear</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10725</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>quantgau</td>\n",
       "      <td>32</td>\n",
       "      <td>537</td>\n",
       "      <td>0.77684</td>\n",
       "      <td>0.60628</td>\n",
       "      <td>0.89268</td>\n",
       "      <td>0.77681</td>\n",
       "      <td>0.61488</td>\n",
       "      <td>0.86622</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          run_id activation-inner  \\\n",
       "115  HD_81ace623-e09b-4393-8a5e-131ea8749a35_115             relu   \n",
       "781  HD_81ace623-e09b-4393-8a5e-131ea8749a35_781             tanh   \n",
       "997  HD_81ace623-e09b-4393-8a5e-131ea8749a35_997             relu   \n",
       "338  HD_81ace623-e09b-4393-8a5e-131ea8749a35_338             relu   \n",
       "537  HD_81ace623-e09b-4393-8a5e-131ea8749a35_537          sigmoid   \n",
       "\n",
       "    activation-output batch-norm batch-shuffle batch-size dropout-ratio  \\\n",
       "115           softmax          1             0       3300           0.2   \n",
       "781            linear          1             1      21450           0.3   \n",
       "997            linear          1             1      10725           0.5   \n",
       "338            linear          0             0      21450           0.2   \n",
       "537            linear          1             1      10725           0.3   \n",
       "\n",
       "    feature-lags featureset first-layer-neurons  ... pastobs-in-percentage  \\\n",
       "115            1          3                 128  ...                     1   \n",
       "781            3          0                  64  ...                     1   \n",
       "997            3          2                  64  ...                     0   \n",
       "338            0          1                  64  ...                     0   \n",
       "537            0          0                  64  ...                     1   \n",
       "\n",
       "    pre-processing second-layer-neurons   id      AUC Accuracy     Loss  \\\n",
       "115       quantgau                  128  115  0.80363  0.58075  0.98257   \n",
       "781         minmax                   32  781  0.79064  0.57710  0.99908   \n",
       "997            pow                   64  997  0.78380  0.60282  0.90322   \n",
       "338       quantgau                   64  338  0.78078  0.60986  0.88815   \n",
       "537       quantgau                   32  537  0.77684  0.60628  0.89268   \n",
       "\n",
       "    Train AUC Train Accuracy  Train Loss  \n",
       "115   0.80358        0.66548     0.77074  \n",
       "781   0.79060        0.65135     0.80627  \n",
       "997   0.78376        0.62677     0.84667  \n",
       "338   0.78075        0.62015     0.86651  \n",
       "537   0.77681        0.61488     0.86622  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_table[np.isin(combined_table.AUC,final_output_auc.loc[0].values.flatten())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>activation-inner</th>\n",
       "      <th>activation-output</th>\n",
       "      <th>batch-norm</th>\n",
       "      <th>batch-shuffle</th>\n",
       "      <th>batch-size</th>\n",
       "      <th>dropout-ratio</th>\n",
       "      <th>feature-lags</th>\n",
       "      <th>featureset</th>\n",
       "      <th>first-layer-neurons</th>\n",
       "      <th>...</th>\n",
       "      <th>pastobs-in-percentage</th>\n",
       "      <th>pre-processing</th>\n",
       "      <th>second-layer-neurons</th>\n",
       "      <th>id</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Train AUC</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Train Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_686</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>linear</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>21450</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>quantgau</td>\n",
       "      <td>32</td>\n",
       "      <td>686</td>\n",
       "      <td>0.75976</td>\n",
       "      <td>0.61322</td>\n",
       "      <td>0.88116</td>\n",
       "      <td>0.75970</td>\n",
       "      <td>0.61041</td>\n",
       "      <td>0.89109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_716</td>\n",
       "      <td>relu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>21450</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>pow</td>\n",
       "      <td>32</td>\n",
       "      <td>716</td>\n",
       "      <td>0.75923</td>\n",
       "      <td>0.61299</td>\n",
       "      <td>0.88144</td>\n",
       "      <td>0.75916</td>\n",
       "      <td>0.61234</td>\n",
       "      <td>0.88095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_868</td>\n",
       "      <td>leakyrelu</td>\n",
       "      <td>linear</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3300</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>std</td>\n",
       "      <td>64</td>\n",
       "      <td>868</td>\n",
       "      <td>0.76452</td>\n",
       "      <td>0.61282</td>\n",
       "      <td>0.88599</td>\n",
       "      <td>0.76448</td>\n",
       "      <td>0.60774</td>\n",
       "      <td>0.89207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_717</td>\n",
       "      <td>leakyrelu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21450</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>128</td>\n",
       "      <td>717</td>\n",
       "      <td>0.76304</td>\n",
       "      <td>0.61409</td>\n",
       "      <td>0.87683</td>\n",
       "      <td>0.76298</td>\n",
       "      <td>0.61164</td>\n",
       "      <td>0.87896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_133</td>\n",
       "      <td>tanh</td>\n",
       "      <td>softmax</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10725</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>pow</td>\n",
       "      <td>64</td>\n",
       "      <td>133</td>\n",
       "      <td>0.76220</td>\n",
       "      <td>0.61248</td>\n",
       "      <td>0.88257</td>\n",
       "      <td>0.76215</td>\n",
       "      <td>0.61133</td>\n",
       "      <td>0.88838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          run_id activation-inner  \\\n",
       "686  HD_81ace623-e09b-4393-8a5e-131ea8749a35_686          sigmoid   \n",
       "716  HD_81ace623-e09b-4393-8a5e-131ea8749a35_716             relu   \n",
       "868  HD_81ace623-e09b-4393-8a5e-131ea8749a35_868        leakyrelu   \n",
       "717  HD_81ace623-e09b-4393-8a5e-131ea8749a35_717        leakyrelu   \n",
       "133  HD_81ace623-e09b-4393-8a5e-131ea8749a35_133             tanh   \n",
       "\n",
       "    activation-output batch-norm batch-shuffle batch-size dropout-ratio  \\\n",
       "686            linear          1             1      21450           0.4   \n",
       "716           softmax          1             1      21450           0.4   \n",
       "868            linear          1             0       3300           0.4   \n",
       "717           softmax          0             1      21450           0.0   \n",
       "133           softmax          1             1      10725           0.3   \n",
       "\n",
       "    feature-lags featureset first-layer-neurons  ... pastobs-in-percentage  \\\n",
       "686            3          0                  32  ...                     1   \n",
       "716            3          0                  32  ...                     1   \n",
       "868            0          0                  32  ...                     0   \n",
       "717            5          3                  32  ...                     0   \n",
       "133            1          3                  64  ...                     0   \n",
       "\n",
       "    pre-processing second-layer-neurons   id      AUC Accuracy     Loss  \\\n",
       "686       quantgau                   32  686  0.75976  0.61322  0.88116   \n",
       "716            pow                   32  716  0.75923  0.61299  0.88144   \n",
       "868            std                   64  868  0.76452  0.61282  0.88599   \n",
       "717           None                  128  717  0.76304  0.61409  0.87683   \n",
       "133            pow                   64  133  0.76220  0.61248  0.88257   \n",
       "\n",
       "    Train AUC Train Accuracy  Train Loss  \n",
       "686   0.75970        0.61041     0.89109  \n",
       "716   0.75916        0.61234     0.88095  \n",
       "868   0.76448        0.60774     0.89207  \n",
       "717   0.76298        0.61164     0.87896  \n",
       "133   0.76215        0.61133     0.88838  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_table[np.isin(combined_table.Accuracy,final_output_acc.loc[0].values.flatten())].sort_values('label-type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label-type\n",
       "0    0.438856\n",
       "1    0.445478\n",
       "2    0.427569\n",
       "3    0.417984\n",
       "4    0.395516\n",
       "dtype: float64"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_output_acc.loc[0:170].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.98627683 0.87339195 0.50974552]\n",
      " [0.27183571 0.33691873 0.21695427]\n",
      " [0.27647714 0.34331559 0.86215894]\n",
      " ...\n",
      " [0.36449376 0.88818802 0.38373482]\n",
      " [0.47743707 0.74612918 0.50447322]\n",
      " [0.18474035 0.45689353 0.30267824]]\n",
      "[2.3694143  0.82570871 1.48195167 ... 1.6364166  1.72803947 0.94431212]\n",
      "[[2.3694143 ]\n",
      " [0.82570871]\n",
      " [1.48195167]\n",
      " ...\n",
      " [1.6364166 ]\n",
      " [1.72803947]\n",
      " [0.94431212]]\n",
      "[0.41625343 0.3686109  0.21513567]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.41625343, 0.3686109 , 0.21513567],\n",
       "       [0.32921503, 0.40803582, 0.26274915],\n",
       "       [0.18656286, 0.2316645 , 0.58177264],\n",
       "       ...,\n",
       "       [0.22273898, 0.542764  , 0.23449702],\n",
       "       [0.27628829, 0.43177786, 0.29193385],\n",
       "       [0.19563484, 0.48383741, 0.32052775]])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(2020)\n",
    "rand_numbers = np.random.rand(85690,3)\n",
    "rand_prob = rand_numbers / rand_numbers.sum(axis=1).reshape(-1,1)\n",
    "rand_prob\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reading in the market data (done automatically atm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'8'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>spread_open</th>\n",
       "      <th>spread_high</th>\n",
       "      <th>spread_low</th>\n",
       "      <th>spread_close</th>\n",
       "      <th>bidsize_open</th>\n",
       "      <th>bidsize_high</th>\n",
       "      <th>bidsize_low</th>\n",
       "      <th>bidsize_close</th>\n",
       "      <th>ofrsize_open</th>\n",
       "      <th>ofrsize_high</th>\n",
       "      <th>ofrsize_low</th>\n",
       "      <th>ofrsize_close</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>sector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">20200501</th>\n",
       "      <th>0</th>\n",
       "      <td>286.250</td>\n",
       "      <td>289.260</td>\n",
       "      <td>285.870</td>\n",
       "      <td>289.260</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.24</td>\n",
       "      <td>6.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>289.260</td>\n",
       "      <td>289.350</td>\n",
       "      <td>288.365</td>\n",
       "      <td>289.020</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.10</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>289.035</td>\n",
       "      <td>289.705</td>\n",
       "      <td>288.280</td>\n",
       "      <td>288.580</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>288.485</td>\n",
       "      <td>289.315</td>\n",
       "      <td>288.280</td>\n",
       "      <td>289.095</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>289.100</td>\n",
       "      <td>290.435</td>\n",
       "      <td>288.940</td>\n",
       "      <td>290.320</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.10</td>\n",
       "      <td>13.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">20200529</th>\n",
       "      <th>385</th>\n",
       "      <td>91.500</td>\n",
       "      <td>91.755</td>\n",
       "      <td>91.485</td>\n",
       "      <td>91.740</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>XNTK</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>91.740</td>\n",
       "      <td>91.740</td>\n",
       "      <td>91.740</td>\n",
       "      <td>91.740</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>XNTK</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>91.580</td>\n",
       "      <td>91.830</td>\n",
       "      <td>91.580</td>\n",
       "      <td>91.715</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.45</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>XNTK</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>91.595</td>\n",
       "      <td>91.880</td>\n",
       "      <td>91.595</td>\n",
       "      <td>91.750</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.52</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>XNTK</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>46.005</td>\n",
       "      <td>46.005</td>\n",
       "      <td>45.815</td>\n",
       "      <td>45.815</td>\n",
       "      <td>92.01</td>\n",
       "      <td>92.01</td>\n",
       "      <td>91.63</td>\n",
       "      <td>91.63</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>XNTK</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>546000 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 open     high      low    close  spread_open  spread_high  \\\n",
       "20200501 0    286.250  289.260  285.870  289.260         0.50         0.50   \n",
       "         1    289.260  289.350  288.365  289.020         0.24         0.45   \n",
       "         2    289.035  289.705  288.280  288.580         0.07         0.49   \n",
       "         3    288.485  289.315  288.280  289.095         0.49         0.49   \n",
       "         4    289.100  290.435  288.940  290.320         0.16         0.33   \n",
       "...               ...      ...      ...      ...          ...          ...   \n",
       "20200529 385   91.500   91.755   91.485   91.740         0.42         0.93   \n",
       "         386   91.740   91.740   91.740   91.740         0.50         0.50   \n",
       "         387   91.580   91.830   91.580   91.715         0.18         0.68   \n",
       "         388   91.595   91.880   91.595   91.750         0.21         0.78   \n",
       "         389   46.005   46.005   45.815   45.815        92.01        92.01   \n",
       "\n",
       "              spread_low  spread_close  bidsize_open  bidsize_high  \\\n",
       "20200501 0          0.01          0.24           6.0          95.0   \n",
       "         1          0.01          0.10           9.0          20.0   \n",
       "         2          0.01          0.30           1.0          50.0   \n",
       "         3          0.01          0.17           1.0          25.0   \n",
       "         4          0.01          0.10          13.0          71.0   \n",
       "...                  ...           ...           ...           ...   \n",
       "20200529 385        0.39          0.50           5.0           5.0   \n",
       "         386        0.50          0.50           5.0           5.0   \n",
       "         387        0.18          0.45           5.0           5.0   \n",
       "         388        0.21          0.52           5.0           5.0   \n",
       "         389       91.63         91.63           0.0           0.0   \n",
       "\n",
       "              bidsize_low  bidsize_close  ofrsize_open  ofrsize_high  \\\n",
       "20200501 0            1.0           10.0           1.0          85.0   \n",
       "         1            1.0            1.0           4.0          56.0   \n",
       "         2            1.0            1.0           1.0          13.0   \n",
       "         3            1.0           16.0           1.0           8.0   \n",
       "         4            1.0            1.0           1.0         236.0   \n",
       "...                   ...            ...           ...           ...   \n",
       "20200529 385          5.0            5.0           1.0           5.0   \n",
       "         386          5.0            5.0           5.0           5.0   \n",
       "         387          5.0            5.0           1.0           5.0   \n",
       "         388          5.0            5.0           1.0           5.0   \n",
       "         389          0.0            0.0           5.0           5.0   \n",
       "\n",
       "              ofrsize_low  ofrsize_close Ticker      sector  \n",
       "20200501 0            1.0            4.0   AAPL  Technology  \n",
       "         1            1.0            1.0   AAPL  Technology  \n",
       "         2            1.0            1.0   AAPL  Technology  \n",
       "         3            1.0            1.0   AAPL  Technology  \n",
       "         4            1.0            1.0   AAPL  Technology  \n",
       "...                   ...            ...    ...         ...  \n",
       "20200529 385          1.0            5.0   XNTK         NaN  \n",
       "         386          5.0            5.0   XNTK         NaN  \n",
       "         387          1.0            5.0   XNTK         NaN  \n",
       "         388          1.0            5.0   XNTK         NaN  \n",
       "         389          1.0            1.0   XNTK         NaN  \n",
       "\n",
       "[546000 rows x 18 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>spread_open</th>\n",
       "      <th>spread_high</th>\n",
       "      <th>spread_low</th>\n",
       "      <th>spread_close</th>\n",
       "      <th>bidsize_open</th>\n",
       "      <th>bidsize_high</th>\n",
       "      <th>bidsize_low</th>\n",
       "      <th>bidsize_close</th>\n",
       "      <th>ofrsize_open</th>\n",
       "      <th>ofrsize_high</th>\n",
       "      <th>ofrsize_low</th>\n",
       "      <th>ofrsize_close</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>sector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">20200501</th>\n",
       "      <th>0</th>\n",
       "      <td>286.250</td>\n",
       "      <td>289.260</td>\n",
       "      <td>285.870</td>\n",
       "      <td>289.260</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.24</td>\n",
       "      <td>6.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>289.260</td>\n",
       "      <td>289.350</td>\n",
       "      <td>288.365</td>\n",
       "      <td>289.020</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.10</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>289.035</td>\n",
       "      <td>289.705</td>\n",
       "      <td>288.280</td>\n",
       "      <td>288.580</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>288.485</td>\n",
       "      <td>289.315</td>\n",
       "      <td>288.280</td>\n",
       "      <td>289.095</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>289.100</td>\n",
       "      <td>290.435</td>\n",
       "      <td>288.940</td>\n",
       "      <td>290.320</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.10</td>\n",
       "      <td>13.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">20200529</th>\n",
       "      <th>385</th>\n",
       "      <td>91.500</td>\n",
       "      <td>91.755</td>\n",
       "      <td>91.485</td>\n",
       "      <td>91.740</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>XNTK</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>91.740</td>\n",
       "      <td>91.740</td>\n",
       "      <td>91.740</td>\n",
       "      <td>91.740</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>XNTK</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>91.580</td>\n",
       "      <td>91.830</td>\n",
       "      <td>91.580</td>\n",
       "      <td>91.715</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.45</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>XNTK</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>91.595</td>\n",
       "      <td>91.880</td>\n",
       "      <td>91.595</td>\n",
       "      <td>91.750</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.52</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>XNTK</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>46.005</td>\n",
       "      <td>46.005</td>\n",
       "      <td>45.815</td>\n",
       "      <td>45.815</td>\n",
       "      <td>92.01</td>\n",
       "      <td>92.01</td>\n",
       "      <td>91.63</td>\n",
       "      <td>91.63</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>XNTK</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>546000 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 open     high      low    close  spread_open  spread_high  \\\n",
       "20200501 0    286.250  289.260  285.870  289.260         0.50         0.50   \n",
       "         1    289.260  289.350  288.365  289.020         0.24         0.45   \n",
       "         2    289.035  289.705  288.280  288.580         0.07         0.49   \n",
       "         3    288.485  289.315  288.280  289.095         0.49         0.49   \n",
       "         4    289.100  290.435  288.940  290.320         0.16         0.33   \n",
       "...               ...      ...      ...      ...          ...          ...   \n",
       "20200529 385   91.500   91.755   91.485   91.740         0.42         0.93   \n",
       "         386   91.740   91.740   91.740   91.740         0.50         0.50   \n",
       "         387   91.580   91.830   91.580   91.715         0.18         0.68   \n",
       "         388   91.595   91.880   91.595   91.750         0.21         0.78   \n",
       "         389   46.005   46.005   45.815   45.815        92.01        92.01   \n",
       "\n",
       "              spread_low  spread_close  bidsize_open  bidsize_high  \\\n",
       "20200501 0          0.01          0.24           6.0          95.0   \n",
       "         1          0.01          0.10           9.0          20.0   \n",
       "         2          0.01          0.30           1.0          50.0   \n",
       "         3          0.01          0.17           1.0          25.0   \n",
       "         4          0.01          0.10          13.0          71.0   \n",
       "...                  ...           ...           ...           ...   \n",
       "20200529 385        0.39          0.50           5.0           5.0   \n",
       "         386        0.50          0.50           5.0           5.0   \n",
       "         387        0.18          0.45           5.0           5.0   \n",
       "         388        0.21          0.52           5.0           5.0   \n",
       "         389       91.63         91.63           0.0           0.0   \n",
       "\n",
       "              bidsize_low  bidsize_close  ofrsize_open  ofrsize_high  \\\n",
       "20200501 0            1.0           10.0           1.0          85.0   \n",
       "         1            1.0            1.0           4.0          56.0   \n",
       "         2            1.0            1.0           1.0          13.0   \n",
       "         3            1.0           16.0           1.0           8.0   \n",
       "         4            1.0            1.0           1.0         236.0   \n",
       "...                   ...            ...           ...           ...   \n",
       "20200529 385          5.0            5.0           1.0           5.0   \n",
       "         386          5.0            5.0           5.0           5.0   \n",
       "         387          5.0            5.0           1.0           5.0   \n",
       "         388          5.0            5.0           1.0           5.0   \n",
       "         389          0.0            0.0           5.0           5.0   \n",
       "\n",
       "              ofrsize_low  ofrsize_close Ticker      sector  \n",
       "20200501 0            1.0            4.0   AAPL  Technology  \n",
       "         1            1.0            1.0   AAPL  Technology  \n",
       "         2            1.0            1.0   AAPL  Technology  \n",
       "         3            1.0            1.0   AAPL  Technology  \n",
       "         4            1.0            1.0   AAPL  Technology  \n",
       "...                   ...            ...    ...         ...  \n",
       "20200529 385          1.0            5.0   XNTK         NaN  \n",
       "         386          5.0            5.0   XNTK         NaN  \n",
       "         387          1.0            5.0   XNTK         NaN  \n",
       "         388          1.0            5.0   XNTK         NaN  \n",
       "         389          1.0            1.0   XNTK         NaN  \n",
       "\n",
       "[546000 rows x 18 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['open', 'high', 'low', 'close', 'spread_open', 'spread_high',\n",
       "       'spread_low', 'spread_close', 'bidsize_open', 'bidsize_high',\n",
       "       'bidsize_low', 'bidsize_close', 'ofrsize_open', 'ofrsize_high',\n",
       "       'ofrsize_low', 'ofrsize_close', 'Ticker', 'sector'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping ETFS and market indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AAPL', 'ABBV', 'ABT', 'AEP', 'AMT', 'APD', 'BA', 'BABA', 'BAC',\n",
       "       'BHP', 'BP', 'CCI', 'CHL', 'COST', 'CSGP', 'D', 'DIS', 'ECL',\n",
       "       'ENB', 'EXC', 'FB', 'FMX', 'GOOG', 'IDU', 'INTC', 'IYC', 'IYE',\n",
       "       'IYG', 'IYH', 'IYJ', 'IYK', 'IYM', 'IYR', 'IYW', 'IYZ', 'JNJ',\n",
       "       'KO', 'LFC', 'LIN', 'LMT', 'MA', 'MCD', 'MSFT', 'NKE', 'NVDA',\n",
       "       'NVS', 'PBR', 'PEP', 'PFE', 'PLD', 'PSA', 'PTR', 'PYPL', 'RTX',\n",
       "       'SHW', 'SNP', 'SO', 'SRE', 'T', 'TM', 'TSLA', 'TSM', 'UNP', 'UPS',\n",
       "       'V', 'WMT', 'DIA', 'QQQ', 'SPY', 'XNTK'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Ticker.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the XNTK ticker\n",
    "data = data[~data.Ticker.isin(['XNTK'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AAPL', 'ABBV', 'ABT', 'AEP', 'AMT', 'APD', 'BA', 'BABA', 'BAC',\n",
       "       'BHP', 'BP', 'CCI', 'CHL', 'COST', 'CSGP', 'D', 'DIS', 'ECL',\n",
       "       'ENB', 'EXC', 'FB', 'FMX', 'GOOG', 'IDU', 'INTC', 'IYC', 'IYE',\n",
       "       'IYG', 'IYH', 'IYJ', 'IYK', 'IYM', 'IYR', 'IYW', 'IYZ', 'JNJ',\n",
       "       'KO', 'LFC', 'LIN', 'LMT', 'MA', 'MCD', 'MSFT', 'NKE', 'NVDA',\n",
       "       'NVS', 'PBR', 'PEP', 'PFE', 'PLD', 'PSA', 'PTR', 'PYPL', 'RTX',\n",
       "       'SHW', 'SNP', 'SO', 'SRE', 'T', 'TM', 'TSLA', 'TSM', 'UNP', 'UPS',\n",
       "       'V', 'WMT', 'DIA', 'QQQ', 'SPY'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Ticker.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the XNTK ticker\n",
    "data = data[~data.Ticker.isin(['XNTK'])]\n",
    "\n",
    "etfs = ['IYH','IYM','IYK','IYJ','IYG','IYW','IYC','IYR','IDU','IYZ','IYE','IYF','SPY','DIA','QQQ']\n",
    "\n",
    "# Extracting the sector ETFs to a separate variable\n",
    "sectorETFS = data[data.Ticker.isin(etfs)]\n",
    "\n",
    "# Removing the ETFs\n",
    "data = data[~data.Ticker.isin(etfs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['open', 'high', 'low', 'close', 'spread_open', 'spread_high',\n",
       "       'spread_low', 'spread_close', 'bidsize_open', 'bidsize_high',\n",
       "       'bidsize_low', 'bidsize_close', 'ofrsize_open', 'ofrsize_high',\n",
       "       'ofrsize_low', 'ofrsize_close', 'Ticker', 'sector'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>spread_open</th>\n",
       "      <th>spread_high</th>\n",
       "      <th>spread_low</th>\n",
       "      <th>spread_close</th>\n",
       "      <th>bidsize_open</th>\n",
       "      <th>bidsize_high</th>\n",
       "      <th>bidsize_low</th>\n",
       "      <th>bidsize_close</th>\n",
       "      <th>ofrsize_open</th>\n",
       "      <th>ofrsize_high</th>\n",
       "      <th>ofrsize_low</th>\n",
       "      <th>ofrsize_close</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>sector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">20200501</th>\n",
       "      <th>0</th>\n",
       "      <td>286.250</td>\n",
       "      <td>289.260</td>\n",
       "      <td>285.870</td>\n",
       "      <td>289.260</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.24</td>\n",
       "      <td>6.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>289.260</td>\n",
       "      <td>289.350</td>\n",
       "      <td>288.365</td>\n",
       "      <td>289.020</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.10</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>289.035</td>\n",
       "      <td>289.705</td>\n",
       "      <td>288.280</td>\n",
       "      <td>288.580</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>288.485</td>\n",
       "      <td>289.315</td>\n",
       "      <td>288.280</td>\n",
       "      <td>289.095</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>289.100</td>\n",
       "      <td>290.435</td>\n",
       "      <td>288.940</td>\n",
       "      <td>290.320</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.10</td>\n",
       "      <td>13.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">20200529</th>\n",
       "      <th>385</th>\n",
       "      <td>123.950</td>\n",
       "      <td>124.110</td>\n",
       "      <td>123.910</td>\n",
       "      <td>124.100</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WMT</td>\n",
       "      <td>Consumer Defensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>124.085</td>\n",
       "      <td>124.085</td>\n",
       "      <td>123.920</td>\n",
       "      <td>123.995</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>WMT</td>\n",
       "      <td>Consumer Defensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>123.995</td>\n",
       "      <td>124.355</td>\n",
       "      <td>123.985</td>\n",
       "      <td>124.335</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.05</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>WMT</td>\n",
       "      <td>Consumer Defensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>124.335</td>\n",
       "      <td>124.355</td>\n",
       "      <td>124.060</td>\n",
       "      <td>124.075</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>WMT</td>\n",
       "      <td>Consumer Defensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>124.075</td>\n",
       "      <td>124.225</td>\n",
       "      <td>122.810</td>\n",
       "      <td>123.855</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.43</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.21</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WMT</td>\n",
       "      <td>Consumer Defensive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>429000 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 open     high      low    close  spread_open  spread_high  \\\n",
       "20200501 0    286.250  289.260  285.870  289.260         0.50         0.50   \n",
       "         1    289.260  289.350  288.365  289.020         0.24         0.45   \n",
       "         2    289.035  289.705  288.280  288.580         0.07         0.49   \n",
       "         3    288.485  289.315  288.280  289.095         0.49         0.49   \n",
       "         4    289.100  290.435  288.940  290.320         0.16         0.33   \n",
       "...               ...      ...      ...      ...          ...          ...   \n",
       "20200529 385  123.950  124.110  123.910  124.100         0.02         0.07   \n",
       "         386  124.085  124.085  123.920  123.995         0.01         0.06   \n",
       "         387  123.995  124.355  123.985  124.335         0.01         0.07   \n",
       "         388  124.335  124.355  124.060  124.075         0.05         0.12   \n",
       "         389  124.075  124.225  122.810  123.855         0.01         2.43   \n",
       "\n",
       "              spread_low  spread_close  bidsize_open  bidsize_high  \\\n",
       "20200501 0          0.01          0.24           6.0          95.0   \n",
       "         1          0.01          0.10           9.0          20.0   \n",
       "         2          0.01          0.30           1.0          50.0   \n",
       "         3          0.01          0.17           1.0          25.0   \n",
       "         4          0.01          0.10          13.0          71.0   \n",
       "...                  ...           ...           ...           ...   \n",
       "20200529 385        0.01          0.04           1.0          11.0   \n",
       "         386        0.01          0.01           1.0           8.0   \n",
       "         387        0.01          0.05           4.0          16.0   \n",
       "         388        0.01          0.01           3.0           6.0   \n",
       "         389        0.01          0.21           1.0          20.0   \n",
       "\n",
       "              bidsize_low  bidsize_close  ofrsize_open  ofrsize_high  \\\n",
       "20200501 0            1.0           10.0           1.0          85.0   \n",
       "         1            1.0            1.0           4.0          56.0   \n",
       "         2            1.0            1.0           1.0          13.0   \n",
       "         3            1.0           16.0           1.0           8.0   \n",
       "         4            1.0            1.0           1.0         236.0   \n",
       "...                   ...            ...           ...           ...   \n",
       "20200529 385          1.0            1.0           5.0           9.0   \n",
       "         386          1.0            3.0           1.0           9.0   \n",
       "         387          1.0            2.0           2.0          10.0   \n",
       "         388          1.0            2.0           2.0          10.0   \n",
       "         389          1.0            2.0           4.0          12.0   \n",
       "\n",
       "              ofrsize_low  ofrsize_close Ticker              sector  \n",
       "20200501 0            1.0            4.0   AAPL          Technology  \n",
       "         1            1.0            1.0   AAPL          Technology  \n",
       "         2            1.0            1.0   AAPL          Technology  \n",
       "         3            1.0            1.0   AAPL          Technology  \n",
       "         4            1.0            1.0   AAPL          Technology  \n",
       "...                   ...            ...    ...                 ...  \n",
       "20200529 385          1.0            1.0    WMT  Consumer Defensive  \n",
       "         386          1.0            2.0    WMT  Consumer Defensive  \n",
       "         387          1.0            2.0    WMT  Consumer Defensive  \n",
       "         388          1.0            4.0    WMT  Consumer Defensive  \n",
       "         389          1.0            1.0    WMT  Consumer Defensive  \n",
       "\n",
       "[429000 rows x 18 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:MainThread:numexpr.utils:NumExpr defaulting to 4 threads.\n",
      "C:\\Users\\PC\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:844: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "C:\\Users\\PC\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:965: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAPL done\n",
      "ABBV done\n",
      "ABT done\n",
      "AEP done\n",
      "AMT done\n",
      "APD done\n",
      "BA done\n",
      "BABA done\n",
      "BAC done\n",
      "BHP done\n",
      "BP done\n",
      "CCI done\n",
      "CHL done\n",
      "COST done\n",
      "CSGP done\n",
      "D done\n",
      "DIS done\n",
      "ECL done\n",
      "ENB done\n",
      "EXC done\n",
      "FB done\n",
      "FMX done\n",
      "GOOG done\n",
      "INTC done\n",
      "JNJ done\n",
      "KO done\n",
      "LFC done\n",
      "LIN done\n",
      "LMT done\n",
      "MA done\n",
      "MCD done\n",
      "MSFT done\n",
      "NKE done\n",
      "NVDA done\n",
      "NVS done\n",
      "Number of NaNs in label: 1. 1 is expected\n",
      "Returns that lead to NaNs in label: [0.0907158]\n",
      "PBR done\n",
      "PEP done\n",
      "PFE done\n",
      "PLD done\n",
      "PSA done\n",
      "PTR done\n",
      "PYPL done\n",
      "RTX done\n",
      "SHW done\n",
      "SNP done\n",
      "SO done\n",
      "SRE done\n",
      "T done\n",
      "TM done\n",
      "TSLA done\n",
      "TSM done\n",
      "UNP done\n",
      "UPS done\n",
      "V done\n",
      "WMT done\n"
     ]
    }
   ],
   "source": [
    "########### Generate Features ################\n",
    "\n",
    "n_feature_lags = 1\n",
    "\n",
    "# features = generateFeatures_multi_final(data = data, \n",
    "#                                   listOfFeatures = [\n",
    "#                                                     'pastobs',\n",
    "#                                                     'spread',\n",
    "#                                                     'bidsize',\n",
    "#                                                     'ofrsize',\n",
    "# #                                                     'stok',\n",
    "# #                                                     'stod',\n",
    "# #                                                     'sstod',\n",
    "# #                                                     'wilr',\n",
    "# #                                                     'roc',\n",
    "# #                                                     'rsi',\n",
    "# #                                                     'atr',\n",
    "# #                                                     'cci',\n",
    "# #                                                     'dpo',\n",
    "# #                                                     'sma',\n",
    "# #                                                     'ema',\n",
    "# #                                                     'macd',\n",
    "# #                                                       'macd_diff',\n",
    "# #                                                       'macd_signal',\n",
    "# #                                                     'dis5',\n",
    "# #                                                     'dis10',\n",
    "#                                                       'sector'\n",
    "#                                                    ], \n",
    "#                                    feature_lags = n_feature_lags\n",
    "#                                      ,stockTable=stockTable)\n",
    "features = generateFeatures_multi_final(data = data, \n",
    "                                  listOfFeatures = [\n",
    "                                                    'pastobs',\n",
    "                                                    'spread',\n",
    "                                                    'bidsize',\n",
    "                                                    'ofrsize',\n",
    "                                                    'stok',\n",
    "                                                    'stod',\n",
    "                                                    'sstod',\n",
    "#                                                     'wilr',\n",
    "                                                    'roc',\n",
    "                                                    'rsi',\n",
    "                                                    'atr',\n",
    "                                                    'cci',\n",
    "                                                    'dpo',\n",
    "                                                    'sma',\n",
    "                                                    'ema',\n",
    "                                                    'macd',\n",
    "                                                      'macd_diff',\n",
    "                                                      'macd_signal',\n",
    "                                                    'dis5',\n",
    "                                                    'dis10',\n",
    "                                                      'sector'\n",
    "                                                   ], \n",
    "                                   feature_lags = n_feature_lags\n",
    "                                     ,sectorETFS=sectorETFS)\n",
    "\n",
    "########### Generate Labels ################\n",
    "\n",
    "n_classes = 2\n",
    "# extract first 4 columns as the lag0 or raw OHLC prices (used for labelling)\n",
    "price_candles = data[['open','high','low','close','Ticker']]\n",
    "\n",
    "########### Align Data ################\n",
    "\n",
    "# from imported function (see testing_preprocessing_features_and_labels.ipynb for thorough experimenting with all the cut-offs):    \n",
    "X, y,indices = align_features_and_labels_multi_final(price_candles = price_candles, \n",
    "                                                 all_features = features,\n",
    "                                                 prediction_horizon = 1, \n",
    "                                                 n_feature_lags = n_feature_lags, \n",
    "                                                 n_classes = n_classes, # 5,\n",
    "                                                 safe_burn_in = False, \n",
    "                                                 data_sample = 'full',\n",
    "                                                 splitType='global',\n",
    "                                                 noise=False,ticker_dummies=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding ticker dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Adding ticker dummies\n",
    "tickers = X.pop('ticker')\n",
    "X = pd.concat([X, pd.get_dummies(tickers, prefix='ticker', drop_first=False)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['open_lag0', 'high_lag0', 'low_lag0', 'close_lag0', 'spread_open_lag0',\n",
       "       'spread_high_lag0', 'spread_low_lag0', 'spread_close_lag0',\n",
       "       'bidsize_open_lag0', 'bidsize_high_lag0',\n",
       "       ...\n",
       "       'ticker_SO', 'ticker_SRE', 'ticker_T', 'ticker_TM', 'ticker_TSLA',\n",
       "       'ticker_TSM', 'ticker_UNP', 'ticker_UPS', 'ticker_V', 'ticker_WMT'],\n",
       "      dtype='object', length=156)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing our final train/validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(341385, 156)\n",
      "(341385, 1)\n",
      "(85690, 156)\n",
      "(85690, 1)\n"
     ]
    }
   ],
   "source": [
    "# train_ds = pd.concat([X.iloc[start:end, :] for (start, end) in train_ranges]).reset_index(drop=True)\n",
    "# train_y = pd.concat([y.iloc[start:end] for (start, end) in train_ranges]).reset_index(drop=True)\n",
    "\n",
    "# validate_ds = pd.concat([X.iloc[start:end, :] for (start, end) in val_ranges]).reset_index(drop=True)\n",
    "# val_y = pd.concat([y.iloc[start:end] for (start, end) in val_ranges]).reset_index(drop=True)\n",
    "\n",
    "# train_ds.shape, train_y.shape, validate_ds.shape, val_y.shape, train_y.shape[0] + val_y.shape[0]\n",
    "\n",
    "# Let's have a proper split (along tickers & dates)\n",
    "train_size = 0.8\n",
    "\n",
    "# Sort the indices\n",
    "tempIndices = indices.sort_values(['days','timestamps','ticker'])\n",
    "\n",
    "# Sorting the data\n",
    "X = X.loc[tempIndices.index,:]#.head(66)\n",
    "y = y.loc[tempIndices.index,:]\n",
    "\n",
    "# extracting the first date for the validation data.\n",
    "first_val_day = int(np.floor(indices.days.unique().shape[0]*0.8))\n",
    "\n",
    "# Splitting the data\n",
    "X_train = X[tempIndices.days<tempIndices.days.unique()[first_val_day]].reset_index(drop=True)\n",
    "y_train = y[tempIndices.days<tempIndices.days.unique()[first_val_day]].reset_index(drop=True)\n",
    "\n",
    "X_test = X[tempIndices.days>=tempIndices.days.unique()[first_val_day]].reset_index(drop=True)\n",
    "y_test = y[tempIndices.days>=tempIndices.days.unique()[first_val_day]].reset_index(drop=True)\n",
    "\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open_lag0</th>\n",
       "      <th>high_lag0</th>\n",
       "      <th>low_lag0</th>\n",
       "      <th>close_lag0</th>\n",
       "      <th>spread_open_lag0</th>\n",
       "      <th>spread_high_lag0</th>\n",
       "      <th>spread_low_lag0</th>\n",
       "      <th>spread_close_lag0</th>\n",
       "      <th>bidsize_open_lag0</th>\n",
       "      <th>bidsize_high_lag0</th>\n",
       "      <th>...</th>\n",
       "      <th>ticker_SO</th>\n",
       "      <th>ticker_SRE</th>\n",
       "      <th>ticker_T</th>\n",
       "      <th>ticker_TM</th>\n",
       "      <th>ticker_TSLA</th>\n",
       "      <th>ticker_TSM</th>\n",
       "      <th>ticker_UNP</th>\n",
       "      <th>ticker_UPS</th>\n",
       "      <th>ticker_V</th>\n",
       "      <th>ticker_WMT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.545</td>\n",
       "      <td>0.205</td>\n",
       "      <td>-0.635</td>\n",
       "      <td>296.440</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.200</td>\n",
       "      <td>0.040</td>\n",
       "      <td>-0.255</td>\n",
       "      <td>82.805</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.030</td>\n",
       "      <td>-0.040</td>\n",
       "      <td>90.855</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.100</td>\n",
       "      <td>0.140</td>\n",
       "      <td>-0.110</td>\n",
       "      <td>81.510</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.070</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>234.230</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341380</th>\n",
       "      <td>0.035</td>\n",
       "      <td>0.165</td>\n",
       "      <td>-0.040</td>\n",
       "      <td>51.300</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>5.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341381</th>\n",
       "      <td>0.890</td>\n",
       "      <td>0.965</td>\n",
       "      <td>-0.290</td>\n",
       "      <td>169.435</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1.41</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341382</th>\n",
       "      <td>0.105</td>\n",
       "      <td>0.235</td>\n",
       "      <td>-0.465</td>\n",
       "      <td>97.955</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1.32</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341383</th>\n",
       "      <td>-0.080</td>\n",
       "      <td>0.540</td>\n",
       "      <td>-0.245</td>\n",
       "      <td>195.705</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.08</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341384</th>\n",
       "      <td>-0.560</td>\n",
       "      <td>0.055</td>\n",
       "      <td>-0.605</td>\n",
       "      <td>125.185</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.11</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>341385 rows × 156 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        open_lag0  high_lag0  low_lag0  close_lag0  spread_open_lag0  \\\n",
       "0          -0.545      0.205    -0.635     296.440              0.09   \n",
       "1          -0.200      0.040    -0.255      82.805              0.21   \n",
       "2           0.000      0.030    -0.040      90.855              0.07   \n",
       "3           0.100      0.140    -0.110      81.510              0.06   \n",
       "4           0.010      0.070    -0.045     234.230              0.26   \n",
       "...           ...        ...       ...         ...               ...   \n",
       "341380      0.035      0.165    -0.040      51.300              0.17   \n",
       "341381      0.890      0.965    -0.290     169.435              0.35   \n",
       "341382      0.105      0.235    -0.465      97.955              0.86   \n",
       "341383     -0.080      0.540    -0.245     195.705              0.75   \n",
       "341384     -0.560      0.055    -0.605     125.185              1.25   \n",
       "\n",
       "        spread_high_lag0  spread_low_lag0  spread_close_lag0  \\\n",
       "0                   0.20             0.01               0.06   \n",
       "1                   0.26             0.01               0.07   \n",
       "2                   0.10             0.01               0.09   \n",
       "3                   0.25             0.03               0.16   \n",
       "4                   0.30             0.11               0.18   \n",
       "...                  ...              ...                ...   \n",
       "341380              0.26             0.01               0.02   \n",
       "341381              1.41             0.01               0.93   \n",
       "341382              1.32             0.06               0.15   \n",
       "341383              1.08             0.01               0.07   \n",
       "341384              1.25             0.01               0.11   \n",
       "\n",
       "        bidsize_open_lag0  bidsize_high_lag0  ...  ticker_SO  ticker_SRE  \\\n",
       "0                     1.0               12.0  ...          0           0   \n",
       "1                     1.0                8.0  ...          0           0   \n",
       "2                     1.0                4.0  ...          0           0   \n",
       "3                     1.0                9.0  ...          0           0   \n",
       "4                     1.0                3.0  ...          0           0   \n",
       "...                   ...                ...  ...        ...         ...   \n",
       "341380                5.0               23.0  ...          0           0   \n",
       "341381                1.0               10.0  ...          0           0   \n",
       "341382                1.0                6.0  ...          0           0   \n",
       "341383                1.0                4.0  ...          0           0   \n",
       "341384                2.0                4.0  ...          0           0   \n",
       "\n",
       "        ticker_T  ticker_TM  ticker_TSLA  ticker_TSM  ticker_UNP  ticker_UPS  \\\n",
       "0              0          0            0           0           0           0   \n",
       "1              0          0            0           0           0           0   \n",
       "2              0          0            0           0           0           0   \n",
       "3              0          0            0           0           0           0   \n",
       "4              0          0            0           0           0           0   \n",
       "...          ...        ...          ...         ...         ...         ...   \n",
       "341380         0          0            0           1           0           0   \n",
       "341381         0          0            0           0           1           0   \n",
       "341382         0          0            0           0           0           1   \n",
       "341383         0          0            0           0           0           0   \n",
       "341384         0          0            0           0           0           0   \n",
       "\n",
       "        ticker_V  ticker_WMT  \n",
       "0              0           0  \n",
       "1              0           0  \n",
       "2              0           0  \n",
       "3              0           0  \n",
       "4              0           0  \n",
       "...          ...         ...  \n",
       "341380         0           0  \n",
       "341381         0           0  \n",
       "341382         0           0  \n",
       "341383         1           0  \n",
       "341384         0           1  \n",
       "\n",
       "[341385 rows x 156 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64),)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where((np.sum(np.isinf(X_train.values), axis=1) == 0) == False),\n",
    "np.where((np.sum(np.isnan(X_train.values), axis=1) == 0) == False)#X_train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{i:colname for i,colname in enumerate(train_ds.columns)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating one ppdict for individual preprocessings\n",
    "# ppdict1 = {'open':'minmax',\n",
    "#           'high':'log',\n",
    "#           'low':'log',\n",
    "#           'close':'std'}\n",
    "# splitpoint = 32\n",
    "\n",
    "# # Standardize some features\n",
    "# ppdict1 = {i:'std' for i in train_ds.columns[0:splitpoint]} \n",
    "# # Keep some in actual levels (Dummies in this case).\n",
    "# ppdict2 = {i:'act' for i in train_ds.columns[splitpoint:]}\n",
    "\n",
    "pre_procesing_applied = 'std'\n",
    "\n",
    "# Merging the two\n",
    "# ppdict = {**ppdict1,**ppdict2}\n",
    "\n",
    "if  pre_procesing_applied == 'None':\n",
    "    # do nothing here\n",
    "    pass\n",
    "\n",
    "elif  pre_procesing_applied == 'std':\n",
    "\n",
    "    # splitpoint = int((args.feature-lags+1)*16)#32\n",
    "    # columns_to_pre_process = [col for col in X_train.columns if 'd_' != col[0:2]]\n",
    "\n",
    "    # Standardize some features\n",
    "    ppdict1 = {i:'std' for i in X_train.columns if 'd_' != i[0:2]} \n",
    "    # Keep some in actual levels (Dummies in this case).\n",
    "    ppdict2 = {i:'act' for i in X_train.columns if 'd_' == i[0:2]} \n",
    "\n",
    "    # Merging the two\n",
    "    ppdict = {**ppdict1,**ppdict2}\n",
    "\n",
    "    # x_train,x_test = pre_processing(x_train,x_test,pp_dict)\n",
    "\n",
    "elif pre_procesing_applied == 'minmax':\n",
    "\n",
    "    # splitpoint = int((args.feature-lags+1)*16)#32\n",
    "    # columns_to_pre_process = [col for col in X_train.columns if 'd_' != col[0:2]]\n",
    "\n",
    "    # Standardize some features\n",
    "    ppdict1 = {i:'minmax' for i in X_train.columns if 'd_' != i[0:2]} \n",
    "    # Keep some in actual levels (Dummies in this case).\n",
    "    ppdict2 = {i:'act' for i in X_train.columns if 'd_' == i[0:2]} \n",
    "\n",
    "    # Merging the two\n",
    "    ppdict = {**ppdict1,**ppdict2}\n",
    "\n",
    "    # x_train,x_test = pre_processing(X_train,X_test,pp_dict)\n",
    "\n",
    "elif pre_procesing_applied == 'pow':\n",
    "\n",
    "    # splitpoint = int((args.feature-lags+1)*16)#32\n",
    "    # columns_to_pre_process = [col for col in X_train.columns if 'd_' != col[0:2]]\n",
    "\n",
    "    # Standardize some features\n",
    "    ppdict1 = {i:'pow' for i in X_train.columns if 'd_' != i[0:2]} \n",
    "    # Keep some in actual levels (Dummies in this case).\n",
    "    ppdict2 = {i:'act' for i in X_train.columns if 'd_' == i[0:2]} \n",
    "\n",
    "    # Merging the two\n",
    "    ppdict = {**ppdict1,**ppdict2}\n",
    "\n",
    "    # x_train,x_test = pre_processing(x_train,x_test,pp_dict)\n",
    "\n",
    "elif pre_procesing_applied == 'quantgau':\n",
    "\n",
    "    # splitpoint = int((args.feature-lags+1)*16)#32\n",
    "    # columns_to_pre_process = [col for col in X_train.columns if 'd_' != col[0:2]]\n",
    "\n",
    "    # Standardize some features\n",
    "    ppdict1 = {i:'quantgau' for i in X_train.columns if 'd_' != i[0:2]} \n",
    "    # Keep some in actual levels (Dummies in this case).\n",
    "    ppdict2 = {i:'act' for i in X_train.columns if 'd_' == i[0:2]} \n",
    "\n",
    "    # Merging the two\n",
    "    ppdict = {**ppdict1,**ppdict2}\n",
    "\n",
    "    # x_train,x_test = pre_processing(x_train,x_test,pp_dict)\n",
    "\n",
    "elif pre_procesing_applied == 'individual':\n",
    "\n",
    "    # splitpoint = int((args.feature-lags+1)*16)#32\n",
    "    # columns_to_pre_process = [col for col in X_train.columns if 'd_' != col[0:2]]\n",
    "\n",
    "    # Standardize some features\n",
    "    \n",
    "    # ppdict1 = {i:'power' for i in X_train.columns if 'd_' != i[0:2]}\n",
    "\n",
    "\n",
    "    # Keep some in actual levels (Dummies in this case).\n",
    "    ppdict2 = {i:'act' for i in X_train.columns if 'd_' == i[0:2]} \n",
    "\n",
    "    # Merging the two\n",
    "    ppdict = {**ppdict1,**ppdict2}\n",
    "\n",
    "    # x_train,x_test = pre_processing(x_train,x_test,pp_dict)\n",
    "\n",
    "elif pre_procesing_applied == 'stacked':\n",
    "\n",
    "    # splitpoint = int((args.feature-lags+1)*16)#32\n",
    "    # columns_to_pre_process = [col for col in X_train.columns if 'd_' != col[0:2]]\n",
    "\n",
    "    # Standardize some features\n",
    "    \n",
    "    for j in ['pow','std','minmax']:\n",
    "\n",
    "        ppdict1 = {i:j for i in X_train.columns if 'd_' != i[0:2]}\n",
    "\n",
    "        # Keep some in actual levels (Dummies in this case).\n",
    "        ppdict2 = {i:'act' for i in X_train.columns if 'd_' == i[0:2]} \n",
    "\n",
    "        # Merging the two\n",
    "        ppdict = {**ppdict1,**ppdict2}\n",
    "\n",
    "        X_train,X_test = pre_processing(X_train,X_test,ppdict)\n",
    "\n",
    "if pre_procesing_applied not in ['None','stacked']:\n",
    "    X_train,X_test = pre_processing(X_train,X_test,ppdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1.8927265537610815e-16, 1.000001457346533)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppX_train.iloc[:,0].mean(),ppX_train.iloc[:,0].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepping for models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(343090, 85800, 428890, 1340, 131, 670000)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_VALIDATION = val_y.shape[0] #int(1e3)\n",
    "N_TRAIN = train_y.shape[0] #int(1e4)\n",
    "# BUFFER_SIZE = int(1e4)\n",
    "BATCH_SIZE = 256 #512 #32\n",
    "MAX_EPOCHS = 500\n",
    "\n",
    "STEPS_PER_EPOCH = N_TRAIN//BATCH_SIZE\n",
    "\n",
    "N_REPEAT = int(N_TRAIN / ((STEPS_PER_EPOCH * MAX_EPOCHS) / BATCH_SIZE))\n",
    "FEATURES = X.shape[1]\n",
    "\n",
    "N_TRAIN, N_VALIDATION, N_TRAIN + N_VALIDATION, STEPS_PER_EPOCH, N_REPEAT, STEPS_PER_EPOCH * MAX_EPOCHS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Logistic Regression model in TF/Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 1)                 99        \n",
      "=================================================================\n",
      "Total params: 99\n",
      "Trainable params: 99\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:MainThread:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.390774). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0, accuracy:0.5352,  auc:0.5034,  loss:0.8996,  val_accuracy:0.5456,  val_auc:0.5453,  val_loss:0.6876,  \n",
      "....................................................................................................\n",
      "Epoch: 100, accuracy:0.5480,  auc:0.5440,  loss:0.6873,  val_accuracy:0.5454,  val_auc:0.5459,  val_loss:0.6879,  \n",
      "..................Restoring model weights from the end of the best epoch.\n",
      "Epoch 00118: early stopping\n"
     ]
    }
   ],
   "source": [
    "METRICS = [\n",
    "      #keras.metrics.TruePositives(name='tp'),\n",
    "      #keras.metrics.FalsePositives(name='fp'),\n",
    "      #keras.metrics.TrueNegatives(name='tn'),\n",
    "      #keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      #keras.metrics.Precision(name='precision'),\n",
    "      #keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "]\n",
    "\n",
    "# def make_model(metrics = METRICS, output_bias=None):\n",
    "#   if output_bias is not None:\n",
    "#     output_bias = tf.keras.initializers.Constant(output_bias)\n",
    "#   model = keras.Sequential([\n",
    "#       keras.layers.Dense(\n",
    "#           16, activation='relu',\n",
    "#           input_shape=(train_features.shape[-1],)),\n",
    "#       keras.layers.Dropout(0.5),\n",
    "#       keras.layers.Dense(1, activation='sigmoid',\n",
    "#                          bias_initializer=output_bias),\n",
    "#   ])\n",
    "\n",
    "#   model.compile(\n",
    "#       optimizer=keras.optimizers.Adam(lr=1e-3),\n",
    "#       loss=keras.losses.BinaryCrossentropy(),\n",
    "#       metrics=metrics)\n",
    "\n",
    "#   return model\n",
    "\n",
    "# model = keras.Sequential({\n",
    "#   keras.layers.Dense(1, input_shape=(FEATURES,))\n",
    "# })\n",
    "\n",
    "model = keras.Sequential([\n",
    "#     keras.layers.Flatten(input_shape=(28, 28)),\n",
    "#     keras.layers.Dense(128, activation='relu'),\n",
    "#     keras.layers.Dense(10)\n",
    "    keras.layers.Dense(1,\n",
    "                       input_shape=(FEATURES,),\n",
    "                       activation='sigmoid',\n",
    "                       kernel_regularizer=regularizers.l2(1))\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# with final activation (Keras/TF tutorial advises against this practice, but they also use it later in the tutorial)\n",
    "# model = keras.Sequential({\n",
    "#   keras.layers.Dense(1, input_shape=(FEATURES,), activation='sigmoid')\n",
    "# })\n",
    "\n",
    "#model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['binary_accuracy', ])\n",
    "model.compile(\n",
    "              optimizer=keras.optimizers.Adam(), #lr=1e-3\n",
    "              loss=keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "              metrics=METRICS)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "                                                monitor='val_auc', \n",
    "                                                verbose=1,\n",
    "                                                patience=100,\n",
    "                                                mode='max',\n",
    "                                                restore_best_weights=True)\n",
    "\n",
    "def get_callbacks(run_id):\n",
    "      return [\n",
    "             tfdocs.modeling.EpochDots(),\n",
    "             early_stopping,\n",
    "             tf.keras.callbacks.TensorBoard(logdir), #/run_id),\n",
    "      ]\n",
    "\n",
    "baseline_history = model.fit(\n",
    "                            train_ds, #train_features,\n",
    "                            train_y, #train_labels,\n",
    "                            batch_size=512, #BATCH_SIZE,\n",
    "                            epochs=1000, #EPOCHS,\n",
    "                            callbacks = get_callbacks(run_id = 'first'), #[early_stopping],\n",
    "                            validation_data=(validate_ds, val_y),\n",
    "                            verbose=0) #(val_features, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2682/2682 - 6s - loss: 0.6879 - accuracy: 0.5457 - auc: 0.5513\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6878659725189209, 0.5456876754760742, 0.5513222217559814]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(validate_ds,  val_y, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Timed out waiting for TensorBoard to start. It may still be running as pid 9296."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datetime\n",
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
