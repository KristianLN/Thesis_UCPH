{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\AppData\\Local\\Temp\\tmp5m_zptdz\\tensorboard_logs\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "import h5py\n",
    "import copy\n",
    "import datetime\n",
    "import ta\n",
    "import pathlib\n",
    "import shutil\n",
    "import tempfile\n",
    "#import vaex\n",
    "from IPython import display\n",
    "from IPython.display import clear_output\n",
    "import pyodbc\n",
    "\n",
    "# Tensorflow related\n",
    "# import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "\n",
    "# from tensorflow.keras import layers\n",
    "# from tensorflow.keras import regularizers\n",
    "# import tensorflow.compat.v2.feature_column as fc\n",
    "\n",
    "# #!pip install -q git+https://github.com/tensorflow/docs\n",
    "\n",
    "# import tensorflow_docs as tfdocs\n",
    "# import tensorflow_docs.modeling\n",
    "# import tensorflow_docs.plots\n",
    "\n",
    "#print(tf.__version__)\n",
    "logdir = pathlib.Path(tempfile.mkdtemp())/\"tensorboard_logs\"\n",
    "shutil.rmtree(logdir, ignore_errors=True)\n",
    "print(logdir)\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, f1_score, log_loss\n",
    "\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.exceptions import ConvergenceWarning \n",
    "from sklearn import ensemble\n",
    "# ConvergenceWarning('ignore')\n",
    "# Do you wanna see?\n",
    "verbose = True\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "#sys.path.append('...../')\n",
    "\n",
    "from utils.data_extraction import load_data_final,load_data_and_save\n",
    "from utils.data_cleaning import HFDataCleaning\n",
    "from utils.generate_features import candleCreateNP_vect_final,\\\n",
    "                                    generateFeatures_final,\\\n",
    "                                    generateFeatures_multi_final\n",
    "\n",
    "from utils.preprocessing_features_and_labels import extract_labels,\\\n",
    "                                                    align_features_and_labels,\\\n",
    "                                                    pre_processing_initial,\\\n",
    "                                                    pre_processing_extended,\\\n",
    "                                                    pre_processing_final,\\\n",
    "                                                    extract_labels_multi_final,\\\n",
    "                                                    align_features_and_labels_multi_final,\\\n",
    "                                                    align_features_and_labels_multi_v5\n",
    "\n",
    "# from utils.models import make_input_fn\n",
    "# from utils.models import performanceTesting,scoreFunction\n",
    "# from utils.plotting import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which one do you want to load? \n",
      "\n",
      "0: aggregateTAQ_May2020_10sec (1).csv\n",
      "1: aggregateTAQ_May2020_30sec (1).csv\n",
      "2: aggregateTAQ_May2020_60sec.csv\n",
      "8: trueAggregateTAQ_60sec.csv\n",
      "\n",
      "\n",
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (19) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>sector</th>\n",
       "      <th>exchange</th>\n",
       "      <th>marketCap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>Technology</td>\n",
       "      <td>NMS</td>\n",
       "      <td>1.578173e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ABBV</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>NYQ</td>\n",
       "      <td>1.742612e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>ABT</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>NYQ</td>\n",
       "      <td>1.631410e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>AEP</td>\n",
       "      <td>Utilities</td>\n",
       "      <td>NYQ</td>\n",
       "      <td>4.089551e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>AMT</td>\n",
       "      <td>Real Estate</td>\n",
       "      <td>NYQ</td>\n",
       "      <td>1.171259e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>APD</td>\n",
       "      <td>Basic Materials</td>\n",
       "      <td>NYQ</td>\n",
       "      <td>5.464395e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>BA</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>NYQ</td>\n",
       "      <td>1.020356e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>BABA</td>\n",
       "      <td>Consumer Cyclical</td>\n",
       "      <td>NYQ</td>\n",
       "      <td>5.936536e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>BAC</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>NYQ</td>\n",
       "      <td>2.020550e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>BHP</td>\n",
       "      <td>Basic Materials</td>\n",
       "      <td>NYQ</td>\n",
       "      <td>1.258194e+11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ticker              sector exchange     marketCap\n",
       "12    AAPL          Technology      NMS  1.578173e+12\n",
       "20    ABBV          Healthcare      NYQ  1.742612e+11\n",
       "34     ABT          Healthcare      NYQ  1.631410e+11\n",
       "126    AEP           Utilities      NYQ  4.089551e+10\n",
       "379    AMT         Real Estate      NYQ  1.171259e+11\n",
       "428    APD     Basic Materials      NYQ  5.464395e+10\n",
       "697     BA         Industrials      NYQ  1.020356e+11\n",
       "699   BABA   Consumer Cyclical      NYQ  5.936536e+11\n",
       "700    BAC  Financial Services      NYQ  2.020550e+11\n",
       "870    BHP     Basic Materials      NYQ  1.258194e+11"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do we extract new data or read in?\n",
    "readIn = True\n",
    "# run load_data()\n",
    "if readIn:\n",
    "    \n",
    "    # Listing the data files \n",
    "    path = '../../../Google Drev/Thesis/Data/TAQ/AggregatedTAQ'\n",
    "#     path = 'F:/AggregatedTAQ/round3'\n",
    "    datafiles = os.listdir(path)\n",
    "    content = np.concatenate([['\\n\\n'],[str(j)+': '+i+'\\n' for j,i in enumerate(datafiles) if 'csv' in i],['\\n\\n']])\n",
    "    \n",
    "    # Asking for user input\n",
    "    file = input('Which one do you want to load? %s'%''.join(content))\n",
    "    if int(file) <= 2:\n",
    "        data = pd.read_csv(path + '/' + datafiles[int(file)],\n",
    "                           header = None,\n",
    "                           names=['open','high','low','close',\n",
    "                                  'spread_open','spread_high','spread_low','spread_close',\n",
    "                                  'bidsize_open','bidsize_high','bidsize_low','bidsize_close',\n",
    "                                  'ofrsize_open','ofrsize_high','ofrsize_low','ofrsize_close',\n",
    "                                  'Ticker'])\n",
    "        # Using the choice of the user to determine the correct market file\n",
    "        key = re.split('[_.]',datafiles[int(file)])[-2]\n",
    "        marketDataFile = [file for file in os.listdir(path+'/round5_market_tickers') if key in file]\n",
    "\n",
    "        # Reading in the market data\n",
    "        tempData = pd.read_csv(path+'/round5_market_tickers/'+marketDataFile[0]\n",
    "                               ,header = None\n",
    "                               ,names=['open','high','low','close',\n",
    "                                      'spread_open','spread_high','spread_low','spread_close',\n",
    "                                      'bidsize_open','bidsize_high','bidsize_low','bidsize_close',\n",
    "                                      'ofrsize_open','ofrsize_high','ofrsize_low','ofrsize_close',\n",
    "                                      'Ticker'])\n",
    "        # Adding the market data to the ticker data\n",
    "        data = pd.concat([data,tempData],axis=0)\n",
    "    else:\n",
    "        data = pd.read_csv(path + '/' + datafiles[int(file)],\n",
    "                           header = 0,\n",
    "                           index_col=[0,1]\n",
    "#                            names=['open','high','low','close',\n",
    "#                                   'spread_open','spread_high','spread_low','spread_close',\n",
    "#                                   'bidsize_open','bidsize_high','bidsize_low','bidsize_close',\n",
    "#                                   'ofrsize_open','ofrsize_high','ofrsize_low','ofrsize_close',\n",
    "#                                   'Ticker']\n",
    "                          )\n",
    "    \n",
    "    # Lower casing all column names\n",
    "#     data.columns = data.columns.str.lower()\n",
    "else:\n",
    "    \n",
    "    # print(os.listdir())\n",
    "    try:\n",
    "        path = 'a:/taqhdf5'  #'a:/taqhdf5'\n",
    "        os.listdir(path)\n",
    "    except:\n",
    "        path = 't:/taqhdf5'  #'a:/taqhdf5'\n",
    "        os.listdir(path)\n",
    "        \n",
    "    # Sample type\n",
    "    data_sample = 'full' # or 'stable'\n",
    "    # allFiles = os.listdir(path)\n",
    "    # print(len(allFiles), allFiles[:5], allFiles[-5:])\n",
    "    # print(allFiles[-10:])\n",
    "\n",
    "    #dates = np.array(['2020040' + str(i) if i < 10 else '202004' + str(i) for i in np.arange(1,16)]).astype(int)\n",
    "    dates = np.array(['20200501']).astype(int)#,'20200402','20200403','20200406','20200407'\n",
    "\n",
    "    # Provide a list of tickers of interest\n",
    "    \n",
    "    tickers = sorted(['TSLA','FB'])#'MSFT'\n",
    "    \n",
    "    # Do we need data on trades, quotes or both?\n",
    "    dataNeeded = 'quotes' # 'trades', 'quotes' or 'both'\n",
    "    \n",
    "    if dataNeeded == 'trades':\n",
    "        tradeData = load_data_final(dates, tickers, dataNeeded, path, verbose)\n",
    "    elif dataNeeded == 'quotes':\n",
    "        quoteData = load_data_final(dates,\n",
    "                                    tickers,\n",
    "                                    dataNeeded,\n",
    "                                    path,\n",
    "                                    verbose,\n",
    "                                    extract_candles = False,\n",
    "                                    aggHorizon = 1,\n",
    "                                    extra_features_from_quotes = None,\n",
    "                                    data_sample = data_sample)\n",
    "    elif dataNeeded == 'both':\n",
    "        tradeData, quoteData = load_data_final(dates, tickers, dataNeeded, path, verbose)\n",
    "\n",
    "# Reading in sector information\n",
    "stockInfo = pd.read_csv('../utils/stockInfo_v1.csv',header=[0,1])\n",
    "stockInfo.columns = ['ticker','sector','exchange','marketCap']\n",
    "\n",
    "# Creating a table with stock information based on the tickers available in the data.\n",
    "uniqueTickers = data.Ticker.unique()\n",
    "stockTable = stockInfo[stockInfo.ticker.isin(uniqueTickers)]\n",
    "stockTable.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hyperparameters.txt',\n",
       " 'hyperparameters_lr_v1.txt',\n",
       " 'hyperparameters_lr_v2.txt',\n",
       " 'hyperparameters_lr_v3.txt',\n",
       " 'metrics.txt',\n",
       " 'metrics_lr_v1.txt',\n",
       " 'metrics_lr_v2.txt',\n",
       " 'metrics_lr_v3.txt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = os.listdir('../AzureML/Output_from_cloud')\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperfiles = [i for i in os.listdir('../AzureML/Output_from_cloud') if 'hyper' in i]\n",
    "metricfiles = [i for i in os.listdir('../AzureML/Output_from_cloud') if 'metric' in i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Reading in the file\n",
    "\n",
    "with open('../AzureML/Output_from_cloud/'+hyperfiles[0],'r') as file:\n",
    "    content = file.readlines()\n",
    "\n",
    "## Containers for the data\n",
    "all_ids = []\n",
    "all_parameters = []\n",
    "\n",
    "## Going over each line in the text file\n",
    "for a in np.arange(len(content)):\n",
    "    \n",
    "    ## Split the lines on tabs\n",
    "    temp_parameters = re.split('[\\t]',content[a])[1]\n",
    "    \n",
    "    ## Basic string cleaning, i.e. removing redundant characters\n",
    "    test = [re.split(': ',i.strip()) for i in re.split(',',temp_parameters.replace('{','')\\\n",
    "                                                                       .replace('}','')\\\n",
    "                                                                       .replace('\\n','')\\\n",
    "                                                                       .replace('\"',''))]\n",
    "    \n",
    "    ## Output of test is a list of lists, where each sublist holds the name of a model variable and its value.\n",
    "    ## We create a dictornary to hold all model variables, making it easy to add the observation to the dataframe.\n",
    "    test = {i[0]:i[1] for i in test}\n",
    "    \n",
    "    # Constructing the dataframe\n",
    "    if a == 0:\n",
    "        parameters = pd.DataFrame(test,index=[re.split('[\\t]',content[a])[0]])\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        parameters.loc[re.split('[\\t]',content[a])[0]] = pd.Series(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activation-inner</th>\n",
       "      <th>activation-output</th>\n",
       "      <th>batch-norm</th>\n",
       "      <th>batch-shuffle</th>\n",
       "      <th>batch-size</th>\n",
       "      <th>dropout-ratio</th>\n",
       "      <th>feature-lags</th>\n",
       "      <th>featureset</th>\n",
       "      <th>first-layer-neurons</th>\n",
       "      <th>label-type</th>\n",
       "      <th>learning-rate</th>\n",
       "      <th>n-epochs</th>\n",
       "      <th>n-layers</th>\n",
       "      <th>nn-type</th>\n",
       "      <th>pastobs-in-percentage</th>\n",
       "      <th>pre-processing</th>\n",
       "      <th>second-layer-neurons</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HD_81ace623-e09b-4393-8a5e-131ea8749a35_0</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>linear</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3300</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>150</td>\n",
       "      <td>3</td>\n",
       "      <td>ffnn</td>\n",
       "      <td>1</td>\n",
       "      <td>stacked</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD_81ace623-e09b-4393-8a5e-131ea8749a35_1</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>linear</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21450</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>150</td>\n",
       "      <td>3</td>\n",
       "      <td>ffnn</td>\n",
       "      <td>1</td>\n",
       "      <td>stacked</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD_81ace623-e09b-4393-8a5e-131ea8749a35_2</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>softmax</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3300</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>150</td>\n",
       "      <td>2</td>\n",
       "      <td>ffnn</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD_81ace623-e09b-4393-8a5e-131ea8749a35_3</th>\n",
       "      <td>tanh</td>\n",
       "      <td>linear</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10725</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>150</td>\n",
       "      <td>2</td>\n",
       "      <td>ffnn</td>\n",
       "      <td>0</td>\n",
       "      <td>quantgau</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD_81ace623-e09b-4393-8a5e-131ea8749a35_4</th>\n",
       "      <td>leakyrelu</td>\n",
       "      <td>linear</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21450</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>150</td>\n",
       "      <td>2</td>\n",
       "      <td>lstm</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD_81ace623-e09b-4393-8a5e-131ea8749a35_995</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>linear</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>21450</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>150</td>\n",
       "      <td>4</td>\n",
       "      <td>ffnn</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD_81ace623-e09b-4393-8a5e-131ea8749a35_996</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>softmax</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10725</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>150</td>\n",
       "      <td>4</td>\n",
       "      <td>ffnn</td>\n",
       "      <td>1</td>\n",
       "      <td>std</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD_81ace623-e09b-4393-8a5e-131ea8749a35_997</th>\n",
       "      <td>relu</td>\n",
       "      <td>linear</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10725</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>150</td>\n",
       "      <td>2</td>\n",
       "      <td>lstm</td>\n",
       "      <td>0</td>\n",
       "      <td>pow</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD_81ace623-e09b-4393-8a5e-131ea8749a35_998</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>softmax</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21450</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>150</td>\n",
       "      <td>2</td>\n",
       "      <td>lstm</td>\n",
       "      <td>0</td>\n",
       "      <td>stacked</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD_81ace623-e09b-4393-8a5e-131ea8749a35_999</th>\n",
       "      <td>tanh</td>\n",
       "      <td>softmax</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21450</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>150</td>\n",
       "      <td>4</td>\n",
       "      <td>lstm</td>\n",
       "      <td>1</td>\n",
       "      <td>quantgau</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            activation-inner  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_0            sigmoid   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_1            sigmoid   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_2            sigmoid   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_3               tanh   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_4          leakyrelu   \n",
       "...                                                      ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_995          sigmoid   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_996          sigmoid   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_997             relu   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_998          sigmoid   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999             tanh   \n",
       "\n",
       "                                            activation-output batch-norm  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_0              linear          0   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_1              linear          0   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_2             softmax          0   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_3              linear          0   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_4              linear          0   \n",
       "...                                                       ...        ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_995            linear          1   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_996           softmax          1   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_997            linear          1   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_998           softmax          0   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999           softmax          0   \n",
       "\n",
       "                                            batch-shuffle batch-size  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_0               1       3300   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_1               1      21450   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_2               0       3300   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_3               0      10725   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_4               1      21450   \n",
       "...                                                   ...        ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_995             0      21450   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_996             1      10725   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_997             1      10725   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_998             0      21450   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999             0      21450   \n",
       "\n",
       "                                            dropout-ratio feature-lags  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_0             0.1            3   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_1             0.1            1   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_2             0.4            0   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_3             0.5            0   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_4             0.4            1   \n",
       "...                                                   ...          ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_995           0.0            3   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_996           0.0            3   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_997           0.5            3   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_998           0.3            5   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999           0.2            0   \n",
       "\n",
       "                                            featureset first-layer-neurons  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_0            2                  32   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_1            1                  64   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_2            2                  32   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_3            1                  64   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_4            2                 128   \n",
       "...                                                ...                 ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_995          3                  64   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_996          0                  64   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_997          2                  64   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_998          3                 128   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999          1                 128   \n",
       "\n",
       "                                            label-type learning-rate n-epochs  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_0            0          0.01      150   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_1            1           0.1      150   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_2            4           0.1      150   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_3            0          0.01      150   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_4            0         0.001      150   \n",
       "...                                                ...           ...      ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_995          2        0.0001      150   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_996          1          0.01      150   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_997          3        0.0001      150   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_998          2         0.001      150   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999          1        0.0001      150   \n",
       "\n",
       "                                            n-layers nn-type  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_0          3    ffnn   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_1          3    ffnn   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_2          2    ffnn   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_3          2    ffnn   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_4          2    lstm   \n",
       "...                                              ...     ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_995        4    ffnn   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_996        4    ffnn   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_997        2    lstm   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_998        2    lstm   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999        4    lstm   \n",
       "\n",
       "                                            pastobs-in-percentage  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_0                       1   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_1                       1   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_2                       0   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_3                       0   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_4                       1   \n",
       "...                                                           ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_995                     0   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_996                     1   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_997                     0   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_998                     0   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999                     1   \n",
       "\n",
       "                                            pre-processing  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_0          stacked   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_1          stacked   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_2             None   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_3         quantgau   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_4             None   \n",
       "...                                                    ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_995           None   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_996            std   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_997            pow   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_998        stacked   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999       quantgau   \n",
       "\n",
       "                                            second-layer-neurons  \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_0                     64  \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_1                     64  \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_2                     64  \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_3                    128  \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_4                     64  \n",
       "...                                                          ...  \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_995                   64  \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_996                   64  \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_997                   64  \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_998                   64  \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999                   32  \n",
       "\n",
       "[1000 rows x 17 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Readidng in the file\n",
    "with open('../AzureML/Output_from_cloud/'+metricfiles[0],'r') as file:\n",
    "    content = file.readlines()\n",
    "\n",
    "## Containers\n",
    "t11 = []\n",
    "t12 = []\n",
    "t13 = []\n",
    "\n",
    "t21 = []\n",
    "t22 = []\n",
    "t23 = []\n",
    "\n",
    "## Going over each line\n",
    "for i in np.arange(len(content)):#\n",
    "    \n",
    "    ## Split each line on tabs\n",
    "    temp = re.split('\\t',content[i].replace('\\n',''))\n",
    "    \n",
    "    #print(temp)\n",
    "    \n",
    "    ## There are two types of observations in the text file; 1. final metrics of those models which where not stoppe early\n",
    "    ## and 2. a time series of a metric for each model.\n",
    "    \n",
    "    ## If the length of the last element, in a line, is less than 50 (because it is just a number, i.e. final metric)\n",
    "    ## It stored separately for the time series.\n",
    "    if len(temp[2]) < 50:\n",
    "\n",
    "        t11.append(temp[0])\n",
    "        t12.append(temp[1])\n",
    "        t13.append(temp[2])\n",
    "    \n",
    "    ## Time series\n",
    "    else:\n",
    "    \n",
    "        container = np.zeros(155)\n",
    "        temp1 = [float(j.strip()) if j.strip() !=\"'NaN'\" else 0 for j in re.split(',',temp[2].replace('[','').replace(']',''))]\n",
    "\n",
    "        container[0:len(temp1)] = temp1\n",
    "        container[len(temp1):] = temp1[-1]\n",
    "\n",
    "        t21.append(temp[0])\n",
    "        t22.append(temp[1])\n",
    "        t23.append(container)        \n",
    "\n",
    "## Storing the time series in a dataframe\n",
    "arrays = [t21,t22]\n",
    "tuples = list(zip(*arrays))\n",
    "\n",
    "runningMetrics = pd.DataFrame(np.array(t23),\n",
    "                              index=pd.MultiIndex.from_tuples(tuples),\n",
    "                              columns = [np.arange(155).astype(str)]\n",
    "                             )\n",
    "## Storing the final metrics in a dataframe.\n",
    "arrays = [t11,t12]\n",
    "tuples = list(zip(*arrays))\n",
    "finalMetrics = pd.DataFrame(t13,index = pd.MultiIndex.from_tuples(tuples),columns = ['size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">HD_81ace623-e09b-4393-8a5e-131ea8749a35_1</th>\n",
       "      <th>Final test loss</th>\n",
       "      <td>0.8833522492045336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Final test AUC</th>\n",
       "      <td>0.7648658156394958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Final test accuracy</th>\n",
       "      <td>0.6109746098518372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">HD_81ace623-e09b-4393-8a5e-131ea8749a35_3</th>\n",
       "      <th>Final test loss</th>\n",
       "      <td>1.1133369887535414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Final test AUC</th>\n",
       "      <td>0.640163779258728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">HD_81ace623-e09b-4393-8a5e-131ea8749a35_997</th>\n",
       "      <th>Final test AUC</th>\n",
       "      <td>0.7837895154953003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Final test accuracy</th>\n",
       "      <td>0.602816104888916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">HD_81ace623-e09b-4393-8a5e-131ea8749a35_998</th>\n",
       "      <th>Final test loss</th>\n",
       "      <td>1.3713646207894699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Final test AUC</th>\n",
       "      <td>0.7241190671920776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Final test accuracy</th>\n",
       "      <td>0.4148908853530884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1170 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                               size\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_1   Final test loss      0.8833522492045336\n",
       "                                            Final test AUC       0.7648658156394958\n",
       "                                            Final test accuracy  0.6109746098518372\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_3   Final test loss      1.1133369887535414\n",
       "                                            Final test AUC        0.640163779258728\n",
       "...                                                                             ...\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_997 Final test AUC       0.7837895154953003\n",
       "                                            Final test accuracy   0.602816104888916\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_998 Final test loss      1.3713646207894699\n",
       "                                            Final test AUC       0.7241190671920776\n",
       "                                            Final test accuracy  0.4148908853530884\n",
       "\n",
       "[1170 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "      <th>150</th>\n",
       "      <th>151</th>\n",
       "      <th>152</th>\n",
       "      <th>153</th>\n",
       "      <th>154</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">HD_81ace623-e09b-4393-8a5e-131ea8749a35_0</th>\n",
       "      <th>Loss</th>\n",
       "      <td>1.098537</td>\n",
       "      <td>1.098504</td>\n",
       "      <td>1.098467</td>\n",
       "      <td>1.098423</td>\n",
       "      <td>1.098371</td>\n",
       "      <td>1.098309</td>\n",
       "      <td>1.098233</td>\n",
       "      <td>1.098140</td>\n",
       "      <td>1.098026</td>\n",
       "      <td>1.097886</td>\n",
       "      <td>...</td>\n",
       "      <td>1.066601</td>\n",
       "      <td>1.066601</td>\n",
       "      <td>1.066601</td>\n",
       "      <td>1.066601</td>\n",
       "      <td>1.066601</td>\n",
       "      <td>1.066601</td>\n",
       "      <td>1.066601</td>\n",
       "      <td>1.066601</td>\n",
       "      <td>1.066601</td>\n",
       "      <td>1.066601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.354843</td>\n",
       "      <td>0.358482</td>\n",
       "      <td>0.362843</td>\n",
       "      <td>0.365199</td>\n",
       "      <td>0.366960</td>\n",
       "      <td>0.367240</td>\n",
       "      <td>0.368826</td>\n",
       "      <td>0.370377</td>\n",
       "      <td>0.371579</td>\n",
       "      <td>0.372220</td>\n",
       "      <td>...</td>\n",
       "      <td>0.412316</td>\n",
       "      <td>0.412316</td>\n",
       "      <td>0.412316</td>\n",
       "      <td>0.412316</td>\n",
       "      <td>0.412316</td>\n",
       "      <td>0.412316</td>\n",
       "      <td>0.412316</td>\n",
       "      <td>0.412316</td>\n",
       "      <td>0.412316</td>\n",
       "      <td>0.412316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC</th>\n",
       "      <td>0.500120</td>\n",
       "      <td>0.500277</td>\n",
       "      <td>0.500545</td>\n",
       "      <td>0.501018</td>\n",
       "      <td>0.501737</td>\n",
       "      <td>0.502806</td>\n",
       "      <td>0.504301</td>\n",
       "      <td>0.506150</td>\n",
       "      <td>0.508213</td>\n",
       "      <td>0.510308</td>\n",
       "      <td>...</td>\n",
       "      <td>0.575838</td>\n",
       "      <td>0.575838</td>\n",
       "      <td>0.575838</td>\n",
       "      <td>0.575838</td>\n",
       "      <td>0.575838</td>\n",
       "      <td>0.575838</td>\n",
       "      <td>0.575838</td>\n",
       "      <td>0.575838</td>\n",
       "      <td>0.575838</td>\n",
       "      <td>0.575838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Loss</th>\n",
       "      <td>1.098558</td>\n",
       "      <td>1.098524</td>\n",
       "      <td>1.098487</td>\n",
       "      <td>1.098442</td>\n",
       "      <td>1.098396</td>\n",
       "      <td>1.098339</td>\n",
       "      <td>1.098267</td>\n",
       "      <td>1.098180</td>\n",
       "      <td>1.098077</td>\n",
       "      <td>1.097955</td>\n",
       "      <td>...</td>\n",
       "      <td>1.068791</td>\n",
       "      <td>1.068791</td>\n",
       "      <td>1.068791</td>\n",
       "      <td>1.068791</td>\n",
       "      <td>1.068791</td>\n",
       "      <td>1.068791</td>\n",
       "      <td>1.068791</td>\n",
       "      <td>1.068791</td>\n",
       "      <td>1.068791</td>\n",
       "      <td>1.068791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Accuracy</th>\n",
       "      <td>0.344181</td>\n",
       "      <td>0.350251</td>\n",
       "      <td>0.353537</td>\n",
       "      <td>0.358348</td>\n",
       "      <td>0.360740</td>\n",
       "      <td>0.363537</td>\n",
       "      <td>0.365985</td>\n",
       "      <td>0.368336</td>\n",
       "      <td>0.368998</td>\n",
       "      <td>0.369959</td>\n",
       "      <td>...</td>\n",
       "      <td>0.412060</td>\n",
       "      <td>0.412060</td>\n",
       "      <td>0.412060</td>\n",
       "      <td>0.412060</td>\n",
       "      <td>0.412060</td>\n",
       "      <td>0.412060</td>\n",
       "      <td>0.412060</td>\n",
       "      <td>0.412060</td>\n",
       "      <td>0.412060</td>\n",
       "      <td>0.412060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">HD_81ace623-e09b-4393-8a5e-131ea8749a35_999</th>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>...</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC</th>\n",
       "      <td>0.006679</td>\n",
       "      <td>0.003153</td>\n",
       "      <td>0.002064</td>\n",
       "      <td>0.001534</td>\n",
       "      <td>0.001221</td>\n",
       "      <td>0.001014</td>\n",
       "      <td>0.000867</td>\n",
       "      <td>0.000757</td>\n",
       "      <td>0.000672</td>\n",
       "      <td>0.000604</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.000113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Loss</th>\n",
       "      <td>5.383223</td>\n",
       "      <td>5.355752</td>\n",
       "      <td>5.355751</td>\n",
       "      <td>5.355751</td>\n",
       "      <td>5.355751</td>\n",
       "      <td>5.355750</td>\n",
       "      <td>5.355750</td>\n",
       "      <td>5.355750</td>\n",
       "      <td>5.355750</td>\n",
       "      <td>5.355750</td>\n",
       "      <td>...</td>\n",
       "      <td>5.355750</td>\n",
       "      <td>5.355750</td>\n",
       "      <td>5.355750</td>\n",
       "      <td>5.355750</td>\n",
       "      <td>5.355750</td>\n",
       "      <td>5.355750</td>\n",
       "      <td>5.355750</td>\n",
       "      <td>5.355750</td>\n",
       "      <td>5.355750</td>\n",
       "      <td>5.355750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Accuracy</th>\n",
       "      <td>0.333057</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>...</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>0.332281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train AUC</th>\n",
       "      <td>0.030584</td>\n",
       "      <td>0.004384</td>\n",
       "      <td>0.002511</td>\n",
       "      <td>0.001766</td>\n",
       "      <td>0.001362</td>\n",
       "      <td>0.001109</td>\n",
       "      <td>0.000935</td>\n",
       "      <td>0.000809</td>\n",
       "      <td>0.000712</td>\n",
       "      <td>0.000636</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6000 rows × 155 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   0  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_0   Loss            1.098537   \n",
       "                                            Accuracy        0.354843   \n",
       "                                            AUC             0.500120   \n",
       "                                            Train Loss      1.098558   \n",
       "                                            Train Accuracy  0.344181   \n",
       "...                                                              ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999 Accuracy        0.337729   \n",
       "                                            AUC             0.006679   \n",
       "                                            Train Loss      5.383223   \n",
       "                                            Train Accuracy  0.333057   \n",
       "                                            Train AUC       0.030584   \n",
       "\n",
       "                                                                   1  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_0   Loss            1.098504   \n",
       "                                            Accuracy        0.358482   \n",
       "                                            AUC             0.500277   \n",
       "                                            Train Loss      1.098524   \n",
       "                                            Train Accuracy  0.350251   \n",
       "...                                                              ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999 Accuracy        0.337729   \n",
       "                                            AUC             0.003153   \n",
       "                                            Train Loss      5.355752   \n",
       "                                            Train Accuracy  0.332281   \n",
       "                                            Train AUC       0.004384   \n",
       "\n",
       "                                                                   2  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_0   Loss            1.098467   \n",
       "                                            Accuracy        0.362843   \n",
       "                                            AUC             0.500545   \n",
       "                                            Train Loss      1.098487   \n",
       "                                            Train Accuracy  0.353537   \n",
       "...                                                              ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999 Accuracy        0.337729   \n",
       "                                            AUC             0.002064   \n",
       "                                            Train Loss      5.355751   \n",
       "                                            Train Accuracy  0.332281   \n",
       "                                            Train AUC       0.002511   \n",
       "\n",
       "                                                                   3  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_0   Loss            1.098423   \n",
       "                                            Accuracy        0.365199   \n",
       "                                            AUC             0.501018   \n",
       "                                            Train Loss      1.098442   \n",
       "                                            Train Accuracy  0.358348   \n",
       "...                                                              ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999 Accuracy        0.337729   \n",
       "                                            AUC             0.001534   \n",
       "                                            Train Loss      5.355751   \n",
       "                                            Train Accuracy  0.332281   \n",
       "                                            Train AUC       0.001766   \n",
       "\n",
       "                                                                   4  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_0   Loss            1.098371   \n",
       "                                            Accuracy        0.366960   \n",
       "                                            AUC             0.501737   \n",
       "                                            Train Loss      1.098396   \n",
       "                                            Train Accuracy  0.360740   \n",
       "...                                                              ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999 Accuracy        0.337729   \n",
       "                                            AUC             0.001221   \n",
       "                                            Train Loss      5.355751   \n",
       "                                            Train Accuracy  0.332281   \n",
       "                                            Train AUC       0.001362   \n",
       "\n",
       "                                                                   5  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_0   Loss            1.098309   \n",
       "                                            Accuracy        0.367240   \n",
       "                                            AUC             0.502806   \n",
       "                                            Train Loss      1.098339   \n",
       "                                            Train Accuracy  0.363537   \n",
       "...                                                              ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999 Accuracy        0.337729   \n",
       "                                            AUC             0.001014   \n",
       "                                            Train Loss      5.355750   \n",
       "                                            Train Accuracy  0.332281   \n",
       "                                            Train AUC       0.001109   \n",
       "\n",
       "                                                                   6  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_0   Loss            1.098233   \n",
       "                                            Accuracy        0.368826   \n",
       "                                            AUC             0.504301   \n",
       "                                            Train Loss      1.098267   \n",
       "                                            Train Accuracy  0.365985   \n",
       "...                                                              ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999 Accuracy        0.337729   \n",
       "                                            AUC             0.000867   \n",
       "                                            Train Loss      5.355750   \n",
       "                                            Train Accuracy  0.332281   \n",
       "                                            Train AUC       0.000935   \n",
       "\n",
       "                                                                   7  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_0   Loss            1.098140   \n",
       "                                            Accuracy        0.370377   \n",
       "                                            AUC             0.506150   \n",
       "                                            Train Loss      1.098180   \n",
       "                                            Train Accuracy  0.368336   \n",
       "...                                                              ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999 Accuracy        0.337729   \n",
       "                                            AUC             0.000757   \n",
       "                                            Train Loss      5.355750   \n",
       "                                            Train Accuracy  0.332281   \n",
       "                                            Train AUC       0.000809   \n",
       "\n",
       "                                                                   8  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_0   Loss            1.098026   \n",
       "                                            Accuracy        0.371579   \n",
       "                                            AUC             0.508213   \n",
       "                                            Train Loss      1.098077   \n",
       "                                            Train Accuracy  0.368998   \n",
       "...                                                              ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999 Accuracy        0.337729   \n",
       "                                            AUC             0.000672   \n",
       "                                            Train Loss      5.355750   \n",
       "                                            Train Accuracy  0.332281   \n",
       "                                            Train AUC       0.000712   \n",
       "\n",
       "                                                                   9  ...  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_0   Loss            1.097886  ...   \n",
       "                                            Accuracy        0.372220  ...   \n",
       "                                            AUC             0.510308  ...   \n",
       "                                            Train Loss      1.097955  ...   \n",
       "                                            Train Accuracy  0.369959  ...   \n",
       "...                                                              ...  ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999 Accuracy        0.337729  ...   \n",
       "                                            AUC             0.000604  ...   \n",
       "                                            Train Loss      5.355750  ...   \n",
       "                                            Train Accuracy  0.332281  ...   \n",
       "                                            Train AUC       0.000636  ...   \n",
       "\n",
       "                                                                 145  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_0   Loss            1.066601   \n",
       "                                            Accuracy        0.412316   \n",
       "                                            AUC             0.575838   \n",
       "                                            Train Loss      1.068791   \n",
       "                                            Train Accuracy  0.412060   \n",
       "...                                                              ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999 Accuracy        0.337729   \n",
       "                                            AUC             0.000113   \n",
       "                                            Train Loss      5.355750   \n",
       "                                            Train Accuracy  0.332281   \n",
       "                                            Train AUC       0.000114   \n",
       "\n",
       "                                                                 146  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_0   Loss            1.066601   \n",
       "                                            Accuracy        0.412316   \n",
       "                                            AUC             0.575838   \n",
       "                                            Train Loss      1.068791   \n",
       "                                            Train Accuracy  0.412060   \n",
       "...                                                              ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999 Accuracy        0.337729   \n",
       "                                            AUC             0.000113   \n",
       "                                            Train Loss      5.355750   \n",
       "                                            Train Accuracy  0.332281   \n",
       "                                            Train AUC       0.000114   \n",
       "\n",
       "                                                                 147  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_0   Loss            1.066601   \n",
       "                                            Accuracy        0.412316   \n",
       "                                            AUC             0.575838   \n",
       "                                            Train Loss      1.068791   \n",
       "                                            Train Accuracy  0.412060   \n",
       "...                                                              ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999 Accuracy        0.337729   \n",
       "                                            AUC             0.000113   \n",
       "                                            Train Loss      5.355750   \n",
       "                                            Train Accuracy  0.332281   \n",
       "                                            Train AUC       0.000114   \n",
       "\n",
       "                                                                 148  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_0   Loss            1.066601   \n",
       "                                            Accuracy        0.412316   \n",
       "                                            AUC             0.575838   \n",
       "                                            Train Loss      1.068791   \n",
       "                                            Train Accuracy  0.412060   \n",
       "...                                                              ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999 Accuracy        0.337729   \n",
       "                                            AUC             0.000113   \n",
       "                                            Train Loss      5.355750   \n",
       "                                            Train Accuracy  0.332281   \n",
       "                                            Train AUC       0.000114   \n",
       "\n",
       "                                                                 149  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_0   Loss            1.066601   \n",
       "                                            Accuracy        0.412316   \n",
       "                                            AUC             0.575838   \n",
       "                                            Train Loss      1.068791   \n",
       "                                            Train Accuracy  0.412060   \n",
       "...                                                              ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999 Accuracy        0.337729   \n",
       "                                            AUC             0.000113   \n",
       "                                            Train Loss      5.355750   \n",
       "                                            Train Accuracy  0.332281   \n",
       "                                            Train AUC       0.000114   \n",
       "\n",
       "                                                                 150  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_0   Loss            1.066601   \n",
       "                                            Accuracy        0.412316   \n",
       "                                            AUC             0.575838   \n",
       "                                            Train Loss      1.068791   \n",
       "                                            Train Accuracy  0.412060   \n",
       "...                                                              ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999 Accuracy        0.337729   \n",
       "                                            AUC             0.000113   \n",
       "                                            Train Loss      5.355750   \n",
       "                                            Train Accuracy  0.332281   \n",
       "                                            Train AUC       0.000114   \n",
       "\n",
       "                                                                 151  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_0   Loss            1.066601   \n",
       "                                            Accuracy        0.412316   \n",
       "                                            AUC             0.575838   \n",
       "                                            Train Loss      1.068791   \n",
       "                                            Train Accuracy  0.412060   \n",
       "...                                                              ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999 Accuracy        0.337729   \n",
       "                                            AUC             0.000113   \n",
       "                                            Train Loss      5.355750   \n",
       "                                            Train Accuracy  0.332281   \n",
       "                                            Train AUC       0.000114   \n",
       "\n",
       "                                                                 152  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_0   Loss            1.066601   \n",
       "                                            Accuracy        0.412316   \n",
       "                                            AUC             0.575838   \n",
       "                                            Train Loss      1.068791   \n",
       "                                            Train Accuracy  0.412060   \n",
       "...                                                              ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999 Accuracy        0.337729   \n",
       "                                            AUC             0.000113   \n",
       "                                            Train Loss      5.355750   \n",
       "                                            Train Accuracy  0.332281   \n",
       "                                            Train AUC       0.000114   \n",
       "\n",
       "                                                                 153       154  \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_0   Loss            1.066601  1.066601  \n",
       "                                            Accuracy        0.412316  0.412316  \n",
       "                                            AUC             0.575838  0.575838  \n",
       "                                            Train Loss      1.068791  1.068791  \n",
       "                                            Train Accuracy  0.412060  0.412060  \n",
       "...                                                              ...       ...  \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999 Accuracy        0.337729  0.337729  \n",
       "                                            AUC             0.000113  0.000113  \n",
       "                                            Train Loss      5.355750  5.355750  \n",
       "                                            Train Accuracy  0.332281  0.332281  \n",
       "                                            Train AUC       0.000114  0.000114  \n",
       "\n",
       "[6000 rows x 155 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runningMetrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attaching the last observation of each model, for each metric, to the parameters of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>activation-inner</th>\n",
       "      <th>activation-output</th>\n",
       "      <th>batch-norm</th>\n",
       "      <th>batch-shuffle</th>\n",
       "      <th>batch-size</th>\n",
       "      <th>dropout-ratio</th>\n",
       "      <th>feature-lags</th>\n",
       "      <th>featureset</th>\n",
       "      <th>first-layer-neurons</th>\n",
       "      <th>...</th>\n",
       "      <th>pastobs-in-percentage</th>\n",
       "      <th>pre-processing</th>\n",
       "      <th>second-layer-neurons</th>\n",
       "      <th>id</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Train AUC</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Train Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_115</td>\n",
       "      <td>relu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3300</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>quantgau</td>\n",
       "      <td>128</td>\n",
       "      <td>115</td>\n",
       "      <td>0.80363</td>\n",
       "      <td>0.58075</td>\n",
       "      <td>0.98257</td>\n",
       "      <td>0.80358</td>\n",
       "      <td>0.66548</td>\n",
       "      <td>0.77074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_781</td>\n",
       "      <td>tanh</td>\n",
       "      <td>linear</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>21450</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>minmax</td>\n",
       "      <td>32</td>\n",
       "      <td>781</td>\n",
       "      <td>0.79064</td>\n",
       "      <td>0.57710</td>\n",
       "      <td>0.99908</td>\n",
       "      <td>0.79060</td>\n",
       "      <td>0.65135</td>\n",
       "      <td>0.80627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_997</td>\n",
       "      <td>relu</td>\n",
       "      <td>linear</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10725</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>pow</td>\n",
       "      <td>64</td>\n",
       "      <td>997</td>\n",
       "      <td>0.78380</td>\n",
       "      <td>0.60282</td>\n",
       "      <td>0.90322</td>\n",
       "      <td>0.78376</td>\n",
       "      <td>0.62677</td>\n",
       "      <td>0.84667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_928</td>\n",
       "      <td>relu</td>\n",
       "      <td>linear</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21450</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>std</td>\n",
       "      <td>32</td>\n",
       "      <td>928</td>\n",
       "      <td>0.78185</td>\n",
       "      <td>0.61228</td>\n",
       "      <td>0.89609</td>\n",
       "      <td>0.78181</td>\n",
       "      <td>0.62734</td>\n",
       "      <td>0.84895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_128</td>\n",
       "      <td>tanh</td>\n",
       "      <td>linear</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>21450</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>0.78175</td>\n",
       "      <td>0.60582</td>\n",
       "      <td>0.92492</td>\n",
       "      <td>0.78172</td>\n",
       "      <td>0.62636</td>\n",
       "      <td>0.85098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_814</td>\n",
       "      <td>tanh</td>\n",
       "      <td>linear</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3300</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>32</td>\n",
       "      <td>814</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.19641</td>\n",
       "      <td>0.94736</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.19952</td>\n",
       "      <td>0.95143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_304</td>\n",
       "      <td>leakyrelu</td>\n",
       "      <td>linear</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10725</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>minmax</td>\n",
       "      <td>32</td>\n",
       "      <td>304</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.19329</td>\n",
       "      <td>0.89643</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.18706</td>\n",
       "      <td>0.91432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_195</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>linear</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10725</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>128</td>\n",
       "      <td>195</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.45457</td>\n",
       "      <td>0.68465</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.45333</td>\n",
       "      <td>0.68717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_861</td>\n",
       "      <td>relu</td>\n",
       "      <td>linear</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3300</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>128</td>\n",
       "      <td>861</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.16547</td>\n",
       "      <td>1.59072</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.17433</td>\n",
       "      <td>1.59977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_321</td>\n",
       "      <td>leakyrelu</td>\n",
       "      <td>linear</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>std</td>\n",
       "      <td>64</td>\n",
       "      <td>321</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.19750</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.19989</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          run_id activation-inner  \\\n",
       "115  HD_81ace623-e09b-4393-8a5e-131ea8749a35_115             relu   \n",
       "781  HD_81ace623-e09b-4393-8a5e-131ea8749a35_781             tanh   \n",
       "997  HD_81ace623-e09b-4393-8a5e-131ea8749a35_997             relu   \n",
       "928  HD_81ace623-e09b-4393-8a5e-131ea8749a35_928             relu   \n",
       "128  HD_81ace623-e09b-4393-8a5e-131ea8749a35_128             tanh   \n",
       "..                                           ...              ...   \n",
       "814  HD_81ace623-e09b-4393-8a5e-131ea8749a35_814             tanh   \n",
       "304  HD_81ace623-e09b-4393-8a5e-131ea8749a35_304        leakyrelu   \n",
       "195  HD_81ace623-e09b-4393-8a5e-131ea8749a35_195          sigmoid   \n",
       "861  HD_81ace623-e09b-4393-8a5e-131ea8749a35_861             relu   \n",
       "321  HD_81ace623-e09b-4393-8a5e-131ea8749a35_321        leakyrelu   \n",
       "\n",
       "    activation-output batch-norm batch-shuffle batch-size dropout-ratio  \\\n",
       "115           softmax          1             0       3300           0.2   \n",
       "781            linear          1             1      21450           0.3   \n",
       "997            linear          1             1      10725           0.5   \n",
       "928            linear          0             1      21450           0.4   \n",
       "128            linear          1             1      21450           0.3   \n",
       "..                ...        ...           ...        ...           ...   \n",
       "814            linear          0             0       3300           0.1   \n",
       "304            linear          0             1      10725           0.1   \n",
       "195            linear          1             1      10725           0.5   \n",
       "861            linear          1             1       3300           0.2   \n",
       "321            linear          0             0       3300           0.0   \n",
       "\n",
       "    feature-lags featureset first-layer-neurons  ... pastobs-in-percentage  \\\n",
       "115            1          3                 128  ...                     1   \n",
       "781            3          0                  64  ...                     1   \n",
       "997            3          2                  64  ...                     0   \n",
       "928            1          0                  64  ...                     0   \n",
       "128            0          2                  64  ...                     1   \n",
       "..           ...        ...                 ...  ...                   ...   \n",
       "814            5          2                  32  ...                     1   \n",
       "304            0          1                  32  ...                     1   \n",
       "195            5          3                  64  ...                     0   \n",
       "861            1          0                 128  ...                     1   \n",
       "321            5          0                  32  ...                     0   \n",
       "\n",
       "    pre-processing second-layer-neurons   id      AUC Accuracy     Loss  \\\n",
       "115       quantgau                  128  115  0.80363  0.58075  0.98257   \n",
       "781         minmax                   32  781  0.79064  0.57710  0.99908   \n",
       "997            pow                   64  997  0.78380  0.60282  0.90322   \n",
       "928            std                   32  928  0.78185  0.61228  0.89609   \n",
       "128           None                  128  128  0.78175  0.60582  0.92492   \n",
       "..             ...                  ...  ...      ...      ...      ...   \n",
       "814           None                   32  814  0.00000  0.19641  0.94736   \n",
       "304         minmax                   32  304  0.00000  0.19329  0.89643   \n",
       "195           None                  128  195  0.00000  0.45457  0.68465   \n",
       "861           None                  128  861  0.00000  0.16547  1.59072   \n",
       "321            std                   64  321  0.00000  0.19750  0.00000   \n",
       "\n",
       "    Train AUC Train Accuracy  Train Loss  \n",
       "115   0.80358        0.66548     0.77074  \n",
       "781   0.79060        0.65135     0.80627  \n",
       "997   0.78376        0.62677     0.84667  \n",
       "928   0.78181        0.62734     0.84895  \n",
       "128   0.78172        0.62636     0.85098  \n",
       "..        ...            ...         ...  \n",
       "814   0.00000        0.19952     0.95143  \n",
       "304   0.00000        0.18706     0.91432  \n",
       "195   0.00000        0.45333     0.68717  \n",
       "861   0.00000        0.17433     1.59977  \n",
       "321   0.00000        0.19989     0.00000  \n",
       "\n",
       "[1000 rows x 25 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Resetting indcies and rename columns\n",
    "runningMetrics = runningMetrics.reset_index().rename(columns={'level_0':'run_id','level_1':'metric'})\n",
    "runningMetrics.columns = runningMetrics.columns.get_level_values(0)\n",
    "\n",
    "## Adding a column of short ids, to merge on.\n",
    "runningMetrics['id'] = [re.split('_',i)[-1] for i in runningMetrics.run_id]\n",
    "\n",
    "## Creating a table, having the short id in the rows and the last observation for each metric in the columns. \n",
    "table = pd.pivot_table(runningMetrics[['run_id','metric','154','id']],index='id',columns=['metric'])\n",
    "table.columns = table.columns.get_level_values(1)\n",
    "table = table.round(5).reset_index()\n",
    "\n",
    "## Preparing the parameter dataframe.\n",
    "parameters = parameters.reset_index().rename(columns={'index':'run_id'})\n",
    "\n",
    "## Setting short ID\n",
    "parameters['id'] = [re.split('_',i)[-1] for i in parameters.run_id]\n",
    "\n",
    "## Creating the combined table\n",
    "combined_table = parameters.merge(table,\n",
    "                                     on = 'id',\n",
    "                                     how='left').sort_values('AUC',ascending=False)\n",
    "combined_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1e0b43d1488>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "runningMetrics[(runningMetrics.metric=='Accuracy')&\\\n",
    "               (np.isin(runningMetrics.id,parameters[parameters['label-type']=='2'].id.values))].sort_values('154')['154'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating a top-X table for each label-type of a given metric, here AUC.\n",
    "temp_auc = pd.pivot_table(combined_table[['label-type','AUC','id']],index='id',columns='label-type')\n",
    "temp_acc = pd.pivot_table(combined_table[['label-type','Accuracy','id']],index='id',columns='label-type')\n",
    "\n",
    "## Final output - AUC\n",
    "final_output_auc = pd.DataFrame(np.sort(temp_auc.fillna(0).values,\n",
    "                             axis=0)[::-1],\n",
    "                             columns=temp_auc.columns.get_level_values(1)).loc[0:10]\n",
    "## Final output - Accuracy\n",
    "final_output_acc = pd.DataFrame(np.sort(temp_acc.fillna(0).values,\n",
    "                             axis=0)[::-1],\n",
    "                             columns=temp_acc.columns.get_level_values(1))#.loc[0:10]\n",
    "# final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['run_id',\n",
       " 'activation-inner',\n",
       " 'activation-output',\n",
       " 'batch-norm',\n",
       " 'batch-shuffle',\n",
       " 'batch-size',\n",
       " 'dropout-ratio',\n",
       " 'feature-lags',\n",
       " 'featureset',\n",
       " 'first-layer-neurons',\n",
       " 'label-type',\n",
       " 'learning-rate',\n",
       " 'n-epochs',\n",
       " 'n-layers',\n",
       " 'nn-type',\n",
       " 'pastobs-in-percentage',\n",
       " 'pre-processing',\n",
       " 'second-layer-neurons',\n",
       " 'id',\n",
       " 'AUC',\n",
       " 'Accuracy',\n",
       " 'Loss',\n",
       " 'Train AUC',\n",
       " 'Train Accuracy',\n",
       " 'Train Loss']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(combined_table.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>activation-inner</th>\n",
       "      <th>activation-output</th>\n",
       "      <th>batch-norm</th>\n",
       "      <th>batch-shuffle</th>\n",
       "      <th>batch-size</th>\n",
       "      <th>dropout-ratio</th>\n",
       "      <th>feature-lags</th>\n",
       "      <th>featureset</th>\n",
       "      <th>first-layer-neurons</th>\n",
       "      <th>...</th>\n",
       "      <th>pastobs-in-percentage</th>\n",
       "      <th>pre-processing</th>\n",
       "      <th>second-layer-neurons</th>\n",
       "      <th>id</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Train AUC</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Train Loss</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label-type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_115</td>\n",
       "      <td>relu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3300</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>quantgau</td>\n",
       "      <td>128</td>\n",
       "      <td>115</td>\n",
       "      <td>0.80363</td>\n",
       "      <td>0.58075</td>\n",
       "      <td>0.98257</td>\n",
       "      <td>0.80358</td>\n",
       "      <td>0.66548</td>\n",
       "      <td>0.77074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_781</td>\n",
       "      <td>tanh</td>\n",
       "      <td>linear</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>21450</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>minmax</td>\n",
       "      <td>32</td>\n",
       "      <td>781</td>\n",
       "      <td>0.79064</td>\n",
       "      <td>0.57710</td>\n",
       "      <td>0.99908</td>\n",
       "      <td>0.79060</td>\n",
       "      <td>0.65135</td>\n",
       "      <td>0.80627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_997</td>\n",
       "      <td>relu</td>\n",
       "      <td>linear</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10725</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>pow</td>\n",
       "      <td>64</td>\n",
       "      <td>997</td>\n",
       "      <td>0.78380</td>\n",
       "      <td>0.60282</td>\n",
       "      <td>0.90322</td>\n",
       "      <td>0.78376</td>\n",
       "      <td>0.62677</td>\n",
       "      <td>0.84667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_338</td>\n",
       "      <td>relu</td>\n",
       "      <td>linear</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21450</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>quantgau</td>\n",
       "      <td>64</td>\n",
       "      <td>338</td>\n",
       "      <td>0.78078</td>\n",
       "      <td>0.60986</td>\n",
       "      <td>0.88815</td>\n",
       "      <td>0.78075</td>\n",
       "      <td>0.62015</td>\n",
       "      <td>0.86651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_537</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>linear</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10725</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>quantgau</td>\n",
       "      <td>32</td>\n",
       "      <td>537</td>\n",
       "      <td>0.77684</td>\n",
       "      <td>0.60628</td>\n",
       "      <td>0.89268</td>\n",
       "      <td>0.77681</td>\n",
       "      <td>0.61488</td>\n",
       "      <td>0.86622</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 run_id activation-inner  \\\n",
       "label-type                                                                 \n",
       "1           HD_81ace623-e09b-4393-8a5e-131ea8749a35_115             relu   \n",
       "4           HD_81ace623-e09b-4393-8a5e-131ea8749a35_781             tanh   \n",
       "3           HD_81ace623-e09b-4393-8a5e-131ea8749a35_997             relu   \n",
       "2           HD_81ace623-e09b-4393-8a5e-131ea8749a35_338             relu   \n",
       "0           HD_81ace623-e09b-4393-8a5e-131ea8749a35_537          sigmoid   \n",
       "\n",
       "           activation-output batch-norm batch-shuffle batch-size  \\\n",
       "label-type                                                         \n",
       "1                    softmax          1             0       3300   \n",
       "4                     linear          1             1      21450   \n",
       "3                     linear          1             1      10725   \n",
       "2                     linear          0             0      21450   \n",
       "0                     linear          1             1      10725   \n",
       "\n",
       "           dropout-ratio feature-lags featureset first-layer-neurons  ...  \\\n",
       "label-type                                                            ...   \n",
       "1                    0.2            1          3                 128  ...   \n",
       "4                    0.3            3          0                  64  ...   \n",
       "3                    0.5            3          2                  64  ...   \n",
       "2                    0.2            0          1                  64  ...   \n",
       "0                    0.3            0          0                  64  ...   \n",
       "\n",
       "           pastobs-in-percentage pre-processing second-layer-neurons   id  \\\n",
       "label-type                                                                  \n",
       "1                              1       quantgau                  128  115   \n",
       "4                              1         minmax                   32  781   \n",
       "3                              0            pow                   64  997   \n",
       "2                              0       quantgau                   64  338   \n",
       "0                              1       quantgau                   32  537   \n",
       "\n",
       "                AUC Accuracy     Loss Train AUC Train Accuracy  Train Loss  \n",
       "label-type                                                                  \n",
       "1           0.80363  0.58075  0.98257   0.80358        0.66548     0.77074  \n",
       "4           0.79064  0.57710  0.99908   0.79060        0.65135     0.80627  \n",
       "3           0.78380  0.60282  0.90322   0.78376        0.62677     0.84667  \n",
       "2           0.78078  0.60986  0.88815   0.78075        0.62015     0.86651  \n",
       "0           0.77684  0.60628  0.89268   0.77681        0.61488     0.86622  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tempFinal_v0 = combined_table[np.isin(combined_table.AUC,final_output_auc.loc[0].values.flatten())]\n",
    "tempFinal_v0.index = tempFinal_v0.loc[:,'label-type']\n",
    "tempFinal_v0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>activation-inner</th>\n",
       "      <th>activation-output</th>\n",
       "      <th>batch-norm</th>\n",
       "      <th>batch-shuffle</th>\n",
       "      <th>batch-size</th>\n",
       "      <th>dropout-ratio</th>\n",
       "      <th>feature-lags</th>\n",
       "      <th>featureset</th>\n",
       "      <th>first-layer-neurons</th>\n",
       "      <th>...</th>\n",
       "      <th>pastobs-in-percentage</th>\n",
       "      <th>pre-processing</th>\n",
       "      <th>second-layer-neurons</th>\n",
       "      <th>id</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Train AUC</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Train Loss</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label-type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_686</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>linear</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>21450</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>quantgau</td>\n",
       "      <td>32</td>\n",
       "      <td>686</td>\n",
       "      <td>0.75976</td>\n",
       "      <td>0.61322</td>\n",
       "      <td>0.88116</td>\n",
       "      <td>0.75970</td>\n",
       "      <td>0.61041</td>\n",
       "      <td>0.89109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_716</td>\n",
       "      <td>relu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>21450</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>pow</td>\n",
       "      <td>32</td>\n",
       "      <td>716</td>\n",
       "      <td>0.75923</td>\n",
       "      <td>0.61299</td>\n",
       "      <td>0.88144</td>\n",
       "      <td>0.75916</td>\n",
       "      <td>0.61234</td>\n",
       "      <td>0.88095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_868</td>\n",
       "      <td>leakyrelu</td>\n",
       "      <td>linear</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3300</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>std</td>\n",
       "      <td>64</td>\n",
       "      <td>868</td>\n",
       "      <td>0.76452</td>\n",
       "      <td>0.61282</td>\n",
       "      <td>0.88599</td>\n",
       "      <td>0.76448</td>\n",
       "      <td>0.60774</td>\n",
       "      <td>0.89207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_717</td>\n",
       "      <td>leakyrelu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21450</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>128</td>\n",
       "      <td>717</td>\n",
       "      <td>0.76304</td>\n",
       "      <td>0.61409</td>\n",
       "      <td>0.87683</td>\n",
       "      <td>0.76298</td>\n",
       "      <td>0.61164</td>\n",
       "      <td>0.87896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_133</td>\n",
       "      <td>tanh</td>\n",
       "      <td>softmax</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10725</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>pow</td>\n",
       "      <td>64</td>\n",
       "      <td>133</td>\n",
       "      <td>0.76220</td>\n",
       "      <td>0.61248</td>\n",
       "      <td>0.88257</td>\n",
       "      <td>0.76215</td>\n",
       "      <td>0.61133</td>\n",
       "      <td>0.88838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 run_id activation-inner  \\\n",
       "label-type                                                                 \n",
       "0           HD_81ace623-e09b-4393-8a5e-131ea8749a35_686          sigmoid   \n",
       "1           HD_81ace623-e09b-4393-8a5e-131ea8749a35_716             relu   \n",
       "2           HD_81ace623-e09b-4393-8a5e-131ea8749a35_868        leakyrelu   \n",
       "3           HD_81ace623-e09b-4393-8a5e-131ea8749a35_717        leakyrelu   \n",
       "4           HD_81ace623-e09b-4393-8a5e-131ea8749a35_133             tanh   \n",
       "\n",
       "           activation-output batch-norm batch-shuffle batch-size  \\\n",
       "label-type                                                         \n",
       "0                     linear          1             1      21450   \n",
       "1                    softmax          1             1      21450   \n",
       "2                     linear          1             0       3300   \n",
       "3                    softmax          0             1      21450   \n",
       "4                    softmax          1             1      10725   \n",
       "\n",
       "           dropout-ratio feature-lags featureset first-layer-neurons  ...  \\\n",
       "label-type                                                            ...   \n",
       "0                    0.4            3          0                  32  ...   \n",
       "1                    0.4            3          0                  32  ...   \n",
       "2                    0.4            0          0                  32  ...   \n",
       "3                    0.0            5          3                  32  ...   \n",
       "4                    0.3            1          3                  64  ...   \n",
       "\n",
       "           pastobs-in-percentage pre-processing second-layer-neurons   id  \\\n",
       "label-type                                                                  \n",
       "0                              1       quantgau                   32  686   \n",
       "1                              1            pow                   32  716   \n",
       "2                              0            std                   64  868   \n",
       "3                              0           None                  128  717   \n",
       "4                              0            pow                   64  133   \n",
       "\n",
       "                AUC Accuracy     Loss Train AUC Train Accuracy  Train Loss  \n",
       "label-type                                                                  \n",
       "0           0.75976  0.61322  0.88116   0.75970        0.61041     0.89109  \n",
       "1           0.75923  0.61299  0.88144   0.75916        0.61234     0.88095  \n",
       "2           0.76452  0.61282  0.88599   0.76448        0.60774     0.89207  \n",
       "3           0.76304  0.61409  0.87683   0.76298        0.61164     0.87896  \n",
       "4           0.76220  0.61248  0.88257   0.76215        0.61133     0.88838  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tempFinal_v1 = combined_table[np.isin(combined_table.Accuracy,final_output_acc.loc[0].values.flatten())].sort_values('label-type').copy(deep=True)\n",
    "tempFinal_v1.index = tempFinal_v1.loc[:,'label-type']\n",
    "tempFinal_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['run_id',\n",
       " 'activation-inner',\n",
       " 'activation-output',\n",
       " 'batch-norm',\n",
       " 'batch-shuffle',\n",
       " 'batch-size',\n",
       " 'dropout-ratio',\n",
       " 'feature-lags',\n",
       " 'featureset',\n",
       " 'first-layer-neurons',\n",
       " 'label-type',\n",
       " 'learning-rate',\n",
       " 'n-epochs',\n",
       " 'n-layers',\n",
       " 'nn-type',\n",
       " 'pastobs-in-percentage',\n",
       " 'pre-processing',\n",
       " 'second-layer-neurons',\n",
       " 'id',\n",
       " 'AUC',\n",
       " 'Accuracy',\n",
       " 'Loss',\n",
       " 'Train AUC',\n",
       " 'Train Accuracy',\n",
       " 'Train Loss']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(combined_table.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An example of a box-plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp = combined_table[(combined_table.loc[:,'label-type']=='0')&(combined_table.loc[:,'nn-type']=='lstm')&(combined_table.AUC>0.5)]\n",
    "temp_2 = pd.pivot_table(temp,values='AUC',columns='dropout-ratio',index='run_id').reset_index()\n",
    "temp_2.boxplot(list(temp_2.columns[1:]),figsize=(7,7))#temp_2.columns[2:]\n",
    "plt.grid(b=None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0.3', '0.1', '0.2', '0.4', '0.0', '0.5'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.loc[:,'dropout-ratio'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation-inner :  ['sigmoid' 'relu' 'leakyrelu' 'tanh'] \n",
      "\n",
      "activation-output :  ['linear' 'softmax'] \n",
      "\n",
      "batch-norm :  ['1' '0'] \n",
      "\n",
      "batch-shuffle :  ['1' '0'] \n",
      "\n",
      "batch-size :  ['10725' '3300' '21450'] \n",
      "\n",
      "dropout-ratio :  ['0.3' '0.1' '0.2' '0.4' '0.0' '0.5'] \n",
      "\n",
      "feature-lags :  ['0' '5' '1' '3'] \n",
      "\n",
      "featureset :  ['0' '1' '2' '3'] \n",
      "\n",
      "first-layer-neurons :  ['64' '32' '128'] \n",
      "\n",
      "learning-rate :  ['0.1' '0.001' '0.0001' '0.01'] \n",
      "\n",
      "n-layers :  ['4' '2' '3' '1'] \n",
      "\n",
      "pastobs-in-percentage :  ['1' '0'] \n",
      "\n",
      "pre-processing :  ['quantgau' 'pow' 'stacked' 'std' 'minmax' 'None'] \n",
      "\n",
      "second-layer-neurons :  ['32' '128' '64'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "cols_not_plot = []\n",
    "cols_to_plot = []\n",
    "\n",
    "for i,col in enumerate(temp.columns):\n",
    "    if (temp.loc[:,col].unique().shape[0]>1)&(temp.loc[:,col].unique().shape[0]<7):\n",
    "        cols_to_plot.append(col)\n",
    "        print(col,': ',temp.loc[:,col].unique(),'\\n')\n",
    "    else:\n",
    "        cols_not_plot.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cols_to_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1224x2880 with 15 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "temp = combined_table[(combined_table.loc[:,'label-type']=='4')&(combined_table.loc[:,'nn-type']=='ffnn')&(combined_table.AUC>0.5)]\n",
    "\n",
    "fig,ax = plt.subplots(5,3,figsize=(17,40))\n",
    "font = {'family' : 'normal',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 12}\n",
    "\n",
    "plt.rc('font', **font)\n",
    "# plt.rcParams.update({'font.size': 12})\n",
    "# plt.rcParams.update({'font.weight': 'normal'})\n",
    "k = 0\n",
    "\n",
    "for i in np.arange(5):\n",
    "    for j in np.arange(3):\n",
    "        \n",
    "\n",
    "\n",
    "        if k < len(cols_to_plot):\n",
    "            temp_2 = pd.pivot_table(temp,values='AUC',columns=cols_to_plot[k],index='run_id').reset_index()\n",
    "\n",
    "            # sns.set_theme(style=\"whitegrid\")\n",
    "            # tips = sns.load_dataset(\"tips\")\n",
    "            # ax = sns.violinplot(x=tips[\"total_bill\"])\n",
    "            sns.boxplot(data=temp_2,ax=ax[i,j],color='gray')#,bw='scott'\n",
    "#             ax[i,j].set_xticks(fontsize=12)\n",
    "#             ax[i,j].set_yticks(fontsize=12)\n",
    "            # plt.legend(fontsize=14)\n",
    "            ax[i,j].set_xlabel(temp_2.columns.name,fontsize=12,fontweight='bold')\n",
    "\n",
    "\n",
    "            k +=1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hyperparameters.txt',\n",
       " 'hyperparameters_lr_v1.txt',\n",
       " 'hyperparameters_lr_v2.txt',\n",
       " 'metrics.txt',\n",
       " 'metrics_lr_v1.txt',\n",
       " 'metrics_lr_v2.txt']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('../AzureML/Output_from_cloud')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperfiles = [i for i in os.listdir('../AzureML/Output_from_cloud') if 'hyper' in i]\n",
    "metricfiles = [i for i in os.listdir('../AzureML/Output_from_cloud') if 'metric' in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hyperparameters.txt',\n",
       " 'hyperparameters_lr_v1.txt',\n",
       " 'hyperparameters_lr_v2.txt',\n",
       " 'hyperparameters_lr_v3.txt']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j,file in enumerate(hyperfiles):\n",
    "    \n",
    "    if j > 0:\n",
    "        \n",
    "        ### Reading in the file\n",
    "\n",
    "        with open('../AzureML/Output_from_cloud/'+hyperfiles[j],'r') as file:\n",
    "            content = file.readlines()\n",
    "\n",
    "        ## Going over each line in the text file\n",
    "        for a in np.arange(len(content)):\n",
    "\n",
    "            ## Split the lines on tabs\n",
    "            temp_parameters = re.split('[\\t]',content[a])[1]\n",
    "\n",
    "            ## Basic string cleaning, i.e. removing redundant characters\n",
    "            test = [re.split(': ',i.strip()) for i in re.split(',',temp_parameters.replace('{','')\\\n",
    "                                                                               .replace('}','')\\\n",
    "                                                                               .replace('\\n','')\\\n",
    "                                                                               .replace('\"',''))]\n",
    "\n",
    "            ## Output of test is a list of lists, where each sublist holds the name of a model variable and its value.\n",
    "            ## We create a dictornary to hold all model variables, making it easy to add the observation to the dataframe.\n",
    "            test = {i[0]:i[1] for i in test}\n",
    "\n",
    "            # Constructing the dataframe\n",
    "            if (a == 0)&(j==1):\n",
    "                parameters_lr = pd.DataFrame(test,index=[re.split('[\\t]',content[a])[0]])\n",
    "\n",
    "            else:\n",
    "\n",
    "                parameters_lr.loc[re.split('[\\t]',content[a])[0]] = pd.Series(test)\n",
    "        \n",
    "#         lastone = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch-shuffle</th>\n",
       "      <th>batch-size</th>\n",
       "      <th>feature-lags</th>\n",
       "      <th>featureset</th>\n",
       "      <th>l2-penalty</th>\n",
       "      <th>l2-type</th>\n",
       "      <th>label-type</th>\n",
       "      <th>learning-rate</th>\n",
       "      <th>loss-from-logits</th>\n",
       "      <th>n-epochs</th>\n",
       "      <th>pastobs-in-percentage</th>\n",
       "      <th>pre-processing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0</td>\n",
       "      <td>1</td>\n",
       "      <td>21450</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>stacked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_1</td>\n",
       "      <td>0</td>\n",
       "      <td>3300</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>quantgau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_2</td>\n",
       "      <td>1</td>\n",
       "      <td>10725</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>pow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_3</td>\n",
       "      <td>1</td>\n",
       "      <td>3300</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>minmax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_4</td>\n",
       "      <td>0</td>\n",
       "      <td>21450</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>std</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_166</td>\n",
       "      <td>0</td>\n",
       "      <td>3300</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>quantgau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_167</td>\n",
       "      <td>1</td>\n",
       "      <td>3300</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_168</td>\n",
       "      <td>1</td>\n",
       "      <td>21450</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>pow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169</td>\n",
       "      <td>0</td>\n",
       "      <td>3300</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>pow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_170</td>\n",
       "      <td>1</td>\n",
       "      <td>10725</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>std</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>655 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            batch-shuffle batch-size  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0               1      21450   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_1               0       3300   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_2               1      10725   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_3               1       3300   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_4               0      21450   \n",
       "...                                                   ...        ...   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_166             0       3300   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_167             1       3300   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_168             1      21450   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169             0       3300   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_170             1      10725   \n",
       "\n",
       "                                            feature-lags featureset  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0              5          1   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_1              1          2   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_2              5          2   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_3              5          1   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_4              5          3   \n",
       "...                                                  ...        ...   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_166            3          2   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_167            1          3   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_168            5          0   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169            1          1   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_170            1          3   \n",
       "\n",
       "                                            l2-penalty l2-type label-type  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0          1.0       6          2   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_1         10.0       1          2   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_2          0.1       1          0   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_3        100.0       4          0   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_4         0.01       5          2   \n",
       "...                                                ...     ...        ...   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_166     0.0001       2          1   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_167        1.0       5          0   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_168        1.0       1          2   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169     1000.0       4          1   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_170      0.001       5          1   \n",
       "\n",
       "                                            learning-rate loss-from-logits  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0           0.001                0   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_1             0.1                0   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_2           0.001                0   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_3           0.001                1   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_4          0.0001                1   \n",
       "...                                                   ...              ...   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_166        0.0001                1   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_167           0.1                0   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_168         0.001                0   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169        0.0001                1   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_170        0.0001                0   \n",
       "\n",
       "                                            n-epochs pastobs-in-percentage  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0        150                     1   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_1        150                     1   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_2        150                     1   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_3        150                     1   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_4        150                     1   \n",
       "...                                              ...                   ...   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_166      150                     0   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_167      150                     0   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_168      150                     1   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169      150                     1   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_170      150                     0   \n",
       "\n",
       "                                            pre-processing  \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0          stacked  \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_1         quantgau  \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_2              pow  \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_3           minmax  \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_4              std  \n",
       "...                                                    ...  \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_166       quantgau  \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_167           None  \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_168            pow  \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169            pow  \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_170            std  \n",
       "\n",
       "[655 rows x 12 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j,file in enumerate(metricfiles):\n",
    "    \n",
    "    if j > 0:\n",
    "        \n",
    "        ## Readidng in the file\n",
    "        with open('../AzureML/Output_from_cloud/'+metricfiles[j],'r') as file:\n",
    "            content = file.readlines()\n",
    "\n",
    "        ## Containers\n",
    "        t11 = []\n",
    "        t12 = []\n",
    "        t13 = []\n",
    "\n",
    "        t21 = []\n",
    "        t22 = []\n",
    "        t23 = []\n",
    "\n",
    "        ## Going over each line\n",
    "        for i in np.arange(len(content)):#\n",
    "\n",
    "            ## Split each line on tabs\n",
    "            temp = re.split('\\t',content[i].replace('\\n',''))\n",
    "\n",
    "            ## There are two types of observations in the text file; 1. final metrics of those models which where not stoppe early\n",
    "            ## and 2. a time series of a metric for each model.\n",
    "\n",
    "            ## If the length of the last element, in a line, is less than 50 (because it is just a number, i.e. final metric)\n",
    "            ## It stored separately for the time series.\n",
    "            if len(temp[2]) < 50:\n",
    "\n",
    "                t11.append(temp[0])\n",
    "                t12.append(temp[1])\n",
    "                t13.append(temp[2])\n",
    "\n",
    "            ## Time series\n",
    "            else:\n",
    "\n",
    "                container = np.zeros(155)\n",
    "                temp1 = [float(j.strip()) if j.strip() !=\"'NaN'\" else 0 for j in re.split(',',temp[2].replace('[','').replace(']',''))]\n",
    "\n",
    "                container[0:len(temp1)] = temp1\n",
    "                container[len(temp1):] = temp1[-1]\n",
    "\n",
    "                t21.append(temp[0])\n",
    "                t22.append(temp[1])\n",
    "                t23.append(container)        \n",
    "\n",
    "        ## Storing the time series in a dataframe\n",
    "        arrays = [t21,t22]\n",
    "        tuples = list(zip(*arrays))\n",
    "        if j == 1:\n",
    "            \n",
    "            runningMetrics_lr = pd.DataFrame(np.array(t23),\n",
    "                                              index=pd.MultiIndex.from_tuples(tuples),\n",
    "                                              columns = [np.arange(155).astype(str)]\n",
    "                                             )\n",
    "        else:\n",
    "            temp_1 = pd.DataFrame(np.array(t23),\n",
    "                                  index=pd.MultiIndex.from_tuples(tuples),\n",
    "                                  columns = [np.arange(155).astype(str)])\n",
    "            runningMetrics_lr = pd.concat([runningMetrics_lr,temp_1])\n",
    "        ## Storing the final metrics in a dataframe.\n",
    "        arrays = [t11,t12]\n",
    "        tuples = list(zip(*arrays))\n",
    "        if j == 1:\n",
    "            \n",
    "            finalMetrics_lr = pd.DataFrame(t13,index = pd.MultiIndex.from_tuples(tuples),columns = ['size'])\n",
    "        else:\n",
    "            \n",
    "            temp = pd.DataFrame(t13,index = pd.MultiIndex.from_tuples(tuples),columns = ['size'])\n",
    "            finalMetrics_lr = pd.concat([finalMetrics_lr,temp],axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "      <th>150</th>\n",
       "      <th>151</th>\n",
       "      <th>152</th>\n",
       "      <th>153</th>\n",
       "      <th>154</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td rowspan=\"5\" valign=\"top\">HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0</td>\n",
       "      <td>Loss</td>\n",
       "      <td>1.097134</td>\n",
       "      <td>1.089486</td>\n",
       "      <td>1.084925</td>\n",
       "      <td>1.082050</td>\n",
       "      <td>1.080157</td>\n",
       "      <td>1.078848</td>\n",
       "      <td>1.077901</td>\n",
       "      <td>1.077183</td>\n",
       "      <td>1.076617</td>\n",
       "      <td>1.076155</td>\n",
       "      <td>...</td>\n",
       "      <td>1.070333</td>\n",
       "      <td>1.070329</td>\n",
       "      <td>1.070325</td>\n",
       "      <td>1.070321</td>\n",
       "      <td>1.070317</td>\n",
       "      <td>1.070317</td>\n",
       "      <td>1.070317</td>\n",
       "      <td>1.070317</td>\n",
       "      <td>1.070317</td>\n",
       "      <td>1.070317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.357927</td>\n",
       "      <td>0.372786</td>\n",
       "      <td>0.380087</td>\n",
       "      <td>0.386206</td>\n",
       "      <td>0.388733</td>\n",
       "      <td>0.389996</td>\n",
       "      <td>0.391295</td>\n",
       "      <td>0.392629</td>\n",
       "      <td>0.393904</td>\n",
       "      <td>0.394478</td>\n",
       "      <td>...</td>\n",
       "      <td>0.401299</td>\n",
       "      <td>0.401381</td>\n",
       "      <td>0.401322</td>\n",
       "      <td>0.401275</td>\n",
       "      <td>0.401299</td>\n",
       "      <td>0.401299</td>\n",
       "      <td>0.401299</td>\n",
       "      <td>0.401299</td>\n",
       "      <td>0.401299</td>\n",
       "      <td>0.401299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>AUC</td>\n",
       "      <td>0.520483</td>\n",
       "      <td>0.533294</td>\n",
       "      <td>0.543315</td>\n",
       "      <td>0.550682</td>\n",
       "      <td>0.556136</td>\n",
       "      <td>0.560248</td>\n",
       "      <td>0.563450</td>\n",
       "      <td>0.566000</td>\n",
       "      <td>0.568082</td>\n",
       "      <td>0.569817</td>\n",
       "      <td>...</td>\n",
       "      <td>0.592322</td>\n",
       "      <td>0.592349</td>\n",
       "      <td>0.592375</td>\n",
       "      <td>0.592401</td>\n",
       "      <td>0.592426</td>\n",
       "      <td>0.592426</td>\n",
       "      <td>0.592426</td>\n",
       "      <td>0.592426</td>\n",
       "      <td>0.592426</td>\n",
       "      <td>0.592426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Train Loss</td>\n",
       "      <td>1.103421</td>\n",
       "      <td>1.092251</td>\n",
       "      <td>1.085799</td>\n",
       "      <td>1.081776</td>\n",
       "      <td>1.079140</td>\n",
       "      <td>1.077343</td>\n",
       "      <td>1.076068</td>\n",
       "      <td>1.075129</td>\n",
       "      <td>1.074413</td>\n",
       "      <td>1.073847</td>\n",
       "      <td>...</td>\n",
       "      <td>1.067931</td>\n",
       "      <td>1.067927</td>\n",
       "      <td>1.067922</td>\n",
       "      <td>1.067918</td>\n",
       "      <td>1.067913</td>\n",
       "      <td>1.067913</td>\n",
       "      <td>1.067913</td>\n",
       "      <td>1.067913</td>\n",
       "      <td>1.067913</td>\n",
       "      <td>1.067913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Train Accuracy</td>\n",
       "      <td>0.348293</td>\n",
       "      <td>0.370394</td>\n",
       "      <td>0.381516</td>\n",
       "      <td>0.386821</td>\n",
       "      <td>0.390184</td>\n",
       "      <td>0.392238</td>\n",
       "      <td>0.393292</td>\n",
       "      <td>0.394232</td>\n",
       "      <td>0.395504</td>\n",
       "      <td>0.396163</td>\n",
       "      <td>...</td>\n",
       "      <td>0.407098</td>\n",
       "      <td>0.407139</td>\n",
       "      <td>0.407136</td>\n",
       "      <td>0.407177</td>\n",
       "      <td>0.407191</td>\n",
       "      <td>0.407191</td>\n",
       "      <td>0.407191</td>\n",
       "      <td>0.407191</td>\n",
       "      <td>0.407191</td>\n",
       "      <td>0.407191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td rowspan=\"5\" valign=\"top\">HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169</td>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.196420</td>\n",
       "      <td>0.195965</td>\n",
       "      <td>0.195393</td>\n",
       "      <td>0.194752</td>\n",
       "      <td>0.194052</td>\n",
       "      <td>0.193772</td>\n",
       "      <td>0.194320</td>\n",
       "      <td>0.194624</td>\n",
       "      <td>0.194764</td>\n",
       "      <td>0.195335</td>\n",
       "      <td>...</td>\n",
       "      <td>0.195592</td>\n",
       "      <td>0.195673</td>\n",
       "      <td>0.195673</td>\n",
       "      <td>0.195533</td>\n",
       "      <td>0.195533</td>\n",
       "      <td>0.195533</td>\n",
       "      <td>0.195533</td>\n",
       "      <td>0.195533</td>\n",
       "      <td>0.195533</td>\n",
       "      <td>0.195533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>AUC</td>\n",
       "      <td>0.498032</td>\n",
       "      <td>0.498719</td>\n",
       "      <td>0.498959</td>\n",
       "      <td>0.499100</td>\n",
       "      <td>0.499201</td>\n",
       "      <td>0.499279</td>\n",
       "      <td>0.499350</td>\n",
       "      <td>0.499412</td>\n",
       "      <td>0.499474</td>\n",
       "      <td>0.499528</td>\n",
       "      <td>...</td>\n",
       "      <td>0.499037</td>\n",
       "      <td>0.499022</td>\n",
       "      <td>0.499007</td>\n",
       "      <td>0.498993</td>\n",
       "      <td>0.498978</td>\n",
       "      <td>0.498978</td>\n",
       "      <td>0.498978</td>\n",
       "      <td>0.498978</td>\n",
       "      <td>0.498978</td>\n",
       "      <td>0.498978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Train Loss</td>\n",
       "      <td>27.245023</td>\n",
       "      <td>24.507504</td>\n",
       "      <td>22.095238</td>\n",
       "      <td>19.988227</td>\n",
       "      <td>18.149702</td>\n",
       "      <td>16.543524</td>\n",
       "      <td>15.139264</td>\n",
       "      <td>13.911686</td>\n",
       "      <td>12.839479</td>\n",
       "      <td>11.904266</td>\n",
       "      <td>...</td>\n",
       "      <td>2.535947</td>\n",
       "      <td>2.523146</td>\n",
       "      <td>2.510520</td>\n",
       "      <td>2.498068</td>\n",
       "      <td>2.485785</td>\n",
       "      <td>2.485785</td>\n",
       "      <td>2.485785</td>\n",
       "      <td>2.485785</td>\n",
       "      <td>2.485785</td>\n",
       "      <td>2.485785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Train Accuracy</td>\n",
       "      <td>0.196710</td>\n",
       "      <td>0.196640</td>\n",
       "      <td>0.196341</td>\n",
       "      <td>0.196336</td>\n",
       "      <td>0.196248</td>\n",
       "      <td>0.196330</td>\n",
       "      <td>0.196661</td>\n",
       "      <td>0.197103</td>\n",
       "      <td>0.197493</td>\n",
       "      <td>0.197821</td>\n",
       "      <td>...</td>\n",
       "      <td>0.199241</td>\n",
       "      <td>0.199253</td>\n",
       "      <td>0.199227</td>\n",
       "      <td>0.199297</td>\n",
       "      <td>0.199192</td>\n",
       "      <td>0.199192</td>\n",
       "      <td>0.199192</td>\n",
       "      <td>0.199192</td>\n",
       "      <td>0.199192</td>\n",
       "      <td>0.199192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Train AUC</td>\n",
       "      <td>0.505100</td>\n",
       "      <td>0.500372</td>\n",
       "      <td>0.499929</td>\n",
       "      <td>0.499766</td>\n",
       "      <td>0.499693</td>\n",
       "      <td>0.499662</td>\n",
       "      <td>0.499652</td>\n",
       "      <td>0.499658</td>\n",
       "      <td>0.499674</td>\n",
       "      <td>0.499695</td>\n",
       "      <td>...</td>\n",
       "      <td>0.499045</td>\n",
       "      <td>0.499030</td>\n",
       "      <td>0.499015</td>\n",
       "      <td>0.499001</td>\n",
       "      <td>0.498986</td>\n",
       "      <td>0.498986</td>\n",
       "      <td>0.498986</td>\n",
       "      <td>0.498986</td>\n",
       "      <td>0.498986</td>\n",
       "      <td>0.498986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3846 rows × 155 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                    0  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss             1.097134   \n",
       "                                            Accuracy         0.357927   \n",
       "                                            AUC              0.520483   \n",
       "                                            Train Loss       1.103421   \n",
       "                                            Train Accuracy   0.348293   \n",
       "...                                                               ...   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169 Accuracy         0.196420   \n",
       "                                            AUC              0.498032   \n",
       "                                            Train Loss      27.245023   \n",
       "                                            Train Accuracy   0.196710   \n",
       "                                            Train AUC        0.505100   \n",
       "\n",
       "                                                                    1  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss             1.089486   \n",
       "                                            Accuracy         0.372786   \n",
       "                                            AUC              0.533294   \n",
       "                                            Train Loss       1.092251   \n",
       "                                            Train Accuracy   0.370394   \n",
       "...                                                               ...   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169 Accuracy         0.195965   \n",
       "                                            AUC              0.498719   \n",
       "                                            Train Loss      24.507504   \n",
       "                                            Train Accuracy   0.196640   \n",
       "                                            Train AUC        0.500372   \n",
       "\n",
       "                                                                    2  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss             1.084925   \n",
       "                                            Accuracy         0.380087   \n",
       "                                            AUC              0.543315   \n",
       "                                            Train Loss       1.085799   \n",
       "                                            Train Accuracy   0.381516   \n",
       "...                                                               ...   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169 Accuracy         0.195393   \n",
       "                                            AUC              0.498959   \n",
       "                                            Train Loss      22.095238   \n",
       "                                            Train Accuracy   0.196341   \n",
       "                                            Train AUC        0.499929   \n",
       "\n",
       "                                                                    3  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss             1.082050   \n",
       "                                            Accuracy         0.386206   \n",
       "                                            AUC              0.550682   \n",
       "                                            Train Loss       1.081776   \n",
       "                                            Train Accuracy   0.386821   \n",
       "...                                                               ...   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169 Accuracy         0.194752   \n",
       "                                            AUC              0.499100   \n",
       "                                            Train Loss      19.988227   \n",
       "                                            Train Accuracy   0.196336   \n",
       "                                            Train AUC        0.499766   \n",
       "\n",
       "                                                                    4  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss             1.080157   \n",
       "                                            Accuracy         0.388733   \n",
       "                                            AUC              0.556136   \n",
       "                                            Train Loss       1.079140   \n",
       "                                            Train Accuracy   0.390184   \n",
       "...                                                               ...   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169 Accuracy         0.194052   \n",
       "                                            AUC              0.499201   \n",
       "                                            Train Loss      18.149702   \n",
       "                                            Train Accuracy   0.196248   \n",
       "                                            Train AUC        0.499693   \n",
       "\n",
       "                                                                    5  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss             1.078848   \n",
       "                                            Accuracy         0.389996   \n",
       "                                            AUC              0.560248   \n",
       "                                            Train Loss       1.077343   \n",
       "                                            Train Accuracy   0.392238   \n",
       "...                                                               ...   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169 Accuracy         0.193772   \n",
       "                                            AUC              0.499279   \n",
       "                                            Train Loss      16.543524   \n",
       "                                            Train Accuracy   0.196330   \n",
       "                                            Train AUC        0.499662   \n",
       "\n",
       "                                                                    6  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss             1.077901   \n",
       "                                            Accuracy         0.391295   \n",
       "                                            AUC              0.563450   \n",
       "                                            Train Loss       1.076068   \n",
       "                                            Train Accuracy   0.393292   \n",
       "...                                                               ...   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169 Accuracy         0.194320   \n",
       "                                            AUC              0.499350   \n",
       "                                            Train Loss      15.139264   \n",
       "                                            Train Accuracy   0.196661   \n",
       "                                            Train AUC        0.499652   \n",
       "\n",
       "                                                                    7  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss             1.077183   \n",
       "                                            Accuracy         0.392629   \n",
       "                                            AUC              0.566000   \n",
       "                                            Train Loss       1.075129   \n",
       "                                            Train Accuracy   0.394232   \n",
       "...                                                               ...   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169 Accuracy         0.194624   \n",
       "                                            AUC              0.499412   \n",
       "                                            Train Loss      13.911686   \n",
       "                                            Train Accuracy   0.197103   \n",
       "                                            Train AUC        0.499658   \n",
       "\n",
       "                                                                    8  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss             1.076617   \n",
       "                                            Accuracy         0.393904   \n",
       "                                            AUC              0.568082   \n",
       "                                            Train Loss       1.074413   \n",
       "                                            Train Accuracy   0.395504   \n",
       "...                                                               ...   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169 Accuracy         0.194764   \n",
       "                                            AUC              0.499474   \n",
       "                                            Train Loss      12.839479   \n",
       "                                            Train Accuracy   0.197493   \n",
       "                                            Train AUC        0.499674   \n",
       "\n",
       "                                                                    9  ...  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss             1.076155  ...   \n",
       "                                            Accuracy         0.394478  ...   \n",
       "                                            AUC              0.569817  ...   \n",
       "                                            Train Loss       1.073847  ...   \n",
       "                                            Train Accuracy   0.396163  ...   \n",
       "...                                                               ...  ...   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169 Accuracy         0.195335  ...   \n",
       "                                            AUC              0.499528  ...   \n",
       "                                            Train Loss      11.904266  ...   \n",
       "                                            Train Accuracy   0.197821  ...   \n",
       "                                            Train AUC        0.499695  ...   \n",
       "\n",
       "                                                                 145  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss            1.070333   \n",
       "                                            Accuracy        0.401299   \n",
       "                                            AUC             0.592322   \n",
       "                                            Train Loss      1.067931   \n",
       "                                            Train Accuracy  0.407098   \n",
       "...                                                              ...   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169 Accuracy        0.195592   \n",
       "                                            AUC             0.499037   \n",
       "                                            Train Loss      2.535947   \n",
       "                                            Train Accuracy  0.199241   \n",
       "                                            Train AUC       0.499045   \n",
       "\n",
       "                                                                 146  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss            1.070329   \n",
       "                                            Accuracy        0.401381   \n",
       "                                            AUC             0.592349   \n",
       "                                            Train Loss      1.067927   \n",
       "                                            Train Accuracy  0.407139   \n",
       "...                                                              ...   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169 Accuracy        0.195673   \n",
       "                                            AUC             0.499022   \n",
       "                                            Train Loss      2.523146   \n",
       "                                            Train Accuracy  0.199253   \n",
       "                                            Train AUC       0.499030   \n",
       "\n",
       "                                                                 147  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss            1.070325   \n",
       "                                            Accuracy        0.401322   \n",
       "                                            AUC             0.592375   \n",
       "                                            Train Loss      1.067922   \n",
       "                                            Train Accuracy  0.407136   \n",
       "...                                                              ...   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169 Accuracy        0.195673   \n",
       "                                            AUC             0.499007   \n",
       "                                            Train Loss      2.510520   \n",
       "                                            Train Accuracy  0.199227   \n",
       "                                            Train AUC       0.499015   \n",
       "\n",
       "                                                                 148  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss            1.070321   \n",
       "                                            Accuracy        0.401275   \n",
       "                                            AUC             0.592401   \n",
       "                                            Train Loss      1.067918   \n",
       "                                            Train Accuracy  0.407177   \n",
       "...                                                              ...   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169 Accuracy        0.195533   \n",
       "                                            AUC             0.498993   \n",
       "                                            Train Loss      2.498068   \n",
       "                                            Train Accuracy  0.199297   \n",
       "                                            Train AUC       0.499001   \n",
       "\n",
       "                                                                 149  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss            1.070317   \n",
       "                                            Accuracy        0.401299   \n",
       "                                            AUC             0.592426   \n",
       "                                            Train Loss      1.067913   \n",
       "                                            Train Accuracy  0.407191   \n",
       "...                                                              ...   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169 Accuracy        0.195533   \n",
       "                                            AUC             0.498978   \n",
       "                                            Train Loss      2.485785   \n",
       "                                            Train Accuracy  0.199192   \n",
       "                                            Train AUC       0.498986   \n",
       "\n",
       "                                                                 150  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss            1.070317   \n",
       "                                            Accuracy        0.401299   \n",
       "                                            AUC             0.592426   \n",
       "                                            Train Loss      1.067913   \n",
       "                                            Train Accuracy  0.407191   \n",
       "...                                                              ...   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169 Accuracy        0.195533   \n",
       "                                            AUC             0.498978   \n",
       "                                            Train Loss      2.485785   \n",
       "                                            Train Accuracy  0.199192   \n",
       "                                            Train AUC       0.498986   \n",
       "\n",
       "                                                                 151  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss            1.070317   \n",
       "                                            Accuracy        0.401299   \n",
       "                                            AUC             0.592426   \n",
       "                                            Train Loss      1.067913   \n",
       "                                            Train Accuracy  0.407191   \n",
       "...                                                              ...   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169 Accuracy        0.195533   \n",
       "                                            AUC             0.498978   \n",
       "                                            Train Loss      2.485785   \n",
       "                                            Train Accuracy  0.199192   \n",
       "                                            Train AUC       0.498986   \n",
       "\n",
       "                                                                 152  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss            1.070317   \n",
       "                                            Accuracy        0.401299   \n",
       "                                            AUC             0.592426   \n",
       "                                            Train Loss      1.067913   \n",
       "                                            Train Accuracy  0.407191   \n",
       "...                                                              ...   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169 Accuracy        0.195533   \n",
       "                                            AUC             0.498978   \n",
       "                                            Train Loss      2.485785   \n",
       "                                            Train Accuracy  0.199192   \n",
       "                                            Train AUC       0.498986   \n",
       "\n",
       "                                                                 153       154  \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss            1.070317  1.070317  \n",
       "                                            Accuracy        0.401299  0.401299  \n",
       "                                            AUC             0.592426  0.592426  \n",
       "                                            Train Loss      1.067913  1.067913  \n",
       "                                            Train Accuracy  0.407191  0.407191  \n",
       "...                                                              ...       ...  \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169 Accuracy        0.195533  0.195533  \n",
       "                                            AUC             0.498978  0.498978  \n",
       "                                            Train Loss      2.485785  2.485785  \n",
       "                                            Train Accuracy  0.199192  0.199192  \n",
       "                                            Train AUC       0.498986  0.498986  \n",
       "\n",
       "[3846 rows x 155 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runningMetrics_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0',),\n",
       " ('1',),\n",
       " ('2',),\n",
       " ('3',),\n",
       " ('4',),\n",
       " ('5',),\n",
       " ('6',),\n",
       " ('7',),\n",
       " ('8',),\n",
       " ('9',),\n",
       " ('10',),\n",
       " ('11',),\n",
       " ('12',),\n",
       " ('13',),\n",
       " ('14',),\n",
       " ('15',),\n",
       " ('16',),\n",
       " ('17',),\n",
       " ('18',),\n",
       " ('19',),\n",
       " ('20',),\n",
       " ('21',),\n",
       " ('22',),\n",
       " ('23',),\n",
       " ('24',),\n",
       " ('25',),\n",
       " ('26',),\n",
       " ('27',),\n",
       " ('28',),\n",
       " ('29',),\n",
       " ('30',),\n",
       " ('31',),\n",
       " ('32',),\n",
       " ('33',),\n",
       " ('34',),\n",
       " ('35',),\n",
       " ('36',),\n",
       " ('37',),\n",
       " ('38',),\n",
       " ('39',),\n",
       " ('40',),\n",
       " ('41',),\n",
       " ('42',),\n",
       " ('43',),\n",
       " ('44',),\n",
       " ('45',),\n",
       " ('46',),\n",
       " ('47',),\n",
       " ('48',),\n",
       " ('49',),\n",
       " ('50',),\n",
       " ('51',),\n",
       " ('52',),\n",
       " ('53',),\n",
       " ('54',),\n",
       " ('55',),\n",
       " ('56',),\n",
       " ('57',),\n",
       " ('58',),\n",
       " ('59',),\n",
       " ('60',),\n",
       " ('61',),\n",
       " ('62',),\n",
       " ('63',),\n",
       " ('64',),\n",
       " ('65',),\n",
       " ('66',),\n",
       " ('67',),\n",
       " ('68',),\n",
       " ('69',),\n",
       " ('70',),\n",
       " ('71',),\n",
       " ('72',),\n",
       " ('73',),\n",
       " ('74',),\n",
       " ('75',),\n",
       " ('76',),\n",
       " ('77',),\n",
       " ('78',),\n",
       " ('79',),\n",
       " ('80',),\n",
       " ('81',),\n",
       " ('82',),\n",
       " ('83',),\n",
       " ('84',),\n",
       " ('85',),\n",
       " ('86',),\n",
       " ('87',),\n",
       " ('88',),\n",
       " ('89',),\n",
       " ('90',),\n",
       " ('91',),\n",
       " ('92',),\n",
       " ('93',),\n",
       " ('94',),\n",
       " ('95',),\n",
       " ('96',),\n",
       " ('97',),\n",
       " ('98',),\n",
       " ('99',),\n",
       " ('100',),\n",
       " ('101',),\n",
       " ('102',),\n",
       " ('103',),\n",
       " ('104',),\n",
       " ('105',),\n",
       " ('106',),\n",
       " ('107',),\n",
       " ('108',),\n",
       " ('109',),\n",
       " ('110',),\n",
       " ('111',),\n",
       " ('112',),\n",
       " ('113',),\n",
       " ('114',),\n",
       " ('115',),\n",
       " ('116',),\n",
       " ('117',),\n",
       " ('118',),\n",
       " ('119',),\n",
       " ('120',),\n",
       " ('121',),\n",
       " ('122',),\n",
       " ('123',),\n",
       " ('124',),\n",
       " ('125',),\n",
       " ('126',),\n",
       " ('127',),\n",
       " ('128',),\n",
       " ('129',),\n",
       " ('130',),\n",
       " ('131',),\n",
       " ('132',),\n",
       " ('133',),\n",
       " ('134',),\n",
       " ('135',),\n",
       " ('136',),\n",
       " ('137',),\n",
       " ('138',),\n",
       " ('139',),\n",
       " ('140',),\n",
       " ('141',),\n",
       " ('142',),\n",
       " ('143',),\n",
       " ('144',),\n",
       " ('145',),\n",
       " ('146',),\n",
       " ('147',),\n",
       " ('148',),\n",
       " ('149',),\n",
       " ('150',),\n",
       " ('151',),\n",
       " ('152',),\n",
       " ('153',),\n",
       " ('154',)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(runningMetrics.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hyperparameters.txt',\n",
       " 'hyperparameters_lr_v1.txt',\n",
       " 'hyperparameters_lr_v2.txt',\n",
       " 'hyperparameters_lr_v3.txt',\n",
       " 'metrics.txt',\n",
       " 'metrics_lr_v1.txt',\n",
       " 'metrics_lr_v2.txt',\n",
       " 'metrics_lr_v3.txt']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('../AzureML/Output_from_cloud/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('../AzureML/Output_from_cloud/'+metricfiles[1],'r') as file:\n",
    "#     content = file.readlines()\n",
    "        \n",
    "# ## Containers\n",
    "# t11 = []\n",
    "# t12 = []\n",
    "# t13 = []\n",
    "\n",
    "# t21 = []\n",
    "# t22 = []\n",
    "# t23 = []\n",
    "\n",
    "# ## Going over each line\n",
    "# for i in np.arange(len(content)):#\n",
    "\n",
    "#     ## Split each line on tabs\n",
    "#     temp = re.split('\\t',content[i].replace('\\n',''))\n",
    "\n",
    "#     ## There are two types of observations in the text file; 1. final metrics of those models which where not stoppe early\n",
    "#     ## and 2. a time series of a metric for each model.\n",
    "\n",
    "#     ## If the length of the last element, in a line, is less than 50 (because it is just a number, i.e. final metric)\n",
    "#     ## It stored separately for the time series.\n",
    "#     if len(temp[2]) < 50:\n",
    "\n",
    "#         t11.append(temp[0])\n",
    "#         t12.append(temp[1])\n",
    "#         t13.append(temp[2])\n",
    "\n",
    "#     ## Time series\n",
    "#     else:\n",
    "\n",
    "#         container = np.zeros(155)\n",
    "#         temp1 = [float(j.strip()) if j.strip() !=\"'NaN'\" else 0 for j in re.split(',',temp[2].replace('[','').replace(']',''))]\n",
    "\n",
    "#         container[0:len(temp1)] = temp1\n",
    "#         container[len(temp1):] = temp1[-1]\n",
    "\n",
    "#         t21.append(temp[0])\n",
    "#         t22.append(temp[1])\n",
    "#         t23.append(container)    \n",
    "        \n",
    "# print([i for i,j in enumerate(t11) if j == 'HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_1'])\n",
    "# print([i for i,j in enumerate(t21) if j == 'HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(t12[5],t13[5])\n",
    "# print(t22[10],t23[10][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('../AzureML/Output_from_cloud/'+metricfiles[2],'r') as file:\n",
    "#     content = file.readlines()\n",
    "        \n",
    "# ## Containers\n",
    "# t11 = []\n",
    "# t12 = []\n",
    "# t13 = []\n",
    "\n",
    "# t21 = []\n",
    "# t22 = []\n",
    "# t23 = []\n",
    "\n",
    "# ## Going over each line\n",
    "# for i in np.arange(len(content)):#\n",
    "\n",
    "#     ## Split each line on tabs\n",
    "#     temp = re.split('\\t',content[i].replace('\\n',''))\n",
    "\n",
    "#     ## There are two types of observations in the text file; 1. final metrics of those models which where not stoppe early\n",
    "#     ## and 2. a time series of a metric for each model.\n",
    "\n",
    "#     ## If the length of the last element, in a line, is less than 50 (because it is just a number, i.e. final metric)\n",
    "#     ## It stored separately for the time series.\n",
    "#     if len(temp[2]) < 50:\n",
    "\n",
    "#         t11.append(temp[0])\n",
    "#         t12.append(temp[1])\n",
    "#         t13.append(temp[2])\n",
    "\n",
    "#     ## Time series\n",
    "#     else:\n",
    "\n",
    "#         container = np.zeros(155)\n",
    "#         temp1 = [float(j.strip()) if j.strip() !=\"'NaN'\" else 0 for j in re.split(',',temp[2].replace('[','').replace(']',''))]\n",
    "\n",
    "#         container[0:len(temp1)] = temp1\n",
    "#         container[len(temp1):] = temp1[-1]\n",
    "\n",
    "#         t21.append(temp[0])\n",
    "#         t22.append(temp[1])\n",
    "#         t23.append(container)   \n",
    "\n",
    "# print([i for i,j in enumerate(t11) if j == 'HD_914f915c-2cac-473e-bea5-c26e4c83673c_1'])\n",
    "# print([i for i,j in enumerate(t21) if j == 'HD_914f915c-2cac-473e-bea5-c26e4c83673c_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(t12[5],t13[5])\n",
    "# print(t22[10],t23[10][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td rowspan=\"3\" valign=\"top\">HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0</td>\n",
       "      <td>Final test loss</td>\n",
       "      <td>1.0703172176779956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Final test AUC</td>\n",
       "      <td>0.5924146175384521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Final test accuracy</td>\n",
       "      <td>0.4012987017631531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td rowspan=\"2\" valign=\"top\">HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_1</td>\n",
       "      <td>Final test loss</td>\n",
       "      <td>0.9833228082609005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Final test AUC</td>\n",
       "      <td>0.7488732933998108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td rowspan=\"2\" valign=\"top\">HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_168</td>\n",
       "      <td>Final test AUC</td>\n",
       "      <td>0.5023971796035767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Final test accuracy</td>\n",
       "      <td>0.5048107504844666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td rowspan=\"3\" valign=\"top\">HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169</td>\n",
       "      <td>Final test loss</td>\n",
       "      <td>1.6155616476873773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Final test AUC</td>\n",
       "      <td>0.4989795684814453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Final test accuracy</td>\n",
       "      <td>0.19553326070308685</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1923 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                size\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Final test loss       1.0703172176779956\n",
       "                                            Final test AUC        0.5924146175384521\n",
       "                                            Final test accuracy   0.4012987017631531\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_1   Final test loss       0.9833228082609005\n",
       "                                            Final test AUC        0.7488732933998108\n",
       "...                                                                              ...\n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_168 Final test AUC        0.5023971796035767\n",
       "                                            Final test accuracy   0.5048107504844666\n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169 Final test loss       1.6155616476873773\n",
       "                                            Final test AUC        0.4989795684814453\n",
       "                                            Final test accuracy  0.19553326070308685\n",
       "\n",
       "[1923 rows x 1 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalMetrics_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "      <th>150</th>\n",
       "      <th>151</th>\n",
       "      <th>152</th>\n",
       "      <th>153</th>\n",
       "      <th>154</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td rowspan=\"5\" valign=\"top\">HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0</td>\n",
       "      <td>Loss</td>\n",
       "      <td>1.097134</td>\n",
       "      <td>1.089486</td>\n",
       "      <td>1.084925</td>\n",
       "      <td>1.082050</td>\n",
       "      <td>1.080157</td>\n",
       "      <td>1.078848</td>\n",
       "      <td>1.077901</td>\n",
       "      <td>1.077183</td>\n",
       "      <td>1.076617</td>\n",
       "      <td>1.076155</td>\n",
       "      <td>...</td>\n",
       "      <td>1.070333</td>\n",
       "      <td>1.070329</td>\n",
       "      <td>1.070325</td>\n",
       "      <td>1.070321</td>\n",
       "      <td>1.070317</td>\n",
       "      <td>1.070317</td>\n",
       "      <td>1.070317</td>\n",
       "      <td>1.070317</td>\n",
       "      <td>1.070317</td>\n",
       "      <td>1.070317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.357927</td>\n",
       "      <td>0.372786</td>\n",
       "      <td>0.380087</td>\n",
       "      <td>0.386206</td>\n",
       "      <td>0.388733</td>\n",
       "      <td>0.389996</td>\n",
       "      <td>0.391295</td>\n",
       "      <td>0.392629</td>\n",
       "      <td>0.393904</td>\n",
       "      <td>0.394478</td>\n",
       "      <td>...</td>\n",
       "      <td>0.401299</td>\n",
       "      <td>0.401381</td>\n",
       "      <td>0.401322</td>\n",
       "      <td>0.401275</td>\n",
       "      <td>0.401299</td>\n",
       "      <td>0.401299</td>\n",
       "      <td>0.401299</td>\n",
       "      <td>0.401299</td>\n",
       "      <td>0.401299</td>\n",
       "      <td>0.401299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>AUC</td>\n",
       "      <td>0.520483</td>\n",
       "      <td>0.533294</td>\n",
       "      <td>0.543315</td>\n",
       "      <td>0.550682</td>\n",
       "      <td>0.556136</td>\n",
       "      <td>0.560248</td>\n",
       "      <td>0.563450</td>\n",
       "      <td>0.566000</td>\n",
       "      <td>0.568082</td>\n",
       "      <td>0.569817</td>\n",
       "      <td>...</td>\n",
       "      <td>0.592322</td>\n",
       "      <td>0.592349</td>\n",
       "      <td>0.592375</td>\n",
       "      <td>0.592401</td>\n",
       "      <td>0.592426</td>\n",
       "      <td>0.592426</td>\n",
       "      <td>0.592426</td>\n",
       "      <td>0.592426</td>\n",
       "      <td>0.592426</td>\n",
       "      <td>0.592426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Train Loss</td>\n",
       "      <td>1.103421</td>\n",
       "      <td>1.092251</td>\n",
       "      <td>1.085799</td>\n",
       "      <td>1.081776</td>\n",
       "      <td>1.079140</td>\n",
       "      <td>1.077343</td>\n",
       "      <td>1.076068</td>\n",
       "      <td>1.075129</td>\n",
       "      <td>1.074413</td>\n",
       "      <td>1.073847</td>\n",
       "      <td>...</td>\n",
       "      <td>1.067931</td>\n",
       "      <td>1.067927</td>\n",
       "      <td>1.067922</td>\n",
       "      <td>1.067918</td>\n",
       "      <td>1.067913</td>\n",
       "      <td>1.067913</td>\n",
       "      <td>1.067913</td>\n",
       "      <td>1.067913</td>\n",
       "      <td>1.067913</td>\n",
       "      <td>1.067913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Train Accuracy</td>\n",
       "      <td>0.348293</td>\n",
       "      <td>0.370394</td>\n",
       "      <td>0.381516</td>\n",
       "      <td>0.386821</td>\n",
       "      <td>0.390184</td>\n",
       "      <td>0.392238</td>\n",
       "      <td>0.393292</td>\n",
       "      <td>0.394232</td>\n",
       "      <td>0.395504</td>\n",
       "      <td>0.396163</td>\n",
       "      <td>...</td>\n",
       "      <td>0.407098</td>\n",
       "      <td>0.407139</td>\n",
       "      <td>0.407136</td>\n",
       "      <td>0.407177</td>\n",
       "      <td>0.407191</td>\n",
       "      <td>0.407191</td>\n",
       "      <td>0.407191</td>\n",
       "      <td>0.407191</td>\n",
       "      <td>0.407191</td>\n",
       "      <td>0.407191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td rowspan=\"5\" valign=\"top\">HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169</td>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.196420</td>\n",
       "      <td>0.195965</td>\n",
       "      <td>0.195393</td>\n",
       "      <td>0.194752</td>\n",
       "      <td>0.194052</td>\n",
       "      <td>0.193772</td>\n",
       "      <td>0.194320</td>\n",
       "      <td>0.194624</td>\n",
       "      <td>0.194764</td>\n",
       "      <td>0.195335</td>\n",
       "      <td>...</td>\n",
       "      <td>0.195592</td>\n",
       "      <td>0.195673</td>\n",
       "      <td>0.195673</td>\n",
       "      <td>0.195533</td>\n",
       "      <td>0.195533</td>\n",
       "      <td>0.195533</td>\n",
       "      <td>0.195533</td>\n",
       "      <td>0.195533</td>\n",
       "      <td>0.195533</td>\n",
       "      <td>0.195533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>AUC</td>\n",
       "      <td>0.498032</td>\n",
       "      <td>0.498719</td>\n",
       "      <td>0.498959</td>\n",
       "      <td>0.499100</td>\n",
       "      <td>0.499201</td>\n",
       "      <td>0.499279</td>\n",
       "      <td>0.499350</td>\n",
       "      <td>0.499412</td>\n",
       "      <td>0.499474</td>\n",
       "      <td>0.499528</td>\n",
       "      <td>...</td>\n",
       "      <td>0.499037</td>\n",
       "      <td>0.499022</td>\n",
       "      <td>0.499007</td>\n",
       "      <td>0.498993</td>\n",
       "      <td>0.498978</td>\n",
       "      <td>0.498978</td>\n",
       "      <td>0.498978</td>\n",
       "      <td>0.498978</td>\n",
       "      <td>0.498978</td>\n",
       "      <td>0.498978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Train Loss</td>\n",
       "      <td>27.245023</td>\n",
       "      <td>24.507504</td>\n",
       "      <td>22.095238</td>\n",
       "      <td>19.988227</td>\n",
       "      <td>18.149702</td>\n",
       "      <td>16.543524</td>\n",
       "      <td>15.139264</td>\n",
       "      <td>13.911686</td>\n",
       "      <td>12.839479</td>\n",
       "      <td>11.904266</td>\n",
       "      <td>...</td>\n",
       "      <td>2.535947</td>\n",
       "      <td>2.523146</td>\n",
       "      <td>2.510520</td>\n",
       "      <td>2.498068</td>\n",
       "      <td>2.485785</td>\n",
       "      <td>2.485785</td>\n",
       "      <td>2.485785</td>\n",
       "      <td>2.485785</td>\n",
       "      <td>2.485785</td>\n",
       "      <td>2.485785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Train Accuracy</td>\n",
       "      <td>0.196710</td>\n",
       "      <td>0.196640</td>\n",
       "      <td>0.196341</td>\n",
       "      <td>0.196336</td>\n",
       "      <td>0.196248</td>\n",
       "      <td>0.196330</td>\n",
       "      <td>0.196661</td>\n",
       "      <td>0.197103</td>\n",
       "      <td>0.197493</td>\n",
       "      <td>0.197821</td>\n",
       "      <td>...</td>\n",
       "      <td>0.199241</td>\n",
       "      <td>0.199253</td>\n",
       "      <td>0.199227</td>\n",
       "      <td>0.199297</td>\n",
       "      <td>0.199192</td>\n",
       "      <td>0.199192</td>\n",
       "      <td>0.199192</td>\n",
       "      <td>0.199192</td>\n",
       "      <td>0.199192</td>\n",
       "      <td>0.199192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Train AUC</td>\n",
       "      <td>0.505100</td>\n",
       "      <td>0.500372</td>\n",
       "      <td>0.499929</td>\n",
       "      <td>0.499766</td>\n",
       "      <td>0.499693</td>\n",
       "      <td>0.499662</td>\n",
       "      <td>0.499652</td>\n",
       "      <td>0.499658</td>\n",
       "      <td>0.499674</td>\n",
       "      <td>0.499695</td>\n",
       "      <td>...</td>\n",
       "      <td>0.499045</td>\n",
       "      <td>0.499030</td>\n",
       "      <td>0.499015</td>\n",
       "      <td>0.499001</td>\n",
       "      <td>0.498986</td>\n",
       "      <td>0.498986</td>\n",
       "      <td>0.498986</td>\n",
       "      <td>0.498986</td>\n",
       "      <td>0.498986</td>\n",
       "      <td>0.498986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3846 rows × 155 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                    0  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss             1.097134   \n",
       "                                            Accuracy         0.357927   \n",
       "                                            AUC              0.520483   \n",
       "                                            Train Loss       1.103421   \n",
       "                                            Train Accuracy   0.348293   \n",
       "...                                                               ...   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169 Accuracy         0.196420   \n",
       "                                            AUC              0.498032   \n",
       "                                            Train Loss      27.245023   \n",
       "                                            Train Accuracy   0.196710   \n",
       "                                            Train AUC        0.505100   \n",
       "\n",
       "                                                                    1  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss             1.089486   \n",
       "                                            Accuracy         0.372786   \n",
       "                                            AUC              0.533294   \n",
       "                                            Train Loss       1.092251   \n",
       "                                            Train Accuracy   0.370394   \n",
       "...                                                               ...   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169 Accuracy         0.195965   \n",
       "                                            AUC              0.498719   \n",
       "                                            Train Loss      24.507504   \n",
       "                                            Train Accuracy   0.196640   \n",
       "                                            Train AUC        0.500372   \n",
       "\n",
       "                                                                    2  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss             1.084925   \n",
       "                                            Accuracy         0.380087   \n",
       "                                            AUC              0.543315   \n",
       "                                            Train Loss       1.085799   \n",
       "                                            Train Accuracy   0.381516   \n",
       "...                                                               ...   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169 Accuracy         0.195393   \n",
       "                                            AUC              0.498959   \n",
       "                                            Train Loss      22.095238   \n",
       "                                            Train Accuracy   0.196341   \n",
       "                                            Train AUC        0.499929   \n",
       "\n",
       "                                                                    3  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss             1.082050   \n",
       "                                            Accuracy         0.386206   \n",
       "                                            AUC              0.550682   \n",
       "                                            Train Loss       1.081776   \n",
       "                                            Train Accuracy   0.386821   \n",
       "...                                                               ...   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169 Accuracy         0.194752   \n",
       "                                            AUC              0.499100   \n",
       "                                            Train Loss      19.988227   \n",
       "                                            Train Accuracy   0.196336   \n",
       "                                            Train AUC        0.499766   \n",
       "\n",
       "                                                                    4  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss             1.080157   \n",
       "                                            Accuracy         0.388733   \n",
       "                                            AUC              0.556136   \n",
       "                                            Train Loss       1.079140   \n",
       "                                            Train Accuracy   0.390184   \n",
       "...                                                               ...   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169 Accuracy         0.194052   \n",
       "                                            AUC              0.499201   \n",
       "                                            Train Loss      18.149702   \n",
       "                                            Train Accuracy   0.196248   \n",
       "                                            Train AUC        0.499693   \n",
       "\n",
       "                                                                    5  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss             1.078848   \n",
       "                                            Accuracy         0.389996   \n",
       "                                            AUC              0.560248   \n",
       "                                            Train Loss       1.077343   \n",
       "                                            Train Accuracy   0.392238   \n",
       "...                                                               ...   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169 Accuracy         0.193772   \n",
       "                                            AUC              0.499279   \n",
       "                                            Train Loss      16.543524   \n",
       "                                            Train Accuracy   0.196330   \n",
       "                                            Train AUC        0.499662   \n",
       "\n",
       "                                                                    6  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss             1.077901   \n",
       "                                            Accuracy         0.391295   \n",
       "                                            AUC              0.563450   \n",
       "                                            Train Loss       1.076068   \n",
       "                                            Train Accuracy   0.393292   \n",
       "...                                                               ...   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169 Accuracy         0.194320   \n",
       "                                            AUC              0.499350   \n",
       "                                            Train Loss      15.139264   \n",
       "                                            Train Accuracy   0.196661   \n",
       "                                            Train AUC        0.499652   \n",
       "\n",
       "                                                                    7  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss             1.077183   \n",
       "                                            Accuracy         0.392629   \n",
       "                                            AUC              0.566000   \n",
       "                                            Train Loss       1.075129   \n",
       "                                            Train Accuracy   0.394232   \n",
       "...                                                               ...   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169 Accuracy         0.194624   \n",
       "                                            AUC              0.499412   \n",
       "                                            Train Loss      13.911686   \n",
       "                                            Train Accuracy   0.197103   \n",
       "                                            Train AUC        0.499658   \n",
       "\n",
       "                                                                    8  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss             1.076617   \n",
       "                                            Accuracy         0.393904   \n",
       "                                            AUC              0.568082   \n",
       "                                            Train Loss       1.074413   \n",
       "                                            Train Accuracy   0.395504   \n",
       "...                                                               ...   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169 Accuracy         0.194764   \n",
       "                                            AUC              0.499474   \n",
       "                                            Train Loss      12.839479   \n",
       "                                            Train Accuracy   0.197493   \n",
       "                                            Train AUC        0.499674   \n",
       "\n",
       "                                                                    9  ...  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss             1.076155  ...   \n",
       "                                            Accuracy         0.394478  ...   \n",
       "                                            AUC              0.569817  ...   \n",
       "                                            Train Loss       1.073847  ...   \n",
       "                                            Train Accuracy   0.396163  ...   \n",
       "...                                                               ...  ...   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169 Accuracy         0.195335  ...   \n",
       "                                            AUC              0.499528  ...   \n",
       "                                            Train Loss      11.904266  ...   \n",
       "                                            Train Accuracy   0.197821  ...   \n",
       "                                            Train AUC        0.499695  ...   \n",
       "\n",
       "                                                                 145  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss            1.070333   \n",
       "                                            Accuracy        0.401299   \n",
       "                                            AUC             0.592322   \n",
       "                                            Train Loss      1.067931   \n",
       "                                            Train Accuracy  0.407098   \n",
       "...                                                              ...   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169 Accuracy        0.195592   \n",
       "                                            AUC             0.499037   \n",
       "                                            Train Loss      2.535947   \n",
       "                                            Train Accuracy  0.199241   \n",
       "                                            Train AUC       0.499045   \n",
       "\n",
       "                                                                 146  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss            1.070329   \n",
       "                                            Accuracy        0.401381   \n",
       "                                            AUC             0.592349   \n",
       "                                            Train Loss      1.067927   \n",
       "                                            Train Accuracy  0.407139   \n",
       "...                                                              ...   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169 Accuracy        0.195673   \n",
       "                                            AUC             0.499022   \n",
       "                                            Train Loss      2.523146   \n",
       "                                            Train Accuracy  0.199253   \n",
       "                                            Train AUC       0.499030   \n",
       "\n",
       "                                                                 147  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss            1.070325   \n",
       "                                            Accuracy        0.401322   \n",
       "                                            AUC             0.592375   \n",
       "                                            Train Loss      1.067922   \n",
       "                                            Train Accuracy  0.407136   \n",
       "...                                                              ...   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169 Accuracy        0.195673   \n",
       "                                            AUC             0.499007   \n",
       "                                            Train Loss      2.510520   \n",
       "                                            Train Accuracy  0.199227   \n",
       "                                            Train AUC       0.499015   \n",
       "\n",
       "                                                                 148  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss            1.070321   \n",
       "                                            Accuracy        0.401275   \n",
       "                                            AUC             0.592401   \n",
       "                                            Train Loss      1.067918   \n",
       "                                            Train Accuracy  0.407177   \n",
       "...                                                              ...   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169 Accuracy        0.195533   \n",
       "                                            AUC             0.498993   \n",
       "                                            Train Loss      2.498068   \n",
       "                                            Train Accuracy  0.199297   \n",
       "                                            Train AUC       0.499001   \n",
       "\n",
       "                                                                 149  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss            1.070317   \n",
       "                                            Accuracy        0.401299   \n",
       "                                            AUC             0.592426   \n",
       "                                            Train Loss      1.067913   \n",
       "                                            Train Accuracy  0.407191   \n",
       "...                                                              ...   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169 Accuracy        0.195533   \n",
       "                                            AUC             0.498978   \n",
       "                                            Train Loss      2.485785   \n",
       "                                            Train Accuracy  0.199192   \n",
       "                                            Train AUC       0.498986   \n",
       "\n",
       "                                                                 150  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss            1.070317   \n",
       "                                            Accuracy        0.401299   \n",
       "                                            AUC             0.592426   \n",
       "                                            Train Loss      1.067913   \n",
       "                                            Train Accuracy  0.407191   \n",
       "...                                                              ...   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169 Accuracy        0.195533   \n",
       "                                            AUC             0.498978   \n",
       "                                            Train Loss      2.485785   \n",
       "                                            Train Accuracy  0.199192   \n",
       "                                            Train AUC       0.498986   \n",
       "\n",
       "                                                                 151  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss            1.070317   \n",
       "                                            Accuracy        0.401299   \n",
       "                                            AUC             0.592426   \n",
       "                                            Train Loss      1.067913   \n",
       "                                            Train Accuracy  0.407191   \n",
       "...                                                              ...   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169 Accuracy        0.195533   \n",
       "                                            AUC             0.498978   \n",
       "                                            Train Loss      2.485785   \n",
       "                                            Train Accuracy  0.199192   \n",
       "                                            Train AUC       0.498986   \n",
       "\n",
       "                                                                 152  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss            1.070317   \n",
       "                                            Accuracy        0.401299   \n",
       "                                            AUC             0.592426   \n",
       "                                            Train Loss      1.067913   \n",
       "                                            Train Accuracy  0.407191   \n",
       "...                                                              ...   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169 Accuracy        0.195533   \n",
       "                                            AUC             0.498978   \n",
       "                                            Train Loss      2.485785   \n",
       "                                            Train Accuracy  0.199192   \n",
       "                                            Train AUC       0.498986   \n",
       "\n",
       "                                                                 153       154  \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss            1.070317  1.070317  \n",
       "                                            Accuracy        0.401299  0.401299  \n",
       "                                            AUC             0.592426  0.592426  \n",
       "                                            Train Loss      1.067913  1.067913  \n",
       "                                            Train Accuracy  0.407191  0.407191  \n",
       "...                                                              ...       ...  \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_169 Accuracy        0.195533  0.195533  \n",
       "                                            AUC             0.498978  0.498978  \n",
       "                                            Train Loss      2.485785  2.485785  \n",
       "                                            Train Accuracy  0.199192  0.199192  \n",
       "                                            Train AUC       0.498986  0.498986  \n",
       "\n",
       "[3846 rows x 155 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runningMetrics_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attaching the last observation of each model, for each metric, to the parameters of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>batch-shuffle</th>\n",
       "      <th>batch-size</th>\n",
       "      <th>feature-lags</th>\n",
       "      <th>featureset</th>\n",
       "      <th>l2-penalty</th>\n",
       "      <th>l2-type</th>\n",
       "      <th>label-type</th>\n",
       "      <th>learning-rate</th>\n",
       "      <th>loss-from-logits</th>\n",
       "      <th>n-epochs</th>\n",
       "      <th>pastobs-in-percentage</th>\n",
       "      <th>pre-processing</th>\n",
       "      <th>id</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Train AUC</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Train Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>321</td>\n",
       "      <td>HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_321</td>\n",
       "      <td>0</td>\n",
       "      <td>3300</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>quantgau</td>\n",
       "      <td>d62b1e6b8d95_321</td>\n",
       "      <td>0.770243</td>\n",
       "      <td>0.609699</td>\n",
       "      <td>0.899017</td>\n",
       "      <td>0.770233</td>\n",
       "      <td>0.607270</td>\n",
       "      <td>0.892077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_57</td>\n",
       "      <td>1</td>\n",
       "      <td>3300</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>d62b1e6b8d95_57</td>\n",
       "      <td>0.769295</td>\n",
       "      <td>0.609793</td>\n",
       "      <td>1.025276</td>\n",
       "      <td>0.769279</td>\n",
       "      <td>0.607994</td>\n",
       "      <td>1.026104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>269</td>\n",
       "      <td>HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_269</td>\n",
       "      <td>1</td>\n",
       "      <td>21450</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>quantgau</td>\n",
       "      <td>d62b1e6b8d95_269</td>\n",
       "      <td>0.765728</td>\n",
       "      <td>0.609536</td>\n",
       "      <td>0.899042</td>\n",
       "      <td>0.765704</td>\n",
       "      <td>0.607570</td>\n",
       "      <td>0.898071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>281</td>\n",
       "      <td>HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_281</td>\n",
       "      <td>0</td>\n",
       "      <td>21450</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>pow</td>\n",
       "      <td>d62b1e6b8d95_281</td>\n",
       "      <td>0.758545</td>\n",
       "      <td>0.609978</td>\n",
       "      <td>0.906770</td>\n",
       "      <td>0.758532</td>\n",
       "      <td>0.605583</td>\n",
       "      <td>0.908269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_16</td>\n",
       "      <td>1</td>\n",
       "      <td>21450</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>quantgau</td>\n",
       "      <td>b36f03f5d186_16</td>\n",
       "      <td>0.757047</td>\n",
       "      <td>0.608576</td>\n",
       "      <td>1.034854</td>\n",
       "      <td>0.757034</td>\n",
       "      <td>0.606462</td>\n",
       "      <td>1.032217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>406</td>\n",
       "      <td>HD_914f915c-2cac-473e-bea5-c26e4c83673c_25</td>\n",
       "      <td>0</td>\n",
       "      <td>10725</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>minmax</td>\n",
       "      <td>c26e4c83673c_25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>434</td>\n",
       "      <td>HD_914f915c-2cac-473e-bea5-c26e4c83673c_53</td>\n",
       "      <td>1</td>\n",
       "      <td>3300</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>c26e4c83673c_53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>449</td>\n",
       "      <td>HD_914f915c-2cac-473e-bea5-c26e4c83673c_68</td>\n",
       "      <td>1</td>\n",
       "      <td>10725</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>quantgau</td>\n",
       "      <td>c26e4c83673c_68</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>483</td>\n",
       "      <td>HD_914f915c-2cac-473e-bea5-c26e4c83673c_102</td>\n",
       "      <td>0</td>\n",
       "      <td>21450</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>minmax</td>\n",
       "      <td>c26e4c83673c_102</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>654</td>\n",
       "      <td>HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_170</td>\n",
       "      <td>1</td>\n",
       "      <td>10725</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>std</td>\n",
       "      <td>b36f03f5d186_170</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>655 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          run_id batch-shuffle batch-size  \\\n",
       "321  HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_321             0       3300   \n",
       "57    HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_57             1       3300   \n",
       "269  HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_269             1      21450   \n",
       "281  HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_281             0      21450   \n",
       "500   HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_16             1      21450   \n",
       "..                                           ...           ...        ...   \n",
       "406   HD_914f915c-2cac-473e-bea5-c26e4c83673c_25             0      10725   \n",
       "434   HD_914f915c-2cac-473e-bea5-c26e4c83673c_53             1       3300   \n",
       "449   HD_914f915c-2cac-473e-bea5-c26e4c83673c_68             1      10725   \n",
       "483  HD_914f915c-2cac-473e-bea5-c26e4c83673c_102             0      21450   \n",
       "654  HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_170             1      10725   \n",
       "\n",
       "    feature-lags featureset l2-penalty l2-type label-type learning-rate  \\\n",
       "321            1          1       10.0       1          1        0.0001   \n",
       "57             3          2       0.01       0          3        0.0001   \n",
       "269            1          3    10000.0       2          2           0.1   \n",
       "281            1          3     1000.0       4          1          0.01   \n",
       "500            3          1        0.1       5          2           0.1   \n",
       "..           ...        ...        ...     ...        ...           ...   \n",
       "406            0          0       0.01       3          1         0.001   \n",
       "434            5          1      0.001       0          3        0.0001   \n",
       "449            5          2        0.1       0          3         0.001   \n",
       "483            3          0       10.0       6          3         0.001   \n",
       "654            1          3      0.001       5          1        0.0001   \n",
       "\n",
       "    loss-from-logits n-epochs pastobs-in-percentage pre-processing  \\\n",
       "321                0      150                     1       quantgau   \n",
       "57                 0      150                     0           None   \n",
       "269                0      150                     0       quantgau   \n",
       "281                0      150                     0            pow   \n",
       "500                1      150                     0       quantgau   \n",
       "..               ...      ...                   ...            ...   \n",
       "406                1      150                     1         minmax   \n",
       "434                1      150                     1           None   \n",
       "449                1      150                     0       quantgau   \n",
       "483                0      150                     0         minmax   \n",
       "654                0      150                     0            std   \n",
       "\n",
       "                   id       AUC  Accuracy      Loss  Train AUC  \\\n",
       "321  d62b1e6b8d95_321  0.770243  0.609699  0.899017   0.770233   \n",
       "57    d62b1e6b8d95_57  0.769295  0.609793  1.025276   0.769279   \n",
       "269  d62b1e6b8d95_269  0.765728  0.609536  0.899042   0.765704   \n",
       "281  d62b1e6b8d95_281  0.758545  0.609978  0.906770   0.758532   \n",
       "500   b36f03f5d186_16  0.757047  0.608576  1.034854   0.757034   \n",
       "..                ...       ...       ...       ...        ...   \n",
       "406   c26e4c83673c_25       NaN       NaN       NaN        NaN   \n",
       "434   c26e4c83673c_53       NaN       NaN       NaN        NaN   \n",
       "449   c26e4c83673c_68       NaN       NaN       NaN        NaN   \n",
       "483  c26e4c83673c_102       NaN       NaN       NaN        NaN   \n",
       "654  b36f03f5d186_170       NaN       NaN       NaN        NaN   \n",
       "\n",
       "     Train Accuracy  Train Loss  \n",
       "321        0.607270    0.892077  \n",
       "57         0.607994    1.026104  \n",
       "269        0.607570    0.898071  \n",
       "281        0.605583    0.908269  \n",
       "500        0.606462    1.032217  \n",
       "..              ...         ...  \n",
       "406             NaN         NaN  \n",
       "434             NaN         NaN  \n",
       "449             NaN         NaN  \n",
       "483             NaN         NaN  \n",
       "654             NaN         NaN  \n",
       "\n",
       "[655 rows x 20 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Resetting indcies and rename columns\n",
    "runningMetrics_lr2 = runningMetrics_lr.reset_index().rename(columns={'level_0':'run_id','level_1':'metric'})\n",
    "runningMetrics_lr2.columns = runningMetrics_lr2.columns.get_level_values(0)\n",
    "\n",
    "## Adding a column of short ids, to merge on.\n",
    "runningMetrics_lr2['id'] = [re.split('-',i)[-1] for i in runningMetrics_lr2.run_id] #np.arange(runningMetrics_lr2.shape[0]).astype(str)#\n",
    "runningMetrics_lr2\n",
    "\n",
    "# ## Creating a table, having the short id in the rows and the last observation for each metric in the columns. \n",
    "table_lr = pd.pivot_table(runningMetrics_lr2[['run_id','metric','154','id']],index='id',columns=['metric'])\n",
    "table_lr.columns = table_lr.columns.get_level_values(1)\n",
    "table_lr = table_lr.round(7).reset_index()\n",
    "table_lr\n",
    "\n",
    "## Preparing the parameter dataframe.\n",
    "parameters_lr2 = parameters_lr.reset_index().rename(columns={'index':'run_id'})\n",
    "\n",
    "## Setting short ID\n",
    "parameters_lr2['id'] = [re.split('-',i)[-1] for i in parameters_lr2.run_id] #np.arange(parameters_lr2.shape[0]).astype(str) #[re.split('_',i)[-1] for i in parameters_lr.run_id]\n",
    "\n",
    "## Creating the combined table\n",
    "combined_table_lr = parameters_lr2.merge(table_lr,\n",
    "                                     on = 'id',\n",
    "                                     how='left').sort_values('AUC',ascending=False)\n",
    "combined_table_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>batch-shuffle</th>\n",
       "      <th>batch-size</th>\n",
       "      <th>feature-lags</th>\n",
       "      <th>featureset</th>\n",
       "      <th>l2-penalty</th>\n",
       "      <th>l2-type</th>\n",
       "      <th>label-type</th>\n",
       "      <th>learning-rate</th>\n",
       "      <th>loss-from-logits</th>\n",
       "      <th>n-epochs</th>\n",
       "      <th>pastobs-in-percentage</th>\n",
       "      <th>pre-processing</th>\n",
       "      <th>id</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Train AUC</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Train Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_380</td>\n",
       "      <td>1</td>\n",
       "      <td>3300</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>std</td>\n",
       "      <td>d62b1e6b8d95_380</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>386</td>\n",
       "      <td>HD_914f915c-2cac-473e-bea5-c26e4c83673c_5</td>\n",
       "      <td>1</td>\n",
       "      <td>21450</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>quantgau</td>\n",
       "      <td>c26e4c83673c_5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>389</td>\n",
       "      <td>HD_914f915c-2cac-473e-bea5-c26e4c83673c_8</td>\n",
       "      <td>1</td>\n",
       "      <td>3300</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>quantgau</td>\n",
       "      <td>c26e4c83673c_8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>HD_914f915c-2cac-473e-bea5-c26e4c83673c_9</td>\n",
       "      <td>0</td>\n",
       "      <td>21450</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>minmax</td>\n",
       "      <td>c26e4c83673c_9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>392</td>\n",
       "      <td>HD_914f915c-2cac-473e-bea5-c26e4c83673c_11</td>\n",
       "      <td>1</td>\n",
       "      <td>3300</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10000000000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>stacked</td>\n",
       "      <td>c26e4c83673c_11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>393</td>\n",
       "      <td>HD_914f915c-2cac-473e-bea5-c26e4c83673c_12</td>\n",
       "      <td>1</td>\n",
       "      <td>10725</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>stacked</td>\n",
       "      <td>c26e4c83673c_12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>396</td>\n",
       "      <td>HD_914f915c-2cac-473e-bea5-c26e4c83673c_15</td>\n",
       "      <td>0</td>\n",
       "      <td>10725</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>pow</td>\n",
       "      <td>c26e4c83673c_15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>397</td>\n",
       "      <td>HD_914f915c-2cac-473e-bea5-c26e4c83673c_16</td>\n",
       "      <td>1</td>\n",
       "      <td>3300</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>pow</td>\n",
       "      <td>c26e4c83673c_16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>HD_914f915c-2cac-473e-bea5-c26e4c83673c_19</td>\n",
       "      <td>1</td>\n",
       "      <td>3300</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>quantgau</td>\n",
       "      <td>c26e4c83673c_19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>406</td>\n",
       "      <td>HD_914f915c-2cac-473e-bea5-c26e4c83673c_25</td>\n",
       "      <td>0</td>\n",
       "      <td>10725</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>minmax</td>\n",
       "      <td>c26e4c83673c_25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>434</td>\n",
       "      <td>HD_914f915c-2cac-473e-bea5-c26e4c83673c_53</td>\n",
       "      <td>1</td>\n",
       "      <td>3300</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>c26e4c83673c_53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>449</td>\n",
       "      <td>HD_914f915c-2cac-473e-bea5-c26e4c83673c_68</td>\n",
       "      <td>1</td>\n",
       "      <td>10725</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>quantgau</td>\n",
       "      <td>c26e4c83673c_68</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>483</td>\n",
       "      <td>HD_914f915c-2cac-473e-bea5-c26e4c83673c_102</td>\n",
       "      <td>0</td>\n",
       "      <td>21450</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>minmax</td>\n",
       "      <td>c26e4c83673c_102</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>654</td>\n",
       "      <td>HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_170</td>\n",
       "      <td>1</td>\n",
       "      <td>10725</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>std</td>\n",
       "      <td>b36f03f5d186_170</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          run_id batch-shuffle batch-size  \\\n",
       "380  HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_380             1       3300   \n",
       "386    HD_914f915c-2cac-473e-bea5-c26e4c83673c_5             1      21450   \n",
       "389    HD_914f915c-2cac-473e-bea5-c26e4c83673c_8             1       3300   \n",
       "390    HD_914f915c-2cac-473e-bea5-c26e4c83673c_9             0      21450   \n",
       "392   HD_914f915c-2cac-473e-bea5-c26e4c83673c_11             1       3300   \n",
       "393   HD_914f915c-2cac-473e-bea5-c26e4c83673c_12             1      10725   \n",
       "396   HD_914f915c-2cac-473e-bea5-c26e4c83673c_15             0      10725   \n",
       "397   HD_914f915c-2cac-473e-bea5-c26e4c83673c_16             1       3300   \n",
       "400   HD_914f915c-2cac-473e-bea5-c26e4c83673c_19             1       3300   \n",
       "406   HD_914f915c-2cac-473e-bea5-c26e4c83673c_25             0      10725   \n",
       "434   HD_914f915c-2cac-473e-bea5-c26e4c83673c_53             1       3300   \n",
       "449   HD_914f915c-2cac-473e-bea5-c26e4c83673c_68             1      10725   \n",
       "483  HD_914f915c-2cac-473e-bea5-c26e4c83673c_102             0      21450   \n",
       "654  HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_170             1      10725   \n",
       "\n",
       "    feature-lags featureset     l2-penalty l2-type label-type learning-rate  \\\n",
       "380            1          1          100.0       3          3        0.0001   \n",
       "386            1          3           0.01       1          0          0.01   \n",
       "389            3          2        10000.0       1          2           0.1   \n",
       "390            1          2           10.0       0          0          0.01   \n",
       "392            1          0  10000000000.0       1          1         0.001   \n",
       "393            3          2          100.0       2          1           0.1   \n",
       "396            3          3        10000.0       5          2        0.0001   \n",
       "397            1          3        10000.0       4          2         0.001   \n",
       "400            5          0         1000.0       5          1         0.001   \n",
       "406            0          0           0.01       3          1         0.001   \n",
       "434            5          1          0.001       0          3        0.0001   \n",
       "449            5          2            0.1       0          3         0.001   \n",
       "483            3          0           10.0       6          3         0.001   \n",
       "654            1          3          0.001       5          1        0.0001   \n",
       "\n",
       "    loss-from-logits n-epochs pastobs-in-percentage pre-processing  \\\n",
       "380                0      150                     0            std   \n",
       "386                0      150                     0       quantgau   \n",
       "389                1      150                     0       quantgau   \n",
       "390                1      150                     1         minmax   \n",
       "392                0      150                     1        stacked   \n",
       "393                0      150                     0        stacked   \n",
       "396                1      150                     1            pow   \n",
       "397                0      150                     0            pow   \n",
       "400                0      150                     0       quantgau   \n",
       "406                1      150                     1         minmax   \n",
       "434                1      150                     1           None   \n",
       "449                1      150                     0       quantgau   \n",
       "483                0      150                     0         minmax   \n",
       "654                0      150                     0            std   \n",
       "\n",
       "                   id  AUC  Accuracy  Loss  Train AUC  Train Accuracy  \\\n",
       "380  d62b1e6b8d95_380  NaN       NaN   NaN        NaN             NaN   \n",
       "386    c26e4c83673c_5  NaN       NaN   NaN        NaN             NaN   \n",
       "389    c26e4c83673c_8  NaN       NaN   NaN        NaN             NaN   \n",
       "390    c26e4c83673c_9  NaN       NaN   NaN        NaN             NaN   \n",
       "392   c26e4c83673c_11  NaN       NaN   NaN        NaN             NaN   \n",
       "393   c26e4c83673c_12  NaN       NaN   NaN        NaN             NaN   \n",
       "396   c26e4c83673c_15  NaN       NaN   NaN        NaN             NaN   \n",
       "397   c26e4c83673c_16  NaN       NaN   NaN        NaN             NaN   \n",
       "400   c26e4c83673c_19  NaN       NaN   NaN        NaN             NaN   \n",
       "406   c26e4c83673c_25  NaN       NaN   NaN        NaN             NaN   \n",
       "434   c26e4c83673c_53  NaN       NaN   NaN        NaN             NaN   \n",
       "449   c26e4c83673c_68  NaN       NaN   NaN        NaN             NaN   \n",
       "483  c26e4c83673c_102  NaN       NaN   NaN        NaN             NaN   \n",
       "654  b36f03f5d186_170  NaN       NaN   NaN        NaN             NaN   \n",
       "\n",
       "     Train Loss  \n",
       "380         NaN  \n",
       "386         NaN  \n",
       "389         NaN  \n",
       "390         NaN  \n",
       "392         NaN  \n",
       "393         NaN  \n",
       "396         NaN  \n",
       "397         NaN  \n",
       "400         NaN  \n",
       "406         NaN  \n",
       "434         NaN  \n",
       "449         NaN  \n",
       "483         NaN  \n",
       "654         NaN  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## How many NaN rows?\n",
    "print(len(combined_table_lr[combined_table_lr.isnull().any(axis=1)]))\n",
    "# 14 in total: 12 from run 881, 1 (last child run) from run 985 , 1 (last child run) from run 453\n",
    "# HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_380 doesn't exist in the experiment window in Azure, looks like it was initialised but not run (hyperparams file has it, metrics file does not)\n",
    "# HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_170 doesn't exist in the experiment window in Azure, looks like it was initialised but not run (hyperparams file has it, metrics file does not)\n",
    "# HD_914f915c-2cac-473e-bea5-c26e4c83673c has 11x NaNs because they failed (but metrics file does have all except _84! so they are included)\n",
    "# the 12 missed runs seems to be an error\n",
    "combined_table_lr[combined_table_lr.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating a top-X table for each label-type of a given metric, here AUC.\n",
    "temp_auc_lr = pd.pivot_table(combined_table_lr[['label-type','AUC','id']],index='id',columns='label-type')\n",
    "temp_acc_lr = pd.pivot_table(combined_table_lr[['label-type','Accuracy','id']],index='id',columns='label-type')\n",
    "\n",
    "## Final output - AUC\n",
    "final_output_auc_lr = pd.DataFrame(np.sort(temp_auc_lr.fillna(0).values,\n",
    "                             axis=0)[::-1],\n",
    "                             columns=temp_auc_lr.columns.get_level_values(1)).loc[0:10]\n",
    "## Final output - Accuracy\n",
    "final_output_acc_lr = pd.DataFrame(np.sort(temp_acc_lr.fillna(0).values,\n",
    "                             axis=0)[::-1],\n",
    "                             columns=temp_acc_lr.columns.get_level_values(1))#.loc[0:10]\n",
    "# final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>batch-shuffle</th>\n",
       "      <th>batch-size</th>\n",
       "      <th>feature-lags</th>\n",
       "      <th>featureset</th>\n",
       "      <th>l2-penalty</th>\n",
       "      <th>l2-type</th>\n",
       "      <th>label-type</th>\n",
       "      <th>learning-rate</th>\n",
       "      <th>loss-from-logits</th>\n",
       "      <th>n-epochs</th>\n",
       "      <th>pastobs-in-percentage</th>\n",
       "      <th>pre-processing</th>\n",
       "      <th>id</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Train AUC</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Train Loss</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label-type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_321</td>\n",
       "      <td>0</td>\n",
       "      <td>3300</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>quantgau</td>\n",
       "      <td>d62b1e6b8d95_321</td>\n",
       "      <td>0.770243</td>\n",
       "      <td>0.609699</td>\n",
       "      <td>0.899017</td>\n",
       "      <td>0.770233</td>\n",
       "      <td>0.607270</td>\n",
       "      <td>0.892077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_57</td>\n",
       "      <td>1</td>\n",
       "      <td>3300</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>d62b1e6b8d95_57</td>\n",
       "      <td>0.769295</td>\n",
       "      <td>0.609793</td>\n",
       "      <td>1.025276</td>\n",
       "      <td>0.769279</td>\n",
       "      <td>0.607994</td>\n",
       "      <td>1.026104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_269</td>\n",
       "      <td>1</td>\n",
       "      <td>21450</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>quantgau</td>\n",
       "      <td>d62b1e6b8d95_269</td>\n",
       "      <td>0.765728</td>\n",
       "      <td>0.609536</td>\n",
       "      <td>0.899042</td>\n",
       "      <td>0.765704</td>\n",
       "      <td>0.607570</td>\n",
       "      <td>0.898071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_330</td>\n",
       "      <td>0</td>\n",
       "      <td>10725</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>d62b1e6b8d95_330</td>\n",
       "      <td>0.743810</td>\n",
       "      <td>0.605753</td>\n",
       "      <td>0.923442</td>\n",
       "      <td>0.743768</td>\n",
       "      <td>0.601687</td>\n",
       "      <td>0.919710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_54</td>\n",
       "      <td>0</td>\n",
       "      <td>21450</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>std</td>\n",
       "      <td>d62b1e6b8d95_54</td>\n",
       "      <td>0.736580</td>\n",
       "      <td>0.605878</td>\n",
       "      <td>0.998291</td>\n",
       "      <td>0.736546</td>\n",
       "      <td>0.599142</td>\n",
       "      <td>0.948503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 run_id batch-shuffle  \\\n",
       "label-type                                                              \n",
       "1           HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_321             0   \n",
       "3            HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_57             1   \n",
       "2           HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_269             1   \n",
       "0           HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_330             0   \n",
       "4            HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_54             0   \n",
       "\n",
       "           batch-size feature-lags featureset l2-penalty l2-type label-type  \\\n",
       "label-type                                                                    \n",
       "1                3300            1          1       10.0       1          1   \n",
       "3                3300            3          2       0.01       0          3   \n",
       "2               21450            1          3    10000.0       2          2   \n",
       "0               10725            5          3       10.0       2          0   \n",
       "4               21450            0          3    10000.0       1          4   \n",
       "\n",
       "           learning-rate loss-from-logits n-epochs pastobs-in-percentage  \\\n",
       "label-type                                                                 \n",
       "1                 0.0001                0      150                     1   \n",
       "3                 0.0001                0      150                     0   \n",
       "2                    0.1                0      150                     0   \n",
       "0                  0.001                1      150                     1   \n",
       "4                   0.01                1      150                     1   \n",
       "\n",
       "           pre-processing                id       AUC  Accuracy      Loss  \\\n",
       "label-type                                                                  \n",
       "1                quantgau  d62b1e6b8d95_321  0.770243  0.609699  0.899017   \n",
       "3                    None   d62b1e6b8d95_57  0.769295  0.609793  1.025276   \n",
       "2                quantgau  d62b1e6b8d95_269  0.765728  0.609536  0.899042   \n",
       "0                    None  d62b1e6b8d95_330  0.743810  0.605753  0.923442   \n",
       "4                     std   d62b1e6b8d95_54  0.736580  0.605878  0.998291   \n",
       "\n",
       "            Train AUC  Train Accuracy  Train Loss  \n",
       "label-type                                         \n",
       "1            0.770233        0.607270    0.892077  \n",
       "3            0.769279        0.607994    1.026104  \n",
       "2            0.765704        0.607570    0.898071  \n",
       "0            0.743768        0.601687    0.919710  \n",
       "4            0.736546        0.599142    0.948503  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tempFinal_v0_lr = combined_table_lr[np.isin(combined_table_lr.AUC,final_output_auc_lr.loc[0].values.flatten())]\n",
    "tempFinal_v0_lr.index = tempFinal_v0_lr.loc[:,'label-type']\n",
    "tempFinal_v0_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>label-type</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.743810</td>\n",
       "      <td>0.770243</td>\n",
       "      <td>0.765728</td>\n",
       "      <td>0.769295</td>\n",
       "      <td>0.736580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.721774</td>\n",
       "      <td>0.758545</td>\n",
       "      <td>0.757047</td>\n",
       "      <td>0.744937</td>\n",
       "      <td>0.724654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.714000</td>\n",
       "      <td>0.750477</td>\n",
       "      <td>0.748841</td>\n",
       "      <td>0.698706</td>\n",
       "      <td>0.724517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.679195</td>\n",
       "      <td>0.743498</td>\n",
       "      <td>0.746708</td>\n",
       "      <td>0.694823</td>\n",
       "      <td>0.711150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.671642</td>\n",
       "      <td>0.734464</td>\n",
       "      <td>0.730215</td>\n",
       "      <td>0.671782</td>\n",
       "      <td>0.711061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.640807</td>\n",
       "      <td>0.715505</td>\n",
       "      <td>0.724101</td>\n",
       "      <td>0.654014</td>\n",
       "      <td>0.710338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.638079</td>\n",
       "      <td>0.713154</td>\n",
       "      <td>0.721513</td>\n",
       "      <td>0.639567</td>\n",
       "      <td>0.702422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.630913</td>\n",
       "      <td>0.709437</td>\n",
       "      <td>0.719707</td>\n",
       "      <td>0.572875</td>\n",
       "      <td>0.698800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.630850</td>\n",
       "      <td>0.684589</td>\n",
       "      <td>0.711174</td>\n",
       "      <td>0.547524</td>\n",
       "      <td>0.684616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.625526</td>\n",
       "      <td>0.675148</td>\n",
       "      <td>0.700884</td>\n",
       "      <td>0.547256</td>\n",
       "      <td>0.679712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.624141</td>\n",
       "      <td>0.669039</td>\n",
       "      <td>0.698419</td>\n",
       "      <td>0.544227</td>\n",
       "      <td>0.673169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "label-type         0         1         2         3         4\n",
       "0           0.743810  0.770243  0.765728  0.769295  0.736580\n",
       "1           0.721774  0.758545  0.757047  0.744937  0.724654\n",
       "2           0.714000  0.750477  0.748841  0.698706  0.724517\n",
       "3           0.679195  0.743498  0.746708  0.694823  0.711150\n",
       "4           0.671642  0.734464  0.730215  0.671782  0.711061\n",
       "5           0.640807  0.715505  0.724101  0.654014  0.710338\n",
       "6           0.638079  0.713154  0.721513  0.639567  0.702422\n",
       "7           0.630913  0.709437  0.719707  0.572875  0.698800\n",
       "8           0.630850  0.684589  0.711174  0.547524  0.684616\n",
       "9           0.625526  0.675148  0.700884  0.547256  0.679712\n",
       "10          0.624141  0.669039  0.698419  0.544227  0.673169"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_output_auc_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label-type\n",
       "0    0.609582\n",
       "1    0.609978\n",
       "2    0.610655\n",
       "3    0.609793\n",
       "4    0.606345\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_output_acc_lr.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>batch-shuffle</th>\n",
       "      <th>batch-size</th>\n",
       "      <th>feature-lags</th>\n",
       "      <th>featureset</th>\n",
       "      <th>l2-penalty</th>\n",
       "      <th>l2-type</th>\n",
       "      <th>label-type</th>\n",
       "      <th>learning-rate</th>\n",
       "      <th>loss-from-logits</th>\n",
       "      <th>n-epochs</th>\n",
       "      <th>pastobs-in-percentage</th>\n",
       "      <th>pre-processing</th>\n",
       "      <th>id</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Train AUC</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Train Loss</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label-type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_73</td>\n",
       "      <td>0</td>\n",
       "      <td>21450</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>std</td>\n",
       "      <td>d62b1e6b8d95_73</td>\n",
       "      <td>0.104320</td>\n",
       "      <td>0.609582</td>\n",
       "      <td>0.896365</td>\n",
       "      <td>0.104317</td>\n",
       "      <td>0.606454</td>\n",
       "      <td>0.900158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_281</td>\n",
       "      <td>0</td>\n",
       "      <td>21450</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>pow</td>\n",
       "      <td>d62b1e6b8d95_281</td>\n",
       "      <td>0.758545</td>\n",
       "      <td>0.609978</td>\n",
       "      <td>0.906770</td>\n",
       "      <td>0.758532</td>\n",
       "      <td>0.605583</td>\n",
       "      <td>0.908269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_1</td>\n",
       "      <td>0</td>\n",
       "      <td>3300</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>quantgau</td>\n",
       "      <td>d62b1e6b8d95_1</td>\n",
       "      <td>0.748841</td>\n",
       "      <td>0.610655</td>\n",
       "      <td>1.028220</td>\n",
       "      <td>0.748771</td>\n",
       "      <td>0.608715</td>\n",
       "      <td>1.028798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_57</td>\n",
       "      <td>1</td>\n",
       "      <td>3300</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>d62b1e6b8d95_57</td>\n",
       "      <td>0.769295</td>\n",
       "      <td>0.609793</td>\n",
       "      <td>1.025276</td>\n",
       "      <td>0.769279</td>\n",
       "      <td>0.607994</td>\n",
       "      <td>1.026104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_43</td>\n",
       "      <td>1</td>\n",
       "      <td>21450</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10000000000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>quantgau</td>\n",
       "      <td>d62b1e6b8d95_43</td>\n",
       "      <td>0.679712</td>\n",
       "      <td>0.606345</td>\n",
       "      <td>1.030533</td>\n",
       "      <td>0.679452</td>\n",
       "      <td>0.602908</td>\n",
       "      <td>1.031799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 run_id batch-shuffle  \\\n",
       "label-type                                                              \n",
       "0            HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_73             0   \n",
       "1           HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_281             0   \n",
       "2             HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_1             0   \n",
       "3            HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_57             1   \n",
       "4            HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_43             1   \n",
       "\n",
       "           batch-size feature-lags featureset     l2-penalty l2-type  \\\n",
       "label-type                                                             \n",
       "0               21450            0          0          0.001       5   \n",
       "1               21450            1          3         1000.0       4   \n",
       "2                3300            1          2           10.0       1   \n",
       "3                3300            3          2           0.01       0   \n",
       "4               21450            1          3  10000000000.0       4   \n",
       "\n",
       "           label-type learning-rate loss-from-logits n-epochs  \\\n",
       "label-type                                                      \n",
       "0                   0         0.001                0      150   \n",
       "1                   1          0.01                0      150   \n",
       "2                   2           0.1                0      150   \n",
       "3                   3        0.0001                0      150   \n",
       "4                   4        0.0001                0      150   \n",
       "\n",
       "           pastobs-in-percentage pre-processing                id       AUC  \\\n",
       "label-type                                                                    \n",
       "0                              1            std   d62b1e6b8d95_73  0.104320   \n",
       "1                              0            pow  d62b1e6b8d95_281  0.758545   \n",
       "2                              1       quantgau    d62b1e6b8d95_1  0.748841   \n",
       "3                              0           None   d62b1e6b8d95_57  0.769295   \n",
       "4                              0       quantgau   d62b1e6b8d95_43  0.679712   \n",
       "\n",
       "            Accuracy      Loss  Train AUC  Train Accuracy  Train Loss  \n",
       "label-type                                                             \n",
       "0           0.609582  0.896365   0.104317        0.606454    0.900158  \n",
       "1           0.609978  0.906770   0.758532        0.605583    0.908269  \n",
       "2           0.610655  1.028220   0.748771        0.608715    1.028798  \n",
       "3           0.609793  1.025276   0.769279        0.607994    1.026104  \n",
       "4           0.606345  1.030533   0.679452        0.602908    1.031799  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tempFinal_v1_lr = combined_table_lr[np.isin(combined_table_lr.Accuracy,final_output_acc_lr.loc[0].values.flatten())].sort_values('label-type').copy(deep=True)\n",
    "tempFinal_v1_lr.index = tempFinal_v1_lr.loc[:,'label-type']\n",
    "tempFinal_v1_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['run_id',\n",
       " 'batch-shuffle',\n",
       " 'batch-size',\n",
       " 'feature-lags',\n",
       " 'featureset',\n",
       " 'l2-penalty',\n",
       " 'l2-type',\n",
       " 'label-type',\n",
       " 'learning-rate',\n",
       " 'loss-from-logits',\n",
       " 'n-epochs',\n",
       " 'pastobs-in-percentage',\n",
       " 'pre-processing',\n",
       " 'id',\n",
       " 'AUC',\n",
       " 'Accuracy',\n",
       " 'Loss',\n",
       " 'Train AUC',\n",
       " 'Train Accuracy',\n",
       " 'Train Loss']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(combined_table_lr.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp_lr = combined_table_lr[(combined_table_lr.loc[:,'label-type']=='0')&\\\n",
    "                            (combined_table_lr.loc[:,'loss-from-logits']=='1')&\\\n",
    "                            (combined_table_lr.AUC>0.5)]\n",
    "temp_2_lr = pd.pivot_table(temp_lr,\n",
    "                        values='AUC',\n",
    "                        columns='learning-rate',\n",
    "                        index='run_id').reset_index()\n",
    "temp_2_lr.boxplot(list(temp_2_lr.columns[1:]),\n",
    "                  figsize=(7,7))#temp_2.columns[2:]\n",
    "plt.grid(b=None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reading in the market data (done automatically atm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'8'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>spread_open</th>\n",
       "      <th>spread_high</th>\n",
       "      <th>spread_low</th>\n",
       "      <th>spread_close</th>\n",
       "      <th>bidsize_open</th>\n",
       "      <th>bidsize_high</th>\n",
       "      <th>bidsize_low</th>\n",
       "      <th>bidsize_close</th>\n",
       "      <th>ofrsize_open</th>\n",
       "      <th>ofrsize_high</th>\n",
       "      <th>ofrsize_low</th>\n",
       "      <th>ofrsize_close</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>sector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">20200501</th>\n",
       "      <th>0</th>\n",
       "      <td>286.250</td>\n",
       "      <td>289.260</td>\n",
       "      <td>285.870</td>\n",
       "      <td>289.260</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.24</td>\n",
       "      <td>6.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>289.260</td>\n",
       "      <td>289.350</td>\n",
       "      <td>288.365</td>\n",
       "      <td>289.020</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.10</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>289.035</td>\n",
       "      <td>289.705</td>\n",
       "      <td>288.280</td>\n",
       "      <td>288.580</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>288.485</td>\n",
       "      <td>289.315</td>\n",
       "      <td>288.280</td>\n",
       "      <td>289.095</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>289.100</td>\n",
       "      <td>290.435</td>\n",
       "      <td>288.940</td>\n",
       "      <td>290.320</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.10</td>\n",
       "      <td>13.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">20200529</th>\n",
       "      <th>385</th>\n",
       "      <td>91.500</td>\n",
       "      <td>91.755</td>\n",
       "      <td>91.485</td>\n",
       "      <td>91.740</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>XNTK</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>91.740</td>\n",
       "      <td>91.740</td>\n",
       "      <td>91.740</td>\n",
       "      <td>91.740</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>XNTK</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>91.580</td>\n",
       "      <td>91.830</td>\n",
       "      <td>91.580</td>\n",
       "      <td>91.715</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.45</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>XNTK</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>91.595</td>\n",
       "      <td>91.880</td>\n",
       "      <td>91.595</td>\n",
       "      <td>91.750</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.52</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>XNTK</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>46.005</td>\n",
       "      <td>46.005</td>\n",
       "      <td>45.815</td>\n",
       "      <td>45.815</td>\n",
       "      <td>92.01</td>\n",
       "      <td>92.01</td>\n",
       "      <td>91.63</td>\n",
       "      <td>91.63</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>XNTK</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>546000 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 open     high      low    close  spread_open  spread_high  \\\n",
       "20200501 0    286.250  289.260  285.870  289.260         0.50         0.50   \n",
       "         1    289.260  289.350  288.365  289.020         0.24         0.45   \n",
       "         2    289.035  289.705  288.280  288.580         0.07         0.49   \n",
       "         3    288.485  289.315  288.280  289.095         0.49         0.49   \n",
       "         4    289.100  290.435  288.940  290.320         0.16         0.33   \n",
       "...               ...      ...      ...      ...          ...          ...   \n",
       "20200529 385   91.500   91.755   91.485   91.740         0.42         0.93   \n",
       "         386   91.740   91.740   91.740   91.740         0.50         0.50   \n",
       "         387   91.580   91.830   91.580   91.715         0.18         0.68   \n",
       "         388   91.595   91.880   91.595   91.750         0.21         0.78   \n",
       "         389   46.005   46.005   45.815   45.815        92.01        92.01   \n",
       "\n",
       "              spread_low  spread_close  bidsize_open  bidsize_high  \\\n",
       "20200501 0          0.01          0.24           6.0          95.0   \n",
       "         1          0.01          0.10           9.0          20.0   \n",
       "         2          0.01          0.30           1.0          50.0   \n",
       "         3          0.01          0.17           1.0          25.0   \n",
       "         4          0.01          0.10          13.0          71.0   \n",
       "...                  ...           ...           ...           ...   \n",
       "20200529 385        0.39          0.50           5.0           5.0   \n",
       "         386        0.50          0.50           5.0           5.0   \n",
       "         387        0.18          0.45           5.0           5.0   \n",
       "         388        0.21          0.52           5.0           5.0   \n",
       "         389       91.63         91.63           0.0           0.0   \n",
       "\n",
       "              bidsize_low  bidsize_close  ofrsize_open  ofrsize_high  \\\n",
       "20200501 0            1.0           10.0           1.0          85.0   \n",
       "         1            1.0            1.0           4.0          56.0   \n",
       "         2            1.0            1.0           1.0          13.0   \n",
       "         3            1.0           16.0           1.0           8.0   \n",
       "         4            1.0            1.0           1.0         236.0   \n",
       "...                   ...            ...           ...           ...   \n",
       "20200529 385          5.0            5.0           1.0           5.0   \n",
       "         386          5.0            5.0           5.0           5.0   \n",
       "         387          5.0            5.0           1.0           5.0   \n",
       "         388          5.0            5.0           1.0           5.0   \n",
       "         389          0.0            0.0           5.0           5.0   \n",
       "\n",
       "              ofrsize_low  ofrsize_close Ticker      sector  \n",
       "20200501 0            1.0            4.0   AAPL  Technology  \n",
       "         1            1.0            1.0   AAPL  Technology  \n",
       "         2            1.0            1.0   AAPL  Technology  \n",
       "         3            1.0            1.0   AAPL  Technology  \n",
       "         4            1.0            1.0   AAPL  Technology  \n",
       "...                   ...            ...    ...         ...  \n",
       "20200529 385          1.0            5.0   XNTK         NaN  \n",
       "         386          5.0            5.0   XNTK         NaN  \n",
       "         387          1.0            5.0   XNTK         NaN  \n",
       "         388          1.0            5.0   XNTK         NaN  \n",
       "         389          1.0            1.0   XNTK         NaN  \n",
       "\n",
       "[546000 rows x 18 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>spread_open</th>\n",
       "      <th>spread_high</th>\n",
       "      <th>spread_low</th>\n",
       "      <th>spread_close</th>\n",
       "      <th>bidsize_open</th>\n",
       "      <th>bidsize_high</th>\n",
       "      <th>bidsize_low</th>\n",
       "      <th>bidsize_close</th>\n",
       "      <th>ofrsize_open</th>\n",
       "      <th>ofrsize_high</th>\n",
       "      <th>ofrsize_low</th>\n",
       "      <th>ofrsize_close</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>sector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">20200501</th>\n",
       "      <th>0</th>\n",
       "      <td>286.250</td>\n",
       "      <td>289.260</td>\n",
       "      <td>285.870</td>\n",
       "      <td>289.260</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.24</td>\n",
       "      <td>6.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>289.260</td>\n",
       "      <td>289.350</td>\n",
       "      <td>288.365</td>\n",
       "      <td>289.020</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.10</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>289.035</td>\n",
       "      <td>289.705</td>\n",
       "      <td>288.280</td>\n",
       "      <td>288.580</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>288.485</td>\n",
       "      <td>289.315</td>\n",
       "      <td>288.280</td>\n",
       "      <td>289.095</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>289.100</td>\n",
       "      <td>290.435</td>\n",
       "      <td>288.940</td>\n",
       "      <td>290.320</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.10</td>\n",
       "      <td>13.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">20200529</th>\n",
       "      <th>385</th>\n",
       "      <td>91.500</td>\n",
       "      <td>91.755</td>\n",
       "      <td>91.485</td>\n",
       "      <td>91.740</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>XNTK</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>91.740</td>\n",
       "      <td>91.740</td>\n",
       "      <td>91.740</td>\n",
       "      <td>91.740</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>XNTK</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>91.580</td>\n",
       "      <td>91.830</td>\n",
       "      <td>91.580</td>\n",
       "      <td>91.715</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.45</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>XNTK</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>91.595</td>\n",
       "      <td>91.880</td>\n",
       "      <td>91.595</td>\n",
       "      <td>91.750</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.52</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>XNTK</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>46.005</td>\n",
       "      <td>46.005</td>\n",
       "      <td>45.815</td>\n",
       "      <td>45.815</td>\n",
       "      <td>92.01</td>\n",
       "      <td>92.01</td>\n",
       "      <td>91.63</td>\n",
       "      <td>91.63</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>XNTK</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>546000 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 open     high      low    close  spread_open  spread_high  \\\n",
       "20200501 0    286.250  289.260  285.870  289.260         0.50         0.50   \n",
       "         1    289.260  289.350  288.365  289.020         0.24         0.45   \n",
       "         2    289.035  289.705  288.280  288.580         0.07         0.49   \n",
       "         3    288.485  289.315  288.280  289.095         0.49         0.49   \n",
       "         4    289.100  290.435  288.940  290.320         0.16         0.33   \n",
       "...               ...      ...      ...      ...          ...          ...   \n",
       "20200529 385   91.500   91.755   91.485   91.740         0.42         0.93   \n",
       "         386   91.740   91.740   91.740   91.740         0.50         0.50   \n",
       "         387   91.580   91.830   91.580   91.715         0.18         0.68   \n",
       "         388   91.595   91.880   91.595   91.750         0.21         0.78   \n",
       "         389   46.005   46.005   45.815   45.815        92.01        92.01   \n",
       "\n",
       "              spread_low  spread_close  bidsize_open  bidsize_high  \\\n",
       "20200501 0          0.01          0.24           6.0          95.0   \n",
       "         1          0.01          0.10           9.0          20.0   \n",
       "         2          0.01          0.30           1.0          50.0   \n",
       "         3          0.01          0.17           1.0          25.0   \n",
       "         4          0.01          0.10          13.0          71.0   \n",
       "...                  ...           ...           ...           ...   \n",
       "20200529 385        0.39          0.50           5.0           5.0   \n",
       "         386        0.50          0.50           5.0           5.0   \n",
       "         387        0.18          0.45           5.0           5.0   \n",
       "         388        0.21          0.52           5.0           5.0   \n",
       "         389       91.63         91.63           0.0           0.0   \n",
       "\n",
       "              bidsize_low  bidsize_close  ofrsize_open  ofrsize_high  \\\n",
       "20200501 0            1.0           10.0           1.0          85.0   \n",
       "         1            1.0            1.0           4.0          56.0   \n",
       "         2            1.0            1.0           1.0          13.0   \n",
       "         3            1.0           16.0           1.0           8.0   \n",
       "         4            1.0            1.0           1.0         236.0   \n",
       "...                   ...            ...           ...           ...   \n",
       "20200529 385          5.0            5.0           1.0           5.0   \n",
       "         386          5.0            5.0           5.0           5.0   \n",
       "         387          5.0            5.0           1.0           5.0   \n",
       "         388          5.0            5.0           1.0           5.0   \n",
       "         389          0.0            0.0           5.0           5.0   \n",
       "\n",
       "              ofrsize_low  ofrsize_close Ticker      sector  \n",
       "20200501 0            1.0            4.0   AAPL  Technology  \n",
       "         1            1.0            1.0   AAPL  Technology  \n",
       "         2            1.0            1.0   AAPL  Technology  \n",
       "         3            1.0            1.0   AAPL  Technology  \n",
       "         4            1.0            1.0   AAPL  Technology  \n",
       "...                   ...            ...    ...         ...  \n",
       "20200529 385          1.0            5.0   XNTK         NaN  \n",
       "         386          5.0            5.0   XNTK         NaN  \n",
       "         387          1.0            5.0   XNTK         NaN  \n",
       "         388          1.0            5.0   XNTK         NaN  \n",
       "         389          1.0            1.0   XNTK         NaN  \n",
       "\n",
       "[546000 rows x 18 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['open', 'high', 'low', 'close', 'spread_open', 'spread_high',\n",
       "       'spread_low', 'spread_close', 'bidsize_open', 'bidsize_high',\n",
       "       'bidsize_low', 'bidsize_close', 'ofrsize_open', 'ofrsize_high',\n",
       "       'ofrsize_low', 'ofrsize_close', 'Ticker', 'sector'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping ETFS and market indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AAPL', 'ABBV', 'ABT', 'AEP', 'AMT', 'APD', 'BA', 'BABA', 'BAC',\n",
       "       'BHP', 'BP', 'CCI', 'CHL', 'COST', 'CSGP', 'D', 'DIS', 'ECL',\n",
       "       'ENB', 'EXC', 'FB', 'FMX', 'GOOG', 'IDU', 'INTC', 'IYC', 'IYE',\n",
       "       'IYG', 'IYH', 'IYJ', 'IYK', 'IYM', 'IYR', 'IYW', 'IYZ', 'JNJ',\n",
       "       'KO', 'LFC', 'LIN', 'LMT', 'MA', 'MCD', 'MSFT', 'NKE', 'NVDA',\n",
       "       'NVS', 'PBR', 'PEP', 'PFE', 'PLD', 'PSA', 'PTR', 'PYPL', 'RTX',\n",
       "       'SHW', 'SNP', 'SO', 'SRE', 'T', 'TM', 'TSLA', 'TSM', 'UNP', 'UPS',\n",
       "       'V', 'WMT', 'DIA', 'QQQ', 'SPY', 'XNTK'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Ticker.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the XNTK ticker\n",
    "data = data[~data.Ticker.isin(['XNTK'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AAPL', 'ABBV', 'ABT', 'AEP', 'AMT', 'APD', 'BA', 'BABA', 'BAC',\n",
       "       'BHP', 'BP', 'CCI', 'CHL', 'COST', 'CSGP', 'D', 'DIS', 'ECL',\n",
       "       'ENB', 'EXC', 'FB', 'FMX', 'GOOG', 'IDU', 'INTC', 'IYC', 'IYE',\n",
       "       'IYG', 'IYH', 'IYJ', 'IYK', 'IYM', 'IYR', 'IYW', 'IYZ', 'JNJ',\n",
       "       'KO', 'LFC', 'LIN', 'LMT', 'MA', 'MCD', 'MSFT', 'NKE', 'NVDA',\n",
       "       'NVS', 'PBR', 'PEP', 'PFE', 'PLD', 'PSA', 'PTR', 'PYPL', 'RTX',\n",
       "       'SHW', 'SNP', 'SO', 'SRE', 'T', 'TM', 'TSLA', 'TSM', 'UNP', 'UPS',\n",
       "       'V', 'WMT', 'DIA', 'QQQ', 'SPY'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Ticker.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the XNTK ticker\n",
    "data = data[~data.Ticker.isin(['XNTK'])]\n",
    "\n",
    "etfs = ['IYH','IYM','IYK','IYJ','IYG','IYW','IYC','IYR','IDU','IYZ','IYE','IYF','SPY','DIA','QQQ']\n",
    "\n",
    "# Extracting the sector ETFs to a separate variable\n",
    "sectorETFS = data[data.Ticker.isin(etfs)]\n",
    "\n",
    "# Removing the ETFs\n",
    "data = data[~data.Ticker.isin(etfs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['open', 'high', 'low', 'close', 'spread_open', 'spread_high',\n",
       "       'spread_low', 'spread_close', 'bidsize_open', 'bidsize_high',\n",
       "       'bidsize_low', 'bidsize_close', 'ofrsize_open', 'ofrsize_high',\n",
       "       'ofrsize_low', 'ofrsize_close', 'Ticker', 'sector'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>spread_open</th>\n",
       "      <th>spread_high</th>\n",
       "      <th>spread_low</th>\n",
       "      <th>spread_close</th>\n",
       "      <th>bidsize_open</th>\n",
       "      <th>bidsize_high</th>\n",
       "      <th>bidsize_low</th>\n",
       "      <th>bidsize_close</th>\n",
       "      <th>ofrsize_open</th>\n",
       "      <th>ofrsize_high</th>\n",
       "      <th>ofrsize_low</th>\n",
       "      <th>ofrsize_close</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>sector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">20200501</th>\n",
       "      <th>0</th>\n",
       "      <td>286.250</td>\n",
       "      <td>289.260</td>\n",
       "      <td>285.870</td>\n",
       "      <td>289.260</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.24</td>\n",
       "      <td>6.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>289.260</td>\n",
       "      <td>289.350</td>\n",
       "      <td>288.365</td>\n",
       "      <td>289.020</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.10</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>289.035</td>\n",
       "      <td>289.705</td>\n",
       "      <td>288.280</td>\n",
       "      <td>288.580</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>288.485</td>\n",
       "      <td>289.315</td>\n",
       "      <td>288.280</td>\n",
       "      <td>289.095</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>289.100</td>\n",
       "      <td>290.435</td>\n",
       "      <td>288.940</td>\n",
       "      <td>290.320</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.10</td>\n",
       "      <td>13.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">20200529</th>\n",
       "      <th>385</th>\n",
       "      <td>123.950</td>\n",
       "      <td>124.110</td>\n",
       "      <td>123.910</td>\n",
       "      <td>124.100</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WMT</td>\n",
       "      <td>Consumer Defensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>124.085</td>\n",
       "      <td>124.085</td>\n",
       "      <td>123.920</td>\n",
       "      <td>123.995</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>WMT</td>\n",
       "      <td>Consumer Defensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>123.995</td>\n",
       "      <td>124.355</td>\n",
       "      <td>123.985</td>\n",
       "      <td>124.335</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.05</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>WMT</td>\n",
       "      <td>Consumer Defensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>124.335</td>\n",
       "      <td>124.355</td>\n",
       "      <td>124.060</td>\n",
       "      <td>124.075</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>WMT</td>\n",
       "      <td>Consumer Defensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>124.075</td>\n",
       "      <td>124.225</td>\n",
       "      <td>122.810</td>\n",
       "      <td>123.855</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.43</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.21</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WMT</td>\n",
       "      <td>Consumer Defensive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>429000 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 open     high      low    close  spread_open  spread_high  \\\n",
       "20200501 0    286.250  289.260  285.870  289.260         0.50         0.50   \n",
       "         1    289.260  289.350  288.365  289.020         0.24         0.45   \n",
       "         2    289.035  289.705  288.280  288.580         0.07         0.49   \n",
       "         3    288.485  289.315  288.280  289.095         0.49         0.49   \n",
       "         4    289.100  290.435  288.940  290.320         0.16         0.33   \n",
       "...               ...      ...      ...      ...          ...          ...   \n",
       "20200529 385  123.950  124.110  123.910  124.100         0.02         0.07   \n",
       "         386  124.085  124.085  123.920  123.995         0.01         0.06   \n",
       "         387  123.995  124.355  123.985  124.335         0.01         0.07   \n",
       "         388  124.335  124.355  124.060  124.075         0.05         0.12   \n",
       "         389  124.075  124.225  122.810  123.855         0.01         2.43   \n",
       "\n",
       "              spread_low  spread_close  bidsize_open  bidsize_high  \\\n",
       "20200501 0          0.01          0.24           6.0          95.0   \n",
       "         1          0.01          0.10           9.0          20.0   \n",
       "         2          0.01          0.30           1.0          50.0   \n",
       "         3          0.01          0.17           1.0          25.0   \n",
       "         4          0.01          0.10          13.0          71.0   \n",
       "...                  ...           ...           ...           ...   \n",
       "20200529 385        0.01          0.04           1.0          11.0   \n",
       "         386        0.01          0.01           1.0           8.0   \n",
       "         387        0.01          0.05           4.0          16.0   \n",
       "         388        0.01          0.01           3.0           6.0   \n",
       "         389        0.01          0.21           1.0          20.0   \n",
       "\n",
       "              bidsize_low  bidsize_close  ofrsize_open  ofrsize_high  \\\n",
       "20200501 0            1.0           10.0           1.0          85.0   \n",
       "         1            1.0            1.0           4.0          56.0   \n",
       "         2            1.0            1.0           1.0          13.0   \n",
       "         3            1.0           16.0           1.0           8.0   \n",
       "         4            1.0            1.0           1.0         236.0   \n",
       "...                   ...            ...           ...           ...   \n",
       "20200529 385          1.0            1.0           5.0           9.0   \n",
       "         386          1.0            3.0           1.0           9.0   \n",
       "         387          1.0            2.0           2.0          10.0   \n",
       "         388          1.0            2.0           2.0          10.0   \n",
       "         389          1.0            2.0           4.0          12.0   \n",
       "\n",
       "              ofrsize_low  ofrsize_close Ticker              sector  \n",
       "20200501 0            1.0            4.0   AAPL          Technology  \n",
       "         1            1.0            1.0   AAPL          Technology  \n",
       "         2            1.0            1.0   AAPL          Technology  \n",
       "         3            1.0            1.0   AAPL          Technology  \n",
       "         4            1.0            1.0   AAPL          Technology  \n",
       "...                   ...            ...    ...                 ...  \n",
       "20200529 385          1.0            1.0    WMT  Consumer Defensive  \n",
       "         386          1.0            2.0    WMT  Consumer Defensive  \n",
       "         387          1.0            2.0    WMT  Consumer Defensive  \n",
       "         388          1.0            4.0    WMT  Consumer Defensive  \n",
       "         389          1.0            1.0    WMT  Consumer Defensive  \n",
       "\n",
       "[429000 rows x 18 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:MainThread:numexpr.utils:NumExpr defaulting to 4 threads.\n",
      "C:\\Users\\PC\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:844: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "C:\\Users\\PC\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:965: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAPL done\n",
      "ABBV done\n",
      "ABT done\n",
      "AEP done\n",
      "AMT done\n",
      "APD done\n",
      "BA done\n",
      "BABA done\n",
      "BAC done\n",
      "BHP done\n",
      "BP done\n",
      "CCI done\n",
      "CHL done\n",
      "COST done\n",
      "CSGP done\n",
      "D done\n",
      "DIS done\n",
      "ECL done\n",
      "ENB done\n",
      "EXC done\n",
      "FB done\n",
      "FMX done\n",
      "GOOG done\n",
      "INTC done\n",
      "JNJ done\n",
      "KO done\n",
      "LFC done\n",
      "LIN done\n",
      "LMT done\n",
      "MA done\n",
      "MCD done\n",
      "MSFT done\n",
      "NKE done\n",
      "NVDA done\n",
      "NVS done\n",
      "Number of NaNs in label: 1. 1 is expected\n",
      "Returns that lead to NaNs in label: [0.0907158]\n",
      "PBR done\n",
      "PEP done\n",
      "PFE done\n",
      "PLD done\n",
      "PSA done\n",
      "PTR done\n",
      "PYPL done\n",
      "RTX done\n",
      "SHW done\n",
      "SNP done\n",
      "SO done\n",
      "SRE done\n",
      "T done\n",
      "TM done\n",
      "TSLA done\n",
      "TSM done\n",
      "UNP done\n",
      "UPS done\n",
      "V done\n",
      "WMT done\n"
     ]
    }
   ],
   "source": [
    "########### Generate Features ################\n",
    "\n",
    "n_feature_lags = 1\n",
    "\n",
    "# features = generateFeatures_multi_final(data = data, \n",
    "#                                   listOfFeatures = [\n",
    "#                                                     'pastobs',\n",
    "#                                                     'spread',\n",
    "#                                                     'bidsize',\n",
    "#                                                     'ofrsize',\n",
    "# #                                                     'stok',\n",
    "# #                                                     'stod',\n",
    "# #                                                     'sstod',\n",
    "# #                                                     'wilr',\n",
    "# #                                                     'roc',\n",
    "# #                                                     'rsi',\n",
    "# #                                                     'atr',\n",
    "# #                                                     'cci',\n",
    "# #                                                     'dpo',\n",
    "# #                                                     'sma',\n",
    "# #                                                     'ema',\n",
    "# #                                                     'macd',\n",
    "# #                                                       'macd_diff',\n",
    "# #                                                       'macd_signal',\n",
    "# #                                                     'dis5',\n",
    "# #                                                     'dis10',\n",
    "#                                                       'sector'\n",
    "#                                                    ], \n",
    "#                                    feature_lags = n_feature_lags\n",
    "#                                      ,stockTable=stockTable)\n",
    "features = generateFeatures_multi_final(data = data, \n",
    "                                  listOfFeatures = [\n",
    "                                                    'pastobs',\n",
    "                                                    'spread',\n",
    "                                                    'bidsize',\n",
    "                                                    'ofrsize',\n",
    "                                                    'stok',\n",
    "                                                    'stod',\n",
    "                                                    'sstod',\n",
    "#                                                     'wilr',\n",
    "                                                    'roc',\n",
    "                                                    'rsi',\n",
    "                                                    'atr',\n",
    "                                                    'cci',\n",
    "                                                    'dpo',\n",
    "                                                    'sma',\n",
    "                                                    'ema',\n",
    "                                                    'macd',\n",
    "                                                      'macd_diff',\n",
    "                                                      'macd_signal',\n",
    "                                                    'dis5',\n",
    "                                                    'dis10',\n",
    "                                                      'sector'\n",
    "                                                   ], \n",
    "                                   feature_lags = n_feature_lags\n",
    "                                     ,sectorETFS=sectorETFS)\n",
    "\n",
    "########### Generate Labels ################\n",
    "\n",
    "n_classes = 2\n",
    "# extract first 4 columns as the lag0 or raw OHLC prices (used for labelling)\n",
    "price_candles = data[['open','high','low','close','Ticker']]\n",
    "\n",
    "########### Align Data ################\n",
    "\n",
    "# from imported function (see testing_preprocessing_features_and_labels.ipynb for thorough experimenting with all the cut-offs):    \n",
    "X, y,indices = align_features_and_labels_multi_final(price_candles = price_candles, \n",
    "                                                 all_features = features,\n",
    "                                                 prediction_horizon = 1, \n",
    "                                                 n_feature_lags = n_feature_lags, \n",
    "                                                 n_classes = n_classes, # 5,\n",
    "                                                 safe_burn_in = False, \n",
    "                                                 data_sample = 'full',\n",
    "                                                 splitType='global',\n",
    "                                                 noise=False,ticker_dummies=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding ticker dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Adding ticker dummies\n",
    "tickers = X.pop('ticker')\n",
    "X = pd.concat([X, pd.get_dummies(tickers, prefix='ticker', drop_first=False)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['open_lag0', 'high_lag0', 'low_lag0', 'close_lag0', 'spread_open_lag0',\n",
       "       'spread_high_lag0', 'spread_low_lag0', 'spread_close_lag0',\n",
       "       'bidsize_open_lag0', 'bidsize_high_lag0',\n",
       "       ...\n",
       "       'ticker_SO', 'ticker_SRE', 'ticker_T', 'ticker_TM', 'ticker_TSLA',\n",
       "       'ticker_TSM', 'ticker_UNP', 'ticker_UPS', 'ticker_V', 'ticker_WMT'],\n",
       "      dtype='object', length=156)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing our final train/validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(341385, 156)\n",
      "(341385, 1)\n",
      "(85690, 156)\n",
      "(85690, 1)\n"
     ]
    }
   ],
   "source": [
    "# train_ds = pd.concat([X.iloc[start:end, :] for (start, end) in train_ranges]).reset_index(drop=True)\n",
    "# train_y = pd.concat([y.iloc[start:end] for (start, end) in train_ranges]).reset_index(drop=True)\n",
    "\n",
    "# validate_ds = pd.concat([X.iloc[start:end, :] for (start, end) in val_ranges]).reset_index(drop=True)\n",
    "# val_y = pd.concat([y.iloc[start:end] for (start, end) in val_ranges]).reset_index(drop=True)\n",
    "\n",
    "# train_ds.shape, train_y.shape, validate_ds.shape, val_y.shape, train_y.shape[0] + val_y.shape[0]\n",
    "\n",
    "# Let's have a proper split (along tickers & dates)\n",
    "train_size = 0.8\n",
    "\n",
    "# Sort the indices\n",
    "tempIndices = indices.sort_values(['days','timestamps','ticker'])\n",
    "\n",
    "# Sorting the data\n",
    "X = X.loc[tempIndices.index,:]#.head(66)\n",
    "y = y.loc[tempIndices.index,:]\n",
    "\n",
    "# extracting the first date for the validation data.\n",
    "first_val_day = int(np.floor(indices.days.unique().shape[0]*0.8))\n",
    "\n",
    "# Splitting the data\n",
    "X_train = X[tempIndices.days<tempIndices.days.unique()[first_val_day]].reset_index(drop=True)\n",
    "y_train = y[tempIndices.days<tempIndices.days.unique()[first_val_day]].reset_index(drop=True)\n",
    "\n",
    "X_test = X[tempIndices.days>=tempIndices.days.unique()[first_val_day]].reset_index(drop=True)\n",
    "y_test = y[tempIndices.days>=tempIndices.days.unique()[first_val_day]].reset_index(drop=True)\n",
    "\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open_lag0</th>\n",
       "      <th>high_lag0</th>\n",
       "      <th>low_lag0</th>\n",
       "      <th>close_lag0</th>\n",
       "      <th>spread_open_lag0</th>\n",
       "      <th>spread_high_lag0</th>\n",
       "      <th>spread_low_lag0</th>\n",
       "      <th>spread_close_lag0</th>\n",
       "      <th>bidsize_open_lag0</th>\n",
       "      <th>bidsize_high_lag0</th>\n",
       "      <th>...</th>\n",
       "      <th>ticker_SO</th>\n",
       "      <th>ticker_SRE</th>\n",
       "      <th>ticker_T</th>\n",
       "      <th>ticker_TM</th>\n",
       "      <th>ticker_TSLA</th>\n",
       "      <th>ticker_TSM</th>\n",
       "      <th>ticker_UNP</th>\n",
       "      <th>ticker_UPS</th>\n",
       "      <th>ticker_V</th>\n",
       "      <th>ticker_WMT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.545</td>\n",
       "      <td>0.205</td>\n",
       "      <td>-0.635</td>\n",
       "      <td>296.440</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.200</td>\n",
       "      <td>0.040</td>\n",
       "      <td>-0.255</td>\n",
       "      <td>82.805</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.030</td>\n",
       "      <td>-0.040</td>\n",
       "      <td>90.855</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.100</td>\n",
       "      <td>0.140</td>\n",
       "      <td>-0.110</td>\n",
       "      <td>81.510</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.070</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>234.230</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341380</th>\n",
       "      <td>0.035</td>\n",
       "      <td>0.165</td>\n",
       "      <td>-0.040</td>\n",
       "      <td>51.300</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>5.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341381</th>\n",
       "      <td>0.890</td>\n",
       "      <td>0.965</td>\n",
       "      <td>-0.290</td>\n",
       "      <td>169.435</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1.41</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341382</th>\n",
       "      <td>0.105</td>\n",
       "      <td>0.235</td>\n",
       "      <td>-0.465</td>\n",
       "      <td>97.955</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1.32</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341383</th>\n",
       "      <td>-0.080</td>\n",
       "      <td>0.540</td>\n",
       "      <td>-0.245</td>\n",
       "      <td>195.705</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.08</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341384</th>\n",
       "      <td>-0.560</td>\n",
       "      <td>0.055</td>\n",
       "      <td>-0.605</td>\n",
       "      <td>125.185</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.11</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>341385 rows × 156 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        open_lag0  high_lag0  low_lag0  close_lag0  spread_open_lag0  \\\n",
       "0          -0.545      0.205    -0.635     296.440              0.09   \n",
       "1          -0.200      0.040    -0.255      82.805              0.21   \n",
       "2           0.000      0.030    -0.040      90.855              0.07   \n",
       "3           0.100      0.140    -0.110      81.510              0.06   \n",
       "4           0.010      0.070    -0.045     234.230              0.26   \n",
       "...           ...        ...       ...         ...               ...   \n",
       "341380      0.035      0.165    -0.040      51.300              0.17   \n",
       "341381      0.890      0.965    -0.290     169.435              0.35   \n",
       "341382      0.105      0.235    -0.465      97.955              0.86   \n",
       "341383     -0.080      0.540    -0.245     195.705              0.75   \n",
       "341384     -0.560      0.055    -0.605     125.185              1.25   \n",
       "\n",
       "        spread_high_lag0  spread_low_lag0  spread_close_lag0  \\\n",
       "0                   0.20             0.01               0.06   \n",
       "1                   0.26             0.01               0.07   \n",
       "2                   0.10             0.01               0.09   \n",
       "3                   0.25             0.03               0.16   \n",
       "4                   0.30             0.11               0.18   \n",
       "...                  ...              ...                ...   \n",
       "341380              0.26             0.01               0.02   \n",
       "341381              1.41             0.01               0.93   \n",
       "341382              1.32             0.06               0.15   \n",
       "341383              1.08             0.01               0.07   \n",
       "341384              1.25             0.01               0.11   \n",
       "\n",
       "        bidsize_open_lag0  bidsize_high_lag0  ...  ticker_SO  ticker_SRE  \\\n",
       "0                     1.0               12.0  ...          0           0   \n",
       "1                     1.0                8.0  ...          0           0   \n",
       "2                     1.0                4.0  ...          0           0   \n",
       "3                     1.0                9.0  ...          0           0   \n",
       "4                     1.0                3.0  ...          0           0   \n",
       "...                   ...                ...  ...        ...         ...   \n",
       "341380                5.0               23.0  ...          0           0   \n",
       "341381                1.0               10.0  ...          0           0   \n",
       "341382                1.0                6.0  ...          0           0   \n",
       "341383                1.0                4.0  ...          0           0   \n",
       "341384                2.0                4.0  ...          0           0   \n",
       "\n",
       "        ticker_T  ticker_TM  ticker_TSLA  ticker_TSM  ticker_UNP  ticker_UPS  \\\n",
       "0              0          0            0           0           0           0   \n",
       "1              0          0            0           0           0           0   \n",
       "2              0          0            0           0           0           0   \n",
       "3              0          0            0           0           0           0   \n",
       "4              0          0            0           0           0           0   \n",
       "...          ...        ...          ...         ...         ...         ...   \n",
       "341380         0          0            0           1           0           0   \n",
       "341381         0          0            0           0           1           0   \n",
       "341382         0          0            0           0           0           1   \n",
       "341383         0          0            0           0           0           0   \n",
       "341384         0          0            0           0           0           0   \n",
       "\n",
       "        ticker_V  ticker_WMT  \n",
       "0              0           0  \n",
       "1              0           0  \n",
       "2              0           0  \n",
       "3              0           0  \n",
       "4              0           0  \n",
       "...          ...         ...  \n",
       "341380         0           0  \n",
       "341381         0           0  \n",
       "341382         0           0  \n",
       "341383         1           0  \n",
       "341384         0           1  \n",
       "\n",
       "[341385 rows x 156 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64),)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where((np.sum(np.isinf(X_train.values), axis=1) == 0) == False),\n",
    "np.where((np.sum(np.isnan(X_train.values), axis=1) == 0) == False)#X_train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{i:colname for i,colname in enumerate(train_ds.columns)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating one ppdict for individual preprocessings\n",
    "# ppdict1 = {'open':'minmax',\n",
    "#           'high':'log',\n",
    "#           'low':'log',\n",
    "#           'close':'std'}\n",
    "# splitpoint = 32\n",
    "\n",
    "# # Standardize some features\n",
    "# ppdict1 = {i:'std' for i in train_ds.columns[0:splitpoint]} \n",
    "# # Keep some in actual levels (Dummies in this case).\n",
    "# ppdict2 = {i:'act' for i in train_ds.columns[splitpoint:]}\n",
    "\n",
    "pre_procesing_applied = 'std'\n",
    "\n",
    "# Merging the two\n",
    "# ppdict = {**ppdict1,**ppdict2}\n",
    "\n",
    "if  pre_procesing_applied == 'None':\n",
    "    # do nothing here\n",
    "    pass\n",
    "\n",
    "elif  pre_procesing_applied == 'std':\n",
    "\n",
    "    # splitpoint = int((args.feature-lags+1)*16)#32\n",
    "    # columns_to_pre_process = [col for col in X_train.columns if 'd_' != col[0:2]]\n",
    "\n",
    "    # Standardize some features\n",
    "    ppdict1 = {i:'std' for i in X_train.columns if 'd_' != i[0:2]} \n",
    "    # Keep some in actual levels (Dummies in this case).\n",
    "    ppdict2 = {i:'act' for i in X_train.columns if 'd_' == i[0:2]} \n",
    "\n",
    "    # Merging the two\n",
    "    ppdict = {**ppdict1,**ppdict2}\n",
    "\n",
    "    # x_train,x_test = pre_processing(x_train,x_test,pp_dict)\n",
    "\n",
    "elif pre_procesing_applied == 'minmax':\n",
    "\n",
    "    # splitpoint = int((args.feature-lags+1)*16)#32\n",
    "    # columns_to_pre_process = [col for col in X_train.columns if 'd_' != col[0:2]]\n",
    "\n",
    "    # Standardize some features\n",
    "    ppdict1 = {i:'minmax' for i in X_train.columns if 'd_' != i[0:2]} \n",
    "    # Keep some in actual levels (Dummies in this case).\n",
    "    ppdict2 = {i:'act' for i in X_train.columns if 'd_' == i[0:2]} \n",
    "\n",
    "    # Merging the two\n",
    "    ppdict = {**ppdict1,**ppdict2}\n",
    "\n",
    "    # x_train,x_test = pre_processing(X_train,X_test,pp_dict)\n",
    "\n",
    "elif pre_procesing_applied == 'pow':\n",
    "\n",
    "    # splitpoint = int((args.feature-lags+1)*16)#32\n",
    "    # columns_to_pre_process = [col for col in X_train.columns if 'd_' != col[0:2]]\n",
    "\n",
    "    # Standardize some features\n",
    "    ppdict1 = {i:'pow' for i in X_train.columns if 'd_' != i[0:2]} \n",
    "    # Keep some in actual levels (Dummies in this case).\n",
    "    ppdict2 = {i:'act' for i in X_train.columns if 'd_' == i[0:2]} \n",
    "\n",
    "    # Merging the two\n",
    "    ppdict = {**ppdict1,**ppdict2}\n",
    "\n",
    "    # x_train,x_test = pre_processing(x_train,x_test,pp_dict)\n",
    "\n",
    "elif pre_procesing_applied == 'quantgau':\n",
    "\n",
    "    # splitpoint = int((args.feature-lags+1)*16)#32\n",
    "    # columns_to_pre_process = [col for col in X_train.columns if 'd_' != col[0:2]]\n",
    "\n",
    "    # Standardize some features\n",
    "    ppdict1 = {i:'quantgau' for i in X_train.columns if 'd_' != i[0:2]} \n",
    "    # Keep some in actual levels (Dummies in this case).\n",
    "    ppdict2 = {i:'act' for i in X_train.columns if 'd_' == i[0:2]} \n",
    "\n",
    "    # Merging the two\n",
    "    ppdict = {**ppdict1,**ppdict2}\n",
    "\n",
    "    # x_train,x_test = pre_processing(x_train,x_test,pp_dict)\n",
    "\n",
    "elif pre_procesing_applied == 'individual':\n",
    "\n",
    "    # splitpoint = int((args.feature-lags+1)*16)#32\n",
    "    # columns_to_pre_process = [col for col in X_train.columns if 'd_' != col[0:2]]\n",
    "\n",
    "    # Standardize some features\n",
    "    \n",
    "    # ppdict1 = {i:'power' for i in X_train.columns if 'd_' != i[0:2]}\n",
    "\n",
    "\n",
    "    # Keep some in actual levels (Dummies in this case).\n",
    "    ppdict2 = {i:'act' for i in X_train.columns if 'd_' == i[0:2]} \n",
    "\n",
    "    # Merging the two\n",
    "    ppdict = {**ppdict1,**ppdict2}\n",
    "\n",
    "    # x_train,x_test = pre_processing(x_train,x_test,pp_dict)\n",
    "\n",
    "elif pre_procesing_applied == 'stacked':\n",
    "\n",
    "    # splitpoint = int((args.feature-lags+1)*16)#32\n",
    "    # columns_to_pre_process = [col for col in X_train.columns if 'd_' != col[0:2]]\n",
    "\n",
    "    # Standardize some features\n",
    "    \n",
    "    for j in ['pow','std','minmax']:\n",
    "\n",
    "        ppdict1 = {i:j for i in X_train.columns if 'd_' != i[0:2]}\n",
    "\n",
    "        # Keep some in actual levels (Dummies in this case).\n",
    "        ppdict2 = {i:'act' for i in X_train.columns if 'd_' == i[0:2]} \n",
    "\n",
    "        # Merging the two\n",
    "        ppdict = {**ppdict1,**ppdict2}\n",
    "\n",
    "        X_train,X_test = pre_processing(X_train,X_test,ppdict)\n",
    "\n",
    "if pre_procesing_applied not in ['None','stacked']:\n",
    "    X_train,X_test = pre_processing(X_train,X_test,ppdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1.8927265537610815e-16, 1.000001457346533)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppX_train.iloc[:,0].mean(),ppX_train.iloc[:,0].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepping for models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(343090, 85800, 428890, 1340, 131, 670000)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_VALIDATION = val_y.shape[0] #int(1e3)\n",
    "N_TRAIN = train_y.shape[0] #int(1e4)\n",
    "# BUFFER_SIZE = int(1e4)\n",
    "BATCH_SIZE = 256 #512 #32\n",
    "MAX_EPOCHS = 500\n",
    "\n",
    "STEPS_PER_EPOCH = N_TRAIN//BATCH_SIZE\n",
    "\n",
    "N_REPEAT = int(N_TRAIN / ((STEPS_PER_EPOCH * MAX_EPOCHS) / BATCH_SIZE))\n",
    "FEATURES = X.shape[1]\n",
    "\n",
    "N_TRAIN, N_VALIDATION, N_TRAIN + N_VALIDATION, STEPS_PER_EPOCH, N_REPEAT, STEPS_PER_EPOCH * MAX_EPOCHS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Logistic Regression model in TF/Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 1)                 99        \n",
      "=================================================================\n",
      "Total params: 99\n",
      "Trainable params: 99\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:MainThread:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.390774). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0, accuracy:0.5352,  auc:0.5034,  loss:0.8996,  val_accuracy:0.5456,  val_auc:0.5453,  val_loss:0.6876,  \n",
      "....................................................................................................\n",
      "Epoch: 100, accuracy:0.5480,  auc:0.5440,  loss:0.6873,  val_accuracy:0.5454,  val_auc:0.5459,  val_loss:0.6879,  \n",
      "..................Restoring model weights from the end of the best epoch.\n",
      "Epoch 00118: early stopping\n"
     ]
    }
   ],
   "source": [
    "METRICS = [\n",
    "      #keras.metrics.TruePositives(name='tp'),\n",
    "      #keras.metrics.FalsePositives(name='fp'),\n",
    "      #keras.metrics.TrueNegatives(name='tn'),\n",
    "      #keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      #keras.metrics.Precision(name='precision'),\n",
    "      #keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "]\n",
    "\n",
    "# def make_model(metrics = METRICS, output_bias=None):\n",
    "#   if output_bias is not None:\n",
    "#     output_bias = tf.keras.initializers.Constant(output_bias)\n",
    "#   model = keras.Sequential([\n",
    "#       keras.layers.Dense(\n",
    "#           16, activation='relu',\n",
    "#           input_shape=(train_features.shape[-1],)),\n",
    "#       keras.layers.Dropout(0.5),\n",
    "#       keras.layers.Dense(1, activation='sigmoid',\n",
    "#                          bias_initializer=output_bias),\n",
    "#   ])\n",
    "\n",
    "#   model.compile(\n",
    "#       optimizer=keras.optimizers.Adam(lr=1e-3),\n",
    "#       loss=keras.losses.BinaryCrossentropy(),\n",
    "#       metrics=metrics)\n",
    "\n",
    "#   return model\n",
    "\n",
    "# model = keras.Sequential({\n",
    "#   keras.layers.Dense(1, input_shape=(FEATURES,))\n",
    "# })\n",
    "\n",
    "model = keras.Sequential([\n",
    "#     keras.layers.Flatten(input_shape=(28, 28)),\n",
    "#     keras.layers.Dense(128, activation='relu'),\n",
    "#     keras.layers.Dense(10)\n",
    "    keras.layers.Dense(1,\n",
    "                       input_shape=(FEATURES,),\n",
    "                       activation='sigmoid',\n",
    "                       kernel_regularizer=regularizers.l2(1))\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# with final activation (Keras/TF tutorial advises against this practice, but they also use it later in the tutorial)\n",
    "# model = keras.Sequential({\n",
    "#   keras.layers.Dense(1, input_shape=(FEATURES,), activation='sigmoid')\n",
    "# })\n",
    "\n",
    "#model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['binary_accuracy', ])\n",
    "model.compile(\n",
    "              optimizer=keras.optimizers.Adam(), #lr=1e-3\n",
    "              loss=keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "              metrics=METRICS)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "                                                monitor='val_auc', \n",
    "                                                verbose=1,\n",
    "                                                patience=100,\n",
    "                                                mode='max',\n",
    "                                                restore_best_weights=True)\n",
    "\n",
    "def get_callbacks(run_id):\n",
    "      return [\n",
    "             tfdocs.modeling.EpochDots(),\n",
    "             early_stopping,\n",
    "             tf.keras.callbacks.TensorBoard(logdir), #/run_id),\n",
    "      ]\n",
    "\n",
    "baseline_history = model.fit(\n",
    "                            train_ds, #train_features,\n",
    "                            train_y, #train_labels,\n",
    "                            batch_size=512, #BATCH_SIZE,\n",
    "                            epochs=1000, #EPOCHS,\n",
    "                            callbacks = get_callbacks(run_id = 'first'), #[early_stopping],\n",
    "                            validation_data=(validate_ds, val_y),\n",
    "                            verbose=0) #(val_features, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2682/2682 - 6s - loss: 0.6879 - accuracy: 0.5457 - auc: 0.5513\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6878659725189209, 0.5456876754760742, 0.5513222217559814]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(validate_ds,  val_y, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Timed out waiting for TensorBoard to start. It may still be running as pid 9296."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datetime\n",
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
