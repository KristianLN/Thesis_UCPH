{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\tmptd9n5_0f\\tensorboard_logs\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "import h5py\n",
    "import copy\n",
    "import datetime\n",
    "import ta\n",
    "import pathlib\n",
    "import shutil\n",
    "import tempfile\n",
    "import vaex\n",
    "from IPython import display\n",
    "from IPython.display import clear_output\n",
    "import pyodbc\n",
    "\n",
    "# Tensorflow related\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "import tensorflow.compat.v2.feature_column as fc\n",
    "\n",
    "#!pip install -q git+https://github.com/tensorflow/docs\n",
    "\n",
    "import tensorflow_docs as tfdocs\n",
    "import tensorflow_docs.modeling\n",
    "import tensorflow_docs.plots\n",
    "\n",
    "print(tf.__version__)\n",
    "logdir = pathlib.Path(tempfile.mkdtemp())/\"tensorboard_logs\"\n",
    "shutil.rmtree(logdir, ignore_errors=True)\n",
    "print(logdir)\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, f1_score, log_loss\n",
    "\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.exceptions import ConvergenceWarning \n",
    "from sklearn import ensemble\n",
    "# ConvergenceWarning('ignore')\n",
    "# Do you wanna see?\n",
    "verbose = True\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "#sys.path.append('...../')\n",
    "\n",
    "from utils.data_extraction import load_data_final,load_data_and_save\n",
    "from utils.data_cleaning import HFDataCleaning\n",
    "from utils.generate_features import candleCreateNP_vect_final,\\\n",
    "                                    generateFeatures_final,\\\n",
    "                                    generateFeatures_multi_final\n",
    "\n",
    "from utils.preprocessing_features_and_labels import extract_labels,\\\n",
    "                                                    align_features_and_labels,\\\n",
    "                                                    pre_processing_initial,\\\n",
    "                                                    pre_processing_extended,\\\n",
    "                                                    pre_processing_final,\\\n",
    "                                                    extract_labels_multi_final,\\\n",
    "                                                    align_features_and_labels_multi_final,\\\n",
    "                                                    align_features_and_labels_multi_v5\n",
    "\n",
    "from utils.models import make_input_fn\n",
    "from utils.models import performanceTesting,scoreFunction\n",
    "from utils.plotting import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which one do you want to load? \n",
      "\n",
      "0: aggregateTAQ_May2020_10sec (1).csv\n",
      "1: aggregateTAQ_May2020_30sec (1).csv\n",
      "2: aggregateTAQ_May2020_60sec.csv\n",
      "8: trueAggregateTAQ_60sec.csv\n",
      "\n",
      "\n",
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (19) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>sector</th>\n",
       "      <th>exchange</th>\n",
       "      <th>marketCap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>Technology</td>\n",
       "      <td>NMS</td>\n",
       "      <td>1.578173e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ABBV</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>NYQ</td>\n",
       "      <td>1.742612e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>ABT</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>NYQ</td>\n",
       "      <td>1.631410e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>AEP</td>\n",
       "      <td>Utilities</td>\n",
       "      <td>NYQ</td>\n",
       "      <td>4.089551e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>AMT</td>\n",
       "      <td>Real Estate</td>\n",
       "      <td>NYQ</td>\n",
       "      <td>1.171259e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>APD</td>\n",
       "      <td>Basic Materials</td>\n",
       "      <td>NYQ</td>\n",
       "      <td>5.464395e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>BA</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>NYQ</td>\n",
       "      <td>1.020356e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>BABA</td>\n",
       "      <td>Consumer Cyclical</td>\n",
       "      <td>NYQ</td>\n",
       "      <td>5.936536e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>BAC</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>NYQ</td>\n",
       "      <td>2.020550e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>BHP</td>\n",
       "      <td>Basic Materials</td>\n",
       "      <td>NYQ</td>\n",
       "      <td>1.258194e+11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ticker              sector exchange     marketCap\n",
       "12    AAPL          Technology      NMS  1.578173e+12\n",
       "20    ABBV          Healthcare      NYQ  1.742612e+11\n",
       "34     ABT          Healthcare      NYQ  1.631410e+11\n",
       "126    AEP           Utilities      NYQ  4.089551e+10\n",
       "379    AMT         Real Estate      NYQ  1.171259e+11\n",
       "428    APD     Basic Materials      NYQ  5.464395e+10\n",
       "697     BA         Industrials      NYQ  1.020356e+11\n",
       "699   BABA   Consumer Cyclical      NYQ  5.936536e+11\n",
       "700    BAC  Financial Services      NYQ  2.020550e+11\n",
       "870    BHP     Basic Materials      NYQ  1.258194e+11"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do we extract new data or read in?\n",
    "readIn = True\n",
    "# run load_data()\n",
    "if readIn:\n",
    "    \n",
    "    # Listing the data files \n",
    "    path = '../../../Google Drev/Thesis/Data/TAQ/AggregatedTAQ'\n",
    "#     path = 'F:/AggregatedTAQ/round3'\n",
    "    datafiles = os.listdir(path)\n",
    "    content = np.concatenate([['\\n\\n'],[str(j)+': '+i+'\\n' for j,i in enumerate(datafiles) if 'csv' in i],['\\n\\n']])\n",
    "    \n",
    "    # Asking for user input\n",
    "    file = input('Which one do you want to load? %s'%''.join(content))\n",
    "    if int(file) <= 2:\n",
    "        data = pd.read_csv(path + '/' + datafiles[int(file)],\n",
    "                           header = None,\n",
    "                           names=['open','high','low','close',\n",
    "                                  'spread_open','spread_high','spread_low','spread_close',\n",
    "                                  'bidsize_open','bidsize_high','bidsize_low','bidsize_close',\n",
    "                                  'ofrsize_open','ofrsize_high','ofrsize_low','ofrsize_close',\n",
    "                                  'Ticker'])\n",
    "        # Using the choice of the user to determine the correct market file\n",
    "        key = re.split('[_.]',datafiles[int(file)])[-2]\n",
    "        marketDataFile = [file for file in os.listdir(path+'/round5_market_tickers') if key in file]\n",
    "\n",
    "        # Reading in the market data\n",
    "        tempData = pd.read_csv(path+'/round5_market_tickers/'+marketDataFile[0]\n",
    "                               ,header = None\n",
    "                               ,names=['open','high','low','close',\n",
    "                                      'spread_open','spread_high','spread_low','spread_close',\n",
    "                                      'bidsize_open','bidsize_high','bidsize_low','bidsize_close',\n",
    "                                      'ofrsize_open','ofrsize_high','ofrsize_low','ofrsize_close',\n",
    "                                      'Ticker'])\n",
    "        # Adding the market data to the ticker data\n",
    "        data = pd.concat([data,tempData],axis=0)\n",
    "    else:\n",
    "        data = pd.read_csv(path + '/' + datafiles[int(file)],\n",
    "                           header = 0,\n",
    "                           index_col=[0,1]\n",
    "#                            names=['open','high','low','close',\n",
    "#                                   'spread_open','spread_high','spread_low','spread_close',\n",
    "#                                   'bidsize_open','bidsize_high','bidsize_low','bidsize_close',\n",
    "#                                   'ofrsize_open','ofrsize_high','ofrsize_low','ofrsize_close',\n",
    "#                                   'Ticker']\n",
    "                          )\n",
    "    \n",
    "    # Lower casing all column names\n",
    "#     data.columns = data.columns.str.lower()\n",
    "else:\n",
    "    \n",
    "    # print(os.listdir())\n",
    "    try:\n",
    "        path = 'a:/taqhdf5'  #'a:/taqhdf5'\n",
    "        os.listdir(path)\n",
    "    except:\n",
    "        path = 't:/taqhdf5'  #'a:/taqhdf5'\n",
    "        os.listdir(path)\n",
    "        \n",
    "    # Sample type\n",
    "    data_sample = 'full' # or 'stable'\n",
    "    # allFiles = os.listdir(path)\n",
    "    # print(len(allFiles), allFiles[:5], allFiles[-5:])\n",
    "    # print(allFiles[-10:])\n",
    "\n",
    "    #dates = np.array(['2020040' + str(i) if i < 10 else '202004' + str(i) for i in np.arange(1,16)]).astype(int)\n",
    "    dates = np.array(['20200501']).astype(int)#,'20200402','20200403','20200406','20200407'\n",
    "\n",
    "    # Provide a list of tickers of interest\n",
    "    \n",
    "    tickers = sorted(['TSLA','FB'])#'MSFT'\n",
    "    \n",
    "    # Do we need data on trades, quotes or both?\n",
    "    dataNeeded = 'quotes' # 'trades', 'quotes' or 'both'\n",
    "    \n",
    "    if dataNeeded == 'trades':\n",
    "        tradeData = load_data_final(dates, tickers, dataNeeded, path, verbose)\n",
    "    elif dataNeeded == 'quotes':\n",
    "        quoteData = load_data_final(dates,\n",
    "                                    tickers,\n",
    "                                    dataNeeded,\n",
    "                                    path,\n",
    "                                    verbose,\n",
    "                                    extract_candles = False,\n",
    "                                    aggHorizon = 1,\n",
    "                                    extra_features_from_quotes = None,\n",
    "                                    data_sample = data_sample)\n",
    "    elif dataNeeded == 'both':\n",
    "        tradeData, quoteData = load_data_final(dates, tickers, dataNeeded, path, verbose)\n",
    "\n",
    "# Reading in sector information\n",
    "stockInfo = pd.read_csv('../utils/stockInfo_v1.csv',header=[0,1])\n",
    "stockInfo.columns = ['ticker','sector','exchange','marketCap']\n",
    "\n",
    "# Creating a table with stock information based on the tickers available in the data.\n",
    "uniqueTickers = data.Ticker.unique()\n",
    "stockTable = stockInfo[stockInfo.ticker.isin(uniqueTickers)]\n",
    "stockTable.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hyperparameters.txt', 'metrics.txt']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = os.listdir('../AzureML/Output_from_cloud')\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Reading in the file\n",
    "\n",
    "with open('../AzureML/Output_from_cloud/'+files[0],'r') as file:\n",
    "    content = file.readlines()\n",
    "\n",
    "## Containers for the data\n",
    "all_ids = []\n",
    "all_parameters = []\n",
    "\n",
    "## Going over each line in the text file\n",
    "for a in np.arange(len(content)):\n",
    "    \n",
    "    ## Split the lines on tabs\n",
    "    temp_parameters = re.split('[\\t]',content[a])[1]\n",
    "    \n",
    "    ## Basic string cleaning, i.e. removing redundant characters\n",
    "    test = [re.split(': ',i.strip()) for i in re.split(',',temp_parameters.replace('{','')\\\n",
    "                                                                       .replace('}','')\\\n",
    "                                                                       .replace('\\n','')\\\n",
    "                                                                       .replace('\"',''))]\n",
    "    \n",
    "    ## Output of test is a list of lists, where each sublist holds the name of a model variable and its value.\n",
    "    ## We create a dictornary to hold all model variables, making it easy to add the observation to the dataframe.\n",
    "    test = {i[0]:i[1] for i in test}\n",
    "    \n",
    "    # Constructing the dataframe\n",
    "    if a == 0:\n",
    "        parameters = pd.DataFrame(test,index=[re.split('[\\t]',content[a])[0]])\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        parameters.loc[re.split('[\\t]',content[a])[0]] = pd.Series(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activation-inner</th>\n",
       "      <th>activation-output</th>\n",
       "      <th>batch-norm</th>\n",
       "      <th>batch-shuffle</th>\n",
       "      <th>batch-size</th>\n",
       "      <th>dropout-ratio</th>\n",
       "      <th>feature-lags</th>\n",
       "      <th>featureset</th>\n",
       "      <th>first-layer-neurons</th>\n",
       "      <th>label-type</th>\n",
       "      <th>learning-rate</th>\n",
       "      <th>n-epochs</th>\n",
       "      <th>n-layers</th>\n",
       "      <th>nn-type</th>\n",
       "      <th>pastobs-in-percentage</th>\n",
       "      <th>pre-processing</th>\n",
       "      <th>second-layer-neurons</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HD_81ace623-e09b-4393-8a5e-131ea8749a35_0</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>linear</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3300</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>150</td>\n",
       "      <td>3</td>\n",
       "      <td>ffnn</td>\n",
       "      <td>1</td>\n",
       "      <td>stacked</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD_81ace623-e09b-4393-8a5e-131ea8749a35_1</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>linear</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21450</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>150</td>\n",
       "      <td>3</td>\n",
       "      <td>ffnn</td>\n",
       "      <td>1</td>\n",
       "      <td>stacked</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD_81ace623-e09b-4393-8a5e-131ea8749a35_2</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>softmax</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3300</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>150</td>\n",
       "      <td>2</td>\n",
       "      <td>ffnn</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD_81ace623-e09b-4393-8a5e-131ea8749a35_3</th>\n",
       "      <td>tanh</td>\n",
       "      <td>linear</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10725</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>150</td>\n",
       "      <td>2</td>\n",
       "      <td>ffnn</td>\n",
       "      <td>0</td>\n",
       "      <td>quantgau</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD_81ace623-e09b-4393-8a5e-131ea8749a35_4</th>\n",
       "      <td>leakyrelu</td>\n",
       "      <td>linear</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21450</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>150</td>\n",
       "      <td>2</td>\n",
       "      <td>lstm</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD_81ace623-e09b-4393-8a5e-131ea8749a35_995</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>linear</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>21450</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>150</td>\n",
       "      <td>4</td>\n",
       "      <td>ffnn</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD_81ace623-e09b-4393-8a5e-131ea8749a35_996</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>softmax</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10725</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>150</td>\n",
       "      <td>4</td>\n",
       "      <td>ffnn</td>\n",
       "      <td>1</td>\n",
       "      <td>std</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD_81ace623-e09b-4393-8a5e-131ea8749a35_997</th>\n",
       "      <td>relu</td>\n",
       "      <td>linear</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10725</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>150</td>\n",
       "      <td>2</td>\n",
       "      <td>lstm</td>\n",
       "      <td>0</td>\n",
       "      <td>pow</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD_81ace623-e09b-4393-8a5e-131ea8749a35_998</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>softmax</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21450</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>150</td>\n",
       "      <td>2</td>\n",
       "      <td>lstm</td>\n",
       "      <td>0</td>\n",
       "      <td>stacked</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD_81ace623-e09b-4393-8a5e-131ea8749a35_999</th>\n",
       "      <td>tanh</td>\n",
       "      <td>softmax</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21450</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>150</td>\n",
       "      <td>4</td>\n",
       "      <td>lstm</td>\n",
       "      <td>1</td>\n",
       "      <td>quantgau</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            activation-inner  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_0            sigmoid   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_1            sigmoid   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_2            sigmoid   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_3               tanh   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_4          leakyrelu   \n",
       "...                                                      ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_995          sigmoid   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_996          sigmoid   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_997             relu   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_998          sigmoid   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999             tanh   \n",
       "\n",
       "                                            activation-output batch-norm  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_0              linear          0   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_1              linear          0   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_2             softmax          0   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_3              linear          0   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_4              linear          0   \n",
       "...                                                       ...        ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_995            linear          1   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_996           softmax          1   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_997            linear          1   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_998           softmax          0   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999           softmax          0   \n",
       "\n",
       "                                            batch-shuffle batch-size  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_0               1       3300   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_1               1      21450   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_2               0       3300   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_3               0      10725   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_4               1      21450   \n",
       "...                                                   ...        ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_995             0      21450   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_996             1      10725   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_997             1      10725   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_998             0      21450   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999             0      21450   \n",
       "\n",
       "                                            dropout-ratio feature-lags  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_0             0.1            3   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_1             0.1            1   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_2             0.4            0   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_3             0.5            0   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_4             0.4            1   \n",
       "...                                                   ...          ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_995           0.0            3   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_996           0.0            3   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_997           0.5            3   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_998           0.3            5   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999           0.2            0   \n",
       "\n",
       "                                            featureset first-layer-neurons  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_0            2                  32   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_1            1                  64   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_2            2                  32   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_3            1                  64   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_4            2                 128   \n",
       "...                                                ...                 ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_995          3                  64   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_996          0                  64   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_997          2                  64   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_998          3                 128   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999          1                 128   \n",
       "\n",
       "                                            label-type learning-rate n-epochs  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_0            0          0.01      150   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_1            1           0.1      150   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_2            4           0.1      150   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_3            0          0.01      150   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_4            0         0.001      150   \n",
       "...                                                ...           ...      ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_995          2        0.0001      150   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_996          1          0.01      150   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_997          3        0.0001      150   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_998          2         0.001      150   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999          1        0.0001      150   \n",
       "\n",
       "                                            n-layers nn-type  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_0          3    ffnn   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_1          3    ffnn   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_2          2    ffnn   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_3          2    ffnn   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_4          2    lstm   \n",
       "...                                              ...     ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_995        4    ffnn   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_996        4    ffnn   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_997        2    lstm   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_998        2    lstm   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999        4    lstm   \n",
       "\n",
       "                                            pastobs-in-percentage  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_0                       1   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_1                       1   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_2                       0   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_3                       0   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_4                       1   \n",
       "...                                                           ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_995                     0   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_996                     1   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_997                     0   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_998                     0   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999                     1   \n",
       "\n",
       "                                            pre-processing  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_0          stacked   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_1          stacked   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_2             None   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_3         quantgau   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_4             None   \n",
       "...                                                    ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_995           None   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_996            std   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_997            pow   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_998        stacked   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999       quantgau   \n",
       "\n",
       "                                            second-layer-neurons  \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_0                     64  \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_1                     64  \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_2                     64  \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_3                    128  \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_4                     64  \n",
       "...                                                          ...  \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_995                   64  \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_996                   64  \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_997                   64  \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_998                   64  \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999                   32  \n",
       "\n",
       "[1000 rows x 17 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Readidng in the file\n",
    "with open('../AzureML/Output_from_cloud/'+files[1],'r') as file:\n",
    "    content = file.readlines()\n",
    "\n",
    "## Containers\n",
    "t11 = []\n",
    "t12 = []\n",
    "t13 = []\n",
    "\n",
    "t21 = []\n",
    "t22 = []\n",
    "t23 = []\n",
    "\n",
    "## Going over each line\n",
    "for i in np.arange(len(content)):#\n",
    "    \n",
    "    ## Split each line on tabs\n",
    "    temp = re.split('\\t',content[i].replace('\\n',''))\n",
    "    \n",
    "    ## There are two types of observations in the text file; 1. final metrics of those models which where not stoppe early\n",
    "    ## and 2. a time series of a metric for each model.\n",
    "    \n",
    "    ## If the length of the last element, in a line, is less than 50 (because it is just a number, i.e. final metric)\n",
    "    ## It stored separately for the time series.\n",
    "    if len(temp[2]) < 50:\n",
    "\n",
    "        t11.append(temp[0])\n",
    "        t12.append(temp[1])\n",
    "        t13.append(temp[2])\n",
    "    \n",
    "    ## Time series\n",
    "    else:\n",
    "    \n",
    "        container = np.zeros(155)\n",
    "        temp1 = [float(j.strip()) if j.strip() !=\"'NaN'\" else 0 for j in re.split(',',temp[2].replace('[','').replace(']',''))]\n",
    "\n",
    "        container[0:len(temp1)] = temp1\n",
    "        container[len(temp1):] = temp1[-1]\n",
    "\n",
    "        t21.append(temp[0])\n",
    "        t22.append(temp[1])\n",
    "        t23.append(container)        \n",
    "\n",
    "## Storing the time series in a dataframe\n",
    "arrays = [t21,t22]\n",
    "tuples = list(zip(*arrays))\n",
    "\n",
    "runningMetrics = pd.DataFrame(np.array(t23),\n",
    "                              index=pd.MultiIndex.from_tuples(tuples),\n",
    "                              columns = [np.arange(155).astype(str)]\n",
    "                             )\n",
    "## Storing the final metrics in a dataframe.\n",
    "arrays = [t11,t12]\n",
    "tuples = list(zip(*arrays))\n",
    "finalMetrics = pd.DataFrame(t13,index = pd.MultiIndex.from_tuples(tuples),columns = ['size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">HD_81ace623-e09b-4393-8a5e-131ea8749a35_1</th>\n",
       "      <th>Final test loss</th>\n",
       "      <td>0.8833522492045336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Final test AUC</th>\n",
       "      <td>0.7648658156394958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Final test accuracy</th>\n",
       "      <td>0.6109746098518372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">HD_81ace623-e09b-4393-8a5e-131ea8749a35_3</th>\n",
       "      <th>Final test loss</th>\n",
       "      <td>1.1133369887535414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Final test AUC</th>\n",
       "      <td>0.640163779258728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">HD_81ace623-e09b-4393-8a5e-131ea8749a35_997</th>\n",
       "      <th>Final test AUC</th>\n",
       "      <td>0.7837895154953003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Final test accuracy</th>\n",
       "      <td>0.602816104888916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">HD_81ace623-e09b-4393-8a5e-131ea8749a35_998</th>\n",
       "      <th>Final test loss</th>\n",
       "      <td>1.3713646207894699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Final test AUC</th>\n",
       "      <td>0.7241190671920776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Final test accuracy</th>\n",
       "      <td>0.4148908853530884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1170 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                               size\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_1   Final test loss      0.8833522492045336\n",
       "                                            Final test AUC       0.7648658156394958\n",
       "                                            Final test accuracy  0.6109746098518372\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_3   Final test loss      1.1133369887535414\n",
       "                                            Final test AUC        0.640163779258728\n",
       "...                                                                             ...\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_997 Final test AUC       0.7837895154953003\n",
       "                                            Final test accuracy   0.602816104888916\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_998 Final test loss      1.3713646207894699\n",
       "                                            Final test AUC       0.7241190671920776\n",
       "                                            Final test accuracy  0.4148908853530884\n",
       "\n",
       "[1170 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "      <th>150</th>\n",
       "      <th>151</th>\n",
       "      <th>152</th>\n",
       "      <th>153</th>\n",
       "      <th>154</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">HD_81ace623-e09b-4393-8a5e-131ea8749a35_0</th>\n",
       "      <th>Loss</th>\n",
       "      <td>1.098537</td>\n",
       "      <td>1.098504</td>\n",
       "      <td>1.098467</td>\n",
       "      <td>1.098423</td>\n",
       "      <td>1.098371</td>\n",
       "      <td>1.098309</td>\n",
       "      <td>1.098233</td>\n",
       "      <td>1.098140</td>\n",
       "      <td>1.098026</td>\n",
       "      <td>1.097886</td>\n",
       "      <td>...</td>\n",
       "      <td>1.066601</td>\n",
       "      <td>1.066601</td>\n",
       "      <td>1.066601</td>\n",
       "      <td>1.066601</td>\n",
       "      <td>1.066601</td>\n",
       "      <td>1.066601</td>\n",
       "      <td>1.066601</td>\n",
       "      <td>1.066601</td>\n",
       "      <td>1.066601</td>\n",
       "      <td>1.066601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.354843</td>\n",
       "      <td>0.358482</td>\n",
       "      <td>0.362843</td>\n",
       "      <td>0.365199</td>\n",
       "      <td>0.366960</td>\n",
       "      <td>0.367240</td>\n",
       "      <td>0.368826</td>\n",
       "      <td>0.370377</td>\n",
       "      <td>0.371579</td>\n",
       "      <td>0.372220</td>\n",
       "      <td>...</td>\n",
       "      <td>0.412316</td>\n",
       "      <td>0.412316</td>\n",
       "      <td>0.412316</td>\n",
       "      <td>0.412316</td>\n",
       "      <td>0.412316</td>\n",
       "      <td>0.412316</td>\n",
       "      <td>0.412316</td>\n",
       "      <td>0.412316</td>\n",
       "      <td>0.412316</td>\n",
       "      <td>0.412316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC</th>\n",
       "      <td>0.500120</td>\n",
       "      <td>0.500277</td>\n",
       "      <td>0.500545</td>\n",
       "      <td>0.501018</td>\n",
       "      <td>0.501737</td>\n",
       "      <td>0.502806</td>\n",
       "      <td>0.504301</td>\n",
       "      <td>0.506150</td>\n",
       "      <td>0.508213</td>\n",
       "      <td>0.510308</td>\n",
       "      <td>...</td>\n",
       "      <td>0.575838</td>\n",
       "      <td>0.575838</td>\n",
       "      <td>0.575838</td>\n",
       "      <td>0.575838</td>\n",
       "      <td>0.575838</td>\n",
       "      <td>0.575838</td>\n",
       "      <td>0.575838</td>\n",
       "      <td>0.575838</td>\n",
       "      <td>0.575838</td>\n",
       "      <td>0.575838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Loss</th>\n",
       "      <td>1.098558</td>\n",
       "      <td>1.098524</td>\n",
       "      <td>1.098487</td>\n",
       "      <td>1.098442</td>\n",
       "      <td>1.098396</td>\n",
       "      <td>1.098339</td>\n",
       "      <td>1.098267</td>\n",
       "      <td>1.098180</td>\n",
       "      <td>1.098077</td>\n",
       "      <td>1.097955</td>\n",
       "      <td>...</td>\n",
       "      <td>1.068791</td>\n",
       "      <td>1.068791</td>\n",
       "      <td>1.068791</td>\n",
       "      <td>1.068791</td>\n",
       "      <td>1.068791</td>\n",
       "      <td>1.068791</td>\n",
       "      <td>1.068791</td>\n",
       "      <td>1.068791</td>\n",
       "      <td>1.068791</td>\n",
       "      <td>1.068791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Accuracy</th>\n",
       "      <td>0.344181</td>\n",
       "      <td>0.350251</td>\n",
       "      <td>0.353537</td>\n",
       "      <td>0.358348</td>\n",
       "      <td>0.360740</td>\n",
       "      <td>0.363537</td>\n",
       "      <td>0.365985</td>\n",
       "      <td>0.368336</td>\n",
       "      <td>0.368998</td>\n",
       "      <td>0.369959</td>\n",
       "      <td>...</td>\n",
       "      <td>0.412060</td>\n",
       "      <td>0.412060</td>\n",
       "      <td>0.412060</td>\n",
       "      <td>0.412060</td>\n",
       "      <td>0.412060</td>\n",
       "      <td>0.412060</td>\n",
       "      <td>0.412060</td>\n",
       "      <td>0.412060</td>\n",
       "      <td>0.412060</td>\n",
       "      <td>0.412060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">HD_81ace623-e09b-4393-8a5e-131ea8749a35_999</th>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>...</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC</th>\n",
       "      <td>0.006679</td>\n",
       "      <td>0.003153</td>\n",
       "      <td>0.002064</td>\n",
       "      <td>0.001534</td>\n",
       "      <td>0.001221</td>\n",
       "      <td>0.001014</td>\n",
       "      <td>0.000867</td>\n",
       "      <td>0.000757</td>\n",
       "      <td>0.000672</td>\n",
       "      <td>0.000604</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.000113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Loss</th>\n",
       "      <td>5.383223</td>\n",
       "      <td>5.355752</td>\n",
       "      <td>5.355751</td>\n",
       "      <td>5.355751</td>\n",
       "      <td>5.355751</td>\n",
       "      <td>5.355750</td>\n",
       "      <td>5.355750</td>\n",
       "      <td>5.355750</td>\n",
       "      <td>5.355750</td>\n",
       "      <td>5.355750</td>\n",
       "      <td>...</td>\n",
       "      <td>5.355750</td>\n",
       "      <td>5.355750</td>\n",
       "      <td>5.355750</td>\n",
       "      <td>5.355750</td>\n",
       "      <td>5.355750</td>\n",
       "      <td>5.355750</td>\n",
       "      <td>5.355750</td>\n",
       "      <td>5.355750</td>\n",
       "      <td>5.355750</td>\n",
       "      <td>5.355750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Accuracy</th>\n",
       "      <td>0.333057</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>...</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>0.332281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train AUC</th>\n",
       "      <td>0.030584</td>\n",
       "      <td>0.004384</td>\n",
       "      <td>0.002511</td>\n",
       "      <td>0.001766</td>\n",
       "      <td>0.001362</td>\n",
       "      <td>0.001109</td>\n",
       "      <td>0.000935</td>\n",
       "      <td>0.000809</td>\n",
       "      <td>0.000712</td>\n",
       "      <td>0.000636</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6000 rows × 155 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   0  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_0   Loss            1.098537   \n",
       "                                            Accuracy        0.354843   \n",
       "                                            AUC             0.500120   \n",
       "                                            Train Loss      1.098558   \n",
       "                                            Train Accuracy  0.344181   \n",
       "...                                                              ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999 Accuracy        0.337729   \n",
       "                                            AUC             0.006679   \n",
       "                                            Train Loss      5.383223   \n",
       "                                            Train Accuracy  0.333057   \n",
       "                                            Train AUC       0.030584   \n",
       "\n",
       "                                                                   1  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_0   Loss            1.098504   \n",
       "                                            Accuracy        0.358482   \n",
       "                                            AUC             0.500277   \n",
       "                                            Train Loss      1.098524   \n",
       "                                            Train Accuracy  0.350251   \n",
       "...                                                              ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999 Accuracy        0.337729   \n",
       "                                            AUC             0.003153   \n",
       "                                            Train Loss      5.355752   \n",
       "                                            Train Accuracy  0.332281   \n",
       "                                            Train AUC       0.004384   \n",
       "\n",
       "                                                                   2  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_0   Loss            1.098467   \n",
       "                                            Accuracy        0.362843   \n",
       "                                            AUC             0.500545   \n",
       "                                            Train Loss      1.098487   \n",
       "                                            Train Accuracy  0.353537   \n",
       "...                                                              ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999 Accuracy        0.337729   \n",
       "                                            AUC             0.002064   \n",
       "                                            Train Loss      5.355751   \n",
       "                                            Train Accuracy  0.332281   \n",
       "                                            Train AUC       0.002511   \n",
       "\n",
       "                                                                   3  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_0   Loss            1.098423   \n",
       "                                            Accuracy        0.365199   \n",
       "                                            AUC             0.501018   \n",
       "                                            Train Loss      1.098442   \n",
       "                                            Train Accuracy  0.358348   \n",
       "...                                                              ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999 Accuracy        0.337729   \n",
       "                                            AUC             0.001534   \n",
       "                                            Train Loss      5.355751   \n",
       "                                            Train Accuracy  0.332281   \n",
       "                                            Train AUC       0.001766   \n",
       "\n",
       "                                                                   4  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_0   Loss            1.098371   \n",
       "                                            Accuracy        0.366960   \n",
       "                                            AUC             0.501737   \n",
       "                                            Train Loss      1.098396   \n",
       "                                            Train Accuracy  0.360740   \n",
       "...                                                              ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999 Accuracy        0.337729   \n",
       "                                            AUC             0.001221   \n",
       "                                            Train Loss      5.355751   \n",
       "                                            Train Accuracy  0.332281   \n",
       "                                            Train AUC       0.001362   \n",
       "\n",
       "                                                                   5  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_0   Loss            1.098309   \n",
       "                                            Accuracy        0.367240   \n",
       "                                            AUC             0.502806   \n",
       "                                            Train Loss      1.098339   \n",
       "                                            Train Accuracy  0.363537   \n",
       "...                                                              ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999 Accuracy        0.337729   \n",
       "                                            AUC             0.001014   \n",
       "                                            Train Loss      5.355750   \n",
       "                                            Train Accuracy  0.332281   \n",
       "                                            Train AUC       0.001109   \n",
       "\n",
       "                                                                   6  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_0   Loss            1.098233   \n",
       "                                            Accuracy        0.368826   \n",
       "                                            AUC             0.504301   \n",
       "                                            Train Loss      1.098267   \n",
       "                                            Train Accuracy  0.365985   \n",
       "...                                                              ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999 Accuracy        0.337729   \n",
       "                                            AUC             0.000867   \n",
       "                                            Train Loss      5.355750   \n",
       "                                            Train Accuracy  0.332281   \n",
       "                                            Train AUC       0.000935   \n",
       "\n",
       "                                                                   7  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_0   Loss            1.098140   \n",
       "                                            Accuracy        0.370377   \n",
       "                                            AUC             0.506150   \n",
       "                                            Train Loss      1.098180   \n",
       "                                            Train Accuracy  0.368336   \n",
       "...                                                              ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999 Accuracy        0.337729   \n",
       "                                            AUC             0.000757   \n",
       "                                            Train Loss      5.355750   \n",
       "                                            Train Accuracy  0.332281   \n",
       "                                            Train AUC       0.000809   \n",
       "\n",
       "                                                                   8  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_0   Loss            1.098026   \n",
       "                                            Accuracy        0.371579   \n",
       "                                            AUC             0.508213   \n",
       "                                            Train Loss      1.098077   \n",
       "                                            Train Accuracy  0.368998   \n",
       "...                                                              ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999 Accuracy        0.337729   \n",
       "                                            AUC             0.000672   \n",
       "                                            Train Loss      5.355750   \n",
       "                                            Train Accuracy  0.332281   \n",
       "                                            Train AUC       0.000712   \n",
       "\n",
       "                                                                   9  ...  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_0   Loss            1.097886  ...   \n",
       "                                            Accuracy        0.372220  ...   \n",
       "                                            AUC             0.510308  ...   \n",
       "                                            Train Loss      1.097955  ...   \n",
       "                                            Train Accuracy  0.369959  ...   \n",
       "...                                                              ...  ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999 Accuracy        0.337729  ...   \n",
       "                                            AUC             0.000604  ...   \n",
       "                                            Train Loss      5.355750  ...   \n",
       "                                            Train Accuracy  0.332281  ...   \n",
       "                                            Train AUC       0.000636  ...   \n",
       "\n",
       "                                                                 145  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_0   Loss            1.066601   \n",
       "                                            Accuracy        0.412316   \n",
       "                                            AUC             0.575838   \n",
       "                                            Train Loss      1.068791   \n",
       "                                            Train Accuracy  0.412060   \n",
       "...                                                              ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999 Accuracy        0.337729   \n",
       "                                            AUC             0.000113   \n",
       "                                            Train Loss      5.355750   \n",
       "                                            Train Accuracy  0.332281   \n",
       "                                            Train AUC       0.000114   \n",
       "\n",
       "                                                                 146  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_0   Loss            1.066601   \n",
       "                                            Accuracy        0.412316   \n",
       "                                            AUC             0.575838   \n",
       "                                            Train Loss      1.068791   \n",
       "                                            Train Accuracy  0.412060   \n",
       "...                                                              ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999 Accuracy        0.337729   \n",
       "                                            AUC             0.000113   \n",
       "                                            Train Loss      5.355750   \n",
       "                                            Train Accuracy  0.332281   \n",
       "                                            Train AUC       0.000114   \n",
       "\n",
       "                                                                 147  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_0   Loss            1.066601   \n",
       "                                            Accuracy        0.412316   \n",
       "                                            AUC             0.575838   \n",
       "                                            Train Loss      1.068791   \n",
       "                                            Train Accuracy  0.412060   \n",
       "...                                                              ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999 Accuracy        0.337729   \n",
       "                                            AUC             0.000113   \n",
       "                                            Train Loss      5.355750   \n",
       "                                            Train Accuracy  0.332281   \n",
       "                                            Train AUC       0.000114   \n",
       "\n",
       "                                                                 148  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_0   Loss            1.066601   \n",
       "                                            Accuracy        0.412316   \n",
       "                                            AUC             0.575838   \n",
       "                                            Train Loss      1.068791   \n",
       "                                            Train Accuracy  0.412060   \n",
       "...                                                              ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999 Accuracy        0.337729   \n",
       "                                            AUC             0.000113   \n",
       "                                            Train Loss      5.355750   \n",
       "                                            Train Accuracy  0.332281   \n",
       "                                            Train AUC       0.000114   \n",
       "\n",
       "                                                                 149  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_0   Loss            1.066601   \n",
       "                                            Accuracy        0.412316   \n",
       "                                            AUC             0.575838   \n",
       "                                            Train Loss      1.068791   \n",
       "                                            Train Accuracy  0.412060   \n",
       "...                                                              ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999 Accuracy        0.337729   \n",
       "                                            AUC             0.000113   \n",
       "                                            Train Loss      5.355750   \n",
       "                                            Train Accuracy  0.332281   \n",
       "                                            Train AUC       0.000114   \n",
       "\n",
       "                                                                 150  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_0   Loss            1.066601   \n",
       "                                            Accuracy        0.412316   \n",
       "                                            AUC             0.575838   \n",
       "                                            Train Loss      1.068791   \n",
       "                                            Train Accuracy  0.412060   \n",
       "...                                                              ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999 Accuracy        0.337729   \n",
       "                                            AUC             0.000113   \n",
       "                                            Train Loss      5.355750   \n",
       "                                            Train Accuracy  0.332281   \n",
       "                                            Train AUC       0.000114   \n",
       "\n",
       "                                                                 151  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_0   Loss            1.066601   \n",
       "                                            Accuracy        0.412316   \n",
       "                                            AUC             0.575838   \n",
       "                                            Train Loss      1.068791   \n",
       "                                            Train Accuracy  0.412060   \n",
       "...                                                              ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999 Accuracy        0.337729   \n",
       "                                            AUC             0.000113   \n",
       "                                            Train Loss      5.355750   \n",
       "                                            Train Accuracy  0.332281   \n",
       "                                            Train AUC       0.000114   \n",
       "\n",
       "                                                                 152  \\\n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_0   Loss            1.066601   \n",
       "                                            Accuracy        0.412316   \n",
       "                                            AUC             0.575838   \n",
       "                                            Train Loss      1.068791   \n",
       "                                            Train Accuracy  0.412060   \n",
       "...                                                              ...   \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999 Accuracy        0.337729   \n",
       "                                            AUC             0.000113   \n",
       "                                            Train Loss      5.355750   \n",
       "                                            Train Accuracy  0.332281   \n",
       "                                            Train AUC       0.000114   \n",
       "\n",
       "                                                                 153       154  \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_0   Loss            1.066601  1.066601  \n",
       "                                            Accuracy        0.412316  0.412316  \n",
       "                                            AUC             0.575838  0.575838  \n",
       "                                            Train Loss      1.068791  1.068791  \n",
       "                                            Train Accuracy  0.412060  0.412060  \n",
       "...                                                              ...       ...  \n",
       "HD_81ace623-e09b-4393-8a5e-131ea8749a35_999 Accuracy        0.337729  0.337729  \n",
       "                                            AUC             0.000113  0.000113  \n",
       "                                            Train Loss      5.355750  5.355750  \n",
       "                                            Train Accuracy  0.332281  0.332281  \n",
       "                                            Train AUC       0.000114  0.000114  \n",
       "\n",
       "[6000 rows x 155 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runningMetrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attaching the last observation of each model, for each metric, to the parameters of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>activation-inner</th>\n",
       "      <th>activation-output</th>\n",
       "      <th>batch-norm</th>\n",
       "      <th>batch-shuffle</th>\n",
       "      <th>batch-size</th>\n",
       "      <th>dropout-ratio</th>\n",
       "      <th>feature-lags</th>\n",
       "      <th>featureset</th>\n",
       "      <th>first-layer-neurons</th>\n",
       "      <th>...</th>\n",
       "      <th>pastobs-in-percentage</th>\n",
       "      <th>pre-processing</th>\n",
       "      <th>second-layer-neurons</th>\n",
       "      <th>id</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Train AUC</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Train Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_115</td>\n",
       "      <td>relu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3300</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>quantgau</td>\n",
       "      <td>128</td>\n",
       "      <td>115</td>\n",
       "      <td>0.80363</td>\n",
       "      <td>0.58075</td>\n",
       "      <td>0.98257</td>\n",
       "      <td>0.80358</td>\n",
       "      <td>0.66548</td>\n",
       "      <td>0.77074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_781</td>\n",
       "      <td>tanh</td>\n",
       "      <td>linear</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>21450</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>minmax</td>\n",
       "      <td>32</td>\n",
       "      <td>781</td>\n",
       "      <td>0.79064</td>\n",
       "      <td>0.57710</td>\n",
       "      <td>0.99908</td>\n",
       "      <td>0.79060</td>\n",
       "      <td>0.65135</td>\n",
       "      <td>0.80627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_997</td>\n",
       "      <td>relu</td>\n",
       "      <td>linear</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10725</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>pow</td>\n",
       "      <td>64</td>\n",
       "      <td>997</td>\n",
       "      <td>0.78380</td>\n",
       "      <td>0.60282</td>\n",
       "      <td>0.90322</td>\n",
       "      <td>0.78376</td>\n",
       "      <td>0.62677</td>\n",
       "      <td>0.84667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_928</td>\n",
       "      <td>relu</td>\n",
       "      <td>linear</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21450</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>std</td>\n",
       "      <td>32</td>\n",
       "      <td>928</td>\n",
       "      <td>0.78185</td>\n",
       "      <td>0.61228</td>\n",
       "      <td>0.89609</td>\n",
       "      <td>0.78181</td>\n",
       "      <td>0.62734</td>\n",
       "      <td>0.84895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_128</td>\n",
       "      <td>tanh</td>\n",
       "      <td>linear</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>21450</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>0.78175</td>\n",
       "      <td>0.60582</td>\n",
       "      <td>0.92492</td>\n",
       "      <td>0.78172</td>\n",
       "      <td>0.62636</td>\n",
       "      <td>0.85098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_814</td>\n",
       "      <td>tanh</td>\n",
       "      <td>linear</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3300</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>32</td>\n",
       "      <td>814</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.19641</td>\n",
       "      <td>0.94736</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.19952</td>\n",
       "      <td>0.95143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_304</td>\n",
       "      <td>leakyrelu</td>\n",
       "      <td>linear</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10725</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>minmax</td>\n",
       "      <td>32</td>\n",
       "      <td>304</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.19329</td>\n",
       "      <td>0.89643</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.18706</td>\n",
       "      <td>0.91432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_195</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>linear</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10725</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>128</td>\n",
       "      <td>195</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.45457</td>\n",
       "      <td>0.68465</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.45333</td>\n",
       "      <td>0.68717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_861</td>\n",
       "      <td>relu</td>\n",
       "      <td>linear</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3300</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>128</td>\n",
       "      <td>861</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.16547</td>\n",
       "      <td>1.59072</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.17433</td>\n",
       "      <td>1.59977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_321</td>\n",
       "      <td>leakyrelu</td>\n",
       "      <td>linear</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>std</td>\n",
       "      <td>64</td>\n",
       "      <td>321</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.19750</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.19989</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          run_id activation-inner  \\\n",
       "115  HD_81ace623-e09b-4393-8a5e-131ea8749a35_115             relu   \n",
       "781  HD_81ace623-e09b-4393-8a5e-131ea8749a35_781             tanh   \n",
       "997  HD_81ace623-e09b-4393-8a5e-131ea8749a35_997             relu   \n",
       "928  HD_81ace623-e09b-4393-8a5e-131ea8749a35_928             relu   \n",
       "128  HD_81ace623-e09b-4393-8a5e-131ea8749a35_128             tanh   \n",
       "..                                           ...              ...   \n",
       "814  HD_81ace623-e09b-4393-8a5e-131ea8749a35_814             tanh   \n",
       "304  HD_81ace623-e09b-4393-8a5e-131ea8749a35_304        leakyrelu   \n",
       "195  HD_81ace623-e09b-4393-8a5e-131ea8749a35_195          sigmoid   \n",
       "861  HD_81ace623-e09b-4393-8a5e-131ea8749a35_861             relu   \n",
       "321  HD_81ace623-e09b-4393-8a5e-131ea8749a35_321        leakyrelu   \n",
       "\n",
       "    activation-output batch-norm batch-shuffle batch-size dropout-ratio  \\\n",
       "115           softmax          1             0       3300           0.2   \n",
       "781            linear          1             1      21450           0.3   \n",
       "997            linear          1             1      10725           0.5   \n",
       "928            linear          0             1      21450           0.4   \n",
       "128            linear          1             1      21450           0.3   \n",
       "..                ...        ...           ...        ...           ...   \n",
       "814            linear          0             0       3300           0.1   \n",
       "304            linear          0             1      10725           0.1   \n",
       "195            linear          1             1      10725           0.5   \n",
       "861            linear          1             1       3300           0.2   \n",
       "321            linear          0             0       3300           0.0   \n",
       "\n",
       "    feature-lags featureset first-layer-neurons  ... pastobs-in-percentage  \\\n",
       "115            1          3                 128  ...                     1   \n",
       "781            3          0                  64  ...                     1   \n",
       "997            3          2                  64  ...                     0   \n",
       "928            1          0                  64  ...                     0   \n",
       "128            0          2                  64  ...                     1   \n",
       "..           ...        ...                 ...  ...                   ...   \n",
       "814            5          2                  32  ...                     1   \n",
       "304            0          1                  32  ...                     1   \n",
       "195            5          3                  64  ...                     0   \n",
       "861            1          0                 128  ...                     1   \n",
       "321            5          0                  32  ...                     0   \n",
       "\n",
       "    pre-processing second-layer-neurons   id      AUC Accuracy     Loss  \\\n",
       "115       quantgau                  128  115  0.80363  0.58075  0.98257   \n",
       "781         minmax                   32  781  0.79064  0.57710  0.99908   \n",
       "997            pow                   64  997  0.78380  0.60282  0.90322   \n",
       "928            std                   32  928  0.78185  0.61228  0.89609   \n",
       "128           None                  128  128  0.78175  0.60582  0.92492   \n",
       "..             ...                  ...  ...      ...      ...      ...   \n",
       "814           None                   32  814  0.00000  0.19641  0.94736   \n",
       "304         minmax                   32  304  0.00000  0.19329  0.89643   \n",
       "195           None                  128  195  0.00000  0.45457  0.68465   \n",
       "861           None                  128  861  0.00000  0.16547  1.59072   \n",
       "321            std                   64  321  0.00000  0.19750  0.00000   \n",
       "\n",
       "    Train AUC Train Accuracy  Train Loss  \n",
       "115   0.80358        0.66548     0.77074  \n",
       "781   0.79060        0.65135     0.80627  \n",
       "997   0.78376        0.62677     0.84667  \n",
       "928   0.78181        0.62734     0.84895  \n",
       "128   0.78172        0.62636     0.85098  \n",
       "..        ...            ...         ...  \n",
       "814   0.00000        0.19952     0.95143  \n",
       "304   0.00000        0.18706     0.91432  \n",
       "195   0.00000        0.45333     0.68717  \n",
       "861   0.00000        0.17433     1.59977  \n",
       "321   0.00000        0.19989     0.00000  \n",
       "\n",
       "[1000 rows x 25 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Resetting indcies and rename columns\n",
    "runningMetrics = runningMetrics.reset_index().rename(columns={'level_0':'run_id','level_1':'metric'})\n",
    "runningMetrics.columns = runningMetrics.columns.get_level_values(0)\n",
    "\n",
    "## Adding a column of short ids, to merge on.\n",
    "runningMetrics['id'] = [re.split('_',i)[-1] for i in runningMetrics.run_id]\n",
    "\n",
    "## Creating a table, having the short id in the rows and the last observation for each metric in the columns. \n",
    "table = pd.pivot_table(runningMetrics[['run_id','metric','154','id']],index='id',columns=['metric'])\n",
    "table.columns = table.columns.get_level_values(1)\n",
    "table = table.round(5).reset_index()\n",
    "\n",
    "## Preparing the parameter dataframe.\n",
    "parameters = parameters.reset_index().rename(columns={'index':'run_id'})\n",
    "\n",
    "## Setting short ID\n",
    "parameters['id'] = [re.split('_',i)[-1] for i in parameters.run_id]\n",
    "\n",
    "## Creating the combined table\n",
    "combined_table = parameters.merge(table,\n",
    "                                     on = 'id',\n",
    "                                     how='left').sort_values('AUC',ascending=False)\n",
    "combined_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1d431086708>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "runningMetrics[(runningMetrics.metric=='Accuracy')&\\\n",
    "               (np.isin(runningMetrics.id,parameters[parameters['label-type']=='2'].id.values))].sort_values('154')['154'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating a top-X table for each label-type of a given metric, here AUC.\n",
    "temp_auc = pd.pivot_table(combined_table[['label-type','AUC','id']],index='id',columns='label-type')\n",
    "temp_acc = pd.pivot_table(combined_table[['label-type','Accuracy','id']],index='id',columns='label-type')\n",
    "\n",
    "## Final output - AUC\n",
    "final_output_auc = pd.DataFrame(np.sort(temp_auc.fillna(0).values,\n",
    "                             axis=0)[::-1],\n",
    "                             columns=temp_auc.columns.get_level_values(1)).loc[0:10]\n",
    "## Final output - Accuracy\n",
    "final_output_acc = pd.DataFrame(np.sort(temp_acc.fillna(0).values,\n",
    "                             axis=0)[::-1],\n",
    "                             columns=temp_acc.columns.get_level_values(1))#.loc[0:10]\n",
    "# final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['run_id',\n",
       " 'activation-inner',\n",
       " 'activation-output',\n",
       " 'batch-norm',\n",
       " 'batch-shuffle',\n",
       " 'batch-size',\n",
       " 'dropout-ratio',\n",
       " 'feature-lags',\n",
       " 'featureset',\n",
       " 'first-layer-neurons',\n",
       " 'label-type',\n",
       " 'learning-rate',\n",
       " 'n-epochs',\n",
       " 'n-layers',\n",
       " 'nn-type',\n",
       " 'pastobs-in-percentage',\n",
       " 'pre-processing',\n",
       " 'second-layer-neurons',\n",
       " 'id',\n",
       " 'AUC',\n",
       " 'Accuracy',\n",
       " 'Loss',\n",
       " 'Train AUC',\n",
       " 'Train Accuracy',\n",
       " 'Train Loss']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(combined_table.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>activation-inner</th>\n",
       "      <th>activation-output</th>\n",
       "      <th>batch-norm</th>\n",
       "      <th>batch-shuffle</th>\n",
       "      <th>batch-size</th>\n",
       "      <th>dropout-ratio</th>\n",
       "      <th>feature-lags</th>\n",
       "      <th>featureset</th>\n",
       "      <th>first-layer-neurons</th>\n",
       "      <th>...</th>\n",
       "      <th>pastobs-in-percentage</th>\n",
       "      <th>pre-processing</th>\n",
       "      <th>second-layer-neurons</th>\n",
       "      <th>id</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Train AUC</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Train Loss</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label-type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_115</td>\n",
       "      <td>relu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3300</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>quantgau</td>\n",
       "      <td>128</td>\n",
       "      <td>115</td>\n",
       "      <td>0.80363</td>\n",
       "      <td>0.58075</td>\n",
       "      <td>0.98257</td>\n",
       "      <td>0.80358</td>\n",
       "      <td>0.66548</td>\n",
       "      <td>0.77074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_781</td>\n",
       "      <td>tanh</td>\n",
       "      <td>linear</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>21450</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>minmax</td>\n",
       "      <td>32</td>\n",
       "      <td>781</td>\n",
       "      <td>0.79064</td>\n",
       "      <td>0.57710</td>\n",
       "      <td>0.99908</td>\n",
       "      <td>0.79060</td>\n",
       "      <td>0.65135</td>\n",
       "      <td>0.80627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_997</td>\n",
       "      <td>relu</td>\n",
       "      <td>linear</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10725</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>pow</td>\n",
       "      <td>64</td>\n",
       "      <td>997</td>\n",
       "      <td>0.78380</td>\n",
       "      <td>0.60282</td>\n",
       "      <td>0.90322</td>\n",
       "      <td>0.78376</td>\n",
       "      <td>0.62677</td>\n",
       "      <td>0.84667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_338</td>\n",
       "      <td>relu</td>\n",
       "      <td>linear</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21450</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>quantgau</td>\n",
       "      <td>64</td>\n",
       "      <td>338</td>\n",
       "      <td>0.78078</td>\n",
       "      <td>0.60986</td>\n",
       "      <td>0.88815</td>\n",
       "      <td>0.78075</td>\n",
       "      <td>0.62015</td>\n",
       "      <td>0.86651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_537</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>linear</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10725</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>quantgau</td>\n",
       "      <td>32</td>\n",
       "      <td>537</td>\n",
       "      <td>0.77684</td>\n",
       "      <td>0.60628</td>\n",
       "      <td>0.89268</td>\n",
       "      <td>0.77681</td>\n",
       "      <td>0.61488</td>\n",
       "      <td>0.86622</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 run_id activation-inner  \\\n",
       "label-type                                                                 \n",
       "1           HD_81ace623-e09b-4393-8a5e-131ea8749a35_115             relu   \n",
       "4           HD_81ace623-e09b-4393-8a5e-131ea8749a35_781             tanh   \n",
       "3           HD_81ace623-e09b-4393-8a5e-131ea8749a35_997             relu   \n",
       "2           HD_81ace623-e09b-4393-8a5e-131ea8749a35_338             relu   \n",
       "0           HD_81ace623-e09b-4393-8a5e-131ea8749a35_537          sigmoid   \n",
       "\n",
       "           activation-output batch-norm batch-shuffle batch-size  \\\n",
       "label-type                                                         \n",
       "1                    softmax          1             0       3300   \n",
       "4                     linear          1             1      21450   \n",
       "3                     linear          1             1      10725   \n",
       "2                     linear          0             0      21450   \n",
       "0                     linear          1             1      10725   \n",
       "\n",
       "           dropout-ratio feature-lags featureset first-layer-neurons  ...  \\\n",
       "label-type                                                            ...   \n",
       "1                    0.2            1          3                 128  ...   \n",
       "4                    0.3            3          0                  64  ...   \n",
       "3                    0.5            3          2                  64  ...   \n",
       "2                    0.2            0          1                  64  ...   \n",
       "0                    0.3            0          0                  64  ...   \n",
       "\n",
       "           pastobs-in-percentage pre-processing second-layer-neurons   id  \\\n",
       "label-type                                                                  \n",
       "1                              1       quantgau                  128  115   \n",
       "4                              1         minmax                   32  781   \n",
       "3                              0            pow                   64  997   \n",
       "2                              0       quantgau                   64  338   \n",
       "0                              1       quantgau                   32  537   \n",
       "\n",
       "                AUC Accuracy     Loss Train AUC Train Accuracy  Train Loss  \n",
       "label-type                                                                  \n",
       "1           0.80363  0.58075  0.98257   0.80358        0.66548     0.77074  \n",
       "4           0.79064  0.57710  0.99908   0.79060        0.65135     0.80627  \n",
       "3           0.78380  0.60282  0.90322   0.78376        0.62677     0.84667  \n",
       "2           0.78078  0.60986  0.88815   0.78075        0.62015     0.86651  \n",
       "0           0.77684  0.60628  0.89268   0.77681        0.61488     0.86622  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tempFinal_v0 = combined_table[np.isin(combined_table.AUC,final_output_auc.loc[0].values.flatten())]\n",
    "tempFinal_v0.index = tempFinal_v0.loc[:,'label-type']\n",
    "tempFinal_v0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>activation-inner</th>\n",
       "      <th>activation-output</th>\n",
       "      <th>batch-norm</th>\n",
       "      <th>batch-shuffle</th>\n",
       "      <th>batch-size</th>\n",
       "      <th>dropout-ratio</th>\n",
       "      <th>feature-lags</th>\n",
       "      <th>featureset</th>\n",
       "      <th>first-layer-neurons</th>\n",
       "      <th>...</th>\n",
       "      <th>pastobs-in-percentage</th>\n",
       "      <th>pre-processing</th>\n",
       "      <th>second-layer-neurons</th>\n",
       "      <th>id</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Train AUC</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Train Loss</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label-type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_686</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>linear</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>21450</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>quantgau</td>\n",
       "      <td>32</td>\n",
       "      <td>686</td>\n",
       "      <td>0.75976</td>\n",
       "      <td>0.61322</td>\n",
       "      <td>0.88116</td>\n",
       "      <td>0.75970</td>\n",
       "      <td>0.61041</td>\n",
       "      <td>0.89109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_716</td>\n",
       "      <td>relu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>21450</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>pow</td>\n",
       "      <td>32</td>\n",
       "      <td>716</td>\n",
       "      <td>0.75923</td>\n",
       "      <td>0.61299</td>\n",
       "      <td>0.88144</td>\n",
       "      <td>0.75916</td>\n",
       "      <td>0.61234</td>\n",
       "      <td>0.88095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_868</td>\n",
       "      <td>leakyrelu</td>\n",
       "      <td>linear</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3300</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>std</td>\n",
       "      <td>64</td>\n",
       "      <td>868</td>\n",
       "      <td>0.76452</td>\n",
       "      <td>0.61282</td>\n",
       "      <td>0.88599</td>\n",
       "      <td>0.76448</td>\n",
       "      <td>0.60774</td>\n",
       "      <td>0.89207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_717</td>\n",
       "      <td>leakyrelu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21450</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>128</td>\n",
       "      <td>717</td>\n",
       "      <td>0.76304</td>\n",
       "      <td>0.61409</td>\n",
       "      <td>0.87683</td>\n",
       "      <td>0.76298</td>\n",
       "      <td>0.61164</td>\n",
       "      <td>0.87896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_133</td>\n",
       "      <td>tanh</td>\n",
       "      <td>softmax</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10725</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>pow</td>\n",
       "      <td>64</td>\n",
       "      <td>133</td>\n",
       "      <td>0.76220</td>\n",
       "      <td>0.61248</td>\n",
       "      <td>0.88257</td>\n",
       "      <td>0.76215</td>\n",
       "      <td>0.61133</td>\n",
       "      <td>0.88838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 run_id activation-inner  \\\n",
       "label-type                                                                 \n",
       "0           HD_81ace623-e09b-4393-8a5e-131ea8749a35_686          sigmoid   \n",
       "1           HD_81ace623-e09b-4393-8a5e-131ea8749a35_716             relu   \n",
       "2           HD_81ace623-e09b-4393-8a5e-131ea8749a35_868        leakyrelu   \n",
       "3           HD_81ace623-e09b-4393-8a5e-131ea8749a35_717        leakyrelu   \n",
       "4           HD_81ace623-e09b-4393-8a5e-131ea8749a35_133             tanh   \n",
       "\n",
       "           activation-output batch-norm batch-shuffle batch-size  \\\n",
       "label-type                                                         \n",
       "0                     linear          1             1      21450   \n",
       "1                    softmax          1             1      21450   \n",
       "2                     linear          1             0       3300   \n",
       "3                    softmax          0             1      21450   \n",
       "4                    softmax          1             1      10725   \n",
       "\n",
       "           dropout-ratio feature-lags featureset first-layer-neurons  ...  \\\n",
       "label-type                                                            ...   \n",
       "0                    0.4            3          0                  32  ...   \n",
       "1                    0.4            3          0                  32  ...   \n",
       "2                    0.4            0          0                  32  ...   \n",
       "3                    0.0            5          3                  32  ...   \n",
       "4                    0.3            1          3                  64  ...   \n",
       "\n",
       "           pastobs-in-percentage pre-processing second-layer-neurons   id  \\\n",
       "label-type                                                                  \n",
       "0                              1       quantgau                   32  686   \n",
       "1                              1            pow                   32  716   \n",
       "2                              0            std                   64  868   \n",
       "3                              0           None                  128  717   \n",
       "4                              0            pow                   64  133   \n",
       "\n",
       "                AUC Accuracy     Loss Train AUC Train Accuracy  Train Loss  \n",
       "label-type                                                                  \n",
       "0           0.75976  0.61322  0.88116   0.75970        0.61041     0.89109  \n",
       "1           0.75923  0.61299  0.88144   0.75916        0.61234     0.88095  \n",
       "2           0.76452  0.61282  0.88599   0.76448        0.60774     0.89207  \n",
       "3           0.76304  0.61409  0.87683   0.76298        0.61164     0.87896  \n",
       "4           0.76220  0.61248  0.88257   0.76215        0.61133     0.88838  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tempFinal_v1 = combined_table[np.isin(combined_table.Accuracy,final_output_acc.loc[0].values.flatten())].sort_values('label-type').copy(deep=True)\n",
    "tempFinal_v1.index = tempFinal_v1.loc[:,'label-type']\n",
    "tempFinal_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['run_id',\n",
       " 'activation-inner',\n",
       " 'activation-output',\n",
       " 'batch-norm',\n",
       " 'batch-shuffle',\n",
       " 'batch-size',\n",
       " 'dropout-ratio',\n",
       " 'feature-lags',\n",
       " 'featureset',\n",
       " 'first-layer-neurons',\n",
       " 'label-type',\n",
       " 'learning-rate',\n",
       " 'n-epochs',\n",
       " 'n-layers',\n",
       " 'nn-type',\n",
       " 'pastobs-in-percentage',\n",
       " 'pre-processing',\n",
       " 'second-layer-neurons',\n",
       " 'id',\n",
       " 'AUC',\n",
       " 'Accuracy',\n",
       " 'Loss',\n",
       " 'Train AUC',\n",
       " 'Train Accuracy',\n",
       " 'Train Loss']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(combined_table.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An example of a box-plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp = combined_table[(combined_table.loc[:,'label-type']=='0')&(combined_table.loc[:,'nn-type']=='lstm')&(combined_table.AUC>0.5)]\n",
    "temp_2 = pd.pivot_table(temp,values='AUC',columns='dropout-ratio',index='run_id').reset_index()\n",
    "temp_2.boxplot(list(temp_2.columns[1:]),figsize=(7,7))#temp_2.columns[2:]\n",
    "plt.grid(b=None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0.3', '0.1', '0.2', '0.4', '0.0', '0.5'], dtype=object)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.loc[:,'dropout-ratio'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "fig,ax = plt.subplots(figsize=(10,10))\n",
    "# sns.set_theme(style=\"whitegrid\")\n",
    "# tips = sns.load_dataset(\"tips\")\n",
    "# ax = sns.violinplot(x=tips[\"total_bill\"])\n",
    "sns.violinplot(data=temp_2,ax=ax,bw='scott')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hyperparameters.txt',\n",
       " 'hyperparameters_lr_v1.txt',\n",
       " 'hyperparameters_lr_v2.txt',\n",
       " 'metrics.txt',\n",
       " 'metrics_lr_v1.txt',\n",
       " 'metrics_lr_v2.txt']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('../AzureML/Output_from_cloud')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperfiles = [i for i in os.listdir('../AzureML/Output_from_cloud') if 'hyper' in i]\n",
    "metricfiles = [i for i in os.listdir('../AzureML/Output_from_cloud') if 'metric' in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hyperparameters.txt',\n",
       " 'hyperparameters_lr_v1.txt',\n",
       " 'hyperparameters_lr_v2.txt']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j,file in enumerate(hyperfiles):\n",
    "    \n",
    "    if j > 0:\n",
    "        \n",
    "        ### Reading in the file\n",
    "\n",
    "        with open('../AzureML/Output_from_cloud/'+hyperfiles[j],'r') as file:\n",
    "            content = file.readlines()\n",
    "\n",
    "        ## Going over each line in the text file\n",
    "        for a in np.arange(len(content)):\n",
    "\n",
    "            ## Split the lines on tabs\n",
    "            temp_parameters = re.split('[\\t]',content[a])[1]\n",
    "\n",
    "            ## Basic string cleaning, i.e. removing redundant characters\n",
    "            test = [re.split(': ',i.strip()) for i in re.split(',',temp_parameters.replace('{','')\\\n",
    "                                                                               .replace('}','')\\\n",
    "                                                                               .replace('\\n','')\\\n",
    "                                                                               .replace('\"',''))]\n",
    "\n",
    "            ## Output of test is a list of lists, where each sublist holds the name of a model variable and its value.\n",
    "            ## We create a dictornary to hold all model variables, making it easy to add the observation to the dataframe.\n",
    "            test = {i[0]:i[1] for i in test}\n",
    "\n",
    "            # Constructing the dataframe\n",
    "            if (a == 0)&(j==1):\n",
    "                parameters_lr = pd.DataFrame(test,index=[re.split('[\\t]',content[a])[0]])\n",
    "\n",
    "            else:\n",
    "\n",
    "                parameters_lr.loc[re.split('[\\t]',content[a])[0]] = pd.Series(test)\n",
    "        \n",
    "#         lastone = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch-shuffle</th>\n",
       "      <th>batch-size</th>\n",
       "      <th>feature-lags</th>\n",
       "      <th>featureset</th>\n",
       "      <th>l2-penalty</th>\n",
       "      <th>l2-type</th>\n",
       "      <th>label-type</th>\n",
       "      <th>learning-rate</th>\n",
       "      <th>loss-from-logits</th>\n",
       "      <th>n-epochs</th>\n",
       "      <th>pastobs-in-percentage</th>\n",
       "      <th>pre-processing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0</th>\n",
       "      <td>1</td>\n",
       "      <td>21450</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>stacked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_1</th>\n",
       "      <td>0</td>\n",
       "      <td>3300</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>quantgau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_2</th>\n",
       "      <td>1</td>\n",
       "      <td>10725</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>pow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_3</th>\n",
       "      <td>1</td>\n",
       "      <td>3300</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>minmax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_4</th>\n",
       "      <td>0</td>\n",
       "      <td>21450</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>std</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD_914f915c-2cac-473e-bea5-c26e4c83673c_98</th>\n",
       "      <td>1</td>\n",
       "      <td>10725</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>10000000000.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD_914f915c-2cac-473e-bea5-c26e4c83673c_99</th>\n",
       "      <td>1</td>\n",
       "      <td>3300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD_914f915c-2cac-473e-bea5-c26e4c83673c_100</th>\n",
       "      <td>1</td>\n",
       "      <td>21450</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>std</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD_914f915c-2cac-473e-bea5-c26e4c83673c_101</th>\n",
       "      <td>0</td>\n",
       "      <td>10725</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>pow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD_914f915c-2cac-473e-bea5-c26e4c83673c_102</th>\n",
       "      <td>0</td>\n",
       "      <td>21450</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>minmax</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>484 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            batch-shuffle batch-size  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0               1      21450   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_1               0       3300   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_2               1      10725   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_3               1       3300   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_4               0      21450   \n",
       "...                                                   ...        ...   \n",
       "HD_914f915c-2cac-473e-bea5-c26e4c83673c_98              1      10725   \n",
       "HD_914f915c-2cac-473e-bea5-c26e4c83673c_99              1       3300   \n",
       "HD_914f915c-2cac-473e-bea5-c26e4c83673c_100             1      21450   \n",
       "HD_914f915c-2cac-473e-bea5-c26e4c83673c_101             0      10725   \n",
       "HD_914f915c-2cac-473e-bea5-c26e4c83673c_102             0      21450   \n",
       "\n",
       "                                            feature-lags featureset  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0              5          1   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_1              1          2   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_2              5          2   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_3              5          1   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_4              5          3   \n",
       "...                                                  ...        ...   \n",
       "HD_914f915c-2cac-473e-bea5-c26e4c83673c_98             3          2   \n",
       "HD_914f915c-2cac-473e-bea5-c26e4c83673c_99             0          0   \n",
       "HD_914f915c-2cac-473e-bea5-c26e4c83673c_100            3          1   \n",
       "HD_914f915c-2cac-473e-bea5-c26e4c83673c_101            3          0   \n",
       "HD_914f915c-2cac-473e-bea5-c26e4c83673c_102            3          0   \n",
       "\n",
       "                                                l2-penalty l2-type label-type  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0              1.0       6          2   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_1             10.0       1          2   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_2              0.1       1          0   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_3            100.0       4          0   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_4             0.01       5          2   \n",
       "...                                                    ...     ...        ...   \n",
       "HD_914f915c-2cac-473e-bea5-c26e4c83673c_98   10000000000.0       5          4   \n",
       "HD_914f915c-2cac-473e-bea5-c26e4c83673c_99          0.0001       6          0   \n",
       "HD_914f915c-2cac-473e-bea5-c26e4c83673c_100         1000.0       5          1   \n",
       "HD_914f915c-2cac-473e-bea5-c26e4c83673c_101            1.0       5          3   \n",
       "HD_914f915c-2cac-473e-bea5-c26e4c83673c_102           10.0       6          3   \n",
       "\n",
       "                                            learning-rate loss-from-logits  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0           0.001                0   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_1             0.1                0   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_2           0.001                0   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_3           0.001                1   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_4          0.0001                1   \n",
       "...                                                   ...              ...   \n",
       "HD_914f915c-2cac-473e-bea5-c26e4c83673c_98           0.01                1   \n",
       "HD_914f915c-2cac-473e-bea5-c26e4c83673c_99          0.001                1   \n",
       "HD_914f915c-2cac-473e-bea5-c26e4c83673c_100         0.001                0   \n",
       "HD_914f915c-2cac-473e-bea5-c26e4c83673c_101        0.0001                1   \n",
       "HD_914f915c-2cac-473e-bea5-c26e4c83673c_102         0.001                0   \n",
       "\n",
       "                                            n-epochs pastobs-in-percentage  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0        150                     1   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_1        150                     1   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_2        150                     1   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_3        150                     1   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_4        150                     1   \n",
       "...                                              ...                   ...   \n",
       "HD_914f915c-2cac-473e-bea5-c26e4c83673c_98       150                     0   \n",
       "HD_914f915c-2cac-473e-bea5-c26e4c83673c_99       150                     1   \n",
       "HD_914f915c-2cac-473e-bea5-c26e4c83673c_100      150                     0   \n",
       "HD_914f915c-2cac-473e-bea5-c26e4c83673c_101      150                     1   \n",
       "HD_914f915c-2cac-473e-bea5-c26e4c83673c_102      150                     0   \n",
       "\n",
       "                                            pre-processing  \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0          stacked  \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_1         quantgau  \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_2              pow  \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_3           minmax  \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_4              std  \n",
       "...                                                    ...  \n",
       "HD_914f915c-2cac-473e-bea5-c26e4c83673c_98            None  \n",
       "HD_914f915c-2cac-473e-bea5-c26e4c83673c_99            None  \n",
       "HD_914f915c-2cac-473e-bea5-c26e4c83673c_100            std  \n",
       "HD_914f915c-2cac-473e-bea5-c26e4c83673c_101            pow  \n",
       "HD_914f915c-2cac-473e-bea5-c26e4c83673c_102         minmax  \n",
       "\n",
       "[484 rows x 12 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j,file in enumerate(metricfiles):\n",
    "    \n",
    "    if j > 0:#) & (j<2)\n",
    "        \n",
    "        ## Readidng in the file\n",
    "        with open('../AzureML/Output_from_cloud/'+metricfiles[j],'r') as file:\n",
    "            content = file.readlines()\n",
    "\n",
    "        ## Containers\n",
    "        t11 = []\n",
    "        t12 = []\n",
    "        t13 = []\n",
    "\n",
    "        t21 = []\n",
    "        t22 = []\n",
    "        t23 = []\n",
    "\n",
    "        ## Going over each line\n",
    "        for i in np.arange(len(content)):#\n",
    "\n",
    "            ## Split each line on tabs\n",
    "            temp = re.split('\\t',content[i].replace('\\n',''))\n",
    "\n",
    "            ## There are two types of observations in the text file; 1. final metrics of those models which where not stoppe early\n",
    "            ## and 2. a time series of a metric for each model.\n",
    "\n",
    "            ## If the length of the last element, in a line, is less than 50 (because it is just a number, i.e. final metric)\n",
    "            ## It stored separately for the time series.\n",
    "            if len(temp[2]) < 50:\n",
    "\n",
    "                t11.append(temp[0])\n",
    "                t12.append(temp[1])\n",
    "                t13.append(temp[2])\n",
    "\n",
    "            ## Time series\n",
    "            else:\n",
    "\n",
    "                container = np.zeros(155)\n",
    "                temp1 = [float(j.strip()) if j.strip() !=\"'NaN'\" else 0 for j in re.split(',',temp[2].replace('[','').replace(']',''))]\n",
    "\n",
    "                container[0:len(temp1)] = temp1\n",
    "                container[len(temp1):] = temp1[-1]\n",
    "\n",
    "                t21.append(temp[0])\n",
    "                t22.append(temp[1])\n",
    "                t23.append(container)        \n",
    "\n",
    "        ## Storing the time series in a dataframe\n",
    "        arrays = [t21,t22]\n",
    "        tuples = list(zip(*arrays))\n",
    "        if j == 1:\n",
    "            \n",
    "            runningMetrics_lr = pd.DataFrame(np.array(t23),\n",
    "                                              index=pd.MultiIndex.from_tuples(tuples),\n",
    "                                              columns = [np.arange(155).astype(str)]\n",
    "                                             )\n",
    "        else:\n",
    "            temp_1 = pd.DataFrame(np.array(t23),\n",
    "                                  index=pd.MultiIndex.from_tuples(tuples),\n",
    "                                  columns = [np.arange(155).astype(str)])\n",
    "            runningMetrics_lr = pd.concat([runningMetrics_lr,temp_1])\n",
    "        ## Storing the final metrics in a dataframe.\n",
    "        arrays = [t11,t12]\n",
    "        tuples = list(zip(*arrays))\n",
    "        if j == 1:\n",
    "            \n",
    "            finalMetrics_lr = pd.DataFrame(t13,index = pd.MultiIndex.from_tuples(tuples),columns = ['size'])\n",
    "        else:\n",
    "            \n",
    "            temp = pd.DataFrame(t13,index = pd.MultiIndex.from_tuples(tuples),columns = ['size'])\n",
    "            finalMetrics_lr = pd.concat([finalMetrics_lr,temp],axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "      <th>150</th>\n",
       "      <th>151</th>\n",
       "      <th>152</th>\n",
       "      <th>153</th>\n",
       "      <th>154</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0</th>\n",
       "      <th>Loss</th>\n",
       "      <td>1.097134</td>\n",
       "      <td>1.089486</td>\n",
       "      <td>1.084925</td>\n",
       "      <td>1.082050</td>\n",
       "      <td>1.080157</td>\n",
       "      <td>1.078848</td>\n",
       "      <td>1.077901</td>\n",
       "      <td>1.077183</td>\n",
       "      <td>1.076617</td>\n",
       "      <td>1.076155</td>\n",
       "      <td>...</td>\n",
       "      <td>1.070333</td>\n",
       "      <td>1.070329</td>\n",
       "      <td>1.070325</td>\n",
       "      <td>1.070321</td>\n",
       "      <td>1.070317</td>\n",
       "      <td>1.070317</td>\n",
       "      <td>1.070317</td>\n",
       "      <td>1.070317</td>\n",
       "      <td>1.070317</td>\n",
       "      <td>1.070317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.357927</td>\n",
       "      <td>0.372786</td>\n",
       "      <td>0.380087</td>\n",
       "      <td>0.386206</td>\n",
       "      <td>0.388733</td>\n",
       "      <td>0.389996</td>\n",
       "      <td>0.391295</td>\n",
       "      <td>0.392629</td>\n",
       "      <td>0.393904</td>\n",
       "      <td>0.394478</td>\n",
       "      <td>...</td>\n",
       "      <td>0.401299</td>\n",
       "      <td>0.401381</td>\n",
       "      <td>0.401322</td>\n",
       "      <td>0.401275</td>\n",
       "      <td>0.401299</td>\n",
       "      <td>0.401299</td>\n",
       "      <td>0.401299</td>\n",
       "      <td>0.401299</td>\n",
       "      <td>0.401299</td>\n",
       "      <td>0.401299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC</th>\n",
       "      <td>0.520483</td>\n",
       "      <td>0.533294</td>\n",
       "      <td>0.543315</td>\n",
       "      <td>0.550682</td>\n",
       "      <td>0.556136</td>\n",
       "      <td>0.560248</td>\n",
       "      <td>0.563450</td>\n",
       "      <td>0.566000</td>\n",
       "      <td>0.568082</td>\n",
       "      <td>0.569817</td>\n",
       "      <td>...</td>\n",
       "      <td>0.592322</td>\n",
       "      <td>0.592349</td>\n",
       "      <td>0.592375</td>\n",
       "      <td>0.592401</td>\n",
       "      <td>0.592426</td>\n",
       "      <td>0.592426</td>\n",
       "      <td>0.592426</td>\n",
       "      <td>0.592426</td>\n",
       "      <td>0.592426</td>\n",
       "      <td>0.592426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Loss</th>\n",
       "      <td>1.103421</td>\n",
       "      <td>1.092251</td>\n",
       "      <td>1.085799</td>\n",
       "      <td>1.081776</td>\n",
       "      <td>1.079140</td>\n",
       "      <td>1.077343</td>\n",
       "      <td>1.076068</td>\n",
       "      <td>1.075129</td>\n",
       "      <td>1.074413</td>\n",
       "      <td>1.073847</td>\n",
       "      <td>...</td>\n",
       "      <td>1.067931</td>\n",
       "      <td>1.067927</td>\n",
       "      <td>1.067922</td>\n",
       "      <td>1.067918</td>\n",
       "      <td>1.067913</td>\n",
       "      <td>1.067913</td>\n",
       "      <td>1.067913</td>\n",
       "      <td>1.067913</td>\n",
       "      <td>1.067913</td>\n",
       "      <td>1.067913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Accuracy</th>\n",
       "      <td>0.348293</td>\n",
       "      <td>0.370394</td>\n",
       "      <td>0.381516</td>\n",
       "      <td>0.386821</td>\n",
       "      <td>0.390184</td>\n",
       "      <td>0.392238</td>\n",
       "      <td>0.393292</td>\n",
       "      <td>0.394232</td>\n",
       "      <td>0.395504</td>\n",
       "      <td>0.396163</td>\n",
       "      <td>...</td>\n",
       "      <td>0.407098</td>\n",
       "      <td>0.407139</td>\n",
       "      <td>0.407136</td>\n",
       "      <td>0.407177</td>\n",
       "      <td>0.407191</td>\n",
       "      <td>0.407191</td>\n",
       "      <td>0.407191</td>\n",
       "      <td>0.407191</td>\n",
       "      <td>0.407191</td>\n",
       "      <td>0.407191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_379</th>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.320367</td>\n",
       "      <td>0.339238</td>\n",
       "      <td>0.328944</td>\n",
       "      <td>0.305141</td>\n",
       "      <td>0.346308</td>\n",
       "      <td>0.346857</td>\n",
       "      <td>0.313999</td>\n",
       "      <td>0.307969</td>\n",
       "      <td>0.307864</td>\n",
       "      <td>0.319140</td>\n",
       "      <td>...</td>\n",
       "      <td>0.262737</td>\n",
       "      <td>0.386574</td>\n",
       "      <td>0.351519</td>\n",
       "      <td>0.396553</td>\n",
       "      <td>0.197908</td>\n",
       "      <td>0.197908</td>\n",
       "      <td>0.197908</td>\n",
       "      <td>0.197908</td>\n",
       "      <td>0.197908</td>\n",
       "      <td>0.197908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC</th>\n",
       "      <td>0.504284</td>\n",
       "      <td>0.504207</td>\n",
       "      <td>0.505291</td>\n",
       "      <td>0.505693</td>\n",
       "      <td>0.506208</td>\n",
       "      <td>0.507373</td>\n",
       "      <td>0.507962</td>\n",
       "      <td>0.508196</td>\n",
       "      <td>0.508435</td>\n",
       "      <td>0.508788</td>\n",
       "      <td>...</td>\n",
       "      <td>0.514035</td>\n",
       "      <td>0.514007</td>\n",
       "      <td>0.514043</td>\n",
       "      <td>0.514050</td>\n",
       "      <td>0.513845</td>\n",
       "      <td>0.513845</td>\n",
       "      <td>0.513845</td>\n",
       "      <td>0.513845</td>\n",
       "      <td>0.513845</td>\n",
       "      <td>0.513845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Loss</th>\n",
       "      <td>277.681401</td>\n",
       "      <td>37.135827</td>\n",
       "      <td>10.825353</td>\n",
       "      <td>5.201888</td>\n",
       "      <td>3.251213</td>\n",
       "      <td>2.345294</td>\n",
       "      <td>1.875076</td>\n",
       "      <td>1.603717</td>\n",
       "      <td>1.446390</td>\n",
       "      <td>1.349141</td>\n",
       "      <td>...</td>\n",
       "      <td>1.847613</td>\n",
       "      <td>1.556370</td>\n",
       "      <td>1.309945</td>\n",
       "      <td>1.425046</td>\n",
       "      <td>1.940013</td>\n",
       "      <td>1.940013</td>\n",
       "      <td>1.940013</td>\n",
       "      <td>1.940013</td>\n",
       "      <td>1.940013</td>\n",
       "      <td>1.940013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Accuracy</th>\n",
       "      <td>0.346011</td>\n",
       "      <td>0.342229</td>\n",
       "      <td>0.344201</td>\n",
       "      <td>0.353328</td>\n",
       "      <td>0.356905</td>\n",
       "      <td>0.357705</td>\n",
       "      <td>0.355350</td>\n",
       "      <td>0.355704</td>\n",
       "      <td>0.354585</td>\n",
       "      <td>0.354014</td>\n",
       "      <td>...</td>\n",
       "      <td>0.311970</td>\n",
       "      <td>0.304653</td>\n",
       "      <td>0.352435</td>\n",
       "      <td>0.334895</td>\n",
       "      <td>0.302553</td>\n",
       "      <td>0.302553</td>\n",
       "      <td>0.302553</td>\n",
       "      <td>0.302553</td>\n",
       "      <td>0.302553</td>\n",
       "      <td>0.302553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train AUC</th>\n",
       "      <td>0.501814</td>\n",
       "      <td>0.503613</td>\n",
       "      <td>0.504672</td>\n",
       "      <td>0.505701</td>\n",
       "      <td>0.505716</td>\n",
       "      <td>0.506760</td>\n",
       "      <td>0.507739</td>\n",
       "      <td>0.508042</td>\n",
       "      <td>0.508290</td>\n",
       "      <td>0.508570</td>\n",
       "      <td>...</td>\n",
       "      <td>0.514087</td>\n",
       "      <td>0.513999</td>\n",
       "      <td>0.514039</td>\n",
       "      <td>0.514046</td>\n",
       "      <td>0.514037</td>\n",
       "      <td>0.514037</td>\n",
       "      <td>0.514037</td>\n",
       "      <td>0.514037</td>\n",
       "      <td>0.514037</td>\n",
       "      <td>0.514037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2280 rows × 155 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                     0  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss              1.097134   \n",
       "                                            Accuracy          0.357927   \n",
       "                                            AUC               0.520483   \n",
       "                                            Train Loss        1.103421   \n",
       "                                            Train Accuracy    0.348293   \n",
       "...                                                                ...   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_379 Accuracy          0.320367   \n",
       "                                            AUC               0.504284   \n",
       "                                            Train Loss      277.681401   \n",
       "                                            Train Accuracy    0.346011   \n",
       "                                            Train AUC         0.501814   \n",
       "\n",
       "                                                                    1  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss             1.089486   \n",
       "                                            Accuracy         0.372786   \n",
       "                                            AUC              0.533294   \n",
       "                                            Train Loss       1.092251   \n",
       "                                            Train Accuracy   0.370394   \n",
       "...                                                               ...   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_379 Accuracy         0.339238   \n",
       "                                            AUC              0.504207   \n",
       "                                            Train Loss      37.135827   \n",
       "                                            Train Accuracy   0.342229   \n",
       "                                            Train AUC        0.503613   \n",
       "\n",
       "                                                                    2  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss             1.084925   \n",
       "                                            Accuracy         0.380087   \n",
       "                                            AUC              0.543315   \n",
       "                                            Train Loss       1.085799   \n",
       "                                            Train Accuracy   0.381516   \n",
       "...                                                               ...   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_379 Accuracy         0.328944   \n",
       "                                            AUC              0.505291   \n",
       "                                            Train Loss      10.825353   \n",
       "                                            Train Accuracy   0.344201   \n",
       "                                            Train AUC        0.504672   \n",
       "\n",
       "                                                                   3  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss            1.082050   \n",
       "                                            Accuracy        0.386206   \n",
       "                                            AUC             0.550682   \n",
       "                                            Train Loss      1.081776   \n",
       "                                            Train Accuracy  0.386821   \n",
       "...                                                              ...   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_379 Accuracy        0.305141   \n",
       "                                            AUC             0.505693   \n",
       "                                            Train Loss      5.201888   \n",
       "                                            Train Accuracy  0.353328   \n",
       "                                            Train AUC       0.505701   \n",
       "\n",
       "                                                                   4  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss            1.080157   \n",
       "                                            Accuracy        0.388733   \n",
       "                                            AUC             0.556136   \n",
       "                                            Train Loss      1.079140   \n",
       "                                            Train Accuracy  0.390184   \n",
       "...                                                              ...   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_379 Accuracy        0.346308   \n",
       "                                            AUC             0.506208   \n",
       "                                            Train Loss      3.251213   \n",
       "                                            Train Accuracy  0.356905   \n",
       "                                            Train AUC       0.505716   \n",
       "\n",
       "                                                                   5  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss            1.078848   \n",
       "                                            Accuracy        0.389996   \n",
       "                                            AUC             0.560248   \n",
       "                                            Train Loss      1.077343   \n",
       "                                            Train Accuracy  0.392238   \n",
       "...                                                              ...   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_379 Accuracy        0.346857   \n",
       "                                            AUC             0.507373   \n",
       "                                            Train Loss      2.345294   \n",
       "                                            Train Accuracy  0.357705   \n",
       "                                            Train AUC       0.506760   \n",
       "\n",
       "                                                                   6  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss            1.077901   \n",
       "                                            Accuracy        0.391295   \n",
       "                                            AUC             0.563450   \n",
       "                                            Train Loss      1.076068   \n",
       "                                            Train Accuracy  0.393292   \n",
       "...                                                              ...   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_379 Accuracy        0.313999   \n",
       "                                            AUC             0.507962   \n",
       "                                            Train Loss      1.875076   \n",
       "                                            Train Accuracy  0.355350   \n",
       "                                            Train AUC       0.507739   \n",
       "\n",
       "                                                                   7  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss            1.077183   \n",
       "                                            Accuracy        0.392629   \n",
       "                                            AUC             0.566000   \n",
       "                                            Train Loss      1.075129   \n",
       "                                            Train Accuracy  0.394232   \n",
       "...                                                              ...   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_379 Accuracy        0.307969   \n",
       "                                            AUC             0.508196   \n",
       "                                            Train Loss      1.603717   \n",
       "                                            Train Accuracy  0.355704   \n",
       "                                            Train AUC       0.508042   \n",
       "\n",
       "                                                                   8  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss            1.076617   \n",
       "                                            Accuracy        0.393904   \n",
       "                                            AUC             0.568082   \n",
       "                                            Train Loss      1.074413   \n",
       "                                            Train Accuracy  0.395504   \n",
       "...                                                              ...   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_379 Accuracy        0.307864   \n",
       "                                            AUC             0.508435   \n",
       "                                            Train Loss      1.446390   \n",
       "                                            Train Accuracy  0.354585   \n",
       "                                            Train AUC       0.508290   \n",
       "\n",
       "                                                                   9  ...  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss            1.076155  ...   \n",
       "                                            Accuracy        0.394478  ...   \n",
       "                                            AUC             0.569817  ...   \n",
       "                                            Train Loss      1.073847  ...   \n",
       "                                            Train Accuracy  0.396163  ...   \n",
       "...                                                              ...  ...   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_379 Accuracy        0.319140  ...   \n",
       "                                            AUC             0.508788  ...   \n",
       "                                            Train Loss      1.349141  ...   \n",
       "                                            Train Accuracy  0.354014  ...   \n",
       "                                            Train AUC       0.508570  ...   \n",
       "\n",
       "                                                                 145  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss            1.070333   \n",
       "                                            Accuracy        0.401299   \n",
       "                                            AUC             0.592322   \n",
       "                                            Train Loss      1.067931   \n",
       "                                            Train Accuracy  0.407098   \n",
       "...                                                              ...   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_379 Accuracy        0.262737   \n",
       "                                            AUC             0.514035   \n",
       "                                            Train Loss      1.847613   \n",
       "                                            Train Accuracy  0.311970   \n",
       "                                            Train AUC       0.514087   \n",
       "\n",
       "                                                                 146  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss            1.070329   \n",
       "                                            Accuracy        0.401381   \n",
       "                                            AUC             0.592349   \n",
       "                                            Train Loss      1.067927   \n",
       "                                            Train Accuracy  0.407139   \n",
       "...                                                              ...   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_379 Accuracy        0.386574   \n",
       "                                            AUC             0.514007   \n",
       "                                            Train Loss      1.556370   \n",
       "                                            Train Accuracy  0.304653   \n",
       "                                            Train AUC       0.513999   \n",
       "\n",
       "                                                                 147  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss            1.070325   \n",
       "                                            Accuracy        0.401322   \n",
       "                                            AUC             0.592375   \n",
       "                                            Train Loss      1.067922   \n",
       "                                            Train Accuracy  0.407136   \n",
       "...                                                              ...   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_379 Accuracy        0.351519   \n",
       "                                            AUC             0.514043   \n",
       "                                            Train Loss      1.309945   \n",
       "                                            Train Accuracy  0.352435   \n",
       "                                            Train AUC       0.514039   \n",
       "\n",
       "                                                                 148  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss            1.070321   \n",
       "                                            Accuracy        0.401275   \n",
       "                                            AUC             0.592401   \n",
       "                                            Train Loss      1.067918   \n",
       "                                            Train Accuracy  0.407177   \n",
       "...                                                              ...   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_379 Accuracy        0.396553   \n",
       "                                            AUC             0.514050   \n",
       "                                            Train Loss      1.425046   \n",
       "                                            Train Accuracy  0.334895   \n",
       "                                            Train AUC       0.514046   \n",
       "\n",
       "                                                                 149  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss            1.070317   \n",
       "                                            Accuracy        0.401299   \n",
       "                                            AUC             0.592426   \n",
       "                                            Train Loss      1.067913   \n",
       "                                            Train Accuracy  0.407191   \n",
       "...                                                              ...   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_379 Accuracy        0.197908   \n",
       "                                            AUC             0.513845   \n",
       "                                            Train Loss      1.940013   \n",
       "                                            Train Accuracy  0.302553   \n",
       "                                            Train AUC       0.514037   \n",
       "\n",
       "                                                                 150  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss            1.070317   \n",
       "                                            Accuracy        0.401299   \n",
       "                                            AUC             0.592426   \n",
       "                                            Train Loss      1.067913   \n",
       "                                            Train Accuracy  0.407191   \n",
       "...                                                              ...   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_379 Accuracy        0.197908   \n",
       "                                            AUC             0.513845   \n",
       "                                            Train Loss      1.940013   \n",
       "                                            Train Accuracy  0.302553   \n",
       "                                            Train AUC       0.514037   \n",
       "\n",
       "                                                                 151  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss            1.070317   \n",
       "                                            Accuracy        0.401299   \n",
       "                                            AUC             0.592426   \n",
       "                                            Train Loss      1.067913   \n",
       "                                            Train Accuracy  0.407191   \n",
       "...                                                              ...   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_379 Accuracy        0.197908   \n",
       "                                            AUC             0.513845   \n",
       "                                            Train Loss      1.940013   \n",
       "                                            Train Accuracy  0.302553   \n",
       "                                            Train AUC       0.514037   \n",
       "\n",
       "                                                                 152  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss            1.070317   \n",
       "                                            Accuracy        0.401299   \n",
       "                                            AUC             0.592426   \n",
       "                                            Train Loss      1.067913   \n",
       "                                            Train Accuracy  0.407191   \n",
       "...                                                              ...   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_379 Accuracy        0.197908   \n",
       "                                            AUC             0.513845   \n",
       "                                            Train Loss      1.940013   \n",
       "                                            Train Accuracy  0.302553   \n",
       "                                            Train AUC       0.514037   \n",
       "\n",
       "                                                                 153       154  \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss            1.070317  1.070317  \n",
       "                                            Accuracy        0.401299  0.401299  \n",
       "                                            AUC             0.592426  0.592426  \n",
       "                                            Train Loss      1.067913  1.067913  \n",
       "                                            Train Accuracy  0.407191  0.407191  \n",
       "...                                                              ...       ...  \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_379 Accuracy        0.197908  0.197908  \n",
       "                                            AUC             0.513845  0.513845  \n",
       "                                            Train Loss      1.940013  1.940013  \n",
       "                                            Train Accuracy  0.302553  0.302553  \n",
       "                                            Train AUC       0.514037  0.514037  \n",
       "\n",
       "[2280 rows x 155 columns]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runningMetrics_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0',),\n",
       " ('1',),\n",
       " ('2',),\n",
       " ('3',),\n",
       " ('4',),\n",
       " ('5',),\n",
       " ('6',),\n",
       " ('7',),\n",
       " ('8',),\n",
       " ('9',),\n",
       " ('10',),\n",
       " ('11',),\n",
       " ('12',),\n",
       " ('13',),\n",
       " ('14',),\n",
       " ('15',),\n",
       " ('16',),\n",
       " ('17',),\n",
       " ('18',),\n",
       " ('19',),\n",
       " ('20',),\n",
       " ('21',),\n",
       " ('22',),\n",
       " ('23',),\n",
       " ('24',),\n",
       " ('25',),\n",
       " ('26',),\n",
       " ('27',),\n",
       " ('28',),\n",
       " ('29',),\n",
       " ('30',),\n",
       " ('31',),\n",
       " ('32',),\n",
       " ('33',),\n",
       " ('34',),\n",
       " ('35',),\n",
       " ('36',),\n",
       " ('37',),\n",
       " ('38',),\n",
       " ('39',),\n",
       " ('40',),\n",
       " ('41',),\n",
       " ('42',),\n",
       " ('43',),\n",
       " ('44',),\n",
       " ('45',),\n",
       " ('46',),\n",
       " ('47',),\n",
       " ('48',),\n",
       " ('49',),\n",
       " ('50',),\n",
       " ('51',),\n",
       " ('52',),\n",
       " ('53',),\n",
       " ('54',),\n",
       " ('55',),\n",
       " ('56',),\n",
       " ('57',),\n",
       " ('58',),\n",
       " ('59',),\n",
       " ('60',),\n",
       " ('61',),\n",
       " ('62',),\n",
       " ('63',),\n",
       " ('64',),\n",
       " ('65',),\n",
       " ('66',),\n",
       " ('67',),\n",
       " ('68',),\n",
       " ('69',),\n",
       " ('70',),\n",
       " ('71',),\n",
       " ('72',),\n",
       " ('73',),\n",
       " ('74',),\n",
       " ('75',),\n",
       " ('76',),\n",
       " ('77',),\n",
       " ('78',),\n",
       " ('79',),\n",
       " ('80',),\n",
       " ('81',),\n",
       " ('82',),\n",
       " ('83',),\n",
       " ('84',),\n",
       " ('85',),\n",
       " ('86',),\n",
       " ('87',),\n",
       " ('88',),\n",
       " ('89',),\n",
       " ('90',),\n",
       " ('91',),\n",
       " ('92',),\n",
       " ('93',),\n",
       " ('94',),\n",
       " ('95',),\n",
       " ('96',),\n",
       " ('97',),\n",
       " ('98',),\n",
       " ('99',),\n",
       " ('100',),\n",
       " ('101',),\n",
       " ('102',),\n",
       " ('103',),\n",
       " ('104',),\n",
       " ('105',),\n",
       " ('106',),\n",
       " ('107',),\n",
       " ('108',),\n",
       " ('109',),\n",
       " ('110',),\n",
       " ('111',),\n",
       " ('112',),\n",
       " ('113',),\n",
       " ('114',),\n",
       " ('115',),\n",
       " ('116',),\n",
       " ('117',),\n",
       " ('118',),\n",
       " ('119',),\n",
       " ('120',),\n",
       " ('121',),\n",
       " ('122',),\n",
       " ('123',),\n",
       " ('124',),\n",
       " ('125',),\n",
       " ('126',),\n",
       " ('127',),\n",
       " ('128',),\n",
       " ('129',),\n",
       " ('130',),\n",
       " ('131',),\n",
       " ('132',),\n",
       " ('133',),\n",
       " ('134',),\n",
       " ('135',),\n",
       " ('136',),\n",
       " ('137',),\n",
       " ('138',),\n",
       " ('139',),\n",
       " ('140',),\n",
       " ('141',),\n",
       " ('142',),\n",
       " ('143',),\n",
       " ('144',),\n",
       " ('145',),\n",
       " ('146',),\n",
       " ('147',),\n",
       " ('148',),\n",
       " ('149',),\n",
       " ('150',),\n",
       " ('151',),\n",
       " ('152',),\n",
       " ('153',),\n",
       " ('154',)]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(runningMetrics.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hyperparameters.txt',\n",
       " 'hyperparameters_lr_v1.txt',\n",
       " 'hyperparameters_lr_v2.txt',\n",
       " 'hyperparameters_lr_v3.txt',\n",
       " 'metrics.txt',\n",
       " 'metrics_lr_v1.txt',\n",
       " 'metrics_lr_v2.txt',\n",
       " 'metrics_lr_v3.txt']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('../AzureML/Output_from_cloud/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 4, 5]\n",
      "[6, 7, 8, 9, 10, 11]\n"
     ]
    }
   ],
   "source": [
    "with open('../AzureML/Output_from_cloud/'+metricfiles[1],'r') as file:\n",
    "    content = file.readlines()\n",
    "        \n",
    "## Containers\n",
    "t11 = []\n",
    "t12 = []\n",
    "t13 = []\n",
    "\n",
    "t21 = []\n",
    "t22 = []\n",
    "t23 = []\n",
    "\n",
    "## Going over each line\n",
    "for i in np.arange(len(content)):#\n",
    "\n",
    "    ## Split each line on tabs\n",
    "    temp = re.split('\\t',content[i].replace('\\n',''))\n",
    "\n",
    "    ## There are two types of observations in the text file; 1. final metrics of those models which where not stoppe early\n",
    "    ## and 2. a time series of a metric for each model.\n",
    "\n",
    "    ## If the length of the last element, in a line, is less than 50 (because it is just a number, i.e. final metric)\n",
    "    ## It stored separately for the time series.\n",
    "    if len(temp[2]) < 50:\n",
    "\n",
    "        t11.append(temp[0])\n",
    "        t12.append(temp[1])\n",
    "        t13.append(temp[2])\n",
    "\n",
    "    ## Time series\n",
    "    else:\n",
    "\n",
    "        container = np.zeros(155)\n",
    "        temp1 = [float(j.strip()) if j.strip() !=\"'NaN'\" else 0 for j in re.split(',',temp[2].replace('[','').replace(']',''))]\n",
    "\n",
    "        container[0:len(temp1)] = temp1\n",
    "        container[len(temp1):] = temp1[-1]\n",
    "\n",
    "        t21.append(temp[0])\n",
    "        t22.append(temp[1])\n",
    "        t23.append(container)    \n",
    "        \n",
    "print([i for i,j in enumerate(t11) if j == 'HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_1'])\n",
    "print([i for i,j in enumerate(t21) if j == 'HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final test accuracy 0.6106547117233276\n",
      "Train Accuracy 0.6087145209312439\n"
     ]
    }
   ],
   "source": [
    "print(t12[5],t13[5])\n",
    "print(t22[10],t23[10][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy 0.6087145209312439\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 4, 5]\n",
      "[6, 7, 8, 9, 10, 11]\n"
     ]
    }
   ],
   "source": [
    "with open('../AzureML/Output_from_cloud/'+metricfiles[2],'r') as file:\n",
    "    content = file.readlines()\n",
    "        \n",
    "## Containers\n",
    "t11 = []\n",
    "t12 = []\n",
    "t13 = []\n",
    "\n",
    "t21 = []\n",
    "t22 = []\n",
    "t23 = []\n",
    "\n",
    "## Going over each line\n",
    "for i in np.arange(len(content)):#\n",
    "\n",
    "    ## Split each line on tabs\n",
    "    temp = re.split('\\t',content[i].replace('\\n',''))\n",
    "\n",
    "    ## There are two types of observations in the text file; 1. final metrics of those models which where not stoppe early\n",
    "    ## and 2. a time series of a metric for each model.\n",
    "\n",
    "    ## If the length of the last element, in a line, is less than 50 (because it is just a number, i.e. final metric)\n",
    "    ## It stored separately for the time series.\n",
    "    if len(temp[2]) < 50:\n",
    "\n",
    "        t11.append(temp[0])\n",
    "        t12.append(temp[1])\n",
    "        t13.append(temp[2])\n",
    "\n",
    "    ## Time series\n",
    "    else:\n",
    "\n",
    "        container = np.zeros(155)\n",
    "        temp1 = [float(j.strip()) if j.strip() !=\"'NaN'\" else 0 for j in re.split(',',temp[2].replace('[','').replace(']',''))]\n",
    "\n",
    "        container[0:len(temp1)] = temp1\n",
    "        container[len(temp1):] = temp1[-1]\n",
    "\n",
    "        t21.append(temp[0])\n",
    "        t22.append(temp[1])\n",
    "        t23.append(container)   \n",
    "\n",
    "print([i for i,j in enumerate(t11) if j == 'HD_914f915c-2cac-473e-bea5-c26e4c83673c_1'])\n",
    "print([i for i,j in enumerate(t21) if j == 'HD_914f915c-2cac-473e-bea5-c26e4c83673c_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final test accuracy 0.6057029366493225\n",
      "Train Accuracy 0.6022814512252808\n"
     ]
    }
   ],
   "source": [
    "print(t12[5],t13[5])\n",
    "print(t22[10],t23[10][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0</th>\n",
       "      <th>Final test loss</th>\n",
       "      <td>1.0703172176779956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Final test AUC</th>\n",
       "      <td>0.5924146175384521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Final test accuracy</th>\n",
       "      <td>0.4012987017631531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_1</th>\n",
       "      <th>Final test loss</th>\n",
       "      <td>0.9833228082609005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Final test AUC</th>\n",
       "      <td>0.7488732933998108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">HD_914f915c-2cac-473e-bea5-c26e4c83673c_100</th>\n",
       "      <th>Final test AUC</th>\n",
       "      <td>0.12177372723817825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Final test accuracy</th>\n",
       "      <td>0.22250525653362274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">HD_914f915c-2cac-473e-bea5-c26e4c83673c_101</th>\n",
       "      <th>Final test loss</th>\n",
       "      <td>0.7250796820548917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Final test AUC</th>\n",
       "      <td>0.54725581407547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Final test accuracy</th>\n",
       "      <td>0.5373607873916626</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1413 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                size\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Final test loss       1.0703172176779956\n",
       "                                            Final test AUC        0.5924146175384521\n",
       "                                            Final test accuracy   0.4012987017631531\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_1   Final test loss       0.9833228082609005\n",
       "                                            Final test AUC        0.7488732933998108\n",
       "...                                                                              ...\n",
       "HD_914f915c-2cac-473e-bea5-c26e4c83673c_100 Final test AUC       0.12177372723817825\n",
       "                                            Final test accuracy  0.22250525653362274\n",
       "HD_914f915c-2cac-473e-bea5-c26e4c83673c_101 Final test loss       0.7250796820548917\n",
       "                                            Final test AUC          0.54725581407547\n",
       "                                            Final test accuracy   0.5373607873916626\n",
       "\n",
       "[1413 rows x 1 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalMetrics_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "      <th>150</th>\n",
       "      <th>151</th>\n",
       "      <th>152</th>\n",
       "      <th>153</th>\n",
       "      <th>154</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0</th>\n",
       "      <th>Loss</th>\n",
       "      <td>1.097134</td>\n",
       "      <td>1.089486</td>\n",
       "      <td>1.084925</td>\n",
       "      <td>1.082050</td>\n",
       "      <td>1.080157</td>\n",
       "      <td>1.078848</td>\n",
       "      <td>1.077901</td>\n",
       "      <td>1.077183</td>\n",
       "      <td>1.076617</td>\n",
       "      <td>1.076155</td>\n",
       "      <td>...</td>\n",
       "      <td>1.070333</td>\n",
       "      <td>1.070329</td>\n",
       "      <td>1.070325</td>\n",
       "      <td>1.070321</td>\n",
       "      <td>1.070317</td>\n",
       "      <td>1.070317</td>\n",
       "      <td>1.070317</td>\n",
       "      <td>1.070317</td>\n",
       "      <td>1.070317</td>\n",
       "      <td>1.070317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.357927</td>\n",
       "      <td>0.372786</td>\n",
       "      <td>0.380087</td>\n",
       "      <td>0.386206</td>\n",
       "      <td>0.388733</td>\n",
       "      <td>0.389996</td>\n",
       "      <td>0.391295</td>\n",
       "      <td>0.392629</td>\n",
       "      <td>0.393904</td>\n",
       "      <td>0.394478</td>\n",
       "      <td>...</td>\n",
       "      <td>0.401299</td>\n",
       "      <td>0.401381</td>\n",
       "      <td>0.401322</td>\n",
       "      <td>0.401275</td>\n",
       "      <td>0.401299</td>\n",
       "      <td>0.401299</td>\n",
       "      <td>0.401299</td>\n",
       "      <td>0.401299</td>\n",
       "      <td>0.401299</td>\n",
       "      <td>0.401299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC</th>\n",
       "      <td>0.520483</td>\n",
       "      <td>0.533294</td>\n",
       "      <td>0.543315</td>\n",
       "      <td>0.550682</td>\n",
       "      <td>0.556136</td>\n",
       "      <td>0.560248</td>\n",
       "      <td>0.563450</td>\n",
       "      <td>0.566000</td>\n",
       "      <td>0.568082</td>\n",
       "      <td>0.569817</td>\n",
       "      <td>...</td>\n",
       "      <td>0.592322</td>\n",
       "      <td>0.592349</td>\n",
       "      <td>0.592375</td>\n",
       "      <td>0.592401</td>\n",
       "      <td>0.592426</td>\n",
       "      <td>0.592426</td>\n",
       "      <td>0.592426</td>\n",
       "      <td>0.592426</td>\n",
       "      <td>0.592426</td>\n",
       "      <td>0.592426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Loss</th>\n",
       "      <td>1.103421</td>\n",
       "      <td>1.092251</td>\n",
       "      <td>1.085799</td>\n",
       "      <td>1.081776</td>\n",
       "      <td>1.079140</td>\n",
       "      <td>1.077343</td>\n",
       "      <td>1.076068</td>\n",
       "      <td>1.075129</td>\n",
       "      <td>1.074413</td>\n",
       "      <td>1.073847</td>\n",
       "      <td>...</td>\n",
       "      <td>1.067931</td>\n",
       "      <td>1.067927</td>\n",
       "      <td>1.067922</td>\n",
       "      <td>1.067918</td>\n",
       "      <td>1.067913</td>\n",
       "      <td>1.067913</td>\n",
       "      <td>1.067913</td>\n",
       "      <td>1.067913</td>\n",
       "      <td>1.067913</td>\n",
       "      <td>1.067913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Accuracy</th>\n",
       "      <td>0.348293</td>\n",
       "      <td>0.370394</td>\n",
       "      <td>0.381516</td>\n",
       "      <td>0.386821</td>\n",
       "      <td>0.390184</td>\n",
       "      <td>0.392238</td>\n",
       "      <td>0.393292</td>\n",
       "      <td>0.394232</td>\n",
       "      <td>0.395504</td>\n",
       "      <td>0.396163</td>\n",
       "      <td>...</td>\n",
       "      <td>0.407098</td>\n",
       "      <td>0.407139</td>\n",
       "      <td>0.407136</td>\n",
       "      <td>0.407177</td>\n",
       "      <td>0.407191</td>\n",
       "      <td>0.407191</td>\n",
       "      <td>0.407191</td>\n",
       "      <td>0.407191</td>\n",
       "      <td>0.407191</td>\n",
       "      <td>0.407191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">HD_914f915c-2cac-473e-bea5-c26e4c83673c_101</th>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.545000</td>\n",
       "      <td>0.528089</td>\n",
       "      <td>0.534760</td>\n",
       "      <td>0.533022</td>\n",
       "      <td>0.537606</td>\n",
       "      <td>0.537186</td>\n",
       "      <td>0.538049</td>\n",
       "      <td>0.537466</td>\n",
       "      <td>0.537781</td>\n",
       "      <td>0.537664</td>\n",
       "      <td>...</td>\n",
       "      <td>0.537361</td>\n",
       "      <td>0.537361</td>\n",
       "      <td>0.537361</td>\n",
       "      <td>0.537361</td>\n",
       "      <td>0.537361</td>\n",
       "      <td>0.537361</td>\n",
       "      <td>0.537361</td>\n",
       "      <td>0.537361</td>\n",
       "      <td>0.537361</td>\n",
       "      <td>0.537361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC</th>\n",
       "      <td>0.550652</td>\n",
       "      <td>0.546950</td>\n",
       "      <td>0.546178</td>\n",
       "      <td>0.545355</td>\n",
       "      <td>0.545480</td>\n",
       "      <td>0.545659</td>\n",
       "      <td>0.545795</td>\n",
       "      <td>0.545820</td>\n",
       "      <td>0.545810</td>\n",
       "      <td>0.545811</td>\n",
       "      <td>...</td>\n",
       "      <td>0.547250</td>\n",
       "      <td>0.547252</td>\n",
       "      <td>0.547253</td>\n",
       "      <td>0.547254</td>\n",
       "      <td>0.547255</td>\n",
       "      <td>0.547255</td>\n",
       "      <td>0.547255</td>\n",
       "      <td>0.547255</td>\n",
       "      <td>0.547255</td>\n",
       "      <td>0.547255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Loss</th>\n",
       "      <td>0.704141</td>\n",
       "      <td>0.722193</td>\n",
       "      <td>0.718967</td>\n",
       "      <td>0.727249</td>\n",
       "      <td>0.717748</td>\n",
       "      <td>0.716054</td>\n",
       "      <td>0.716037</td>\n",
       "      <td>0.718115</td>\n",
       "      <td>0.719101</td>\n",
       "      <td>0.718774</td>\n",
       "      <td>...</td>\n",
       "      <td>0.715954</td>\n",
       "      <td>0.715954</td>\n",
       "      <td>0.715954</td>\n",
       "      <td>0.715954</td>\n",
       "      <td>0.715954</td>\n",
       "      <td>0.715954</td>\n",
       "      <td>0.715954</td>\n",
       "      <td>0.715954</td>\n",
       "      <td>0.715954</td>\n",
       "      <td>0.715954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Accuracy</th>\n",
       "      <td>0.531084</td>\n",
       "      <td>0.526480</td>\n",
       "      <td>0.528231</td>\n",
       "      <td>0.525877</td>\n",
       "      <td>0.527252</td>\n",
       "      <td>0.527832</td>\n",
       "      <td>0.527844</td>\n",
       "      <td>0.527147</td>\n",
       "      <td>0.526635</td>\n",
       "      <td>0.527060</td>\n",
       "      <td>...</td>\n",
       "      <td>0.528193</td>\n",
       "      <td>0.528193</td>\n",
       "      <td>0.528193</td>\n",
       "      <td>0.528193</td>\n",
       "      <td>0.528193</td>\n",
       "      <td>0.528193</td>\n",
       "      <td>0.528193</td>\n",
       "      <td>0.528193</td>\n",
       "      <td>0.528193</td>\n",
       "      <td>0.528193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train AUC</th>\n",
       "      <td>0.534949</td>\n",
       "      <td>0.548933</td>\n",
       "      <td>0.546634</td>\n",
       "      <td>0.545650</td>\n",
       "      <td>0.545351</td>\n",
       "      <td>0.545567</td>\n",
       "      <td>0.545751</td>\n",
       "      <td>0.545838</td>\n",
       "      <td>0.545843</td>\n",
       "      <td>0.545833</td>\n",
       "      <td>...</td>\n",
       "      <td>0.547252</td>\n",
       "      <td>0.547253</td>\n",
       "      <td>0.547254</td>\n",
       "      <td>0.547256</td>\n",
       "      <td>0.547257</td>\n",
       "      <td>0.547257</td>\n",
       "      <td>0.547257</td>\n",
       "      <td>0.547257</td>\n",
       "      <td>0.547257</td>\n",
       "      <td>0.547257</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2826 rows × 155 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   0  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss            1.097134   \n",
       "                                            Accuracy        0.357927   \n",
       "                                            AUC             0.520483   \n",
       "                                            Train Loss      1.103421   \n",
       "                                            Train Accuracy  0.348293   \n",
       "...                                                              ...   \n",
       "HD_914f915c-2cac-473e-bea5-c26e4c83673c_101 Accuracy        0.545000   \n",
       "                                            AUC             0.550652   \n",
       "                                            Train Loss      0.704141   \n",
       "                                            Train Accuracy  0.531084   \n",
       "                                            Train AUC       0.534949   \n",
       "\n",
       "                                                                   1  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss            1.089486   \n",
       "                                            Accuracy        0.372786   \n",
       "                                            AUC             0.533294   \n",
       "                                            Train Loss      1.092251   \n",
       "                                            Train Accuracy  0.370394   \n",
       "...                                                              ...   \n",
       "HD_914f915c-2cac-473e-bea5-c26e4c83673c_101 Accuracy        0.528089   \n",
       "                                            AUC             0.546950   \n",
       "                                            Train Loss      0.722193   \n",
       "                                            Train Accuracy  0.526480   \n",
       "                                            Train AUC       0.548933   \n",
       "\n",
       "                                                                   2  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss            1.084925   \n",
       "                                            Accuracy        0.380087   \n",
       "                                            AUC             0.543315   \n",
       "                                            Train Loss      1.085799   \n",
       "                                            Train Accuracy  0.381516   \n",
       "...                                                              ...   \n",
       "HD_914f915c-2cac-473e-bea5-c26e4c83673c_101 Accuracy        0.534760   \n",
       "                                            AUC             0.546178   \n",
       "                                            Train Loss      0.718967   \n",
       "                                            Train Accuracy  0.528231   \n",
       "                                            Train AUC       0.546634   \n",
       "\n",
       "                                                                   3  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss            1.082050   \n",
       "                                            Accuracy        0.386206   \n",
       "                                            AUC             0.550682   \n",
       "                                            Train Loss      1.081776   \n",
       "                                            Train Accuracy  0.386821   \n",
       "...                                                              ...   \n",
       "HD_914f915c-2cac-473e-bea5-c26e4c83673c_101 Accuracy        0.533022   \n",
       "                                            AUC             0.545355   \n",
       "                                            Train Loss      0.727249   \n",
       "                                            Train Accuracy  0.525877   \n",
       "                                            Train AUC       0.545650   \n",
       "\n",
       "                                                                   4  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss            1.080157   \n",
       "                                            Accuracy        0.388733   \n",
       "                                            AUC             0.556136   \n",
       "                                            Train Loss      1.079140   \n",
       "                                            Train Accuracy  0.390184   \n",
       "...                                                              ...   \n",
       "HD_914f915c-2cac-473e-bea5-c26e4c83673c_101 Accuracy        0.537606   \n",
       "                                            AUC             0.545480   \n",
       "                                            Train Loss      0.717748   \n",
       "                                            Train Accuracy  0.527252   \n",
       "                                            Train AUC       0.545351   \n",
       "\n",
       "                                                                   5  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss            1.078848   \n",
       "                                            Accuracy        0.389996   \n",
       "                                            AUC             0.560248   \n",
       "                                            Train Loss      1.077343   \n",
       "                                            Train Accuracy  0.392238   \n",
       "...                                                              ...   \n",
       "HD_914f915c-2cac-473e-bea5-c26e4c83673c_101 Accuracy        0.537186   \n",
       "                                            AUC             0.545659   \n",
       "                                            Train Loss      0.716054   \n",
       "                                            Train Accuracy  0.527832   \n",
       "                                            Train AUC       0.545567   \n",
       "\n",
       "                                                                   6  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss            1.077901   \n",
       "                                            Accuracy        0.391295   \n",
       "                                            AUC             0.563450   \n",
       "                                            Train Loss      1.076068   \n",
       "                                            Train Accuracy  0.393292   \n",
       "...                                                              ...   \n",
       "HD_914f915c-2cac-473e-bea5-c26e4c83673c_101 Accuracy        0.538049   \n",
       "                                            AUC             0.545795   \n",
       "                                            Train Loss      0.716037   \n",
       "                                            Train Accuracy  0.527844   \n",
       "                                            Train AUC       0.545751   \n",
       "\n",
       "                                                                   7  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss            1.077183   \n",
       "                                            Accuracy        0.392629   \n",
       "                                            AUC             0.566000   \n",
       "                                            Train Loss      1.075129   \n",
       "                                            Train Accuracy  0.394232   \n",
       "...                                                              ...   \n",
       "HD_914f915c-2cac-473e-bea5-c26e4c83673c_101 Accuracy        0.537466   \n",
       "                                            AUC             0.545820   \n",
       "                                            Train Loss      0.718115   \n",
       "                                            Train Accuracy  0.527147   \n",
       "                                            Train AUC       0.545838   \n",
       "\n",
       "                                                                   8  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss            1.076617   \n",
       "                                            Accuracy        0.393904   \n",
       "                                            AUC             0.568082   \n",
       "                                            Train Loss      1.074413   \n",
       "                                            Train Accuracy  0.395504   \n",
       "...                                                              ...   \n",
       "HD_914f915c-2cac-473e-bea5-c26e4c83673c_101 Accuracy        0.537781   \n",
       "                                            AUC             0.545810   \n",
       "                                            Train Loss      0.719101   \n",
       "                                            Train Accuracy  0.526635   \n",
       "                                            Train AUC       0.545843   \n",
       "\n",
       "                                                                   9  ...  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss            1.076155  ...   \n",
       "                                            Accuracy        0.394478  ...   \n",
       "                                            AUC             0.569817  ...   \n",
       "                                            Train Loss      1.073847  ...   \n",
       "                                            Train Accuracy  0.396163  ...   \n",
       "...                                                              ...  ...   \n",
       "HD_914f915c-2cac-473e-bea5-c26e4c83673c_101 Accuracy        0.537664  ...   \n",
       "                                            AUC             0.545811  ...   \n",
       "                                            Train Loss      0.718774  ...   \n",
       "                                            Train Accuracy  0.527060  ...   \n",
       "                                            Train AUC       0.545833  ...   \n",
       "\n",
       "                                                                 145  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss            1.070333   \n",
       "                                            Accuracy        0.401299   \n",
       "                                            AUC             0.592322   \n",
       "                                            Train Loss      1.067931   \n",
       "                                            Train Accuracy  0.407098   \n",
       "...                                                              ...   \n",
       "HD_914f915c-2cac-473e-bea5-c26e4c83673c_101 Accuracy        0.537361   \n",
       "                                            AUC             0.547250   \n",
       "                                            Train Loss      0.715954   \n",
       "                                            Train Accuracy  0.528193   \n",
       "                                            Train AUC       0.547252   \n",
       "\n",
       "                                                                 146  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss            1.070329   \n",
       "                                            Accuracy        0.401381   \n",
       "                                            AUC             0.592349   \n",
       "                                            Train Loss      1.067927   \n",
       "                                            Train Accuracy  0.407139   \n",
       "...                                                              ...   \n",
       "HD_914f915c-2cac-473e-bea5-c26e4c83673c_101 Accuracy        0.537361   \n",
       "                                            AUC             0.547252   \n",
       "                                            Train Loss      0.715954   \n",
       "                                            Train Accuracy  0.528193   \n",
       "                                            Train AUC       0.547253   \n",
       "\n",
       "                                                                 147  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss            1.070325   \n",
       "                                            Accuracy        0.401322   \n",
       "                                            AUC             0.592375   \n",
       "                                            Train Loss      1.067922   \n",
       "                                            Train Accuracy  0.407136   \n",
       "...                                                              ...   \n",
       "HD_914f915c-2cac-473e-bea5-c26e4c83673c_101 Accuracy        0.537361   \n",
       "                                            AUC             0.547253   \n",
       "                                            Train Loss      0.715954   \n",
       "                                            Train Accuracy  0.528193   \n",
       "                                            Train AUC       0.547254   \n",
       "\n",
       "                                                                 148  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss            1.070321   \n",
       "                                            Accuracy        0.401275   \n",
       "                                            AUC             0.592401   \n",
       "                                            Train Loss      1.067918   \n",
       "                                            Train Accuracy  0.407177   \n",
       "...                                                              ...   \n",
       "HD_914f915c-2cac-473e-bea5-c26e4c83673c_101 Accuracy        0.537361   \n",
       "                                            AUC             0.547254   \n",
       "                                            Train Loss      0.715954   \n",
       "                                            Train Accuracy  0.528193   \n",
       "                                            Train AUC       0.547256   \n",
       "\n",
       "                                                                 149  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss            1.070317   \n",
       "                                            Accuracy        0.401299   \n",
       "                                            AUC             0.592426   \n",
       "                                            Train Loss      1.067913   \n",
       "                                            Train Accuracy  0.407191   \n",
       "...                                                              ...   \n",
       "HD_914f915c-2cac-473e-bea5-c26e4c83673c_101 Accuracy        0.537361   \n",
       "                                            AUC             0.547255   \n",
       "                                            Train Loss      0.715954   \n",
       "                                            Train Accuracy  0.528193   \n",
       "                                            Train AUC       0.547257   \n",
       "\n",
       "                                                                 150  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss            1.070317   \n",
       "                                            Accuracy        0.401299   \n",
       "                                            AUC             0.592426   \n",
       "                                            Train Loss      1.067913   \n",
       "                                            Train Accuracy  0.407191   \n",
       "...                                                              ...   \n",
       "HD_914f915c-2cac-473e-bea5-c26e4c83673c_101 Accuracy        0.537361   \n",
       "                                            AUC             0.547255   \n",
       "                                            Train Loss      0.715954   \n",
       "                                            Train Accuracy  0.528193   \n",
       "                                            Train AUC       0.547257   \n",
       "\n",
       "                                                                 151  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss            1.070317   \n",
       "                                            Accuracy        0.401299   \n",
       "                                            AUC             0.592426   \n",
       "                                            Train Loss      1.067913   \n",
       "                                            Train Accuracy  0.407191   \n",
       "...                                                              ...   \n",
       "HD_914f915c-2cac-473e-bea5-c26e4c83673c_101 Accuracy        0.537361   \n",
       "                                            AUC             0.547255   \n",
       "                                            Train Loss      0.715954   \n",
       "                                            Train Accuracy  0.528193   \n",
       "                                            Train AUC       0.547257   \n",
       "\n",
       "                                                                 152  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss            1.070317   \n",
       "                                            Accuracy        0.401299   \n",
       "                                            AUC             0.592426   \n",
       "                                            Train Loss      1.067913   \n",
       "                                            Train Accuracy  0.407191   \n",
       "...                                                              ...   \n",
       "HD_914f915c-2cac-473e-bea5-c26e4c83673c_101 Accuracy        0.537361   \n",
       "                                            AUC             0.547255   \n",
       "                                            Train Loss      0.715954   \n",
       "                                            Train Accuracy  0.528193   \n",
       "                                            Train AUC       0.547257   \n",
       "\n",
       "                                                                 153       154  \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_0   Loss            1.070317  1.070317  \n",
       "                                            Accuracy        0.401299  0.401299  \n",
       "                                            AUC             0.592426  0.592426  \n",
       "                                            Train Loss      1.067913  1.067913  \n",
       "                                            Train Accuracy  0.407191  0.407191  \n",
       "...                                                              ...       ...  \n",
       "HD_914f915c-2cac-473e-bea5-c26e4c83673c_101 Accuracy        0.537361  0.537361  \n",
       "                                            AUC             0.547255  0.547255  \n",
       "                                            Train Loss      0.715954  0.715954  \n",
       "                                            Train Accuracy  0.528193  0.528193  \n",
       "                                            Train AUC       0.547257  0.547257  \n",
       "\n",
       "[2826 rows x 155 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runningMetrics_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attaching the last observation of each model, for each metric, to the parameters of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>run_id</th>\n",
       "      <th>run_id</th>\n",
       "      <th>run_id</th>\n",
       "      <th>batch-shuffle</th>\n",
       "      <th>batch-size</th>\n",
       "      <th>feature-lags</th>\n",
       "      <th>featureset</th>\n",
       "      <th>l2-penalty</th>\n",
       "      <th>l2-type</th>\n",
       "      <th>...</th>\n",
       "      <th>n-epochs</th>\n",
       "      <th>pastobs-in-percentage</th>\n",
       "      <th>pre-processing</th>\n",
       "      <th>id</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Train AUC</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Train Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>344</td>\n",
       "      <td>344</td>\n",
       "      <td>344</td>\n",
       "      <td>HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_344</td>\n",
       "      <td>1</td>\n",
       "      <td>10725</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10000000000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>std</td>\n",
       "      <td>344</td>\n",
       "      <td>0.769295</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_8</td>\n",
       "      <td>0</td>\n",
       "      <td>3300</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>std</td>\n",
       "      <td>8</td>\n",
       "      <td>0.748841</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>194</td>\n",
       "      <td>194</td>\n",
       "      <td>194</td>\n",
       "      <td>HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_194</td>\n",
       "      <td>1</td>\n",
       "      <td>10725</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>194</td>\n",
       "      <td>0.743498</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>326</td>\n",
       "      <td>326</td>\n",
       "      <td>326</td>\n",
       "      <td>HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_326</td>\n",
       "      <td>0</td>\n",
       "      <td>10725</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>stacked</td>\n",
       "      <td>326</td>\n",
       "      <td>0.736580</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>278</td>\n",
       "      <td>278</td>\n",
       "      <td>278</td>\n",
       "      <td>HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_278</td>\n",
       "      <td>1</td>\n",
       "      <td>3300</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>stacked</td>\n",
       "      <td>278</td>\n",
       "      <td>0.734464</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>478</td>\n",
       "      <td>478</td>\n",
       "      <td>478</td>\n",
       "      <td>HD_914f915c-2cac-473e-bea5-c26e4c83673c_97</td>\n",
       "      <td>1</td>\n",
       "      <td>21450</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>10000000000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>std</td>\n",
       "      <td>478</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.552116</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>479</td>\n",
       "      <td>479</td>\n",
       "      <td>479</td>\n",
       "      <td>HD_914f915c-2cac-473e-bea5-c26e4c83673c_98</td>\n",
       "      <td>1</td>\n",
       "      <td>10725</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>10000000000.0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>479</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.465899</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>480</td>\n",
       "      <td>480</td>\n",
       "      <td>480</td>\n",
       "      <td>HD_914f915c-2cac-473e-bea5-c26e4c83673c_99</td>\n",
       "      <td>1</td>\n",
       "      <td>3300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>480</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>146285.365738</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>481</td>\n",
       "      <td>481</td>\n",
       "      <td>481</td>\n",
       "      <td>HD_914f915c-2cac-473e-bea5-c26e4c83673c_100</td>\n",
       "      <td>1</td>\n",
       "      <td>21450</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>std</td>\n",
       "      <td>481</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.19385</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>483</td>\n",
       "      <td>483</td>\n",
       "      <td>483</td>\n",
       "      <td>HD_914f915c-2cac-473e-bea5-c26e4c83673c_102</td>\n",
       "      <td>0</td>\n",
       "      <td>21450</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>minmax</td>\n",
       "      <td>483</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.836298e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>484 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    run_id run_id run_id                                       run_id  \\\n",
       "344    344    344    344  HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_344   \n",
       "8        8      8      8    HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_8   \n",
       "194    194    194    194  HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_194   \n",
       "326    326    326    326  HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_326   \n",
       "278    278    278    278  HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_278   \n",
       "..     ...    ...    ...                                          ...   \n",
       "478    478    478    478   HD_914f915c-2cac-473e-bea5-c26e4c83673c_97   \n",
       "479    479    479    479   HD_914f915c-2cac-473e-bea5-c26e4c83673c_98   \n",
       "480    480    480    480   HD_914f915c-2cac-473e-bea5-c26e4c83673c_99   \n",
       "481    481    481    481  HD_914f915c-2cac-473e-bea5-c26e4c83673c_100   \n",
       "483    483    483    483  HD_914f915c-2cac-473e-bea5-c26e4c83673c_102   \n",
       "\n",
       "    batch-shuffle batch-size feature-lags featureset     l2-penalty l2-type  \\\n",
       "344             1      10725            1          0  10000000000.0       4   \n",
       "8               0       3300            1          0            0.1       4   \n",
       "194             1      10725            0          0          0.001       6   \n",
       "326             0      10725            5          2           0.01       4   \n",
       "278             1       3300            3          2            0.1       6   \n",
       "..            ...        ...          ...        ...            ...     ...   \n",
       "478             1      21450            5          2  10000000000.0       3   \n",
       "479             1      10725            3          2  10000000000.0       5   \n",
       "480             1       3300            0          0         0.0001       6   \n",
       "481             1      21450            3          1         1000.0       5   \n",
       "483             0      21450            3          0           10.0       6   \n",
       "\n",
       "     ... n-epochs pastobs-in-percentage pre-processing   id       AUC  \\\n",
       "344  ...      150                     0            std  344  0.769295   \n",
       "8    ...      150                     1            std    8  0.748841   \n",
       "194  ...      150                     1           None  194  0.743498   \n",
       "326  ...      150                     0        stacked  326  0.736580   \n",
       "278  ...      150                     0        stacked  278  0.734464   \n",
       "..   ...      ...                   ...            ...  ...       ...   \n",
       "478  ...      150                     1            std  478       NaN   \n",
       "479  ...      150                     0           None  479       NaN   \n",
       "480  ...      150                     1           None  480       NaN   \n",
       "481  ...      150                     0            std  481       NaN   \n",
       "483  ...      150                     0         minmax  483       NaN   \n",
       "\n",
       "    Accuracy           Loss  Train AUC  Train Accuracy    Train Loss  \n",
       "344      NaN            NaN        NaN             NaN           NaN  \n",
       "8        NaN            NaN        NaN             NaN           NaN  \n",
       "194      NaN            NaN        NaN             NaN           NaN  \n",
       "326      NaN            NaN        NaN             NaN           NaN  \n",
       "278      NaN            NaN        NaN             NaN           NaN  \n",
       "..       ...            ...        ...             ...           ...  \n",
       "478      NaN            NaN        NaN        0.552116           NaN  \n",
       "479      NaN            NaN   0.465899             NaN           NaN  \n",
       "480      NaN  146285.365738        NaN             NaN           NaN  \n",
       "481  0.19385            NaN        NaN             NaN           NaN  \n",
       "483      NaN            NaN        NaN             NaN  1.836298e+06  \n",
       "\n",
       "[484 rows x 23 columns]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Resetting indcies and rename columns\n",
    "runningMetrics_lr = runningMetrics_lr.reset_index().rename(columns={'level_0':'run_id','level_1':'metric'})\n",
    "runningMetrics_lr.columns = runningMetrics_lr.columns.get_level_values(0)\n",
    "\n",
    "## Adding a column of short ids, to merge on.\n",
    "runningMetrics_lr['id'] = np.arange(runningMetrics_lr.shape[0]).astype(str)#[re.split('_',i)[-1] for i in runningMetrics_lr.run_id]\n",
    "\n",
    "## Creating a table, having the short id in the rows and the last observation for each metric in the columns. \n",
    "table_lr = pd.pivot_table(runningMetrics_lr[['run_id','metric','154','id']],index='id',columns=['metric'])\n",
    "table_lr.columns = table_lr.columns.get_level_values(1)\n",
    "table_lr = table_lr.round(7).reset_index()\n",
    "\n",
    "## Preparing the parameter dataframe.\n",
    "parameters_lr = parameters_lr.reset_index().rename(columns={'index':'run_id'})\n",
    "\n",
    "## Setting short ID\n",
    "parameters_lr['id'] = np.arange(parameters_lr.shape[0]).astype(str)#[re.split('_',i)[-1] for i in parameters_lr.run_id]\n",
    "\n",
    "## Creating the combined table\n",
    "combined_table_lr = parameters_lr.merge(table_lr,\n",
    "                                     on = 'id',\n",
    "                                     how='left').sort_values('AUC',ascending=False)\n",
    "combined_table_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating a top-X table for each label-type of a given metric, here AUC.\n",
    "temp_auc_lr = pd.pivot_table(combined_table_lr[['label-type','AUC','id']],index='id',columns='label-type')\n",
    "temp_acc_lr = pd.pivot_table(combined_table_lr[['label-type','Accuracy','id']],index='id',columns='label-type')\n",
    "\n",
    "## Final output - AUC\n",
    "final_output_auc_lr = pd.DataFrame(np.sort(temp_auc_lr.fillna(0).values,\n",
    "                             axis=0)[::-1],\n",
    "                             columns=temp_auc_lr.columns.get_level_values(1)).loc[0:10]\n",
    "## Final output - Accuracy\n",
    "final_output_acc_lr = pd.DataFrame(np.sort(temp_acc_lr.fillna(0).values,\n",
    "                             axis=0)[::-1],\n",
    "                             columns=temp_acc_lr.columns.get_level_values(1))#.loc[0:10]\n",
    "# final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>run_id</th>\n",
       "      <th>run_id</th>\n",
       "      <th>run_id</th>\n",
       "      <th>batch-shuffle</th>\n",
       "      <th>batch-size</th>\n",
       "      <th>feature-lags</th>\n",
       "      <th>featureset</th>\n",
       "      <th>l2-penalty</th>\n",
       "      <th>l2-type</th>\n",
       "      <th>...</th>\n",
       "      <th>n-epochs</th>\n",
       "      <th>pastobs-in-percentage</th>\n",
       "      <th>pre-processing</th>\n",
       "      <th>id</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Train AUC</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Train Loss</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label-type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>344</td>\n",
       "      <td>344</td>\n",
       "      <td>344</td>\n",
       "      <td>HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_344</td>\n",
       "      <td>1</td>\n",
       "      <td>10725</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10000000000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>std</td>\n",
       "      <td>344</td>\n",
       "      <td>0.769295</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_8</td>\n",
       "      <td>0</td>\n",
       "      <td>3300</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>std</td>\n",
       "      <td>8</td>\n",
       "      <td>0.748841</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>194</td>\n",
       "      <td>194</td>\n",
       "      <td>194</td>\n",
       "      <td>HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_194</td>\n",
       "      <td>1</td>\n",
       "      <td>10725</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>194</td>\n",
       "      <td>0.743498</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>326</td>\n",
       "      <td>326</td>\n",
       "      <td>326</td>\n",
       "      <td>HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_326</td>\n",
       "      <td>0</td>\n",
       "      <td>10725</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>stacked</td>\n",
       "      <td>326</td>\n",
       "      <td>0.736580</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>278</td>\n",
       "      <td>278</td>\n",
       "      <td>278</td>\n",
       "      <td>HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_278</td>\n",
       "      <td>1</td>\n",
       "      <td>3300</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>stacked</td>\n",
       "      <td>278</td>\n",
       "      <td>0.734464</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           run_id run_id run_id                                       run_id  \\\n",
       "label-type                                                                     \n",
       "2             344    344    344  HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_344   \n",
       "1               8      8      8    HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_8   \n",
       "0             194    194    194  HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_194   \n",
       "3             326    326    326  HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_326   \n",
       "4             278    278    278  HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_278   \n",
       "\n",
       "           batch-shuffle batch-size feature-lags featureset     l2-penalty  \\\n",
       "label-type                                                                   \n",
       "2                      1      10725            1          0  10000000000.0   \n",
       "1                      0       3300            1          0            0.1   \n",
       "0                      1      10725            0          0          0.001   \n",
       "3                      0      10725            5          2           0.01   \n",
       "4                      1       3300            3          2            0.1   \n",
       "\n",
       "           l2-type  ... n-epochs pastobs-in-percentage pre-processing   id  \\\n",
       "label-type          ...                                                      \n",
       "2                4  ...      150                     0            std  344   \n",
       "1                4  ...      150                     1            std    8   \n",
       "0                6  ...      150                     1           None  194   \n",
       "3                4  ...      150                     0        stacked  326   \n",
       "4                6  ...      150                     0        stacked  278   \n",
       "\n",
       "                 AUC Accuracy Loss  Train AUC  Train Accuracy  Train Loss  \n",
       "label-type                                                                 \n",
       "2           0.769295      NaN  NaN        NaN             NaN         NaN  \n",
       "1           0.748841      NaN  NaN        NaN             NaN         NaN  \n",
       "0           0.743498      NaN  NaN        NaN             NaN         NaN  \n",
       "3           0.736580      NaN  NaN        NaN             NaN         NaN  \n",
       "4           0.734464      NaN  NaN        NaN             NaN         NaN  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tempFinal_v0_lr = combined_table_lr[np.isin(combined_table_lr.AUC,final_output_auc_lr.loc[0].values.flatten())]\n",
    "tempFinal_v0_lr.index = tempFinal_v0_lr.loc[:,'label-type']\n",
    "tempFinal_v0_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label-type\n",
       "0    0.609582\n",
       "1    0.519679\n",
       "2    0.606345\n",
       "3    0.610655\n",
       "4    0.609793\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_output_acc_lr.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>run_id</th>\n",
       "      <th>run_id</th>\n",
       "      <th>run_id</th>\n",
       "      <th>batch-shuffle</th>\n",
       "      <th>batch-size</th>\n",
       "      <th>feature-lags</th>\n",
       "      <th>featureset</th>\n",
       "      <th>l2-penalty</th>\n",
       "      <th>l2-type</th>\n",
       "      <th>...</th>\n",
       "      <th>n-epochs</th>\n",
       "      <th>pastobs-in-percentage</th>\n",
       "      <th>pre-processing</th>\n",
       "      <th>id</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Train AUC</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Train Loss</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label-type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>439</td>\n",
       "      <td>439</td>\n",
       "      <td>439</td>\n",
       "      <td>HD_914f915c-2cac-473e-bea5-c26e4c83673c_58</td>\n",
       "      <td>0</td>\n",
       "      <td>21450</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>std</td>\n",
       "      <td>439</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.609582</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>157</td>\n",
       "      <td>157</td>\n",
       "      <td>157</td>\n",
       "      <td>HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_157</td>\n",
       "      <td>0</td>\n",
       "      <td>21450</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10000000000.0</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>minmax</td>\n",
       "      <td>157</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.519679</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>259</td>\n",
       "      <td>259</td>\n",
       "      <td>259</td>\n",
       "      <td>HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_259</td>\n",
       "      <td>0</td>\n",
       "      <td>21450</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>minmax</td>\n",
       "      <td>259</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.606345</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_7</td>\n",
       "      <td>1</td>\n",
       "      <td>3300</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>quantgau</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.610655</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>343</td>\n",
       "      <td>343</td>\n",
       "      <td>343</td>\n",
       "      <td>HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_343</td>\n",
       "      <td>1</td>\n",
       "      <td>21450</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>343</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.609793</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           run_id run_id run_id                                       run_id  \\\n",
       "label-type                                                                     \n",
       "0             439    439    439   HD_914f915c-2cac-473e-bea5-c26e4c83673c_58   \n",
       "1             157    157    157  HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_157   \n",
       "2             259    259    259  HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_259   \n",
       "3               7      7      7    HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_7   \n",
       "4             343    343    343  HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_343   \n",
       "\n",
       "           batch-shuffle batch-size feature-lags featureset     l2-penalty  \\\n",
       "label-type                                                                   \n",
       "0                      0      21450            0          2         1000.0   \n",
       "1                      0      21450            1          1  10000000000.0   \n",
       "2                      0      21450            3          1           10.0   \n",
       "3                      1       3300            5          1            0.1   \n",
       "4                      1      21450            1          1        10000.0   \n",
       "\n",
       "           l2-type  ... n-epochs pastobs-in-percentage pre-processing   id  \\\n",
       "label-type          ...                                                      \n",
       "0                5  ...      150                     0            std  439   \n",
       "1                6  ...      150                     1         minmax  157   \n",
       "2                5  ...      150                     1         minmax  259   \n",
       "3                1  ...      150                     1       quantgau    7   \n",
       "4                2  ...      150                     0           None  343   \n",
       "\n",
       "           AUC  Accuracy Loss  Train AUC  Train Accuracy  Train Loss  \n",
       "label-type                                                            \n",
       "0          NaN  0.609582  NaN        NaN             NaN         NaN  \n",
       "1          NaN  0.519679  NaN        NaN             NaN         NaN  \n",
       "2          NaN  0.606345  NaN        NaN             NaN         NaN  \n",
       "3          NaN  0.610655  NaN        NaN             NaN         NaN  \n",
       "4          NaN  0.609793  NaN        NaN             NaN         NaN  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tempFinal_v1_lr = combined_table_lr[np.isin(combined_table_lr.Accuracy,final_output_acc_lr.loc[0].values.flatten())].sort_values('label-type').copy(deep=True)\n",
    "tempFinal_v1_lr.index = tempFinal_v1_lr.loc[:,'label-type']\n",
    "tempFinal_v1_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['run_id',\n",
       " 'batch-shuffle',\n",
       " 'batch-size',\n",
       " 'feature-lags',\n",
       " 'featureset',\n",
       " 'l2-penalty',\n",
       " 'l2-type',\n",
       " 'label-type',\n",
       " 'learning-rate',\n",
       " 'loss-from-logits',\n",
       " 'n-epochs',\n",
       " 'pastobs-in-percentage',\n",
       " 'pre-processing',\n",
       " 'id',\n",
       " 'AUC',\n",
       " 'Accuracy',\n",
       " 'Loss',\n",
       " 'Train AUC',\n",
       " 'Train Accuracy',\n",
       " 'Train Loss']"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(combined_table_lr.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp_lr = combined_table_lr[(combined_table_lr.loc[:,'label-type']=='0')&\\\n",
    "                            (combined_table_lr.loc[:,'loss-from-logits']=='1')&\\\n",
    "                            (combined_table_lr.AUC>0.5)]\n",
    "temp_2_lr = pd.pivot_table(temp_lr,\n",
    "                        values='AUC',\n",
    "                        columns='learning-rate',\n",
    "                        index='run_id').reset_index()\n",
    "temp_2_lr.boxplot(list(temp_2_lr.columns[1:]),\n",
    "                  figsize=(7,7))#temp_2.columns[2:]\n",
    "plt.grid(b=None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reading in the market data (done automatically atm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'8'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>spread_open</th>\n",
       "      <th>spread_high</th>\n",
       "      <th>spread_low</th>\n",
       "      <th>spread_close</th>\n",
       "      <th>bidsize_open</th>\n",
       "      <th>bidsize_high</th>\n",
       "      <th>bidsize_low</th>\n",
       "      <th>bidsize_close</th>\n",
       "      <th>ofrsize_open</th>\n",
       "      <th>ofrsize_high</th>\n",
       "      <th>ofrsize_low</th>\n",
       "      <th>ofrsize_close</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>sector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">20200501</th>\n",
       "      <th>0</th>\n",
       "      <td>286.250</td>\n",
       "      <td>289.260</td>\n",
       "      <td>285.870</td>\n",
       "      <td>289.260</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.24</td>\n",
       "      <td>6.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>289.260</td>\n",
       "      <td>289.350</td>\n",
       "      <td>288.365</td>\n",
       "      <td>289.020</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.10</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>289.035</td>\n",
       "      <td>289.705</td>\n",
       "      <td>288.280</td>\n",
       "      <td>288.580</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>288.485</td>\n",
       "      <td>289.315</td>\n",
       "      <td>288.280</td>\n",
       "      <td>289.095</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>289.100</td>\n",
       "      <td>290.435</td>\n",
       "      <td>288.940</td>\n",
       "      <td>290.320</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.10</td>\n",
       "      <td>13.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">20200529</th>\n",
       "      <th>385</th>\n",
       "      <td>91.500</td>\n",
       "      <td>91.755</td>\n",
       "      <td>91.485</td>\n",
       "      <td>91.740</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>XNTK</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>91.740</td>\n",
       "      <td>91.740</td>\n",
       "      <td>91.740</td>\n",
       "      <td>91.740</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>XNTK</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>91.580</td>\n",
       "      <td>91.830</td>\n",
       "      <td>91.580</td>\n",
       "      <td>91.715</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.45</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>XNTK</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>91.595</td>\n",
       "      <td>91.880</td>\n",
       "      <td>91.595</td>\n",
       "      <td>91.750</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.52</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>XNTK</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>46.005</td>\n",
       "      <td>46.005</td>\n",
       "      <td>45.815</td>\n",
       "      <td>45.815</td>\n",
       "      <td>92.01</td>\n",
       "      <td>92.01</td>\n",
       "      <td>91.63</td>\n",
       "      <td>91.63</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>XNTK</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>546000 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 open     high      low    close  spread_open  spread_high  \\\n",
       "20200501 0    286.250  289.260  285.870  289.260         0.50         0.50   \n",
       "         1    289.260  289.350  288.365  289.020         0.24         0.45   \n",
       "         2    289.035  289.705  288.280  288.580         0.07         0.49   \n",
       "         3    288.485  289.315  288.280  289.095         0.49         0.49   \n",
       "         4    289.100  290.435  288.940  290.320         0.16         0.33   \n",
       "...               ...      ...      ...      ...          ...          ...   \n",
       "20200529 385   91.500   91.755   91.485   91.740         0.42         0.93   \n",
       "         386   91.740   91.740   91.740   91.740         0.50         0.50   \n",
       "         387   91.580   91.830   91.580   91.715         0.18         0.68   \n",
       "         388   91.595   91.880   91.595   91.750         0.21         0.78   \n",
       "         389   46.005   46.005   45.815   45.815        92.01        92.01   \n",
       "\n",
       "              spread_low  spread_close  bidsize_open  bidsize_high  \\\n",
       "20200501 0          0.01          0.24           6.0          95.0   \n",
       "         1          0.01          0.10           9.0          20.0   \n",
       "         2          0.01          0.30           1.0          50.0   \n",
       "         3          0.01          0.17           1.0          25.0   \n",
       "         4          0.01          0.10          13.0          71.0   \n",
       "...                  ...           ...           ...           ...   \n",
       "20200529 385        0.39          0.50           5.0           5.0   \n",
       "         386        0.50          0.50           5.0           5.0   \n",
       "         387        0.18          0.45           5.0           5.0   \n",
       "         388        0.21          0.52           5.0           5.0   \n",
       "         389       91.63         91.63           0.0           0.0   \n",
       "\n",
       "              bidsize_low  bidsize_close  ofrsize_open  ofrsize_high  \\\n",
       "20200501 0            1.0           10.0           1.0          85.0   \n",
       "         1            1.0            1.0           4.0          56.0   \n",
       "         2            1.0            1.0           1.0          13.0   \n",
       "         3            1.0           16.0           1.0           8.0   \n",
       "         4            1.0            1.0           1.0         236.0   \n",
       "...                   ...            ...           ...           ...   \n",
       "20200529 385          5.0            5.0           1.0           5.0   \n",
       "         386          5.0            5.0           5.0           5.0   \n",
       "         387          5.0            5.0           1.0           5.0   \n",
       "         388          5.0            5.0           1.0           5.0   \n",
       "         389          0.0            0.0           5.0           5.0   \n",
       "\n",
       "              ofrsize_low  ofrsize_close Ticker      sector  \n",
       "20200501 0            1.0            4.0   AAPL  Technology  \n",
       "         1            1.0            1.0   AAPL  Technology  \n",
       "         2            1.0            1.0   AAPL  Technology  \n",
       "         3            1.0            1.0   AAPL  Technology  \n",
       "         4            1.0            1.0   AAPL  Technology  \n",
       "...                   ...            ...    ...         ...  \n",
       "20200529 385          1.0            5.0   XNTK         NaN  \n",
       "         386          5.0            5.0   XNTK         NaN  \n",
       "         387          1.0            5.0   XNTK         NaN  \n",
       "         388          1.0            5.0   XNTK         NaN  \n",
       "         389          1.0            1.0   XNTK         NaN  \n",
       "\n",
       "[546000 rows x 18 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>spread_open</th>\n",
       "      <th>spread_high</th>\n",
       "      <th>spread_low</th>\n",
       "      <th>spread_close</th>\n",
       "      <th>bidsize_open</th>\n",
       "      <th>bidsize_high</th>\n",
       "      <th>bidsize_low</th>\n",
       "      <th>bidsize_close</th>\n",
       "      <th>ofrsize_open</th>\n",
       "      <th>ofrsize_high</th>\n",
       "      <th>ofrsize_low</th>\n",
       "      <th>ofrsize_close</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>sector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">20200501</th>\n",
       "      <th>0</th>\n",
       "      <td>286.250</td>\n",
       "      <td>289.260</td>\n",
       "      <td>285.870</td>\n",
       "      <td>289.260</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.24</td>\n",
       "      <td>6.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>289.260</td>\n",
       "      <td>289.350</td>\n",
       "      <td>288.365</td>\n",
       "      <td>289.020</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.10</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>289.035</td>\n",
       "      <td>289.705</td>\n",
       "      <td>288.280</td>\n",
       "      <td>288.580</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>288.485</td>\n",
       "      <td>289.315</td>\n",
       "      <td>288.280</td>\n",
       "      <td>289.095</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>289.100</td>\n",
       "      <td>290.435</td>\n",
       "      <td>288.940</td>\n",
       "      <td>290.320</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.10</td>\n",
       "      <td>13.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">20200529</th>\n",
       "      <th>385</th>\n",
       "      <td>91.500</td>\n",
       "      <td>91.755</td>\n",
       "      <td>91.485</td>\n",
       "      <td>91.740</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>XNTK</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>91.740</td>\n",
       "      <td>91.740</td>\n",
       "      <td>91.740</td>\n",
       "      <td>91.740</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>XNTK</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>91.580</td>\n",
       "      <td>91.830</td>\n",
       "      <td>91.580</td>\n",
       "      <td>91.715</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.45</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>XNTK</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>91.595</td>\n",
       "      <td>91.880</td>\n",
       "      <td>91.595</td>\n",
       "      <td>91.750</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.52</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>XNTK</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>46.005</td>\n",
       "      <td>46.005</td>\n",
       "      <td>45.815</td>\n",
       "      <td>45.815</td>\n",
       "      <td>92.01</td>\n",
       "      <td>92.01</td>\n",
       "      <td>91.63</td>\n",
       "      <td>91.63</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>XNTK</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>546000 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 open     high      low    close  spread_open  spread_high  \\\n",
       "20200501 0    286.250  289.260  285.870  289.260         0.50         0.50   \n",
       "         1    289.260  289.350  288.365  289.020         0.24         0.45   \n",
       "         2    289.035  289.705  288.280  288.580         0.07         0.49   \n",
       "         3    288.485  289.315  288.280  289.095         0.49         0.49   \n",
       "         4    289.100  290.435  288.940  290.320         0.16         0.33   \n",
       "...               ...      ...      ...      ...          ...          ...   \n",
       "20200529 385   91.500   91.755   91.485   91.740         0.42         0.93   \n",
       "         386   91.740   91.740   91.740   91.740         0.50         0.50   \n",
       "         387   91.580   91.830   91.580   91.715         0.18         0.68   \n",
       "         388   91.595   91.880   91.595   91.750         0.21         0.78   \n",
       "         389   46.005   46.005   45.815   45.815        92.01        92.01   \n",
       "\n",
       "              spread_low  spread_close  bidsize_open  bidsize_high  \\\n",
       "20200501 0          0.01          0.24           6.0          95.0   \n",
       "         1          0.01          0.10           9.0          20.0   \n",
       "         2          0.01          0.30           1.0          50.0   \n",
       "         3          0.01          0.17           1.0          25.0   \n",
       "         4          0.01          0.10          13.0          71.0   \n",
       "...                  ...           ...           ...           ...   \n",
       "20200529 385        0.39          0.50           5.0           5.0   \n",
       "         386        0.50          0.50           5.0           5.0   \n",
       "         387        0.18          0.45           5.0           5.0   \n",
       "         388        0.21          0.52           5.0           5.0   \n",
       "         389       91.63         91.63           0.0           0.0   \n",
       "\n",
       "              bidsize_low  bidsize_close  ofrsize_open  ofrsize_high  \\\n",
       "20200501 0            1.0           10.0           1.0          85.0   \n",
       "         1            1.0            1.0           4.0          56.0   \n",
       "         2            1.0            1.0           1.0          13.0   \n",
       "         3            1.0           16.0           1.0           8.0   \n",
       "         4            1.0            1.0           1.0         236.0   \n",
       "...                   ...            ...           ...           ...   \n",
       "20200529 385          5.0            5.0           1.0           5.0   \n",
       "         386          5.0            5.0           5.0           5.0   \n",
       "         387          5.0            5.0           1.0           5.0   \n",
       "         388          5.0            5.0           1.0           5.0   \n",
       "         389          0.0            0.0           5.0           5.0   \n",
       "\n",
       "              ofrsize_low  ofrsize_close Ticker      sector  \n",
       "20200501 0            1.0            4.0   AAPL  Technology  \n",
       "         1            1.0            1.0   AAPL  Technology  \n",
       "         2            1.0            1.0   AAPL  Technology  \n",
       "         3            1.0            1.0   AAPL  Technology  \n",
       "         4            1.0            1.0   AAPL  Technology  \n",
       "...                   ...            ...    ...         ...  \n",
       "20200529 385          1.0            5.0   XNTK         NaN  \n",
       "         386          5.0            5.0   XNTK         NaN  \n",
       "         387          1.0            5.0   XNTK         NaN  \n",
       "         388          1.0            5.0   XNTK         NaN  \n",
       "         389          1.0            1.0   XNTK         NaN  \n",
       "\n",
       "[546000 rows x 18 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['open', 'high', 'low', 'close', 'spread_open', 'spread_high',\n",
       "       'spread_low', 'spread_close', 'bidsize_open', 'bidsize_high',\n",
       "       'bidsize_low', 'bidsize_close', 'ofrsize_open', 'ofrsize_high',\n",
       "       'ofrsize_low', 'ofrsize_close', 'Ticker', 'sector'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping ETFS and market indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AAPL', 'ABBV', 'ABT', 'AEP', 'AMT', 'APD', 'BA', 'BABA', 'BAC',\n",
       "       'BHP', 'BP', 'CCI', 'CHL', 'COST', 'CSGP', 'D', 'DIS', 'ECL',\n",
       "       'ENB', 'EXC', 'FB', 'FMX', 'GOOG', 'IDU', 'INTC', 'IYC', 'IYE',\n",
       "       'IYG', 'IYH', 'IYJ', 'IYK', 'IYM', 'IYR', 'IYW', 'IYZ', 'JNJ',\n",
       "       'KO', 'LFC', 'LIN', 'LMT', 'MA', 'MCD', 'MSFT', 'NKE', 'NVDA',\n",
       "       'NVS', 'PBR', 'PEP', 'PFE', 'PLD', 'PSA', 'PTR', 'PYPL', 'RTX',\n",
       "       'SHW', 'SNP', 'SO', 'SRE', 'T', 'TM', 'TSLA', 'TSM', 'UNP', 'UPS',\n",
       "       'V', 'WMT', 'DIA', 'QQQ', 'SPY', 'XNTK'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Ticker.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the XNTK ticker\n",
    "data = data[~data.Ticker.isin(['XNTK'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AAPL', 'ABBV', 'ABT', 'AEP', 'AMT', 'APD', 'BA', 'BABA', 'BAC',\n",
       "       'BHP', 'BP', 'CCI', 'CHL', 'COST', 'CSGP', 'D', 'DIS', 'ECL',\n",
       "       'ENB', 'EXC', 'FB', 'FMX', 'GOOG', 'IDU', 'INTC', 'IYC', 'IYE',\n",
       "       'IYG', 'IYH', 'IYJ', 'IYK', 'IYM', 'IYR', 'IYW', 'IYZ', 'JNJ',\n",
       "       'KO', 'LFC', 'LIN', 'LMT', 'MA', 'MCD', 'MSFT', 'NKE', 'NVDA',\n",
       "       'NVS', 'PBR', 'PEP', 'PFE', 'PLD', 'PSA', 'PTR', 'PYPL', 'RTX',\n",
       "       'SHW', 'SNP', 'SO', 'SRE', 'T', 'TM', 'TSLA', 'TSM', 'UNP', 'UPS',\n",
       "       'V', 'WMT', 'DIA', 'QQQ', 'SPY'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Ticker.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the XNTK ticker\n",
    "data = data[~data.Ticker.isin(['XNTK'])]\n",
    "\n",
    "etfs = ['IYH','IYM','IYK','IYJ','IYG','IYW','IYC','IYR','IDU','IYZ','IYE','IYF','SPY','DIA','QQQ']\n",
    "\n",
    "# Extracting the sector ETFs to a separate variable\n",
    "sectorETFS = data[data.Ticker.isin(etfs)]\n",
    "\n",
    "# Removing the ETFs\n",
    "data = data[~data.Ticker.isin(etfs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['open', 'high', 'low', 'close', 'spread_open', 'spread_high',\n",
       "       'spread_low', 'spread_close', 'bidsize_open', 'bidsize_high',\n",
       "       'bidsize_low', 'bidsize_close', 'ofrsize_open', 'ofrsize_high',\n",
       "       'ofrsize_low', 'ofrsize_close', 'Ticker', 'sector'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>spread_open</th>\n",
       "      <th>spread_high</th>\n",
       "      <th>spread_low</th>\n",
       "      <th>spread_close</th>\n",
       "      <th>bidsize_open</th>\n",
       "      <th>bidsize_high</th>\n",
       "      <th>bidsize_low</th>\n",
       "      <th>bidsize_close</th>\n",
       "      <th>ofrsize_open</th>\n",
       "      <th>ofrsize_high</th>\n",
       "      <th>ofrsize_low</th>\n",
       "      <th>ofrsize_close</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>sector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">20200501</th>\n",
       "      <th>0</th>\n",
       "      <td>286.250</td>\n",
       "      <td>289.260</td>\n",
       "      <td>285.870</td>\n",
       "      <td>289.260</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.24</td>\n",
       "      <td>6.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>289.260</td>\n",
       "      <td>289.350</td>\n",
       "      <td>288.365</td>\n",
       "      <td>289.020</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.10</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>289.035</td>\n",
       "      <td>289.705</td>\n",
       "      <td>288.280</td>\n",
       "      <td>288.580</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>288.485</td>\n",
       "      <td>289.315</td>\n",
       "      <td>288.280</td>\n",
       "      <td>289.095</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>289.100</td>\n",
       "      <td>290.435</td>\n",
       "      <td>288.940</td>\n",
       "      <td>290.320</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.10</td>\n",
       "      <td>13.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">20200529</th>\n",
       "      <th>385</th>\n",
       "      <td>123.950</td>\n",
       "      <td>124.110</td>\n",
       "      <td>123.910</td>\n",
       "      <td>124.100</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WMT</td>\n",
       "      <td>Consumer Defensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>124.085</td>\n",
       "      <td>124.085</td>\n",
       "      <td>123.920</td>\n",
       "      <td>123.995</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>WMT</td>\n",
       "      <td>Consumer Defensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>123.995</td>\n",
       "      <td>124.355</td>\n",
       "      <td>123.985</td>\n",
       "      <td>124.335</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.05</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>WMT</td>\n",
       "      <td>Consumer Defensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>124.335</td>\n",
       "      <td>124.355</td>\n",
       "      <td>124.060</td>\n",
       "      <td>124.075</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>WMT</td>\n",
       "      <td>Consumer Defensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>124.075</td>\n",
       "      <td>124.225</td>\n",
       "      <td>122.810</td>\n",
       "      <td>123.855</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.43</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.21</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WMT</td>\n",
       "      <td>Consumer Defensive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>429000 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 open     high      low    close  spread_open  spread_high  \\\n",
       "20200501 0    286.250  289.260  285.870  289.260         0.50         0.50   \n",
       "         1    289.260  289.350  288.365  289.020         0.24         0.45   \n",
       "         2    289.035  289.705  288.280  288.580         0.07         0.49   \n",
       "         3    288.485  289.315  288.280  289.095         0.49         0.49   \n",
       "         4    289.100  290.435  288.940  290.320         0.16         0.33   \n",
       "...               ...      ...      ...      ...          ...          ...   \n",
       "20200529 385  123.950  124.110  123.910  124.100         0.02         0.07   \n",
       "         386  124.085  124.085  123.920  123.995         0.01         0.06   \n",
       "         387  123.995  124.355  123.985  124.335         0.01         0.07   \n",
       "         388  124.335  124.355  124.060  124.075         0.05         0.12   \n",
       "         389  124.075  124.225  122.810  123.855         0.01         2.43   \n",
       "\n",
       "              spread_low  spread_close  bidsize_open  bidsize_high  \\\n",
       "20200501 0          0.01          0.24           6.0          95.0   \n",
       "         1          0.01          0.10           9.0          20.0   \n",
       "         2          0.01          0.30           1.0          50.0   \n",
       "         3          0.01          0.17           1.0          25.0   \n",
       "         4          0.01          0.10          13.0          71.0   \n",
       "...                  ...           ...           ...           ...   \n",
       "20200529 385        0.01          0.04           1.0          11.0   \n",
       "         386        0.01          0.01           1.0           8.0   \n",
       "         387        0.01          0.05           4.0          16.0   \n",
       "         388        0.01          0.01           3.0           6.0   \n",
       "         389        0.01          0.21           1.0          20.0   \n",
       "\n",
       "              bidsize_low  bidsize_close  ofrsize_open  ofrsize_high  \\\n",
       "20200501 0            1.0           10.0           1.0          85.0   \n",
       "         1            1.0            1.0           4.0          56.0   \n",
       "         2            1.0            1.0           1.0          13.0   \n",
       "         3            1.0           16.0           1.0           8.0   \n",
       "         4            1.0            1.0           1.0         236.0   \n",
       "...                   ...            ...           ...           ...   \n",
       "20200529 385          1.0            1.0           5.0           9.0   \n",
       "         386          1.0            3.0           1.0           9.0   \n",
       "         387          1.0            2.0           2.0          10.0   \n",
       "         388          1.0            2.0           2.0          10.0   \n",
       "         389          1.0            2.0           4.0          12.0   \n",
       "\n",
       "              ofrsize_low  ofrsize_close Ticker              sector  \n",
       "20200501 0            1.0            4.0   AAPL          Technology  \n",
       "         1            1.0            1.0   AAPL          Technology  \n",
       "         2            1.0            1.0   AAPL          Technology  \n",
       "         3            1.0            1.0   AAPL          Technology  \n",
       "         4            1.0            1.0   AAPL          Technology  \n",
       "...                   ...            ...    ...                 ...  \n",
       "20200529 385          1.0            1.0    WMT  Consumer Defensive  \n",
       "         386          1.0            2.0    WMT  Consumer Defensive  \n",
       "         387          1.0            2.0    WMT  Consumer Defensive  \n",
       "         388          1.0            4.0    WMT  Consumer Defensive  \n",
       "         389          1.0            1.0    WMT  Consumer Defensive  \n",
       "\n",
       "[429000 rows x 18 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:MainThread:numexpr.utils:NumExpr defaulting to 4 threads.\n",
      "C:\\Users\\PC\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:844: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "C:\\Users\\PC\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:965: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAPL done\n",
      "ABBV done\n",
      "ABT done\n",
      "AEP done\n",
      "AMT done\n",
      "APD done\n",
      "BA done\n",
      "BABA done\n",
      "BAC done\n",
      "BHP done\n",
      "BP done\n",
      "CCI done\n",
      "CHL done\n",
      "COST done\n",
      "CSGP done\n",
      "D done\n",
      "DIS done\n",
      "ECL done\n",
      "ENB done\n",
      "EXC done\n",
      "FB done\n",
      "FMX done\n",
      "GOOG done\n",
      "INTC done\n",
      "JNJ done\n",
      "KO done\n",
      "LFC done\n",
      "LIN done\n",
      "LMT done\n",
      "MA done\n",
      "MCD done\n",
      "MSFT done\n",
      "NKE done\n",
      "NVDA done\n",
      "NVS done\n",
      "Number of NaNs in label: 1. 1 is expected\n",
      "Returns that lead to NaNs in label: [0.0907158]\n",
      "PBR done\n",
      "PEP done\n",
      "PFE done\n",
      "PLD done\n",
      "PSA done\n",
      "PTR done\n",
      "PYPL done\n",
      "RTX done\n",
      "SHW done\n",
      "SNP done\n",
      "SO done\n",
      "SRE done\n",
      "T done\n",
      "TM done\n",
      "TSLA done\n",
      "TSM done\n",
      "UNP done\n",
      "UPS done\n",
      "V done\n",
      "WMT done\n"
     ]
    }
   ],
   "source": [
    "########### Generate Features ################\n",
    "\n",
    "n_feature_lags = 1\n",
    "\n",
    "# features = generateFeatures_multi_final(data = data, \n",
    "#                                   listOfFeatures = [\n",
    "#                                                     'pastobs',\n",
    "#                                                     'spread',\n",
    "#                                                     'bidsize',\n",
    "#                                                     'ofrsize',\n",
    "# #                                                     'stok',\n",
    "# #                                                     'stod',\n",
    "# #                                                     'sstod',\n",
    "# #                                                     'wilr',\n",
    "# #                                                     'roc',\n",
    "# #                                                     'rsi',\n",
    "# #                                                     'atr',\n",
    "# #                                                     'cci',\n",
    "# #                                                     'dpo',\n",
    "# #                                                     'sma',\n",
    "# #                                                     'ema',\n",
    "# #                                                     'macd',\n",
    "# #                                                       'macd_diff',\n",
    "# #                                                       'macd_signal',\n",
    "# #                                                     'dis5',\n",
    "# #                                                     'dis10',\n",
    "#                                                       'sector'\n",
    "#                                                    ], \n",
    "#                                    feature_lags = n_feature_lags\n",
    "#                                      ,stockTable=stockTable)\n",
    "features = generateFeatures_multi_final(data = data, \n",
    "                                  listOfFeatures = [\n",
    "                                                    'pastobs',\n",
    "                                                    'spread',\n",
    "                                                    'bidsize',\n",
    "                                                    'ofrsize',\n",
    "                                                    'stok',\n",
    "                                                    'stod',\n",
    "                                                    'sstod',\n",
    "#                                                     'wilr',\n",
    "                                                    'roc',\n",
    "                                                    'rsi',\n",
    "                                                    'atr',\n",
    "                                                    'cci',\n",
    "                                                    'dpo',\n",
    "                                                    'sma',\n",
    "                                                    'ema',\n",
    "                                                    'macd',\n",
    "                                                      'macd_diff',\n",
    "                                                      'macd_signal',\n",
    "                                                    'dis5',\n",
    "                                                    'dis10',\n",
    "                                                      'sector'\n",
    "                                                   ], \n",
    "                                   feature_lags = n_feature_lags\n",
    "                                     ,sectorETFS=sectorETFS)\n",
    "\n",
    "########### Generate Labels ################\n",
    "\n",
    "n_classes = 2\n",
    "# extract first 4 columns as the lag0 or raw OHLC prices (used for labelling)\n",
    "price_candles = data[['open','high','low','close','Ticker']]\n",
    "\n",
    "########### Align Data ################\n",
    "\n",
    "# from imported function (see testing_preprocessing_features_and_labels.ipynb for thorough experimenting with all the cut-offs):    \n",
    "X, y,indices = align_features_and_labels_multi_final(price_candles = price_candles, \n",
    "                                                 all_features = features,\n",
    "                                                 prediction_horizon = 1, \n",
    "                                                 n_feature_lags = n_feature_lags, \n",
    "                                                 n_classes = n_classes, # 5,\n",
    "                                                 safe_burn_in = False, \n",
    "                                                 data_sample = 'full',\n",
    "                                                 splitType='global',\n",
    "                                                 noise=False,ticker_dummies=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding ticker dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Adding ticker dummies\n",
    "tickers = X.pop('ticker')\n",
    "X = pd.concat([X, pd.get_dummies(tickers, prefix='ticker', drop_first=False)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['open_lag0', 'high_lag0', 'low_lag0', 'close_lag0', 'spread_open_lag0',\n",
       "       'spread_high_lag0', 'spread_low_lag0', 'spread_close_lag0',\n",
       "       'bidsize_open_lag0', 'bidsize_high_lag0',\n",
       "       ...\n",
       "       'ticker_SO', 'ticker_SRE', 'ticker_T', 'ticker_TM', 'ticker_TSLA',\n",
       "       'ticker_TSM', 'ticker_UNP', 'ticker_UPS', 'ticker_V', 'ticker_WMT'],\n",
       "      dtype='object', length=156)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing our final train/validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(341385, 156)\n",
      "(341385, 1)\n",
      "(85690, 156)\n",
      "(85690, 1)\n"
     ]
    }
   ],
   "source": [
    "# train_ds = pd.concat([X.iloc[start:end, :] for (start, end) in train_ranges]).reset_index(drop=True)\n",
    "# train_y = pd.concat([y.iloc[start:end] for (start, end) in train_ranges]).reset_index(drop=True)\n",
    "\n",
    "# validate_ds = pd.concat([X.iloc[start:end, :] for (start, end) in val_ranges]).reset_index(drop=True)\n",
    "# val_y = pd.concat([y.iloc[start:end] for (start, end) in val_ranges]).reset_index(drop=True)\n",
    "\n",
    "# train_ds.shape, train_y.shape, validate_ds.shape, val_y.shape, train_y.shape[0] + val_y.shape[0]\n",
    "\n",
    "# Let's have a proper split (along tickers & dates)\n",
    "train_size = 0.8\n",
    "\n",
    "# Sort the indices\n",
    "tempIndices = indices.sort_values(['days','timestamps','ticker'])\n",
    "\n",
    "# Sorting the data\n",
    "X = X.loc[tempIndices.index,:]#.head(66)\n",
    "y = y.loc[tempIndices.index,:]\n",
    "\n",
    "# extracting the first date for the validation data.\n",
    "first_val_day = int(np.floor(indices.days.unique().shape[0]*0.8))\n",
    "\n",
    "# Splitting the data\n",
    "X_train = X[tempIndices.days<tempIndices.days.unique()[first_val_day]].reset_index(drop=True)\n",
    "y_train = y[tempIndices.days<tempIndices.days.unique()[first_val_day]].reset_index(drop=True)\n",
    "\n",
    "X_test = X[tempIndices.days>=tempIndices.days.unique()[first_val_day]].reset_index(drop=True)\n",
    "y_test = y[tempIndices.days>=tempIndices.days.unique()[first_val_day]].reset_index(drop=True)\n",
    "\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open_lag0</th>\n",
       "      <th>high_lag0</th>\n",
       "      <th>low_lag0</th>\n",
       "      <th>close_lag0</th>\n",
       "      <th>spread_open_lag0</th>\n",
       "      <th>spread_high_lag0</th>\n",
       "      <th>spread_low_lag0</th>\n",
       "      <th>spread_close_lag0</th>\n",
       "      <th>bidsize_open_lag0</th>\n",
       "      <th>bidsize_high_lag0</th>\n",
       "      <th>...</th>\n",
       "      <th>ticker_SO</th>\n",
       "      <th>ticker_SRE</th>\n",
       "      <th>ticker_T</th>\n",
       "      <th>ticker_TM</th>\n",
       "      <th>ticker_TSLA</th>\n",
       "      <th>ticker_TSM</th>\n",
       "      <th>ticker_UNP</th>\n",
       "      <th>ticker_UPS</th>\n",
       "      <th>ticker_V</th>\n",
       "      <th>ticker_WMT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.545</td>\n",
       "      <td>0.205</td>\n",
       "      <td>-0.635</td>\n",
       "      <td>296.440</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.200</td>\n",
       "      <td>0.040</td>\n",
       "      <td>-0.255</td>\n",
       "      <td>82.805</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.030</td>\n",
       "      <td>-0.040</td>\n",
       "      <td>90.855</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.100</td>\n",
       "      <td>0.140</td>\n",
       "      <td>-0.110</td>\n",
       "      <td>81.510</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.070</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>234.230</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341380</th>\n",
       "      <td>0.035</td>\n",
       "      <td>0.165</td>\n",
       "      <td>-0.040</td>\n",
       "      <td>51.300</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>5.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341381</th>\n",
       "      <td>0.890</td>\n",
       "      <td>0.965</td>\n",
       "      <td>-0.290</td>\n",
       "      <td>169.435</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1.41</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341382</th>\n",
       "      <td>0.105</td>\n",
       "      <td>0.235</td>\n",
       "      <td>-0.465</td>\n",
       "      <td>97.955</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1.32</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341383</th>\n",
       "      <td>-0.080</td>\n",
       "      <td>0.540</td>\n",
       "      <td>-0.245</td>\n",
       "      <td>195.705</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.08</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341384</th>\n",
       "      <td>-0.560</td>\n",
       "      <td>0.055</td>\n",
       "      <td>-0.605</td>\n",
       "      <td>125.185</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.11</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>341385 rows × 156 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        open_lag0  high_lag0  low_lag0  close_lag0  spread_open_lag0  \\\n",
       "0          -0.545      0.205    -0.635     296.440              0.09   \n",
       "1          -0.200      0.040    -0.255      82.805              0.21   \n",
       "2           0.000      0.030    -0.040      90.855              0.07   \n",
       "3           0.100      0.140    -0.110      81.510              0.06   \n",
       "4           0.010      0.070    -0.045     234.230              0.26   \n",
       "...           ...        ...       ...         ...               ...   \n",
       "341380      0.035      0.165    -0.040      51.300              0.17   \n",
       "341381      0.890      0.965    -0.290     169.435              0.35   \n",
       "341382      0.105      0.235    -0.465      97.955              0.86   \n",
       "341383     -0.080      0.540    -0.245     195.705              0.75   \n",
       "341384     -0.560      0.055    -0.605     125.185              1.25   \n",
       "\n",
       "        spread_high_lag0  spread_low_lag0  spread_close_lag0  \\\n",
       "0                   0.20             0.01               0.06   \n",
       "1                   0.26             0.01               0.07   \n",
       "2                   0.10             0.01               0.09   \n",
       "3                   0.25             0.03               0.16   \n",
       "4                   0.30             0.11               0.18   \n",
       "...                  ...              ...                ...   \n",
       "341380              0.26             0.01               0.02   \n",
       "341381              1.41             0.01               0.93   \n",
       "341382              1.32             0.06               0.15   \n",
       "341383              1.08             0.01               0.07   \n",
       "341384              1.25             0.01               0.11   \n",
       "\n",
       "        bidsize_open_lag0  bidsize_high_lag0  ...  ticker_SO  ticker_SRE  \\\n",
       "0                     1.0               12.0  ...          0           0   \n",
       "1                     1.0                8.0  ...          0           0   \n",
       "2                     1.0                4.0  ...          0           0   \n",
       "3                     1.0                9.0  ...          0           0   \n",
       "4                     1.0                3.0  ...          0           0   \n",
       "...                   ...                ...  ...        ...         ...   \n",
       "341380                5.0               23.0  ...          0           0   \n",
       "341381                1.0               10.0  ...          0           0   \n",
       "341382                1.0                6.0  ...          0           0   \n",
       "341383                1.0                4.0  ...          0           0   \n",
       "341384                2.0                4.0  ...          0           0   \n",
       "\n",
       "        ticker_T  ticker_TM  ticker_TSLA  ticker_TSM  ticker_UNP  ticker_UPS  \\\n",
       "0              0          0            0           0           0           0   \n",
       "1              0          0            0           0           0           0   \n",
       "2              0          0            0           0           0           0   \n",
       "3              0          0            0           0           0           0   \n",
       "4              0          0            0           0           0           0   \n",
       "...          ...        ...          ...         ...         ...         ...   \n",
       "341380         0          0            0           1           0           0   \n",
       "341381         0          0            0           0           1           0   \n",
       "341382         0          0            0           0           0           1   \n",
       "341383         0          0            0           0           0           0   \n",
       "341384         0          0            0           0           0           0   \n",
       "\n",
       "        ticker_V  ticker_WMT  \n",
       "0              0           0  \n",
       "1              0           0  \n",
       "2              0           0  \n",
       "3              0           0  \n",
       "4              0           0  \n",
       "...          ...         ...  \n",
       "341380         0           0  \n",
       "341381         0           0  \n",
       "341382         0           0  \n",
       "341383         1           0  \n",
       "341384         0           1  \n",
       "\n",
       "[341385 rows x 156 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64),)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where((np.sum(np.isinf(X_train.values), axis=1) == 0) == False),\n",
    "np.where((np.sum(np.isnan(X_train.values), axis=1) == 0) == False)#X_train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{i:colname for i,colname in enumerate(train_ds.columns)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating one ppdict for individual preprocessings\n",
    "# ppdict1 = {'open':'minmax',\n",
    "#           'high':'log',\n",
    "#           'low':'log',\n",
    "#           'close':'std'}\n",
    "# splitpoint = 32\n",
    "\n",
    "# # Standardize some features\n",
    "# ppdict1 = {i:'std' for i in train_ds.columns[0:splitpoint]} \n",
    "# # Keep some in actual levels (Dummies in this case).\n",
    "# ppdict2 = {i:'act' for i in train_ds.columns[splitpoint:]}\n",
    "\n",
    "pre_procesing_applied = 'std'\n",
    "\n",
    "# Merging the two\n",
    "# ppdict = {**ppdict1,**ppdict2}\n",
    "\n",
    "if  pre_procesing_applied == 'None':\n",
    "    # do nothing here\n",
    "    pass\n",
    "\n",
    "elif  pre_procesing_applied == 'std':\n",
    "\n",
    "    # splitpoint = int((args.feature-lags+1)*16)#32\n",
    "    # columns_to_pre_process = [col for col in X_train.columns if 'd_' != col[0:2]]\n",
    "\n",
    "    # Standardize some features\n",
    "    ppdict1 = {i:'std' for i in X_train.columns if 'd_' != i[0:2]} \n",
    "    # Keep some in actual levels (Dummies in this case).\n",
    "    ppdict2 = {i:'act' for i in X_train.columns if 'd_' == i[0:2]} \n",
    "\n",
    "    # Merging the two\n",
    "    ppdict = {**ppdict1,**ppdict2}\n",
    "\n",
    "    # x_train,x_test = pre_processing(x_train,x_test,pp_dict)\n",
    "\n",
    "elif pre_procesing_applied == 'minmax':\n",
    "\n",
    "    # splitpoint = int((args.feature-lags+1)*16)#32\n",
    "    # columns_to_pre_process = [col for col in X_train.columns if 'd_' != col[0:2]]\n",
    "\n",
    "    # Standardize some features\n",
    "    ppdict1 = {i:'minmax' for i in X_train.columns if 'd_' != i[0:2]} \n",
    "    # Keep some in actual levels (Dummies in this case).\n",
    "    ppdict2 = {i:'act' for i in X_train.columns if 'd_' == i[0:2]} \n",
    "\n",
    "    # Merging the two\n",
    "    ppdict = {**ppdict1,**ppdict2}\n",
    "\n",
    "    # x_train,x_test = pre_processing(X_train,X_test,pp_dict)\n",
    "\n",
    "elif pre_procesing_applied == 'pow':\n",
    "\n",
    "    # splitpoint = int((args.feature-lags+1)*16)#32\n",
    "    # columns_to_pre_process = [col for col in X_train.columns if 'd_' != col[0:2]]\n",
    "\n",
    "    # Standardize some features\n",
    "    ppdict1 = {i:'pow' for i in X_train.columns if 'd_' != i[0:2]} \n",
    "    # Keep some in actual levels (Dummies in this case).\n",
    "    ppdict2 = {i:'act' for i in X_train.columns if 'd_' == i[0:2]} \n",
    "\n",
    "    # Merging the two\n",
    "    ppdict = {**ppdict1,**ppdict2}\n",
    "\n",
    "    # x_train,x_test = pre_processing(x_train,x_test,pp_dict)\n",
    "\n",
    "elif pre_procesing_applied == 'quantgau':\n",
    "\n",
    "    # splitpoint = int((args.feature-lags+1)*16)#32\n",
    "    # columns_to_pre_process = [col for col in X_train.columns if 'd_' != col[0:2]]\n",
    "\n",
    "    # Standardize some features\n",
    "    ppdict1 = {i:'quantgau' for i in X_train.columns if 'd_' != i[0:2]} \n",
    "    # Keep some in actual levels (Dummies in this case).\n",
    "    ppdict2 = {i:'act' for i in X_train.columns if 'd_' == i[0:2]} \n",
    "\n",
    "    # Merging the two\n",
    "    ppdict = {**ppdict1,**ppdict2}\n",
    "\n",
    "    # x_train,x_test = pre_processing(x_train,x_test,pp_dict)\n",
    "\n",
    "elif pre_procesing_applied == 'individual':\n",
    "\n",
    "    # splitpoint = int((args.feature-lags+1)*16)#32\n",
    "    # columns_to_pre_process = [col for col in X_train.columns if 'd_' != col[0:2]]\n",
    "\n",
    "    # Standardize some features\n",
    "    \n",
    "    # ppdict1 = {i:'power' for i in X_train.columns if 'd_' != i[0:2]}\n",
    "\n",
    "\n",
    "    # Keep some in actual levels (Dummies in this case).\n",
    "    ppdict2 = {i:'act' for i in X_train.columns if 'd_' == i[0:2]} \n",
    "\n",
    "    # Merging the two\n",
    "    ppdict = {**ppdict1,**ppdict2}\n",
    "\n",
    "    # x_train,x_test = pre_processing(x_train,x_test,pp_dict)\n",
    "\n",
    "elif pre_procesing_applied == 'stacked':\n",
    "\n",
    "    # splitpoint = int((args.feature-lags+1)*16)#32\n",
    "    # columns_to_pre_process = [col for col in X_train.columns if 'd_' != col[0:2]]\n",
    "\n",
    "    # Standardize some features\n",
    "    \n",
    "    for j in ['pow','std','minmax']:\n",
    "\n",
    "        ppdict1 = {i:j for i in X_train.columns if 'd_' != i[0:2]}\n",
    "\n",
    "        # Keep some in actual levels (Dummies in this case).\n",
    "        ppdict2 = {i:'act' for i in X_train.columns if 'd_' == i[0:2]} \n",
    "\n",
    "        # Merging the two\n",
    "        ppdict = {**ppdict1,**ppdict2}\n",
    "\n",
    "        X_train,X_test = pre_processing(X_train,X_test,ppdict)\n",
    "\n",
    "if pre_procesing_applied not in ['None','stacked']:\n",
    "    X_train,X_test = pre_processing(X_train,X_test,ppdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1.8927265537610815e-16, 1.000001457346533)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppX_train.iloc[:,0].mean(),ppX_train.iloc[:,0].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepping for models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(343090, 85800, 428890, 1340, 131, 670000)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_VALIDATION = val_y.shape[0] #int(1e3)\n",
    "N_TRAIN = train_y.shape[0] #int(1e4)\n",
    "# BUFFER_SIZE = int(1e4)\n",
    "BATCH_SIZE = 256 #512 #32\n",
    "MAX_EPOCHS = 500\n",
    "\n",
    "STEPS_PER_EPOCH = N_TRAIN//BATCH_SIZE\n",
    "\n",
    "N_REPEAT = int(N_TRAIN / ((STEPS_PER_EPOCH * MAX_EPOCHS) / BATCH_SIZE))\n",
    "FEATURES = X.shape[1]\n",
    "\n",
    "N_TRAIN, N_VALIDATION, N_TRAIN + N_VALIDATION, STEPS_PER_EPOCH, N_REPEAT, STEPS_PER_EPOCH * MAX_EPOCHS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Logistic Regression model in TF/Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 1)                 99        \n",
      "=================================================================\n",
      "Total params: 99\n",
      "Trainable params: 99\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:MainThread:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.390774). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0, accuracy:0.5352,  auc:0.5034,  loss:0.8996,  val_accuracy:0.5456,  val_auc:0.5453,  val_loss:0.6876,  \n",
      "....................................................................................................\n",
      "Epoch: 100, accuracy:0.5480,  auc:0.5440,  loss:0.6873,  val_accuracy:0.5454,  val_auc:0.5459,  val_loss:0.6879,  \n",
      "..................Restoring model weights from the end of the best epoch.\n",
      "Epoch 00118: early stopping\n"
     ]
    }
   ],
   "source": [
    "METRICS = [\n",
    "      #keras.metrics.TruePositives(name='tp'),\n",
    "      #keras.metrics.FalsePositives(name='fp'),\n",
    "      #keras.metrics.TrueNegatives(name='tn'),\n",
    "      #keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      #keras.metrics.Precision(name='precision'),\n",
    "      #keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "]\n",
    "\n",
    "# def make_model(metrics = METRICS, output_bias=None):\n",
    "#   if output_bias is not None:\n",
    "#     output_bias = tf.keras.initializers.Constant(output_bias)\n",
    "#   model = keras.Sequential([\n",
    "#       keras.layers.Dense(\n",
    "#           16, activation='relu',\n",
    "#           input_shape=(train_features.shape[-1],)),\n",
    "#       keras.layers.Dropout(0.5),\n",
    "#       keras.layers.Dense(1, activation='sigmoid',\n",
    "#                          bias_initializer=output_bias),\n",
    "#   ])\n",
    "\n",
    "#   model.compile(\n",
    "#       optimizer=keras.optimizers.Adam(lr=1e-3),\n",
    "#       loss=keras.losses.BinaryCrossentropy(),\n",
    "#       metrics=metrics)\n",
    "\n",
    "#   return model\n",
    "\n",
    "# model = keras.Sequential({\n",
    "#   keras.layers.Dense(1, input_shape=(FEATURES,))\n",
    "# })\n",
    "\n",
    "model = keras.Sequential([\n",
    "#     keras.layers.Flatten(input_shape=(28, 28)),\n",
    "#     keras.layers.Dense(128, activation='relu'),\n",
    "#     keras.layers.Dense(10)\n",
    "    keras.layers.Dense(1,\n",
    "                       input_shape=(FEATURES,),\n",
    "                       activation='sigmoid',\n",
    "                       kernel_regularizer=regularizers.l2(1))\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# with final activation (Keras/TF tutorial advises against this practice, but they also use it later in the tutorial)\n",
    "# model = keras.Sequential({\n",
    "#   keras.layers.Dense(1, input_shape=(FEATURES,), activation='sigmoid')\n",
    "# })\n",
    "\n",
    "#model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['binary_accuracy', ])\n",
    "model.compile(\n",
    "              optimizer=keras.optimizers.Adam(), #lr=1e-3\n",
    "              loss=keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "              metrics=METRICS)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "                                                monitor='val_auc', \n",
    "                                                verbose=1,\n",
    "                                                patience=100,\n",
    "                                                mode='max',\n",
    "                                                restore_best_weights=True)\n",
    "\n",
    "def get_callbacks(run_id):\n",
    "      return [\n",
    "             tfdocs.modeling.EpochDots(),\n",
    "             early_stopping,\n",
    "             tf.keras.callbacks.TensorBoard(logdir), #/run_id),\n",
    "      ]\n",
    "\n",
    "baseline_history = model.fit(\n",
    "                            train_ds, #train_features,\n",
    "                            train_y, #train_labels,\n",
    "                            batch_size=512, #BATCH_SIZE,\n",
    "                            epochs=1000, #EPOCHS,\n",
    "                            callbacks = get_callbacks(run_id = 'first'), #[early_stopping],\n",
    "                            validation_data=(validate_ds, val_y),\n",
    "                            verbose=0) #(val_features, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2682/2682 - 6s - loss: 0.6879 - accuracy: 0.5457 - auc: 0.5513\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6878659725189209, 0.5456876754760742, 0.5513222217559814]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(validate_ds,  val_y, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Timed out waiting for TensorBoard to start. It may still be running as pid 9296."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datetime\n",
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
