{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD:test/Testing_Area_Extract_Azure_output_FRST_18oct.ipynb
<<<<<<< HEAD:test/Testing_Area_Extract_Azure_output_FRST_18oct.ipynb
<<<<<<< HEAD:test/Testing_Area_Extract_Azure_output_FRST_18oct.ipynb
      "C:\\Users\\fstri\\AppData\\Local\\Temp\\tmp6ud5cyb1\\tensorboard_logs\n"
=======
      "C:\\Users\\PC\\AppData\\Local\\Temp\\tmp2jialnko\\tensorboard_logs\n"
>>>>>>> bb1b39ac2361ae9f0c2e82b5fd08edc8af96cf75:test/Testing_Area_Extract_Azure_output.ipynb
=======
      "C:\\Users\\PC\\AppData\\Local\\Temp\\tmpu7galeer\\tensorboard_logs\n"
>>>>>>> KLN_working_branch:test/Testing_Area_Extract_Azure_output.ipynb
=======
      "C:\\Users\\PC\\AppData\\Local\\Temp\\tmp1meo83a6\\tensorboard_logs\n"
>>>>>>> KLN_working_branch:test/Testing_Area_Extract_Azure_output.ipynb
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "import h5py\n",
    "import copy\n",
    "import datetime\n",
    "import ta\n",
    "import pathlib\n",
    "import shutil\n",
    "import tempfile\n",
    "#import vaex\n",
    "from IPython import display\n",
    "from IPython.display import clear_output\n",
    "import pyodbc\n",
    "\n",
    "# Tensorflow related\n",
    "# import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "\n",
    "# from tensorflow.keras import layers\n",
    "# from tensorflow.keras import regularizers\n",
    "# import tensorflow.compat.v2.feature_column as fc\n",
    "\n",
    "# #!pip install -q git+https://github.com/tensorflow/docs\n",
    "\n",
    "# import tensorflow_docs as tfdocs\n",
    "# import tensorflow_docs.modeling\n",
    "# import tensorflow_docs.plots\n",
    "\n",
    "#print(tf.__version__)\n",
    "logdir = pathlib.Path(tempfile.mkdtemp())/\"tensorboard_logs\"\n",
    "shutil.rmtree(logdir, ignore_errors=True)\n",
    "print(logdir)\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, f1_score, log_loss\n",
    "\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.exceptions import ConvergenceWarning \n",
    "from sklearn import ensemble\n",
    "# ConvergenceWarning('ignore')\n",
    "# Do you wanna see?\n",
    "verbose = True\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "#sys.path.append('...../')\n",
    "\n",
    "from utils.data_extraction import load_data_final,load_data_and_save\n",
    "from utils.data_cleaning import HFDataCleaning\n",
    "from utils.generate_features import candleCreateNP_vect_final,\\\n",
    "                                    generateFeatures_final,\\\n",
    "                                    generateFeatures_multi_final\n",
    "\n",
    "from utils.preprocessing_features_and_labels import extract_labels,\\\n",
    "                                                    align_features_and_labels,\\\n",
    "                                                    pre_processing_initial,\\\n",
    "                                                    pre_processing_extended,\\\n",
    "                                                    pre_processing_final,\\\n",
    "                                                    extract_labels_multi_final,\\\n",
    "                                                    align_features_and_labels_multi_final,\\\n",
    "                                                    align_features_and_labels_multi_v5\n",
    "\n",
    "# from utils.models import make_input_fn\n",
    "# from utils.models import performanceTesting,scoreFunction\n",
    "# from utils.plotting import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which one do you want to load? \n",
      "\n",
<<<<<<< HEAD:test/Testing_Area_Extract_Azure_output_FRST_18oct.ipynb
      "0: aggregateTAQ_10sec.csv\n",
      "1: aggregateTAQ_30sec.csv\n",
      "2: aggregateTAQ_60sec.csv\n",
=======
      "0: aggregateTAQ_May2020_10sec.csv\n",
      "1: aggregateTAQ_May2020_30sec.csv\n",
      "2: aggregateTAQ_May2020_60sec.csv\n",
      "8: trueAggregateTAQ_60sec.csv\n",
>>>>>>> KLN_working_branch:test/Testing_Area_Extract_Azure_output.ipynb
      "\n",
      "\n",
      "2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf2\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m    884\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m                 \u001b[0mident\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf2\\lib\\site-packages\\jupyter_client\\session.py\u001b[0m in \u001b[0;36mrecv\u001b[1;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[0;32m    802\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 803\u001b[1;33m             \u001b[0mmsg_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    804\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf2\\lib\\site-packages\\zmq\\sugar\\socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[1;34m(self, flags, copy, track)\u001b[0m\n\u001b[0;32m    474\u001b[0m         \"\"\"\n\u001b[1;32m--> 475\u001b[1;33m         \u001b[0mparts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    476\u001b[0m         \u001b[1;31m# have first part already, only loop while more to receive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf2\\lib\\site-packages\\zmq\\backend\\cython\\checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-ab82a931c7ae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;31m# Asking for user input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Which one do you want to load? %s'\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         data = pd.read_csv(path + '/' + datafiles[int(file)],\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf2\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m    858\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    859\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 860\u001b[1;33m             \u001b[0mpassword\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    861\u001b[0m         )\n\u001b[0;32m    862\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf2\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m    888\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    889\u001b[0m                 \u001b[1;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 890\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    891\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    892\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Do we extract new data or read in?\n",
    "readIn = True\n",
    "# run load_data()\n",
    "if readIn:\n",
    "    \n",
    "    # Listing the data files \n",
    "#     path = '../../../Google Drev/Thesis/Data/TAQ/AggregatedTAQ'\n",
    "    path = 'F:/AggregatedTAQ/round3'\n",
    "    datafiles = os.listdir(path)\n",
    "    content = np.concatenate([['\\n\\n'],[str(j)+': '+i+'\\n' for j,i in enumerate(datafiles) if 'csv' in i],['\\n\\n']])\n",
    "    \n",
    "    # Asking for user input\n",
    "    file = input('Which one do you want to load? %s'%''.join(content))\n",
    "    if int(file) <= 2:\n",
    "        data = pd.read_csv(path + '/' + datafiles[int(file)],\n",
    "                           header = None,\n",
    "                           names=['open','high','low','close',\n",
    "                                  'spread_open','spread_high','spread_low','spread_close',\n",
    "                                  'bidsize_open','bidsize_high','bidsize_low','bidsize_close',\n",
    "                                  'ofrsize_open','ofrsize_high','ofrsize_low','ofrsize_close',\n",
    "                                  'Ticker'])\n",
    "        # Using the choice of the user to determine the correct market file\n",
    "        key = re.split('[_.]',datafiles[int(file)])[-2]\n",
    "        marketDataFile = [file for file in os.listdir(path+'/round5_market_tickers') if key in file]\n",
    "\n",
    "        # Reading in the market data\n",
    "        tempData = pd.read_csv(path+'/round5_market_tickers/'+marketDataFile[0]\n",
    "                               ,header = None\n",
    "                               ,names=['open','high','low','close',\n",
    "                                      'spread_open','spread_high','spread_low','spread_close',\n",
    "                                      'bidsize_open','bidsize_high','bidsize_low','bidsize_close',\n",
    "                                      'ofrsize_open','ofrsize_high','ofrsize_low','ofrsize_close',\n",
    "                                      'Ticker'])\n",
    "        # Adding the market data to the ticker data\n",
    "        data = pd.concat([data,tempData],axis=0)\n",
    "    else:\n",
    "        data = pd.read_csv(path + '/' + datafiles[int(file)],\n",
    "                           header = 0,\n",
    "                           index_col=[0,1]\n",
    "#                            names=['open','high','low','close',\n",
    "#                                   'spread_open','spread_high','spread_low','spread_close',\n",
    "#                                   'bidsize_open','bidsize_high','bidsize_low','bidsize_close',\n",
    "#                                   'ofrsize_open','ofrsize_high','ofrsize_low','ofrsize_close',\n",
    "#                                   'Ticker']\n",
    "                          )\n",
    "    \n",
    "    # Lower casing all column names\n",
    "#     data.columns = data.columns.str.lower()\n",
    "else:\n",
    "    \n",
    "    # print(os.listdir())\n",
    "    try:\n",
    "        path = 'a:/taqhdf5'  #'a:/taqhdf5'\n",
    "        os.listdir(path)\n",
    "    except:\n",
    "        path = 't:/taqhdf5'  #'a:/taqhdf5'\n",
    "        os.listdir(path)\n",
    "        \n",
    "    # Sample type\n",
    "    data_sample = 'full' # or 'stable'\n",
    "    # allFiles = os.listdir(path)\n",
    "    # print(len(allFiles), allFiles[:5], allFiles[-5:])\n",
    "    # print(allFiles[-10:])\n",
    "\n",
    "    #dates = np.array(['2020040' + str(i) if i < 10 else '202004' + str(i) for i in np.arange(1,16)]).astype(int)\n",
    "    dates = np.array(['20200501']).astype(int)#,'20200402','20200403','20200406','20200407'\n",
    "\n",
    "    # Provide a list of tickers of interest\n",
    "    \n",
    "    tickers = sorted(['TSLA','FB'])#'MSFT'\n",
    "    \n",
    "    # Do we need data on trades, quotes or both?\n",
    "    dataNeeded = 'quotes' # 'trades', 'quotes' or 'both'\n",
    "    \n",
    "    if dataNeeded == 'trades':\n",
    "        tradeData = load_data_final(dates, tickers, dataNeeded, path, verbose)\n",
    "    elif dataNeeded == 'quotes':\n",
    "        quoteData = load_data_final(dates,\n",
    "                                    tickers,\n",
    "                                    dataNeeded,\n",
    "                                    path,\n",
    "                                    verbose,\n",
    "                                    extract_candles = False,\n",
    "                                    aggHorizon = 1,\n",
    "                                    extra_features_from_quotes = None,\n",
    "                                    data_sample = data_sample)\n",
    "    elif dataNeeded == 'both':\n",
    "        tradeData, quoteData = load_data_final(dates, tickers, dataNeeded, path, verbose)\n",
    "\n",
    "# Reading in sector information\n",
    "stockInfo = pd.read_csv('../utils/stockInfo_v1.csv',header=[0,1])\n",
    "stockInfo.columns = ['ticker','sector','exchange','marketCap']\n",
    "\n",
    "# Creating a table with stock information based on the tickers available in the data.\n",
    "uniqueTickers = data.Ticker.unique()\n",
    "stockTable = stockInfo[stockInfo.ticker.isin(uniqueTickers)]\n",
    "stockTable.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Archieve',\n",
       " 'hyperparameters_lr_v1_1.txt',\n",
       " 'hyperparameters_lr_v2_4.txt',\n",
       " 'hyperparameters_lr_v3_1.txt',\n",
       " 'hyperparameters_nn_v4.txt',\n",
       " 'metrics_lr_v1_1.txt',\n",
       " 'metrics_lr_v2_4.txt',\n",
       " 'metrics_lr_v3_1.txt',\n",
       " 'metrics_nn_v4.txt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = os.listdir('../AzureML/Output_from_cloud')\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperfiles_nn = [i for i in os.listdir('../AzureML/Output_from_cloud') if ('hyper' in i) & ('nn' in i)]\n",
    "metricfiles_nn = [i for i in os.listdir('../AzureML/Output_from_cloud') if ('metric' in i) & ('nn' in i)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hyperparameters_nn_v4.txt']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperfiles_nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Reading in the file\n",
    "\n",
    "with open('../AzureML/Output_from_cloud/'+hyperfiles_nn[-1],'r') as file:\n",
    "    content = file.readlines()\n",
    "\n",
    "## Containers for the data\n",
    "all_ids = []\n",
    "all_parameters = []\n",
    "\n",
    "## Going over each line in the text file\n",
    "for a in np.arange(len(content[0:-1])):\n",
    "    \n",
    "    ## Split the lines on tabs\n",
    "    temp_parameters = re.split('[\\t]',content[a])[1]\n",
    "    \n",
    "    ## Basic string cleaning, i.e. removing redundant characters\n",
    "#     test = [re.split(': ',i.strip()) for i in re.split(',',temp_parameters.replace('{','')\\\n",
    "#                                                                        .replace('}','')\\\n",
    "#                                                                        .replace('\\n','')\\\n",
    "#                                                                        .replace('\"',''))]\n",
    "    test = [re.split(': ',i.strip()) for i in re.split(',',temp_parameters.replace('{','')\\\n",
    "                                                                       .replace('}','')\\\n",
    "                                                                       .replace('\\n','')\\\n",
    "                                                                       .replace('\"','')\\\n",
    "                                                                       .replace('--','')\n",
    "                                                                       .replace('\\'',''))]\n",
    "    \n",
    "    ## Output of test is a list of lists, where each sublist holds the name of a model variable and its value.\n",
    "    ## We create a dictornary to hold all model variables, making it easy to add the observation to the dataframe.\n",
    "    test = {i[0]:i[1] for i in test}\n",
    "    \n",
    "    # Constructing the dataframe\n",
    "    if a == 0:\n",
    "        parameters = pd.DataFrame(test,index=[re.split('[\\t]',content[a])[0]])\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        parameters.loc[re.split('[\\t]',content[a])[0]] = pd.Series(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Readidng in the file\n",
    "with open('../AzureML/Output_from_cloud/'+metricfiles_nn[-1],'r') as file:\n",
    "    content = file.readlines()\n",
    "\n",
    "## Containers\n",
    "t11 = []\n",
    "t12 = []\n",
    "t13 = []\n",
    "\n",
    "t21 = []\n",
    "t22 = []\n",
    "t23 = []\n",
    "\n",
    "## Going over each line\n",
    "for i in np.arange(len(content)):#\n",
    "    \n",
    "    ## Split each line on tabs\n",
    "    temp = re.split('\\t',content[i].replace('\\n',''))\n",
    "    \n",
    "    #print(temp)\n",
    "    \n",
    "    ## There are two types of observations in the text file; 1. final metrics of those models which where not stoppe early\n",
    "    ## and 2. a time series of a metric for each model.\n",
    "    \n",
    "    ## If the length of the last element, in a line, is less than 50 (because it is just a number, i.e. final metric)\n",
    "    ## It stored separately for the time series.\n",
    "    if len(temp[2]) < 50:\n",
    "\n",
    "        t11.append(temp[0])\n",
    "        t12.append(temp[1])\n",
    "        t13.append(temp[2])\n",
    "    \n",
    "    ## Time series\n",
    "    else:\n",
    "    \n",
    "        container = np.zeros(155)\n",
    "        temp1 = [float(j.strip()) if j.strip() !=\"'NaN'\" else 0 for j in re.split(',',temp[2].replace('[','').replace(']',''))]\n",
    "\n",
    "        container[0:len(temp1)] = temp1\n",
    "        container[len(temp1):] = temp1[-1]\n",
    "\n",
    "        t21.append(temp[0])\n",
    "        t22.append(temp[1])\n",
    "        t23.append(container)        \n",
    "\n",
    "## Storing the time series in a dataframe\n",
    "arrays = [t21,t22]\n",
    "tuples = list(zip(*arrays))\n",
    "\n",
    "runningMetrics = pd.DataFrame(np.array(t23),\n",
    "                              index=pd.MultiIndex.from_tuples(tuples),\n",
    "                              columns = [np.arange(155).astype(str)]\n",
    "                             )\n",
    "## Storing the final metrics in a dataframe.\n",
    "arrays = [t11,t12]\n",
    "tuples = list(zip(*arrays))\n",
    "finalMetrics = pd.DataFrame(t13,index = pd.MultiIndex.from_tuples(tuples),columns = ['size'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attaching the last observation of each model, for each metric, to the parameters of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>activation-inner</th>\n",
       "      <th>activation-output</th>\n",
       "      <th>batch-norm</th>\n",
       "      <th>batch-shuffle</th>\n",
       "      <th>batch-size</th>\n",
       "      <th>dropout-ratio</th>\n",
       "      <th>feature-lags</th>\n",
       "      <th>featureset</th>\n",
       "      <th>first-layer-neurons</th>\n",
       "      <th>...</th>\n",
       "      <th>pastobs-in-percentage</th>\n",
       "      <th>pre-processing</th>\n",
       "      <th>second-layer-neurons</th>\n",
       "      <th>id</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Train AUC</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Train Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
<<<<<<< HEAD:test/Testing_Area_Extract_Azure_output_FRST_18oct.ipynb
<<<<<<< HEAD:test/Testing_Area_Extract_Azure_output_FRST_18oct.ipynb
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_0</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>linear</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3300</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>150</td>\n",
       "      <td>3</td>\n",
       "      <td>ffnn</td>\n",
       "      <td>1</td>\n",
       "      <td>stacked</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>linear</td>\n",
=======
       "      <th>HD_81ace623-e09b-4393-8a5e-131ea8749a35_999</th>\n",
       "      <td>tanh</td>\n",
       "      <td>softmax</td>\n",
       "      <td>0</td>\n",
>>>>>>> bb1b39ac2361ae9f0c2e82b5fd08edc8af96cf75:test/Testing_Area_Extract_Azure_output.ipynb
       "      <td>0</td>\n",
       "      <td>21450</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
=======
       "      <th>115</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_883</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>softmax</td>\n",
>>>>>>> KLN_working_branch:test/Testing_Area_Extract_Azure_output.ipynb
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10725</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>std</td>\n",
       "      <td>32</td>\n",
       "      <td>883</td>\n",
       "      <td>0.80363</td>\n",
       "      <td>0.58075</td>\n",
       "      <td>0.98257</td>\n",
       "      <td>0.80358</td>\n",
       "      <td>0.66548</td>\n",
       "      <td>0.77074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
<<<<<<< HEAD:test/Testing_Area_Extract_Azure_output_FRST_18oct.ipynb
<<<<<<< HEAD:test/Testing_Area_Extract_Azure_output_FRST_18oct.ipynb
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_2</td>\n",
=======
       "      <th>HD_81ace623-e09b-4393-8a5e-131ea8749a35_998</th>\n",
>>>>>>> bb1b39ac2361ae9f0c2e82b5fd08edc8af96cf75:test/Testing_Area_Extract_Azure_output.ipynb
       "      <td>sigmoid</td>\n",
=======
       "      <th>781</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_218</td>\n",
       "      <td>tanh</td>\n",
>>>>>>> KLN_working_branch:test/Testing_Area_Extract_Azure_output.ipynb
       "      <td>softmax</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>21450</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>pow</td>\n",
       "      <td>32</td>\n",
       "      <td>218</td>\n",
       "      <td>0.79064</td>\n",
       "      <td>0.57710</td>\n",
       "      <td>0.99908</td>\n",
       "      <td>0.79060</td>\n",
       "      <td>0.65135</td>\n",
       "      <td>0.80627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
<<<<<<< HEAD:test/Testing_Area_Extract_Azure_output_FRST_18oct.ipynb
<<<<<<< HEAD:test/Testing_Area_Extract_Azure_output_FRST_18oct.ipynb
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_3</td>\n",
       "      <td>tanh</td>\n",
=======
       "      <th>HD_81ace623-e09b-4393-8a5e-131ea8749a35_997</th>\n",
       "      <td>relu</td>\n",
>>>>>>> bb1b39ac2361ae9f0c2e82b5fd08edc8af96cf75:test/Testing_Area_Extract_Azure_output.ipynb
       "      <td>linear</td>\n",
=======
       "      <th>997</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_5</td>\n",
       "      <td>leakyrelu</td>\n",
       "      <td>softmax</td>\n",
>>>>>>> KLN_working_branch:test/Testing_Area_Extract_Azure_output.ipynb
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>21450</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>quantgau</td>\n",
       "      <td>128</td>\n",
       "      <td>5</td>\n",
       "      <td>0.78380</td>\n",
       "      <td>0.60282</td>\n",
       "      <td>0.90322</td>\n",
       "      <td>0.78376</td>\n",
       "      <td>0.62677</td>\n",
       "      <td>0.84667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_72</td>\n",
       "      <td>tanh</td>\n",
       "      <td>softmax</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3300</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>stacked</td>\n",
       "      <td>64</td>\n",
       "      <td>72</td>\n",
       "      <td>0.78185</td>\n",
       "      <td>0.61228</td>\n",
       "      <td>0.89609</td>\n",
       "      <td>0.78181</td>\n",
       "      <td>0.62734</td>\n",
       "      <td>0.84895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
<<<<<<< HEAD:test/Testing_Area_Extract_Azure_output_FRST_18oct.ipynb
<<<<<<< HEAD:test/Testing_Area_Extract_Azure_output_FRST_18oct.ipynb
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_4</td>\n",
       "      <td>leakyrelu</td>\n",
       "      <td>linear</td>\n",
       "      <td>0</td>\n",
=======
       "      <th>HD_81ace623-e09b-4393-8a5e-131ea8749a35_994</th>\n",
=======
       "      <th>128</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_871</td>\n",
>>>>>>> KLN_working_branch:test/Testing_Area_Extract_Azure_output.ipynb
       "      <td>tanh</td>\n",
       "      <td>softmax</td>\n",
>>>>>>> bb1b39ac2361ae9f0c2e82b5fd08edc8af96cf75:test/Testing_Area_Extract_Azure_output.ipynb
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10725</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>quantgau</td>\n",
       "      <td>32</td>\n",
       "      <td>871</td>\n",
       "      <td>0.78175</td>\n",
       "      <td>0.60582</td>\n",
       "      <td>0.92492</td>\n",
       "      <td>0.78172</td>\n",
       "      <td>0.62636</td>\n",
       "      <td>0.85098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
<<<<<<< HEAD:test/Testing_Area_Extract_Azure_output_FRST_18oct.ipynb
<<<<<<< HEAD:test/Testing_Area_Extract_Azure_output_FRST_18oct.ipynb
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_995</td>\n",
       "      <td>sigmoid</td>\n",
=======
       "      <th>HD_81ace623-e09b-4393-8a5e-131ea8749a35_9</th>\n",
       "      <td>leakyrelu</td>\n",
>>>>>>> bb1b39ac2361ae9f0c2e82b5fd08edc8af96cf75:test/Testing_Area_Extract_Azure_output.ipynb
=======
       "      <th>814</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_185</td>\n",
       "      <td>relu</td>\n",
>>>>>>> KLN_working_branch:test/Testing_Area_Extract_Azure_output.ipynb
       "      <td>linear</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3300</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>128</td>\n",
       "      <td>185</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.19641</td>\n",
       "      <td>0.94736</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.19952</td>\n",
       "      <td>0.95143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
<<<<<<< HEAD:test/Testing_Area_Extract_Azure_output_FRST_18oct.ipynb
<<<<<<< HEAD:test/Testing_Area_Extract_Azure_output_FRST_18oct.ipynb
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_996</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>softmax</td>\n",
       "      <td>1</td>\n",
=======
       "      <th>HD_81ace623-e09b-4393-8a5e-131ea8749a35_7</th>\n",
       "      <td>tanh</td>\n",
       "      <td>linear</td>\n",
       "      <td>0</td>\n",
>>>>>>> bb1b39ac2361ae9f0c2e82b5fd08edc8af96cf75:test/Testing_Area_Extract_Azure_output.ipynb
       "      <td>1</td>\n",
       "      <td>10725</td>\n",
=======
       "      <th>304</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_695</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>linear</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3300</td>\n",
>>>>>>> KLN_working_branch:test/Testing_Area_Extract_Azure_output.ipynb
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
<<<<<<< HEAD:test/Testing_Area_Extract_Azure_output_FRST_18oct.ipynb
       "      <td>0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>ffnn</td>\n",
       "      <td>1</td>\n",
       "      <td>minmax</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
<<<<<<< HEAD:test/Testing_Area_Extract_Azure_output_FRST_18oct.ipynb
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_997</td>\n",
       "      <td>relu</td>\n",
       "      <td>linear</td>\n",
=======
       "      <th>HD_81ace623-e09b-4393-8a5e-131ea8749a35_5</th>\n",
       "      <td>leakyrelu</td>\n",
       "      <td>softmax</td>\n",
>>>>>>> bb1b39ac2361ae9f0c2e82b5fd08edc8af96cf75:test/Testing_Area_Extract_Azure_output.ipynb
       "      <td>1</td>\n",
=======
       "      <td>...</td>\n",
>>>>>>> KLN_working_branch:test/Testing_Area_Extract_Azure_output.ipynb
       "      <td>1</td>\n",
       "      <td>quantgau</td>\n",
       "      <td>128</td>\n",
       "      <td>695</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.19329</td>\n",
       "      <td>0.89643</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.18706</td>\n",
       "      <td>0.91432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
<<<<<<< HEAD:test/Testing_Area_Extract_Azure_output_FRST_18oct.ipynb
<<<<<<< HEAD:test/Testing_Area_Extract_Azure_output_FRST_18oct.ipynb
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_998</td>\n",
       "      <td>sigmoid</td>\n",
=======
       "      <th>HD_81ace623-e09b-4393-8a5e-131ea8749a35_6</th>\n",
       "      <td>relu</td>\n",
>>>>>>> bb1b39ac2361ae9f0c2e82b5fd08edc8af96cf75:test/Testing_Area_Extract_Azure_output.ipynb
       "      <td>softmax</td>\n",
=======
       "      <th>195</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_803</td>\n",
       "      <td>tanh</td>\n",
       "      <td>linear</td>\n",
>>>>>>> KLN_working_branch:test/Testing_Area_Extract_Azure_output.ipynb
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21450</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>minmax</td>\n",
       "      <td>32</td>\n",
       "      <td>803</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.45457</td>\n",
       "      <td>0.68465</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.45333</td>\n",
       "      <td>0.68717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
<<<<<<< HEAD:test/Testing_Area_Extract_Azure_output_FRST_18oct.ipynb
<<<<<<< HEAD:test/Testing_Area_Extract_Azure_output_FRST_18oct.ipynb
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_999</td>\n",
       "      <td>tanh</td>\n",
       "      <td>softmax</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21450</td>\n",
       "      <td>0.2</td>\n",
=======
       "      <th>HD_81ace623-e09b-4393-8a5e-131ea8749a35_1</th>\n",
=======
       "      <th>861</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_137</td>\n",
>>>>>>> KLN_working_branch:test/Testing_Area_Extract_Azure_output.ipynb
       "      <td>sigmoid</td>\n",
       "      <td>linear</td>\n",
>>>>>>> bb1b39ac2361ae9f0c2e82b5fd08edc8af96cf75:test/Testing_Area_Extract_Azure_output.ipynb
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10725</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>stacked</td>\n",
       "      <td>64</td>\n",
       "      <td>137</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.16547</td>\n",
       "      <td>1.59072</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.17433</td>\n",
       "      <td>1.59977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_677</td>\n",
       "      <td>relu</td>\n",
       "      <td>linear</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10725</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>64</td>\n",
       "      <td>677</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.19750</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.19989</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          run_id activation-inner  \\\n",
       "115  HD_81ace623-e09b-4393-8a5e-131ea8749a35_883          sigmoid   \n",
       "781  HD_81ace623-e09b-4393-8a5e-131ea8749a35_218             tanh   \n",
       "997    HD_81ace623-e09b-4393-8a5e-131ea8749a35_5        leakyrelu   \n",
       "928   HD_81ace623-e09b-4393-8a5e-131ea8749a35_72             tanh   \n",
       "128  HD_81ace623-e09b-4393-8a5e-131ea8749a35_871             tanh   \n",
       "..                                           ...              ...   \n",
       "814  HD_81ace623-e09b-4393-8a5e-131ea8749a35_185             relu   \n",
       "304  HD_81ace623-e09b-4393-8a5e-131ea8749a35_695          sigmoid   \n",
       "195  HD_81ace623-e09b-4393-8a5e-131ea8749a35_803             tanh   \n",
       "861  HD_81ace623-e09b-4393-8a5e-131ea8749a35_137          sigmoid   \n",
       "321  HD_81ace623-e09b-4393-8a5e-131ea8749a35_677             relu   \n",
       "\n",
       "    activation-output batch-norm batch-shuffle batch-size dropout-ratio  \\\n",
       "115           softmax          1             1      10725           0.1   \n",
       "781           softmax          1             0      21450             0   \n",
       "997           softmax          1             1      21450           0.5   \n",
       "928           softmax          1             1       3300           0.2   \n",
       "128           softmax          1             1      10725             0   \n",
       "..                ...        ...           ...        ...           ...   \n",
       "814            linear          0             1       3300           0.3   \n",
       "304            linear          0             0       3300           0.1   \n",
       "195            linear          0             0      21450           0.3   \n",
       "861            linear          0             1      10725           0.5   \n",
       "321            linear          0             1      10725           0.5   \n",
       "\n",
       "    feature-lags featureset first-layer-neurons  ... pastobs-in-percentage  \\\n",
       "115            3          3                 128  ...                     0   \n",
       "781            5          1                  64  ...                     0   \n",
       "997            3          3                 128  ...                     0   \n",
       "928            3          3                 128  ...                     1   \n",
       "128            3          0                 128  ...                     0   \n",
       "..           ...        ...                 ...  ...                   ...   \n",
       "814            5          3                 128  ...                     1   \n",
       "304            1          3                  64  ...                     1   \n",
       "195            3          0                  32  ...                     1   \n",
       "861            5          3                 128  ...                     0   \n",
       "321            3          2                  64  ...                     0   \n",
       "\n",
       "    pre-processing second-layer-neurons   id      AUC Accuracy     Loss  \\\n",
       "115            std                   32  883  0.80363  0.58075  0.98257   \n",
       "781            pow                   32  218  0.79064  0.57710  0.99908   \n",
       "997       quantgau                  128    5  0.78380  0.60282  0.90322   \n",
       "928        stacked                   64   72  0.78185  0.61228  0.89609   \n",
       "128       quantgau                   32  871  0.78175  0.60582  0.92492   \n",
       "..             ...                  ...  ...      ...      ...      ...   \n",
       "814           None                  128  185  0.00000  0.19641  0.94736   \n",
       "304       quantgau                  128  695  0.00000  0.19329  0.89643   \n",
       "195         minmax                   32  803  0.00000  0.45457  0.68465   \n",
       "861        stacked                   64  137  0.00000  0.16547  1.59072   \n",
       "321           None                   64  677  0.00000  0.19750  0.00000   \n",
       "\n",
       "    Train AUC Train Accuracy  Train Loss  \n",
       "115   0.80358        0.66548     0.77074  \n",
       "781   0.79060        0.65135     0.80627  \n",
       "997   0.78376        0.62677     0.84667  \n",
       "928   0.78181        0.62734     0.84895  \n",
       "128   0.78172        0.62636     0.85098  \n",
       "..        ...            ...         ...  \n",
       "814   0.00000        0.19952     0.95143  \n",
       "304   0.00000        0.18706     0.91432  \n",
       "195   0.00000        0.45333     0.68717  \n",
       "861   0.00000        0.17433     1.59977  \n",
       "321   0.00000        0.19989     0.00000  \n",
       "\n",
       "[1000 rows x 25 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Resetting indcies and rename columns\n",
    "runningMetrics = runningMetrics.reset_index().rename(columns={'level_0':'run_id','level_1':'metric'})\n",
    "runningMetrics.columns = runningMetrics.columns.get_level_values(0)\n",
    "\n",
    "## Adding a column of short ids, to merge on.\n",
    "runningMetrics['id'] = [re.split('_',i)[-1] for i in runningMetrics.run_id]\n",
    "\n",
    "## Creating a table, having the short id in the rows and the last observation for each metric in the columns. \n",
    "table = pd.pivot_table(runningMetrics[['run_id','metric','154','id']],index='id',columns=['metric'])\n",
    "table.columns = table.columns.get_level_values(1)\n",
    "table = table.round(5).reset_index()\n",
    "\n",
    "## Preparing the parameter dataframe.\n",
    "parameters = parameters.reset_index().rename(columns={'index':'run_id'})\n",
    "\n",
    "## Setting short ID\n",
    "parameters['id'] = [re.split('_',i)[-1] for i in parameters.run_id]\n",
    "\n",
    "## Creating the combined table\n",
    "combined_table = parameters.merge(table,\n",
    "                                     on = 'id',\n",
    "                                     how='left').sort_values('AUC',ascending=False)\n",
    "combined_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
<<<<<<< HEAD:test/Testing_Area_Extract_Azure_output_FRST_18oct.ipynb
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
<<<<<<< HEAD:test/Testing_Area_Extract_Azure_output_FRST_18oct.ipynb
       "      <td rowspan=\"3\" valign=\"top\">HD_81ace623-e09b-4393-8a5e-131ea8749a35_1</td>\n",
       "      <td>Final test loss</td>\n",
=======
       "      <th rowspan=\"3\" valign=\"top\">HD_81ace623-e09b-4393-8a5e-131ea8749a35_998</th>\n",
       "      <th>Final test loss</th>\n",
>>>>>>> bb1b39ac2361ae9f0c2e82b5fd08edc8af96cf75:test/Testing_Area_Extract_Azure_output.ipynb
       "      <td>0.8833522492045336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Final test AUC</td>\n",
       "      <td>0.7648658156394958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Final test accuracy</td>\n",
       "      <td>0.6109746098518372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
<<<<<<< HEAD:test/Testing_Area_Extract_Azure_output_FRST_18oct.ipynb
       "      <td rowspan=\"2\" valign=\"top\">HD_81ace623-e09b-4393-8a5e-131ea8749a35_3</td>\n",
       "      <td>Final test loss</td>\n",
=======
       "      <th rowspan=\"2\" valign=\"top\">HD_81ace623-e09b-4393-8a5e-131ea8749a35_996</th>\n",
       "      <th>Final test loss</th>\n",
>>>>>>> bb1b39ac2361ae9f0c2e82b5fd08edc8af96cf75:test/Testing_Area_Extract_Azure_output.ipynb
       "      <td>1.1133369887535414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Final test AUC</td>\n",
       "      <td>0.640163779258728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
<<<<<<< HEAD:test/Testing_Area_Extract_Azure_output_FRST_18oct.ipynb
       "      <td rowspan=\"2\" valign=\"top\">HD_81ace623-e09b-4393-8a5e-131ea8749a35_997</td>\n",
       "      <td>Final test AUC</td>\n",
=======
       "      <th rowspan=\"2\" valign=\"top\">HD_81ace623-e09b-4393-8a5e-131ea8749a35_5</th>\n",
       "      <th>Final test AUC</th>\n",
>>>>>>> bb1b39ac2361ae9f0c2e82b5fd08edc8af96cf75:test/Testing_Area_Extract_Azure_output.ipynb
       "      <td>0.7837895154953003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Final test accuracy</td>\n",
       "      <td>0.602816104888916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
<<<<<<< HEAD:test/Testing_Area_Extract_Azure_output_FRST_18oct.ipynb
       "      <td rowspan=\"3\" valign=\"top\">HD_81ace623-e09b-4393-8a5e-131ea8749a35_998</td>\n",
       "      <td>Final test loss</td>\n",
=======
       "      <th rowspan=\"3\" valign=\"top\">HD_81ace623-e09b-4393-8a5e-131ea8749a35_6</th>\n",
       "      <th>Final test loss</th>\n",
>>>>>>> bb1b39ac2361ae9f0c2e82b5fd08edc8af96cf75:test/Testing_Area_Extract_Azure_output.ipynb
       "      <td>1.3713646207894699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Final test AUC</td>\n",
       "      <td>0.7241190671920776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Final test accuracy</td>\n",
       "      <td>0.4148908853530884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1170 rows × 1 columns</p>\n",
       "</div>"
      ],
=======
>>>>>>> KLN_working_branch:test/Testing_Area_Extract_Azure_output.ipynb
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2b7803c8d48>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "runningMetrics[(runningMetrics.metric=='Accuracy')&\\\n",
    "               (np.isin(runningMetrics.id,parameters[parameters['label-type']=='2'].id.values))].sort_values('154')['154'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating a top-X table for each label-type of a given metric, here AUC.\n",
    "temp_auc = pd.pivot_table(combined_table[['label-type','AUC','id']],index='id',columns='label-type')\n",
    "temp_acc = pd.pivot_table(combined_table[['label-type','Accuracy','id']],index='id',columns='label-type')\n",
    "\n",
    "## Final output - AUC\n",
    "final_output_auc = pd.DataFrame(np.sort(temp_auc.fillna(0).values,\n",
    "                             axis=0)[::-1],\n",
    "                             columns=temp_auc.columns.get_level_values(1)).loc[0:10]\n",
    "## Final output - Accuracy\n",
    "final_output_acc = pd.DataFrame(np.sort(temp_acc.fillna(0).values,\n",
    "                             axis=0)[::-1],\n",
    "                             columns=temp_acc.columns.get_level_values(1))#.loc[0:10]\n",
    "# final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>activation-inner</th>\n",
       "      <th>activation-output</th>\n",
       "      <th>batch-norm</th>\n",
       "      <th>batch-shuffle</th>\n",
       "      <th>batch-size</th>\n",
       "      <th>dropout-ratio</th>\n",
       "      <th>feature-lags</th>\n",
       "      <th>featureset</th>\n",
       "      <th>first-layer-neurons</th>\n",
       "      <th>...</th>\n",
       "      <th>pastobs-in-percentage</th>\n",
       "      <th>pre-processing</th>\n",
       "      <th>second-layer-neurons</th>\n",
       "      <th>id</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Train AUC</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Train Loss</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label-type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
<<<<<<< HEAD:test/Testing_Area_Extract_Azure_output_FRST_18oct.ipynb
<<<<<<< HEAD:test/Testing_Area_Extract_Azure_output_FRST_18oct.ipynb
       "      <td rowspan=\"5\" valign=\"top\">HD_81ace623-e09b-4393-8a5e-131ea8749a35_0</td>\n",
       "      <td>Loss</td>\n",
=======
       "      <th rowspan=\"5\" valign=\"top\">HD_81ace623-e09b-4393-8a5e-131ea8749a35_999</th>\n",
       "      <th>Loss</th>\n",
>>>>>>> bb1b39ac2361ae9f0c2e82b5fd08edc8af96cf75:test/Testing_Area_Extract_Azure_output.ipynb
       "      <td>1.098537</td>\n",
       "      <td>1.098504</td>\n",
       "      <td>1.098467</td>\n",
       "      <td>1.098423</td>\n",
       "      <td>1.098371</td>\n",
       "      <td>1.098309</td>\n",
       "      <td>1.098233</td>\n",
       "      <td>1.098140</td>\n",
       "      <td>1.098026</td>\n",
       "      <td>1.097886</td>\n",
       "      <td>...</td>\n",
       "      <td>1.066601</td>\n",
       "      <td>1.066601</td>\n",
       "      <td>1.066601</td>\n",
       "      <td>1.066601</td>\n",
       "      <td>1.066601</td>\n",
       "      <td>1.066601</td>\n",
       "      <td>1.066601</td>\n",
       "      <td>1.066601</td>\n",
       "      <td>1.066601</td>\n",
       "      <td>1.066601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.354843</td>\n",
       "      <td>0.358482</td>\n",
       "      <td>0.362843</td>\n",
       "      <td>0.365199</td>\n",
       "      <td>0.366960</td>\n",
       "      <td>0.367240</td>\n",
       "      <td>0.368826</td>\n",
       "      <td>0.370377</td>\n",
       "      <td>0.371579</td>\n",
       "      <td>0.372220</td>\n",
       "      <td>...</td>\n",
       "      <td>0.412316</td>\n",
       "      <td>0.412316</td>\n",
       "      <td>0.412316</td>\n",
       "      <td>0.412316</td>\n",
       "      <td>0.412316</td>\n",
       "      <td>0.412316</td>\n",
       "      <td>0.412316</td>\n",
       "      <td>0.412316</td>\n",
       "      <td>0.412316</td>\n",
       "      <td>0.412316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>AUC</td>\n",
       "      <td>0.500120</td>\n",
       "      <td>0.500277</td>\n",
       "      <td>0.500545</td>\n",
       "      <td>0.501018</td>\n",
       "      <td>0.501737</td>\n",
       "      <td>0.502806</td>\n",
       "      <td>0.504301</td>\n",
       "      <td>0.506150</td>\n",
       "      <td>0.508213</td>\n",
       "      <td>0.510308</td>\n",
       "      <td>...</td>\n",
       "      <td>0.575838</td>\n",
       "      <td>0.575838</td>\n",
       "      <td>0.575838</td>\n",
       "      <td>0.575838</td>\n",
       "      <td>0.575838</td>\n",
       "      <td>0.575838</td>\n",
       "      <td>0.575838</td>\n",
       "      <td>0.575838</td>\n",
       "      <td>0.575838</td>\n",
       "      <td>0.575838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Train Loss</td>\n",
       "      <td>1.098558</td>\n",
       "      <td>1.098524</td>\n",
       "      <td>1.098487</td>\n",
       "      <td>1.098442</td>\n",
       "      <td>1.098396</td>\n",
       "      <td>1.098339</td>\n",
       "      <td>1.098267</td>\n",
       "      <td>1.098180</td>\n",
       "      <td>1.098077</td>\n",
       "      <td>1.097955</td>\n",
       "      <td>...</td>\n",
       "      <td>1.068791</td>\n",
       "      <td>1.068791</td>\n",
       "      <td>1.068791</td>\n",
       "      <td>1.068791</td>\n",
       "      <td>1.068791</td>\n",
       "      <td>1.068791</td>\n",
       "      <td>1.068791</td>\n",
       "      <td>1.068791</td>\n",
       "      <td>1.068791</td>\n",
       "      <td>1.068791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Train Accuracy</td>\n",
       "      <td>0.344181</td>\n",
       "      <td>0.350251</td>\n",
       "      <td>0.353537</td>\n",
       "      <td>0.358348</td>\n",
       "      <td>0.360740</td>\n",
       "      <td>0.363537</td>\n",
       "      <td>0.365985</td>\n",
       "      <td>0.368336</td>\n",
       "      <td>0.368998</td>\n",
       "      <td>0.369959</td>\n",
       "      <td>...</td>\n",
       "      <td>0.412060</td>\n",
       "      <td>0.412060</td>\n",
       "      <td>0.412060</td>\n",
       "      <td>0.412060</td>\n",
       "      <td>0.412060</td>\n",
       "      <td>0.412060</td>\n",
       "      <td>0.412060</td>\n",
       "      <td>0.412060</td>\n",
       "      <td>0.412060</td>\n",
       "      <td>0.412060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
<<<<<<< HEAD:test/Testing_Area_Extract_Azure_output_FRST_18oct.ipynb
       "      <td rowspan=\"5\" valign=\"top\">HD_81ace623-e09b-4393-8a5e-131ea8749a35_999</td>\n",
       "      <td>Accuracy</td>\n",
=======
       "      <th rowspan=\"5\" valign=\"top\">HD_81ace623-e09b-4393-8a5e-131ea8749a35_1</th>\n",
       "      <th>Accuracy</th>\n",
>>>>>>> bb1b39ac2361ae9f0c2e82b5fd08edc8af96cf75:test/Testing_Area_Extract_Azure_output.ipynb
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>0.337729</td>\n",
=======
       "      <th>2</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_883</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>softmax</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10725</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
>>>>>>> KLN_working_branch:test/Testing_Area_Extract_Azure_output.ipynb
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>std</td>\n",
       "      <td>32</td>\n",
       "      <td>883</td>\n",
       "      <td>0.80363</td>\n",
       "      <td>0.58075</td>\n",
       "      <td>0.98257</td>\n",
       "      <td>0.80358</td>\n",
       "      <td>0.66548</td>\n",
       "      <td>0.77074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
<<<<<<< HEAD:test/Testing_Area_Extract_Azure_output_FRST_18oct.ipynb
       "      <td>AUC</td>\n",
       "      <td>0.006679</td>\n",
       "      <td>0.003153</td>\n",
       "      <td>0.002064</td>\n",
       "      <td>0.001534</td>\n",
       "      <td>0.001221</td>\n",
       "      <td>0.001014</td>\n",
       "      <td>0.000867</td>\n",
       "      <td>0.000757</td>\n",
       "      <td>0.000672</td>\n",
       "      <td>0.000604</td>\n",
=======
       "      <th>4</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_743</td>\n",
       "      <td>relu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10725</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
>>>>>>> KLN_working_branch:test/Testing_Area_Extract_Azure_output.ipynb
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>std</td>\n",
       "      <td>32</td>\n",
       "      <td>743</td>\n",
       "      <td>0.75291</td>\n",
       "      <td>0.39708</td>\n",
       "      <td>1.49211</td>\n",
       "      <td>0.75284</td>\n",
       "      <td>0.46585</td>\n",
       "      <td>1.25437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
<<<<<<< HEAD:test/Testing_Area_Extract_Azure_output_FRST_18oct.ipynb
       "      <td>Train Loss</td>\n",
       "      <td>5.383223</td>\n",
       "      <td>5.355752</td>\n",
       "      <td>5.355751</td>\n",
       "      <td>5.355751</td>\n",
       "      <td>5.355751</td>\n",
       "      <td>5.355750</td>\n",
       "      <td>5.355750</td>\n",
       "      <td>5.355750</td>\n",
       "      <td>5.355750</td>\n",
       "      <td>5.355750</td>\n",
=======
       "      <th>1</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_65</td>\n",
       "      <td>leakyrelu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10725</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
>>>>>>> KLN_working_branch:test/Testing_Area_Extract_Azure_output.ipynb
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>std</td>\n",
       "      <td>64</td>\n",
       "      <td>65</td>\n",
       "      <td>0.74085</td>\n",
       "      <td>0.38183</td>\n",
       "      <td>1.54324</td>\n",
       "      <td>0.74076</td>\n",
       "      <td>0.63645</td>\n",
       "      <td>0.77408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
<<<<<<< HEAD:test/Testing_Area_Extract_Azure_output_FRST_18oct.ipynb
       "      <td>Train Accuracy</td>\n",
       "      <td>0.333057</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>0.332281</td>\n",
       "      <td>0.332281</td>\n",
=======
       "      <th>0</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_818</td>\n",
       "      <td>relu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10725</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
>>>>>>> KLN_working_branch:test/Testing_Area_Extract_Azure_output.ipynb
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>pow</td>\n",
       "      <td>128</td>\n",
       "      <td>818</td>\n",
       "      <td>0.71117</td>\n",
       "      <td>0.53313</td>\n",
       "      <td>0.97092</td>\n",
       "      <td>0.71096</td>\n",
       "      <td>0.74884</td>\n",
       "      <td>0.49957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
<<<<<<< HEAD:test/Testing_Area_Extract_Azure_output_FRST_18oct.ipynb
       "      <td>Train AUC</td>\n",
       "      <td>0.030584</td>\n",
       "      <td>0.004384</td>\n",
       "      <td>0.002511</td>\n",
       "      <td>0.001766</td>\n",
       "      <td>0.001362</td>\n",
       "      <td>0.001109</td>\n",
       "      <td>0.000935</td>\n",
       "      <td>0.000809</td>\n",
       "      <td>0.000712</td>\n",
       "      <td>0.000636</td>\n",
=======
       "      <th>3</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_737</td>\n",
       "      <td>tanh</td>\n",
       "      <td>softmax</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3300</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
>>>>>>> KLN_working_branch:test/Testing_Area_Extract_Azure_output.ipynb
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>pow</td>\n",
       "      <td>128</td>\n",
       "      <td>737</td>\n",
       "      <td>0.68440</td>\n",
       "      <td>0.27445</td>\n",
       "      <td>1.66672</td>\n",
       "      <td>0.68431</td>\n",
       "      <td>0.41546</td>\n",
       "      <td>1.36253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 run_id activation-inner  \\\n",
       "label-type                                                                 \n",
       "2           HD_81ace623-e09b-4393-8a5e-131ea8749a35_883          sigmoid   \n",
       "4           HD_81ace623-e09b-4393-8a5e-131ea8749a35_743             relu   \n",
       "1            HD_81ace623-e09b-4393-8a5e-131ea8749a35_65        leakyrelu   \n",
       "0           HD_81ace623-e09b-4393-8a5e-131ea8749a35_818             relu   \n",
       "3           HD_81ace623-e09b-4393-8a5e-131ea8749a35_737             tanh   \n",
       "\n",
       "           activation-output batch-norm batch-shuffle batch-size  \\\n",
       "label-type                                                         \n",
       "2                    softmax          1             1      10725   \n",
       "4                    softmax          1             0      10725   \n",
       "1                    softmax          0             1      10725   \n",
       "0                    softmax          1             1      10725   \n",
       "3                    softmax          1             1       3300   \n",
       "\n",
       "           dropout-ratio feature-lags featureset first-layer-neurons  ...  \\\n",
       "label-type                                                            ...   \n",
       "2                    0.1            3          3                 128  ...   \n",
       "4                      0            3          3                 128  ...   \n",
       "1                      0            5          1                 128  ...   \n",
       "0                      0            5          1                 128  ...   \n",
       "3                      0            5          0                  32  ...   \n",
       "\n",
       "           pastobs-in-percentage pre-processing second-layer-neurons   id  \\\n",
       "label-type                                                                  \n",
       "2                              0            std                   32  883   \n",
       "4                              1            std                   32  743   \n",
       "1                              0            std                   64   65   \n",
       "0                              1            pow                  128  818   \n",
       "3                              0            pow                  128  737   \n",
       "\n",
       "                AUC Accuracy     Loss Train AUC Train Accuracy  Train Loss  \n",
       "label-type                                                                  \n",
       "2           0.80363  0.58075  0.98257   0.80358        0.66548     0.77074  \n",
       "4           0.75291  0.39708  1.49211   0.75284        0.46585     1.25437  \n",
       "1           0.74085  0.38183  1.54324   0.74076        0.63645     0.77408  \n",
       "0           0.71117  0.53313  0.97092   0.71096        0.74884     0.49957  \n",
       "3           0.68440  0.27445  1.66672   0.68431        0.41546     1.36253  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tempFinal_v0 = combined_table[np.isin(combined_table.AUC,final_output_auc.loc[0].values.flatten())]\n",
    "tempFinal_v0.index = tempFinal_v0.loc[:,'label-type']\n",
    "tempFinal_v0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>activation-inner</th>\n",
       "      <th>activation-output</th>\n",
       "      <th>batch-norm</th>\n",
       "      <th>batch-shuffle</th>\n",
       "      <th>batch-size</th>\n",
       "      <th>dropout-ratio</th>\n",
       "      <th>feature-lags</th>\n",
       "      <th>featureset</th>\n",
       "      <th>first-layer-neurons</th>\n",
       "      <th>...</th>\n",
       "      <th>pastobs-in-percentage</th>\n",
       "      <th>pre-processing</th>\n",
       "      <th>second-layer-neurons</th>\n",
       "      <th>id</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Train AUC</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Train Loss</th>\n",
       "    </tr>\n",
       "    <tr>\n",
<<<<<<< HEAD:test/Testing_Area_Extract_Azure_output_FRST_18oct.ipynb
<<<<<<< HEAD:test/Testing_Area_Extract_Azure_output_FRST_18oct.ipynb
       "      <td>115</td>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_115</td>\n",
       "      <td>relu</td>\n",
=======
       "      <th>115</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_883</td>\n",
       "      <td>sigmoid</td>\n",
>>>>>>> bb1b39ac2361ae9f0c2e82b5fd08edc8af96cf75:test/Testing_Area_Extract_Azure_output.ipynb
       "      <td>softmax</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10725</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>std</td>\n",
       "      <td>32</td>\n",
       "      <td>883</td>\n",
       "      <td>0.80363</td>\n",
       "      <td>0.58075</td>\n",
       "      <td>0.98257</td>\n",
       "      <td>0.80358</td>\n",
       "      <td>0.66548</td>\n",
       "      <td>0.77074</td>\n",
=======
       "      <th>label-type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
>>>>>>> KLN_working_branch:test/Testing_Area_Extract_Azure_output.ipynb
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
<<<<<<< HEAD:test/Testing_Area_Extract_Azure_output_FRST_18oct.ipynb
<<<<<<< HEAD:test/Testing_Area_Extract_Azure_output_FRST_18oct.ipynb
       "      <td>781</td>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_781</td>\n",
=======
       "      <th>781</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_218</td>\n",
>>>>>>> bb1b39ac2361ae9f0c2e82b5fd08edc8af96cf75:test/Testing_Area_Extract_Azure_output.ipynb
       "      <td>tanh</td>\n",
=======
       "      <th>0</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_706</td>\n",
       "      <td>leakyrelu</td>\n",
>>>>>>> KLN_working_branch:test/Testing_Area_Extract_Azure_output.ipynb
       "      <td>softmax</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10725</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>quantgau</td>\n",
       "      <td>128</td>\n",
       "      <td>706</td>\n",
       "      <td>0.57765</td>\n",
       "      <td>0.55382</td>\n",
       "      <td>0.67447</td>\n",
       "      <td>0.57746</td>\n",
       "      <td>0.55565</td>\n",
       "      <td>0.67536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
<<<<<<< HEAD:test/Testing_Area_Extract_Azure_output_FRST_18oct.ipynb
<<<<<<< HEAD:test/Testing_Area_Extract_Azure_output_FRST_18oct.ipynb
       "      <td>997</td>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_997</td>\n",
       "      <td>relu</td>\n",
       "      <td>linear</td>\n",
=======
       "      <th>997</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_5</td>\n",
=======
       "      <th>1</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_390</td>\n",
>>>>>>> KLN_working_branch:test/Testing_Area_Extract_Azure_output.ipynb
       "      <td>leakyrelu</td>\n",
       "      <td>softmax</td>\n",
>>>>>>> bb1b39ac2361ae9f0c2e82b5fd08edc8af96cf75:test/Testing_Area_Extract_Azure_output.ipynb
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10725</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
<<<<<<< HEAD:test/Testing_Area_Extract_Azure_output_FRST_18oct.ipynb
       "      <td>quantgau</td>\n",
       "      <td>128</td>\n",
       "      <td>5</td>\n",
       "      <td>0.78380</td>\n",
       "      <td>0.60282</td>\n",
       "      <td>0.90322</td>\n",
       "      <td>0.78376</td>\n",
       "      <td>0.62677</td>\n",
       "      <td>0.84667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
<<<<<<< HEAD:test/Testing_Area_Extract_Azure_output_FRST_18oct.ipynb
       "      <td>928</td>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_928</td>\n",
       "      <td>relu</td>\n",
       "      <td>linear</td>\n",
       "      <td>0</td>\n",
=======
       "      <th>928</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_72</td>\n",
       "      <td>tanh</td>\n",
       "      <td>softmax</td>\n",
>>>>>>> bb1b39ac2361ae9f0c2e82b5fd08edc8af96cf75:test/Testing_Area_Extract_Azure_output.ipynb
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3300</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
=======
>>>>>>> KLN_working_branch:test/Testing_Area_Extract_Azure_output.ipynb
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>pow</td>\n",
       "      <td>64</td>\n",
       "      <td>390</td>\n",
       "      <td>0.62001</td>\n",
       "      <td>0.43072</td>\n",
       "      <td>1.04843</td>\n",
       "      <td>0.61998</td>\n",
       "      <td>0.44065</td>\n",
       "      <td>1.04593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
<<<<<<< HEAD:test/Testing_Area_Extract_Azure_output_FRST_18oct.ipynb
<<<<<<< HEAD:test/Testing_Area_Extract_Azure_output_FRST_18oct.ipynb
       "      <td>128</td>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_128</td>\n",
=======
       "      <th>128</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_871</td>\n",
>>>>>>> bb1b39ac2361ae9f0c2e82b5fd08edc8af96cf75:test/Testing_Area_Extract_Azure_output.ipynb
=======
       "      <th>2</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_283</td>\n",
>>>>>>> KLN_working_branch:test/Testing_Area_Extract_Azure_output.ipynb
       "      <td>tanh</td>\n",
       "      <td>softmax</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3300</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
<<<<<<< HEAD:test/Testing_Area_Extract_Azure_output_FRST_18oct.ipynb
       "      <td>871</td>\n",
       "      <td>0.78175</td>\n",
       "      <td>0.60582</td>\n",
       "      <td>0.92492</td>\n",
       "      <td>0.78172</td>\n",
       "      <td>0.62636</td>\n",
       "      <td>0.85098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
=======
>>>>>>> KLN_working_branch:test/Testing_Area_Extract_Azure_output.ipynb
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>stacked</td>\n",
       "      <td>128</td>\n",
       "      <td>283</td>\n",
       "      <td>0.76304</td>\n",
       "      <td>0.61409</td>\n",
       "      <td>0.87683</td>\n",
       "      <td>0.76298</td>\n",
       "      <td>0.61164</td>\n",
       "      <td>0.87896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
<<<<<<< HEAD:test/Testing_Area_Extract_Azure_output_FRST_18oct.ipynb
<<<<<<< HEAD:test/Testing_Area_Extract_Azure_output_FRST_18oct.ipynb
       "      <td>814</td>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_814</td>\n",
       "      <td>tanh</td>\n",
=======
       "      <th>814</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_185</td>\n",
       "      <td>relu</td>\n",
>>>>>>> bb1b39ac2361ae9f0c2e82b5fd08edc8af96cf75:test/Testing_Area_Extract_Azure_output.ipynb
       "      <td>linear</td>\n",
=======
       "      <th>3</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_213</td>\n",
       "      <td>tanh</td>\n",
       "      <td>softmax</td>\n",
>>>>>>> KLN_working_branch:test/Testing_Area_Extract_Azure_output.ipynb
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21450</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
<<<<<<< HEAD:test/Testing_Area_Extract_Azure_output_FRST_18oct.ipynb
       "      <td>None</td>\n",
       "      <td>128</td>\n",
       "      <td>185</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.19641</td>\n",
       "      <td>0.94736</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.19952</td>\n",
       "      <td>0.95143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
<<<<<<< HEAD:test/Testing_Area_Extract_Azure_output_FRST_18oct.ipynb
       "      <td>304</td>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_304</td>\n",
       "      <td>leakyrelu</td>\n",
=======
       "      <th>304</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_695</td>\n",
       "      <td>sigmoid</td>\n",
>>>>>>> bb1b39ac2361ae9f0c2e82b5fd08edc8af96cf75:test/Testing_Area_Extract_Azure_output.ipynb
       "      <td>linear</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3300</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
=======
       "      <td>pow</td>\n",
>>>>>>> KLN_working_branch:test/Testing_Area_Extract_Azure_output.ipynb
       "      <td>64</td>\n",
       "      <td>213</td>\n",
       "      <td>0.64187</td>\n",
       "      <td>0.30243</td>\n",
       "      <td>1.51325</td>\n",
       "      <td>0.64186</td>\n",
       "      <td>0.30381</td>\n",
       "      <td>1.51441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
<<<<<<< HEAD:test/Testing_Area_Extract_Azure_output_FRST_18oct.ipynb
<<<<<<< HEAD:test/Testing_Area_Extract_Azure_output_FRST_18oct.ipynb
       "      <td>195</td>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_195</td>\n",
       "      <td>sigmoid</td>\n",
=======
       "      <th>195</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_803</td>\n",
       "      <td>tanh</td>\n",
>>>>>>> bb1b39ac2361ae9f0c2e82b5fd08edc8af96cf75:test/Testing_Area_Extract_Azure_output.ipynb
       "      <td>linear</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21450</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>minmax</td>\n",
       "      <td>32</td>\n",
       "      <td>803</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.45457</td>\n",
       "      <td>0.68465</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.45333</td>\n",
       "      <td>0.68717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
<<<<<<< HEAD:test/Testing_Area_Extract_Azure_output_FRST_18oct.ipynb
       "      <td>861</td>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_861</td>\n",
       "      <td>relu</td>\n",
=======
       "      <th>861</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_137</td>\n",
       "      <td>sigmoid</td>\n",
>>>>>>> bb1b39ac2361ae9f0c2e82b5fd08edc8af96cf75:test/Testing_Area_Extract_Azure_output.ipynb
       "      <td>linear</td>\n",
       "      <td>0</td>\n",
=======
       "      <th>4</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_528</td>\n",
       "      <td>tanh</td>\n",
       "      <td>softmax</td>\n",
       "      <td>1</td>\n",
>>>>>>> KLN_working_branch:test/Testing_Area_Extract_Azure_output.ipynb
       "      <td>1</td>\n",
       "      <td>10725</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
<<<<<<< HEAD:test/Testing_Area_Extract_Azure_output_FRST_18oct.ipynb
       "      <td>stacked</td>\n",
       "      <td>64</td>\n",
       "      <td>137</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.16547</td>\n",
       "      <td>1.59072</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.17433</td>\n",
       "      <td>1.59977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
<<<<<<< HEAD:test/Testing_Area_Extract_Azure_output_FRST_18oct.ipynb
       "      <td>321</td>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_321</td>\n",
       "      <td>leakyrelu</td>\n",
=======
       "      <th>321</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_677</td>\n",
       "      <td>relu</td>\n",
>>>>>>> bb1b39ac2361ae9f0c2e82b5fd08edc8af96cf75:test/Testing_Area_Extract_Azure_output.ipynb
       "      <td>linear</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10725</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>64</td>\n",
       "      <td>677</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.19750</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.19989</td>\n",
       "      <td>0.00000</td>\n",
=======
       "      <td>std</td>\n",
       "      <td>32</td>\n",
       "      <td>528</td>\n",
       "      <td>0.73196</td>\n",
       "      <td>0.42030</td>\n",
       "      <td>1.35104</td>\n",
       "      <td>0.73192</td>\n",
       "      <td>0.41582</td>\n",
       "      <td>1.35792</td>\n",
>>>>>>> KLN_working_branch:test/Testing_Area_Extract_Azure_output.ipynb
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 run_id activation-inner  \\\n",
       "label-type                                                                 \n",
       "0           HD_81ace623-e09b-4393-8a5e-131ea8749a35_706        leakyrelu   \n",
       "1           HD_81ace623-e09b-4393-8a5e-131ea8749a35_390        leakyrelu   \n",
       "2           HD_81ace623-e09b-4393-8a5e-131ea8749a35_283             tanh   \n",
       "3           HD_81ace623-e09b-4393-8a5e-131ea8749a35_213             tanh   \n",
       "4           HD_81ace623-e09b-4393-8a5e-131ea8749a35_528             tanh   \n",
       "\n",
       "           activation-output batch-norm batch-shuffle batch-size  \\\n",
       "label-type                                                         \n",
       "0                    softmax          0             0      10725   \n",
       "1                    softmax          1             0      10725   \n",
       "2                    softmax          1             1       3300   \n",
       "3                    softmax          0             1      21450   \n",
       "4                    softmax          1             1      10725   \n",
       "\n",
       "           dropout-ratio feature-lags featureset first-layer-neurons  ...  \\\n",
       "label-type                                                            ...   \n",
       "0                    0.4            1          3                  64  ...   \n",
       "1                    0.5            0          3                 128  ...   \n",
       "2                    0.1            3          2                  32  ...   \n",
       "3                    0.5            5          0                 128  ...   \n",
       "4                    0.1            3          0                 128  ...   \n",
       "\n",
       "           pastobs-in-percentage pre-processing second-layer-neurons   id  \\\n",
       "label-type                                                                  \n",
       "0                              0       quantgau                  128  706   \n",
       "1                              1            pow                   64  390   \n",
       "2                              0        stacked                  128  283   \n",
       "3                              1            pow                   64  213   \n",
       "4                              0            std                   32  528   \n",
       "\n",
       "                AUC Accuracy     Loss Train AUC Train Accuracy  Train Loss  \n",
       "label-type                                                                  \n",
       "0           0.57765  0.55382  0.67447   0.57746        0.55565     0.67536  \n",
       "1           0.62001  0.43072  1.04843   0.61998        0.44065     1.04593  \n",
       "2           0.76304  0.61409  0.87683   0.76298        0.61164     0.87896  \n",
       "3           0.64187  0.30243  1.51325   0.64186        0.30381     1.51441  \n",
       "4           0.73196  0.42030  1.35104   0.73192        0.41582     1.35792  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tempFinal_v1 = combined_table[np.isin(combined_table.Accuracy,final_output_acc.loc[0].values.flatten())].sort_values('label-type').copy(deep=True)\n",
    "tempFinal_v1.index = tempFinal_v1.loc[:,'label-type']\n",
    "tempFinal_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD:test/Testing_Area_Extract_Azure_output_FRST_18oct.ipynb
<<<<<<< HEAD:test/Testing_Area_Extract_Azure_output_FRST_18oct.ipynb
       "<matplotlib.axes._subplots.AxesSubplot at 0x1b4f739a048>"
=======
       "<matplotlib.axes._subplots.AxesSubplot at 0x2099f20abc8>"
>>>>>>> bb1b39ac2361ae9f0c2e82b5fd08edc8af96cf75:test/Testing_Area_Extract_Azure_output.ipynb
=======
       "run_id                   HD_81ace623-e09b-4393-8a5e-131ea8749a35_818\n",
       "activation-inner                                                relu\n",
       "activation-output                                            softmax\n",
       "batch-norm                                                         1\n",
       "batch-shuffle                                                      1\n",
       "batch-size                                                     10725\n",
       "dropout-ratio                                                      0\n",
       "feature-lags                                                       5\n",
       "featureset                                                         1\n",
       "first-layer-neurons                                              128\n",
       "label-type                                                         0\n",
       "learning-rate                                                    0.1\n",
       "n-epochs                                                         150\n",
       "n-layers                                                           3\n",
       "nn-type                                                         ffnn\n",
       "pastobs-in-percentage                                              1\n",
       "pre-processing                                                   pow\n",
       "second-layer-neurons                                             128\n",
       "id                                                               818\n",
       "AUC                                                          0.71117\n",
       "Accuracy                                                     0.53313\n",
       "Loss                                                         0.97092\n",
       "Train AUC                                                    0.71096\n",
       "Train Accuracy                                               0.74884\n",
       "Train Loss                                                   0.49957\n",
       "Name: 0, dtype: object"
>>>>>>> KLN_working_branch:test/Testing_Area_Extract_Azure_output.ipynb
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
<<<<<<< HEAD:test/Testing_Area_Extract_Azure_output_FRST_18oct.ipynb
    },
    {
     "data": {
<<<<<<< HEAD:test/Testing_Area_Extract_Azure_output_FRST_18oct.ipynb
      "image/png": "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\n",
=======
      "image/png": "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\n",
>>>>>>> bb1b39ac2361ae9f0c2e82b5fd08edc8af96cf75:test/Testing_Area_Extract_Azure_output.ipynb
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
=======
>>>>>>> KLN_working_branch:test/Testing_Area_Extract_Azure_output.ipynb
    }
   ],
   "source": [
    "tempFinal_v0.loc['0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structuring for visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <th colspan=\"5\" halign=\"left\">nn</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>second</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
<<<<<<< HEAD:test/Testing_Area_Extract_Azure_output_FRST_18oct.ipynb
<<<<<<< HEAD:test/Testing_Area_Extract_Azure_output_FRST_18oct.ipynb
       "      <td>1</td>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_115</td>\n",
       "      <td>relu</td>\n",
=======
       "      <th>2</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_883</td>\n",
       "      <td>sigmoid</td>\n",
>>>>>>> bb1b39ac2361ae9f0c2e82b5fd08edc8af96cf75:test/Testing_Area_Extract_Azure_output.ipynb
       "      <td>softmax</td>\n",
=======
       "      <th>nn-type</th>\n",
       "      <td>ffnn</td>\n",
       "      <td>lstm</td>\n",
       "      <td>lstm</td>\n",
       "      <td>ffnn</td>\n",
       "      <td>lstm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>818</td>\n",
       "      <td>65</td>\n",
       "      <td>883</td>\n",
       "      <td>737</td>\n",
       "      <td>743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>featureset</th>\n",
>>>>>>> KLN_working_branch:test/Testing_Area_Extract_Azure_output.ipynb
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pre-processing</th>\n",
       "      <td>pow</td>\n",
       "      <td>std</td>\n",
       "      <td>std</td>\n",
       "      <td>pow</td>\n",
       "      <td>std</td>\n",
       "    </tr>\n",
       "    <tr>\n",
<<<<<<< HEAD:test/Testing_Area_Extract_Azure_output_FRST_18oct.ipynb
<<<<<<< HEAD:test/Testing_Area_Extract_Azure_output_FRST_18oct.ipynb
       "      <td>4</td>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_781</td>\n",
       "      <td>tanh</td>\n",
       "      <td>linear</td>\n",
       "      <td>1</td>\n",
=======
       "      <th>4</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_743</td>\n",
       "      <td>relu</td>\n",
       "      <td>softmax</td>\n",
>>>>>>> bb1b39ac2361ae9f0c2e82b5fd08edc8af96cf75:test/Testing_Area_Extract_Azure_output.ipynb
=======
       "      <th>pastobs-in-percentage</th>\n",
>>>>>>> KLN_working_branch:test/Testing_Area_Extract_Azure_output.ipynb
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature-lags</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
<<<<<<< HEAD:test/Testing_Area_Extract_Azure_output_FRST_18oct.ipynb
<<<<<<< HEAD:test/Testing_Area_Extract_Azure_output_FRST_18oct.ipynb
       "      <td>3</td>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_997</td>\n",
       "      <td>relu</td>\n",
       "      <td>linear</td>\n",
       "      <td>1</td>\n",
=======
       "      <th>1</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_65</td>\n",
       "      <td>leakyrelu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>0</td>\n",
>>>>>>> bb1b39ac2361ae9f0c2e82b5fd08edc8af96cf75:test/Testing_Area_Extract_Azure_output.ipynb
=======
       "      <th>batch-norm</th>\n",
>>>>>>> KLN_working_branch:test/Testing_Area_Extract_Azure_output.ipynb
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
<<<<<<< HEAD:test/Testing_Area_Extract_Azure_output_FRST_18oct.ipynb
<<<<<<< HEAD:test/Testing_Area_Extract_Azure_output_FRST_18oct.ipynb
       "      <td>2</td>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_338</td>\n",
=======
       "      <th>0</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_818</td>\n",
>>>>>>> bb1b39ac2361ae9f0c2e82b5fd08edc8af96cf75:test/Testing_Area_Extract_Azure_output.ipynb
       "      <td>relu</td>\n",
       "      <td>softmax</td>\n",
=======
       "      <th>batch-shuffle</th>\n",
>>>>>>> KLN_working_branch:test/Testing_Area_Extract_Azure_output.ipynb
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
<<<<<<< HEAD:test/Testing_Area_Extract_Azure_output_FRST_18oct.ipynb
<<<<<<< HEAD:test/Testing_Area_Extract_Azure_output_FRST_18oct.ipynb
       "      <td>0</td>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_537</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>linear</td>\n",
=======
       "      <th>3</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_737</td>\n",
       "      <td>tanh</td>\n",
       "      <td>softmax</td>\n",
>>>>>>> bb1b39ac2361ae9f0c2e82b5fd08edc8af96cf75:test/Testing_Area_Extract_Azure_output.ipynb
       "      <td>1</td>\n",
       "      <td>1</td>\n",
=======
       "      <th>batch-size</th>\n",
       "      <td>10725</td>\n",
       "      <td>10725</td>\n",
       "      <td>10725</td>\n",
>>>>>>> KLN_working_branch:test/Testing_Area_Extract_Azure_output.ipynb
       "      <td>3300</td>\n",
       "      <td>10725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dropout-ratio</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>learning-rate</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n-layers</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>activation-inner</th>\n",
       "      <td>relu</td>\n",
       "      <td>leakyrelu</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>tanh</td>\n",
       "      <td>relu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>activation-output</th>\n",
       "      <td>softmax</td>\n",
       "      <td>softmax</td>\n",
       "      <td>softmax</td>\n",
       "      <td>softmax</td>\n",
       "      <td>softmax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first-layer-neurons</th>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label-type</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>second-layer-neurons</th>\n",
       "      <td>128</td>\n",
       "      <td>64</td>\n",
       "      <td>32</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC</th>\n",
       "      <td>0.711</td>\n",
       "      <td>0.741</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.533</td>\n",
       "      <td>0.382</td>\n",
       "      <td>0.581</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss</th>\n",
       "      <td>0.971</td>\n",
       "      <td>1.543</td>\n",
       "      <td>0.983</td>\n",
       "      <td>1.667</td>\n",
       "      <td>1.492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train AUC</th>\n",
       "      <td>0.711</td>\n",
       "      <td>0.741</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Accuracy</th>\n",
       "      <td>0.749</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.665</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Loss</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.771</td>\n",
       "      <td>1.363</td>\n",
       "      <td>1.254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "first                       nn                                      \n",
       "second                       0          1        2        3        4\n",
       "nn-type                   ffnn       lstm     lstm     ffnn     lstm\n",
       "id                         818         65      883      737      743\n",
       "featureset                   1          1        3        0        3\n",
       "pre-processing             pow        std      std      pow      std\n",
       "pastobs-in-percentage        1          0        0        0        1\n",
       "feature-lags                 5          5        3        5        3\n",
       "batch-norm                   1          0        1        1        1\n",
       "batch-shuffle                1          1        1        1        0\n",
       "batch-size               10725      10725    10725     3300    10725\n",
       "dropout-ratio                0          0      0.1        0        0\n",
       "learning-rate              0.1       0.01     0.01     0.01    0.001\n",
       "n-layers                     3          4        4        4        4\n",
       "activation-inner          relu  leakyrelu  sigmoid     tanh     relu\n",
       "activation-output      softmax    softmax  softmax  softmax  softmax\n",
       "first-layer-neurons        128        128      128       32      128\n",
       "label-type                   0          1        2        3        4\n",
       "second-layer-neurons       128         64       32      128       32\n",
       "AUC                      0.711      0.741    0.804    0.684    0.753\n",
       "Accuracy                 0.533      0.382    0.581    0.274    0.397\n",
       "Loss                     0.971      1.543    0.983    1.667    1.492\n",
       "Train AUC                0.711      0.741    0.804    0.684    0.753\n",
       "Train Accuracy           0.749      0.636    0.665    0.415    0.466\n",
       "Train Loss                 0.5      0.774    0.771    1.363    1.254"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_step = tempFinal_v0.copy(deep=True).drop(['run_id','n-epochs'],axis=1).sort_index().round({'AUC':3,#'label-type',\n",
    "                                                                                                              'Accuracy':3,\n",
    "                                                                                                              'Loss':3,\n",
    "                                                                                                              'Train AUC':3,\n",
    "                                                                                                              'Train Accuracy':3,\n",
    "                                                                                                              'Train Loss':3})\n",
    "\n",
    "###     First variables for indentification, the data related variables, estimation parameters, model parameters and then performance.\n",
    "columns_on_top = ['nn-type','id','featureset','pre-processing','pastobs-in-percentage','feature-lags',\n",
    "                  'batch-norm','batch-shuffle','batch-size','dropout-ratio','learning-rate','n-layers']\n",
    "residual = [i for i in first_step.columns if i not in columns_on_top]\n",
    "correct_ordered = []\n",
    "correct_ordered += columns_on_top\n",
    "correct_ordered += residual\n",
    "# first_step.T.loc[correct_ordered,:]\n",
    "\n",
    "results_table = first_step.T.loc[correct_ordered,:]\n",
    "\n",
    "iterables = [['nn'], results_table.columns]\n",
    "\n",
    "results_table.columns = pd.MultiIndex.from_product(iterables, names=['first', 'second'])\n",
    "\n",
    "results_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An example of a box-plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbgAAAGbCAYAAAC28oUrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAatklEQVR4nO3df6zddZ3n8edrWsq4u/5CasIAUmZSYpmqGCs7CY2xZGU7caaQSBi6mWgnVcJkwWzYJW1TgyuzTWD3DzabbTaDFsVRCyuJUqFOHXfr7NSRSS+7FW1vOtSCS1M3VERmEhFafe8f51RPD7e93/b+OO3nPh/JCef7+X6+3/P+frm9r/v9nM/5nlQVkiS15jdGXYAkSTPBgJMkNcmAkyQ1yYCTJDXJgJMkNWn+qAs4HRdeeGEtWrRo1GVIks4STz755I+rauFE686pgFu0aBFjY2OjLkOSdJZI8sOTrXOIUpLUJANOktQkA06S1CQDTpLUJANOktQkA06S1CQDTpLUJANOktQkA06S1CQDTpLUJANOktQkA06S1CQDTpLUJANOktQkA06S1CQDTpLUpHPqC09nWpJp2U9VTct+JElnziu4AVV1ysdl6x6btI/hJklnBwNOktQkA06S1CQDTpLUJANOktQkA06S1CQDTpLUJANOktQkA06S1CQDTpLUJANOktQkA06S1CQDTpLUJANOktQkA06S1CQDTpLUJANOktSkTgGXZGWS/UkOJFl/kj43JdmXZG+SL/XbViTZM/D4eZIb+us+l+SZgXVXTd9hSZLmuvmTdUgyD9gMfAA4BOxOsq2q9g30WQxsAK6pqheTvBWgqnYCV/X7XAAcAL4xsPs7q+qR6ToYSZKO63IFdzVwoKoOVtWrwEPA9UN9PgZsrqoXAarq+Qn2cyPw9ar62VQKliSpiy4BdzHw3MDyoX7boCuAK5J8O8kTSVZOsJ+bga1DbZuSPJXkviTnT/TiSW5JMpZk7MiRIx3KlSSpW8BlgrYaWp4PLAbeD6wGPpPkTb/aQXIR8A5gx8A2G4C3A+8FLgDWTfTiVXV/VS2rqmULFy7sUK4kSd0C7hBw6cDyJcDhCfo8WlVHq+oZYD+9wDvuJuArVXX0eENV/ah6XgE+S28oVJKkadEl4HYDi5NcnmQBvaHGbUN9vgqsAEhyIb0hy4MD61czNDzZv6ojSYAbgO+fyQFIkjSRSWdRVtWxJLfRG16cBzxQVXuT3A2MVdW2/rrrkuwDfkFvduQLAEkW0bsC/OuhXX8xyUJ6Q6B7gFun55AkSeoQcABVtR3YPtR218DzAu7oP4a3fZbXTkqhqq49zVolSerMO5lIkppkwEmSmmTASZKaZMBJkppkwEmSmmTASZKaZMBJkppkwEmSmmTASZKaZMBJkppkwEmSmmTASZKaZMBJkppkwEmSmmTASZKaZMBJkppkwEmSmmTASZKaZMBJkppkwEmSmmTASZKaZMBJkppkwEmSmmTASZKaZMBJkppkwEmSmmTASZKaZMBJkppkwEmSmmTASZKaZMBJkppkwEmSmmTASZKaZMBJkppkwEmSmmTASZKaZMBJkppkwEmSmjR/1AVIZ5sk07KfqpqW/Ug6M17BSUOqatLHZesem7SPpNEy4CRJTTLgJElN6hRwSVYm2Z/kQJL1J+lzU5J9SfYm+dJA+y+S7Ok/tg20X57k75I8neThJAumfjiSJPVMGnBJ5gGbgd8HrgRWJ7lyqM9iYANwTVX9LvBvBla/XFVX9R+rBtrvBe6rqsXAi8DaqR2KJEm/1uUK7mrgQFUdrKpXgYeA64f6fAzYXFUvAlTV86faYXrT1K4FHuk3PQjccDqFS5J0Kl0C7mLguYHlQ/22QVcAVyT5dpInkqwcWPebScb67cdD7C3AT6vq2Cn2CUCSW/rbjx05cqRDuZIkdfsc3EQfChqeAz0fWAy8H7gE+JskS6vqp8Dbqupwkt8G/meS7wH/0GGfvcaq+4H7AZYtW+bca0lSJ12u4A4Blw4sXwIcnqDPo1V1tKqeAfbTCzyq6nD/vweBbwHvBn4MvCnJ/FPsU5KkM9Yl4HYDi/uzHhcANwPbhvp8FVgBkORCekOWB5O8Ocn5A+3XAPuq9ynYncCN/e0/Ajw61YORJOm4SQOu/z7ZbcAOYBz471W1N8ndSY7PitwBvJBkH73gurOqXgCWAGNJvttvv6eq9vW3WQfckeQAvffktkzngUmS5rZO96Ksqu3A9qG2uwaeF3BH/zHY52+Bd5xknwfpzdCUJGnaeScTSVKTDDhJUpMMOElSkww4SVKTDDhJUpMMOElSkww4SVKTDDhJUpMMOElSkww4SVKTDDhJUpMMOElSkww4SVKTDDhJUpMMOElSkww4SVKTDDhJUpMMOElSkww4SVKTDDhJUpMMOElSkww4SVKTDDhJUpMMOElSkww4SVKTDDhJUpMMOElSkww4SVKTDDhJUpMMOElSkww4SVKTDDhJUpMMOElSkww4SVKTDDhJUpMMOElSkww4SVKTDDhJUpMMOElSkww4SVKTDDhJUpMMOElSkzoFXJKVSfYnOZBk/Un63JRkX5K9Sb7Ub7sqyXf6bU8l+aOB/p9L8kySPf3HVdNzSJIkwfzJOiSZB2wGPgAcAnYn2VZV+wb6LAY2ANdU1YtJ3tpf9TPgw1X1dJLfAp5MsqOqftpff2dVPTKdByRJEnS7grsaOFBVB6vqVeAh4PqhPh8DNlfViwBV9Xz/v39fVU/3nx8GngcWTlfxkiSdTJeAuxh4bmD5UL9t0BXAFUm+neSJJCuHd5LkamAB8IOB5k39ocv7kpw/0YsnuSXJWJKxI0eOdChXkqRuAZcJ2mpoeT6wGHg/sBr4TJI3/WoHyUXAXwB/UlW/7DdvAN4OvBe4AFg30YtX1f1Vtayqli1c6MWfJKmbLgF3CLh0YPkS4PAEfR6tqqNV9Qywn17gkeQNwOPAJ6rqieMbVNWPqucV4LP0hkIlSZoWXQJuN7A4yeVJFgA3A9uG+nwVWAGQ5EJ6Q5YH+/2/Any+qr48uEH/qo4kAW4Avj+VA5EkadCksyir6liS24AdwDzggaram+RuYKyqtvXXXZdkH/ALerMjX0jyx8D7gLckWdPf5Zqq2gN8MclCekOge4Bbp/vgJElz16QBB1BV24HtQ213DTwv4I7+Y7DPF4AvnGSf155usZIkddUp4KSWvOtT3+Cll49OeT+L1j9+xtu+8XXn8d1PXjflGmZS792Dqen97SuNhgGnOeell4/y7D0fHGkNUwnH2TJZOC1a//jIz6N0Kt6LUpLUJANOktQkA06S1CQDTpLUJANOktQkA06S1KQ59TGB6fj801Snd58Ln3+SpBbMqYDz80+SNHc4RClJapIBJ0lqkgEnSWqSASdJapIBJ0lqkgEnSWqSASdJapIBJ0lqkgEnSWqSASdJapIBJ0lqkgEnSWqSASdJapIBJ0lqkgEnSWqSASdJapIBJ0lqkgEnSWqSASdJapIBJ0lqkgEnSWqSASdJapIBJ0lqkgEnSWqSASdJapIBJ0lqkgEnSWqSASdJOm1bt25l6dKlzJs3j6VLl7J169ZRl/Qa80ddgCSdrZJMeR9VNQ2VnF22bt3Kxo0b2bJlC8uXL2fXrl2sXbsWgNWrV4+4ul/zCk6STqKqTvm4bN1jk/Zp0aZNm9iyZQsrVqzgvPPOY8WKFWzZsoVNmzaNurQTGHCSpNMyPj7O8uXLT2hbvnw54+PjI6poYgacJOm0LFmyhF27dp3QtmvXLpYsWTKiiibWKeCSrEyyP8mBJOtP0uemJPuS7E3ypYH2jyR5uv/4yED7e5J8r7/P/5LpGOyWJM24jRs3snbtWnbu3MnRo0fZuXMna9euZePGjaMu7QSTTjJJMg/YDHwAOATsTrKtqvYN9FkMbACuqaoXk7y1334B8ElgGVDAk/1tXwT+G3AL8ASwHVgJfH06D06SNP2OTyS5/fbbGR8fZ8mSJWzatOmsmmAC3WZRXg0cqKqDAEkeAq4H9g30+RiwuR9cVNXz/fZ/CfxVVf2kv+1fASuTfAt4Q1V9p9/+eeAGDDhJOiesXr36rAu0YV0C7mLguYHlQ8A/H+pzBUCSbwPzgH9fVX95km0v7j8OTdD+GkluoXelx9ve9rYO5UqazLs+9Q1eevnolPezaP3jZ7ztG193Ht/95HVTrkE6mS4BN9F7Y8NzX+cDi4H3A5cAf5Nk6Sm27bLPXmPV/cD9AMuWLWtzzq00y156+SjP3vPBkdYwlXCUuugyyeQQcOnA8iXA4Qn6PFpVR6vqGWA/vcA72baH+s9PtU9Jks5Yl4DbDSxOcnmSBcDNwLahPl8FVgAkuZDekOVBYAdwXZI3J3kzcB2wo6p+BPxjkt/rz578MPDotByRJEl0GKKsqmNJbqMXVvOAB6pqb5K7gbGq2savg2wf8Avgzqp6ASDJn9ELSYC7j084Af4U+BzwOnqTS5xgIkmaNp3uRVlV2+lN5R9su2vgeQF39B/D2z4APDBB+xiw9DTrlSSpE+9kIklqkgEnSWqSASdJapIBJ0lqkgEnSWqSASdJapIBJ0lqkgEnSWqSASdJapIBJ0lqkgEnSWqSASdJalKnmy234vVL1vOOB9ePuAaA0X7RpCTNBXMq4P5x/B6/xViS5giHKCVJTTLgJElNMuAkSU0y4CRJTTLgJElNmlOzKDW5JNOyn6qalv1I0pnyCk4nqKpTPi5b99ikfQw3SWcDA06S1CQDTpLUJANOktQkA06S1CQDTpLUJD8moDnHb5WQ5gYDTnOO3yohzQ0OUUqSmmTASZKaZMBJkppkwEmSmmTASZKa5CxKSXPWuz71DV56+eiU9jGVGbFvfN15fPeT103p9XVyBpykOeull4+O9CMjflxkZhlwc8yo/2IF/2qVziaT/U744b1/MOXXuGzdYyddN5O/Dwy4OWbUf7GCf7VKZ5NJfyfcM7Pf7ziTvw+cZCJJapIBJ0lqkgEnSWqS78FJmrNG/c0SfqvEzDLgJM1Zo/5mCSdczSyHKCVJTeoUcElWJtmf5ECS11zPJ1mT5EiSPf3HR/vtKwba9iT5eZIb+us+l+SZgXVXTe+hSZLmskmHKJPMAzYDHwAOAbuTbKuqfUNdH66q2wYbqmoncFV/PxcAB4BvDHS5s6oemUL9kiRNqMsV3NXAgao6WFWvAg8B15/Ba90IfL2qfnYG20qSdFq6BNzFwHMDy4f6bcM+lOSpJI8kuXSC9TcDW4faNvW3uS/J+RO9eJJbkowlGTty5EiHciVJ6jaLMhO0Dd+75WvA1qp6JcmtwIPAtb/aQXIR8A5gx8A2G4D/BywA7gfWAXe/5oWq7u+vZ9myZTN7zxjNGaOevfbG15030teX5oIuAXcIGLwiuwQ4PNihql4YWPw0cO/QPm4CvlJVRwe2+VH/6StJPgv8u65FS1MxHdPCF61/fOT39JR0al2GKHcDi5NcnmQBvaHGbYMd+ldox60Cxof2sZqh4cnj2yQJcAPw/dMrXZKkk5v0Cq6qjiW5jd7w4jzggaram+RuYKyqtgEfT7IKOAb8BFhzfPski+hdAf710K6/mGQhvSHQPcCtUz4aSZL6Ot3JpKq2A9uH2u4aeL6B3ntqE237LBNMSqmqa1/bWzNt1Lcm6tUA3p5I0kzzVl1zzKhvTQSjn+AhaW4w4KQ5yCt5HTfqn4WZ/DmYcwE36qsHp4frbOCVvI4b9c/CTP4czKmAm+r/RKeGS9K5w28TkCQ1yYCTJDXJgJMkNWlOvQcnSXqtU030+OG9fzDl/V+27rGTrpvJiXcGnCTNYZNOnLvn3L3HvUOUkqQmGXCSpCYZcJKkJvke3Bw06jtIeDcXSbPBgJtjvJuLpLnCIUpJUpMMOElSkxyi1AmSTN7n3sn3U3XufnZGUhsMOJ3AYJLUCocoJUlNMuAkSU0y4CRJTTLgJElNMuAkSU0y4CRJTfJjAtIc5T1J1ToDTpqDpuN+ot6XVGc7hyglSU0y4CRJTTLgJElN8j04SXPaKCfbONFmZhlwkuYsvwC4bQ5RSpKaZMBJkppkwEmSmmTASZKaZMBJkppkwEmSmuTHBAYkmbzPvZPvp6qmoRpJ0lQYcAMMJklqh0OUkqQmGXCSpCYZcJKkJnUKuCQrk+xPciDJ+gnWr0lyJMme/uOjA+t+MdC+baD98iR/l+TpJA8nWTA9hyRJUoeASzIP2Az8PnAlsDrJlRN0fbiqruo/PjPQ/vJA+6qB9nuB+6pqMfAisPbMD0OSpBN1uYK7GjhQVQer6lXgIeD6qbxoevPxrwUe6Tc9CNwwlX1KkjSoS8BdDDw3sHyo3zbsQ0meSvJIkksH2n8zyViSJ5IcD7G3AD+tqmOT7JMkt/S3Hzty5EiHciVJ6hZwE336efgDY18DFlXVO4Fv0rsiO+5tVbUM+FfAf07yOx332Wusur+qllXVsoULF3YoV5KkbgF3CBi8IrsEODzYoapeqKpX+oufBt4zsO5w/78HgW8B7wZ+DLwpyfEPmr9mn5IkTUWXgNsNLO7PelwA3AxsG+yQ5KKBxVXAeL/9zUnO7z+/ELgG2Fe9W4bsBG7sb/MR4NGpHIgkafZs3bqVpUuXMm/ePJYuXcrWrVtHXdJrTHqrrqo6luQ2YAcwD3igqvYmuRsYq6ptwMeTrAKOAT8B1vQ3XwL8eZJf0gvTe6pqX3/dOuChJP8B+D/Almk8LknSDNm6dSsbN25ky5YtLF++nF27drF2bW8i/OrVq0dc3a91uhdlVW0Htg+13TXwfAOwYYLt/hZ4x0n2eZDeDE1J0jlk06ZNbNmyhRUrVgCwYsUKtmzZwu23335WBZx3MpEknZbx8XGWL19+Qtvy5csZHx8fUUUTM+AkSadlyZIl7Nq164S2Xbt2sWTJkhFVNDEDTpJ0WjZu3MjatWvZuXMnR48eZefOnaxdu5aNGzeOurQT+H1wkqTTcvx9tttvv53x8XGWLFnCpk2bzqr338CAkySdgdWrV591gTbMIUpJUpMMOElSkww4SVKTDDhJUpMMOElSkww4SVKTDDhJUpMMOElSkww4SVKTDDhJUpMMOElSkww4SVKTDDhJUpMMOElSkww4SVKTDDhJUpMMOElSkww4SVKTDDhJUpPmj7oASWenJJP3uffU66tqmqqRTp8BJ2lChpPOdQ5RSpKaZMBJkppkwEmSmmTASZKaZMBJkppkwEmSmmTASZKaZMBJkppkwEmSmmTASZKaZMBJkppkwEmSmmTASZKa5LcJSNJJ+JVB5zYDTpJOwnA6tzlEKUlqUqeAS7Iyyf4kB5Ksn2D9miRHkuzpPz7ab78qyXeS7E3yVJI/Gtjmc0meGdjmquk7LEnSXDfpEGWSecBm4APAIWB3km1VtW+o68NVddtQ28+AD1fV00l+C3gyyY6q+ml//Z1V9cgUj0GSpNfocgV3NXCgqg5W1avAQ8D1XXZeVX9fVU/3nx8GngcWnmmxkiR11SXgLgaeG1g+1G8b9qH+MOQjSS4dXpnkamAB8IOB5k39be5Lcv5EL57kliRjScaOHDnSoVxJkroF3ETzZIenFn0NWFRV7wS+CTx4wg6Si4C/AP6kqn7Zb94AvB14L3ABsG6iF6+q+6tqWVUtW7jQiz9JUjddAu4QMHhFdglweLBDVb1QVa/0Fz8NvOf4uiRvAB4HPlFVTwxs86PqeQX4LL2hUEmSpkWXgNsNLE5yeZIFwM3AtsEO/Su041YB4/32BcBXgM9X1Zcn2ia9T1LeAHz/TA9CkqRhk86irKpjSW4DdgDzgAeqam+Su4GxqtoGfDzJKuAY8BNgTX/zm4D3AW9JcrxtTVXtAb6YZCG9IdA9wK3Td1iSpLmu051Mqmo7sH2o7a6B5xvovac2vN0XgC+cZJ/XnlalkiSdBu9kIklqkgEnSWqSASdJapIBJ0lqkgEnSWqSASdJapIBJ0lqkgEnSWqSASdJapIBJ0lqkgEnSWqSASdJalKnmy1Lc0nvG5w69Lv31Ourhr8XWNJsMuCkIQaT1AaHKCVJTTLgJElNMuAkSU0y4CRJTTLgJElNMuAkSU0y4CRJTTLgJElNMuAkSU0y4CRJTTLgJElNMuAkSU0y4CRJTTLgJElNMuAkSU3KufTdV0mOAD8cYQkXAj8e4eufDTwHPZ4HzwF4DmD05+Cyqlo40YpzKuBGLclYVS0bdR2j5Dno8Tx4DsBzAGf3OXCIUpLUJANOktQkA+703D/qAs4CnoMez4PnADwHcBafA9+DkyQ1ySs4SVKTDDhJUpMMuI6SrEyyP8mBJOtHXc9Mm+x4k7wvyf9OcizJjaOocaZ1OAd3JNmX5Kkk/yPJZaOocyZ1OAe3Jvlekj1JdiW5chR1zrSu//6T3JikkpyV0+anosPPwpokR/o/C3uSfHQUdZ6gqnxM8gDmAT8AfhtYAHwXuHLUdY3yeIFFwDuBzwM3jrrmEZ2DFcA/6T//U+DhUdc9gnPwhoHnq4C/HHXdozgP/X6vB/4X8ASwbNR1j+BnYQ3wX0dd6+DDK7hurgYOVNXBqnoVeAi4fsQ1zaRJj7eqnq2qp4BfjqLAWdDlHOysqp/1F58ALpnlGmdal3PwDwOL/xRocdZa13//fwb8R+Dns1ncLDknfwcacN1cDDw3sHyo39aquXa8Ezndc7AW+PqMVjT7Op2DJP86yQ/o/XL/+CzVNpsmPQ9J3g1cWlWPzWZhs6jrv4cP9YfsH0ly6eyUdnIGXDeZoK3Fv1SPm2vHO5HO5yDJHwPLgP80oxXNvk7noKo2V9XvAOuAT8x4VbPvlOchyW8A9wH/dtYqmn1dfha+BiyqqncC3wQenPGqJmHAdXMIGPxr5BLg8IhqmQ1z7Xgn0ukcJPkXwEZgVVW9Mku1zZbT/Tl4CLhhRisajcnOw+uBpcC3kjwL/B6wrbGJJpP+LFTVCwP/Bj4NvGeWajspA66b3cDiJJcnWQDcDGwbcU0zaa4d70QmPQf9Yak/pxduz4+gxpnW5RwsHlj8IPD0LNY3W055Hqrqpaq6sKoWVdUieu/HrqqqsdGUOyO6/CxcNLC4ChifxfomNH/UBZwLqupYktuAHfRmEz1QVXtHXNaMOdnxJrkbGKuqbUneC3wFeDPwh0k+VVW/O8Kyp1WXc0BvSPKfAV9OAvB/q2rVyIqeZh3PwW39q9ijwIvAR0ZX8czoeB6a1vEcfDzJKuAY8BN6sypHylt1SZKa5BClJKlJBpwkqUkGnCSpSQacJKlJBpwkqUkGnCSpSQacJKlJ/x/ms9xcvodQ3AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp = combined_table[(combined_table.loc[:,'label-type']=='0')&\\\n",
    "                      (combined_table.loc[:,'nn-type']=='lstm')&\\\n",
    "                      (combined_table.AUC>0.5)]\n",
    "temp_2 = pd.pivot_table(temp,values='AUC',columns='dropout-ratio',index='run_id').reset_index()\n",
    "temp_2.boxplot(list(temp_2.columns[1:]),figsize=(7,7))#temp_2.columns[2:]\n",
    "plt.grid(b=None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation-inner :  ['tanh' 'sigmoid' 'relu' 'leakyrelu'] \n",
      "\n",
      "activation-output :  ['softmax' 'linear'] \n",
      "\n",
      "batch-norm :  ['1' '0'] \n",
      "\n",
      "batch-shuffle :  ['1' '0'] \n",
      "\n",
      "batch-size :  ['21450' '10725' '3300'] \n",
      "\n",
      "dropout-ratio :  ['0' '0.2' '0.3' '0.4' '0.5' '0.1'] \n",
      "\n",
      "feature-lags :  ['5' '3' '0' '1'] \n",
      "\n",
      "featureset :  ['0' '3' '2' '1'] \n",
      "\n",
      "first-layer-neurons :  ['128' '64' '32'] \n",
      "\n",
      "learning-rate :  ['0.01' '0.1' '0.001' '0.0001'] \n",
      "\n",
      "n-layers :  ['4' '1' '2' '3'] \n",
      "\n",
      "pastobs-in-percentage :  ['1' '0'] \n",
      "\n",
      "pre-processing :  ['pow' 'quantgau' 'minmax' 'std' 'None' 'stacked'] \n",
      "\n",
      "second-layer-neurons :  ['32' '64' '128'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "cols_not_plot = []\n",
    "cols_to_plot = []\n",
    "\n",
    "for i,col in enumerate(temp.columns):\n",
    "    if (temp.loc[:,col].unique().shape[0]>1)&(temp.loc[:,col].unique().shape[0]<7):\n",
    "        cols_to_plot.append(col)\n",
    "        print(col,': ',temp.loc[:,col].unique(),'\\n')\n",
    "    else:\n",
    "        cols_not_plot.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cols_to_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['run_id', 'activation-inner', 'activation-output', 'batch-norm',\n",
       "       'batch-shuffle', 'batch-size', 'dropout-ratio', 'feature-lags',\n",
       "       'featureset', 'first-layer-neurons', 'label-type', 'learning-rate',\n",
       "       'n-epochs', 'n-layers', 'nn-type', 'pastobs-in-percentage',\n",
       "       'pre-processing', 'second-layer-neurons', 'id', 'AUC', 'Accuracy',\n",
       "       'Loss', 'Train AUC', 'Train Accuracy', 'Train Loss'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_table.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['150'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_table.loc[:,'n-epochs'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label types\n",
    "\n",
    "Label type 0: 2 classes - equal split\n",
    "\n",
    "Label type 1: 3 classes - equal split\n",
    "\n",
    "Label type 2: 3 classes - non-equal split\n",
    "\n",
    "Label type 3: 5 classes - equal split\n",
    "\n",
    "Label type 4: 5 classes - non-equal split"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:test/Testing_Area_Extract_Azure_output_FRST_18oct.ipynb
<<<<<<< HEAD:test/Testing_Area_Extract_Azure_output_FRST_18oct.ipynb
   "execution_count": 21,
=======
   "execution_count": 45,
>>>>>>> bb1b39ac2361ae9f0c2e82b5fd08edc8af96cf75:test/Testing_Area_Extract_Azure_output.ipynb
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:test/Testing_Area_Extract_Azure_output_FRST_18oct.ipynb
   "execution_count": 42,
>>>>>>> KLN_working_branch:test/Testing_Area_Extract_Azure_output.ipynb
=======
   "execution_count": 20,
>>>>>>> KLN_working_branch:test/Testing_Area_Extract_Azure_output.ipynb
   "metadata": {},
   "outputs": [
    {
     "data": {
<<<<<<< HEAD:test/Testing_Area_Extract_Azure_output_FRST_18oct.ipynb
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>activation-inner</th>\n",
       "      <th>activation-output</th>\n",
       "      <th>batch-norm</th>\n",
       "      <th>batch-shuffle</th>\n",
       "      <th>batch-size</th>\n",
       "      <th>dropout-ratio</th>\n",
       "      <th>feature-lags</th>\n",
       "      <th>featureset</th>\n",
       "      <th>first-layer-neurons</th>\n",
       "      <th>label-type</th>\n",
       "      <th>learning-rate</th>\n",
       "      <th>n-epochs</th>\n",
       "      <th>n-layers</th>\n",
       "      <th>nn-type</th>\n",
       "      <th>pastobs-in-percentage</th>\n",
       "      <th>pre-processing</th>\n",
       "      <th>second-layer-neurons</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label-type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_115</td>\n",
       "      <td>relu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3300</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>150</td>\n",
       "      <td>3</td>\n",
       "      <td>ffnn</td>\n",
       "      <td>1</td>\n",
       "      <td>quantgau</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_781</td>\n",
       "      <td>tanh</td>\n",
       "      <td>linear</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>21450</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>ffnn</td>\n",
       "      <td>1</td>\n",
       "      <td>minmax</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_997</td>\n",
       "      <td>relu</td>\n",
       "      <td>linear</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10725</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>150</td>\n",
       "      <td>2</td>\n",
       "      <td>lstm</td>\n",
       "      <td>0</td>\n",
       "      <td>pow</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_338</td>\n",
       "      <td>relu</td>\n",
       "      <td>linear</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21450</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>150</td>\n",
       "      <td>3</td>\n",
       "      <td>ffnn</td>\n",
       "      <td>0</td>\n",
       "      <td>quantgau</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_537</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>linear</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10725</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>150</td>\n",
       "      <td>4</td>\n",
       "      <td>lstm</td>\n",
       "      <td>1</td>\n",
       "      <td>quantgau</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 run_id activation-inner  \\\n",
       "label-type                                                                 \n",
       "1           HD_81ace623-e09b-4393-8a5e-131ea8749a35_115             relu   \n",
       "4           HD_81ace623-e09b-4393-8a5e-131ea8749a35_781             tanh   \n",
       "3           HD_81ace623-e09b-4393-8a5e-131ea8749a35_997             relu   \n",
       "2           HD_81ace623-e09b-4393-8a5e-131ea8749a35_338             relu   \n",
       "0           HD_81ace623-e09b-4393-8a5e-131ea8749a35_537          sigmoid   \n",
       "\n",
       "           activation-output batch-norm batch-shuffle batch-size  \\\n",
       "label-type                                                         \n",
       "1                    softmax          1             0       3300   \n",
       "4                     linear          1             1      21450   \n",
       "3                     linear          1             1      10725   \n",
       "2                     linear          0             0      21450   \n",
       "0                     linear          1             1      10725   \n",
       "\n",
       "           dropout-ratio feature-lags featureset first-layer-neurons  \\\n",
       "label-type                                                             \n",
       "1                    0.2            1          3                 128   \n",
       "4                    0.3            3          0                  64   \n",
       "3                    0.5            3          2                  64   \n",
       "2                    0.2            0          1                  64   \n",
       "0                    0.3            0          0                  64   \n",
       "\n",
       "           label-type learning-rate n-epochs n-layers nn-type  \\\n",
       "label-type                                                      \n",
       "1                   1        0.0001      150        3    ffnn   \n",
       "4                   4          0.01      150        1    ffnn   \n",
       "3                   3        0.0001      150        2    lstm   \n",
       "2                   2           0.1      150        3    ffnn   \n",
       "0                   0           0.1      150        4    lstm   \n",
       "\n",
       "           pastobs-in-percentage pre-processing second-layer-neurons  \n",
       "label-type                                                            \n",
       "1                              1       quantgau                  128  \n",
       "4                              1         minmax                   32  \n",
       "3                              0            pow                   64  \n",
       "2                              0       quantgau                   64  \n",
       "0                              1       quantgau                   32  "
      ]
     },
     "execution_count": 21,
=======
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " '.tmp.drivedownload',\n",
       " '20191111_213304.jpg',\n",
       " 'CryptoExtraction',\n",
       " 'CryptoExtraction.zip',\n",
       " 'debug.log',\n",
       " 'direction_1.xlsx',\n",
       " 'dsjn.PNG',\n",
       " 'Figures_Thesis',\n",
       " 'Getting started with Python.gdoc',\n",
       " 'Introduction To Programming',\n",
       " 'output',\n",
       " 'pot_returns.xlsx',\n",
       " 'pot_returns_1.xlsx',\n",
       " 'predications_13_10_2020.xlsx',\n",
       " 'prices.xlsx',\n",
       " 'prices_1.xlsx',\n",
       " 'Sisse',\n",
       " 'spreads.xlsx',\n",
       " 'spreads_1.xlsx',\n",
       " 'Thesis',\n",
       " 'Thesis_UCPH',\n",
       " 'trueAggregateTAQ_60sec.csv']"
      ]
     },
<<<<<<< HEAD:test/Testing_Area_Extract_Azure_output_FRST_18oct.ipynb
<<<<<<< HEAD:test/Testing_Area_Extract_Azure_output_FRST_18oct.ipynb
     "execution_count": 45,
>>>>>>> bb1b39ac2361ae9f0c2e82b5fd08edc8af96cf75:test/Testing_Area_Extract_Azure_output.ipynb
=======
     "execution_count": 42,
>>>>>>> KLN_working_branch:test/Testing_Area_Extract_Azure_output.ipynb
=======
     "execution_count": 20,
>>>>>>> KLN_working_branch:test/Testing_Area_Extract_Azure_output.ipynb
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD:test/Testing_Area_Extract_Azure_output_FRST_18oct.ipynb
<<<<<<< HEAD:test/Testing_Area_Extract_Azure_output_FRST_18oct.ipynb
    "# just for params\n",
    "tempFinal_v0 = combined_table[np.isin(combined_table.AUC,final_output_auc.loc[0].values.flatten())]\n",
    "tempFinal_v0.index = tempFinal_v0.loc[:,'label-type']\n",
    "tempFinal_v0.iloc[:,:-7]"
=======
    "tempFinal_v0.loc['1']"
>>>>>>> bb1b39ac2361ae9f0c2e82b5fd08edc8af96cf75:test/Testing_Area_Extract_Azure_output.ipynb
=======
    "os.listdir('../../')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.mkdir('../../output')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature sets\n",
    "\n",
    "features_to_use == 0:\n",
    "    listOfFeatures = [\n",
    "                        'pastobs',\n",
    "                        'spread',\n",
    "                        'bidsize',\n",
    "                        'ofrsize',\n",
    "                        'pastreturns',\n",
    "                        'intradaytime'\n",
    "                    ]\n",
    "\n",
    "features_to_use == 1:\n",
    "    listOfFeatures = [\n",
    "                    'pastobs',\n",
    "                    'spread',\n",
    "                    'bidsize',\n",
    "                    'ofrsize',\n",
    "                    'pastreturns',\n",
    "                    'intradaytime',\n",
    "                    'sector'\n",
    "                    ]\n",
    "\n",
    "features_to_use == 2:\n",
    "    listOfFeatures = [\n",
    "                        'pastobs',\n",
    "                        'spread',\n",
    "                        'bidsize',\n",
    "                        'ofrsize',\n",
    "                        'pastreturns',\n",
    "                        'intradaytime',\n",
    "                        'stok',\n",
    "                        'stod',\n",
    "                        'sstod',\n",
    "                        'roc',\n",
    "                        'rsi',\n",
    "                        'atr',\n",
    "                        'cci',\n",
    "                        'dpo',\n",
    "                        'sma',\n",
    "                        'ema',\n",
    "                        'macd',\n",
    "                        'macd_diff',\n",
    "                        'macd_signal',\n",
    "                        'dis5',\n",
    "                        'dis10'\n",
    "                        ]\n",
    "\n",
    "features_to_use == 3: \n",
    "    listOfFeatures = [\n",
    "                    'pastobs',\n",
    "                    'spread',\n",
    "                    'bidsize',\n",
    "                    'ofrsize',\n",
    "                    'pastreturns',\n",
    "                    'intradaytime',\n",
    "                    'stok',\n",
    "                    'stod',\n",
    "                    'sstod',\n",
    "                    'roc',\n",
    "                    'rsi',\n",
    "                    'atr',\n",
    "                    'cci',\n",
    "                    'dpo',\n",
    "                    'sma',\n",
    "                    'ema',\n",
    "                    'macd',\n",
    "                    'macd_diff',\n",
    "                    'macd_signal',\n",
    "                    'dis5',\n",
    "                    'dis10',\n",
    "                    'sector'\n",
    "                    ]"
>>>>>>> KLN_working_branch:test/Testing_Area_Extract_Azure_output.ipynb
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:test/Testing_Area_Extract_Azure_output_FRST_18oct.ipynb
<<<<<<< HEAD:test/Testing_Area_Extract_Azure_output_FRST_18oct.ipynb
<<<<<<< HEAD:test/Testing_Area_Extract_Azure_output_FRST_18oct.ipynb
   "execution_count": 15,
=======
   "execution_count": 46,
>>>>>>> bb1b39ac2361ae9f0c2e82b5fd08edc8af96cf75:test/Testing_Area_Extract_Azure_output.ipynb
=======
   "execution_count": 20,
>>>>>>> KLN_working_branch:test/Testing_Area_Extract_Azure_output.ipynb
=======
   "execution_count": 22,
>>>>>>> KLN_working_branch:test/Testing_Area_Extract_Azure_output.ipynb
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x^1</th>\n",
       "      <th>x^2</th>\n",
       "      <th>x^3</th>\n",
       "      <th>x^4</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pastobs</th>\n",
       "      <td>\\checkmark</td>\n",
       "      <td>\\checkmark</td>\n",
       "      <td>\\checkmark</td>\n",
       "      <td>\\checkmark</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spread</th>\n",
       "      <td>\\checkmark</td>\n",
       "      <td>\\checkmark</td>\n",
       "      <td>\\checkmark</td>\n",
       "      <td>\\checkmark</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bidsize</th>\n",
       "      <td>\\checkmark</td>\n",
       "      <td>\\checkmark</td>\n",
       "      <td>\\checkmark</td>\n",
       "      <td>\\checkmark</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ofrsize</th>\n",
       "      <td>\\checkmark</td>\n",
       "      <td>\\checkmark</td>\n",
       "      <td>\\checkmark</td>\n",
       "      <td>\\checkmark</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pastreturns</th>\n",
       "      <td>\\checkmark</td>\n",
       "      <td>\\checkmark</td>\n",
       "      <td>\\checkmark</td>\n",
       "      <td>\\checkmark</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intradaytime</th>\n",
       "      <td>\\checkmark</td>\n",
       "      <td>\\checkmark</td>\n",
       "      <td>\\checkmark</td>\n",
       "      <td>\\checkmark</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sector</th>\n",
       "      <td></td>\n",
       "      <td>\\checkmark</td>\n",
       "      <td></td>\n",
       "      <td>\\checkmark</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stok</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>\\checkmark</td>\n",
       "      <td>\\checkmark</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stod</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>\\checkmark</td>\n",
       "      <td>\\checkmark</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sstod</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>\\checkmark</td>\n",
       "      <td>\\checkmark</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>\\checkmark</td>\n",
       "      <td>\\checkmark</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rsi</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>\\checkmark</td>\n",
       "      <td>\\checkmark</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>atr</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>\\checkmark</td>\n",
       "      <td>\\checkmark</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cci</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>\\checkmark</td>\n",
       "      <td>\\checkmark</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dpo</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>\\checkmark</td>\n",
       "      <td>\\checkmark</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sma</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>\\checkmark</td>\n",
       "      <td>\\checkmark</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ema</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>\\checkmark</td>\n",
       "      <td>\\checkmark</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macd</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>\\checkmark</td>\n",
       "      <td>\\checkmark</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macd_diff</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>\\checkmark</td>\n",
       "      <td>\\checkmark</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macd_signal</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>\\checkmark</td>\n",
       "      <td>\\checkmark</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dis5</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>\\checkmark</td>\n",
       "      <td>\\checkmark</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dis10</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>\\checkmark</td>\n",
       "      <td>\\checkmark</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     x^1         x^2         x^3         x^4 Description\n",
       "pastobs       \\checkmark  \\checkmark  \\checkmark  \\checkmark            \n",
       "spread        \\checkmark  \\checkmark  \\checkmark  \\checkmark            \n",
       "bidsize       \\checkmark  \\checkmark  \\checkmark  \\checkmark            \n",
       "ofrsize       \\checkmark  \\checkmark  \\checkmark  \\checkmark            \n",
       "pastreturns   \\checkmark  \\checkmark  \\checkmark  \\checkmark            \n",
       "intradaytime  \\checkmark  \\checkmark  \\checkmark  \\checkmark            \n",
       "sector                    \\checkmark              \\checkmark            \n",
       "stok                                  \\checkmark  \\checkmark            \n",
       "stod                                  \\checkmark  \\checkmark            \n",
       "sstod                                 \\checkmark  \\checkmark            \n",
       "roc                                   \\checkmark  \\checkmark            \n",
       "rsi                                   \\checkmark  \\checkmark            \n",
       "atr                                   \\checkmark  \\checkmark            \n",
       "cci                                   \\checkmark  \\checkmark            \n",
       "dpo                                   \\checkmark  \\checkmark            \n",
       "sma                                   \\checkmark  \\checkmark            \n",
       "ema                                   \\checkmark  \\checkmark            \n",
       "macd                                  \\checkmark  \\checkmark            \n",
       "macd_diff                             \\checkmark  \\checkmark            \n",
       "macd_signal                           \\checkmark  \\checkmark            \n",
       "dis5                                  \\checkmark  \\checkmark            \n",
       "dis10                                 \\checkmark  \\checkmark            "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = pd.DataFrame({'x^1':'\\checkmark'},index=[\n",
    "                        'pastobs',\n",
    "                        'spread',\n",
    "                        'bidsize',\n",
    "                        'ofrsize',\n",
    "                        'pastreturns',\n",
    "                        'intradaytime'\n",
    "                    ])\n",
    "\n",
    "x2 = pd.DataFrame({'x^2':'\\checkmark'},index=[\n",
    "                    'pastobs',\n",
    "                    'spread',\n",
    "                    'bidsize',\n",
    "                    'ofrsize',\n",
    "                    'pastreturns',\n",
    "                    'intradaytime',\n",
    "                    'sector'\n",
    "                    ])\n",
    "\n",
    "x3 = pd.DataFrame({'x^3':'\\checkmark'},index=[\n",
    "                        'pastobs',\n",
    "                        'spread',\n",
    "                        'bidsize',\n",
    "                        'ofrsize',\n",
    "                        'pastreturns',\n",
    "                        'intradaytime',\n",
    "                        'stok',\n",
    "                        'stod',\n",
    "                        'sstod',\n",
    "                        'roc',\n",
    "                        'rsi',\n",
    "                        'atr',\n",
    "                        'cci',\n",
    "                        'dpo',\n",
    "                        'sma',\n",
    "                        'ema',\n",
    "                        'macd',\n",
    "                        'macd_diff',\n",
    "                        'macd_signal',\n",
    "                        'dis5',\n",
    "                        'dis10'\n",
    "                        ])\n",
    "\n",
    "x4 = pd.DataFrame({'x^4':'\\checkmark'},index=[\n",
    "                    'pastobs',\n",
    "                    'spread',\n",
    "                    'bidsize',\n",
    "                    'ofrsize',\n",
    "                    'pastreturns',\n",
    "                    'intradaytime',\n",
    "                    'stok',\n",
    "                    'stod',\n",
    "                    'sstod',\n",
    "                    'roc',\n",
    "                    'rsi',\n",
    "                    'atr',\n",
    "                    'cci',\n",
    "                    'dpo',\n",
    "                    'sma',\n",
    "                    'ema',\n",
    "                    'macd',\n",
    "                    'macd_diff',\n",
    "                    'macd_signal',\n",
    "                    'dis5',\n",
    "                    'dis10',\n",
    "                    'sector'\n",
    "                    ])\n",
    "\n",
    "x5 = pd.DataFrame({'Description':''},index=[\n",
    "                    'pastobs',\n",
    "                    'spread',\n",
    "                    'bidsize',\n",
    "                    'ofrsize',\n",
    "                    'pastreturns',\n",
    "                    'intradaytime',\n",
    "                    'stok',\n",
    "                    'stod',\n",
    "                    'sstod',\n",
    "                    'roc',\n",
    "                    'rsi',\n",
    "                    'atr',\n",
    "                    'cci',\n",
    "                    'dpo',\n",
    "                    'sma',\n",
    "                    'ema',\n",
    "                    'macd',\n",
    "                    'macd_diff',\n",
    "                    'macd_signal',\n",
    "                    'dis5',\n",
    "                    'dis10',\n",
    "                    'sector'\n",
    "                    ])\n",
    "\n",
    "exo_sets = pd.concat([x1,x2,x3,x4,x5],axis=1).fillna('')\n",
    "exo_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1224x2880 with 15 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "temp = combined_table[(combined_table.loc[:,'label-type']=='4')&\\\n",
    "                      (combined_table.loc[:,'nn-type']=='ffnn')&\\\n",
    "                      (combined_table.AUC>0.5)]\n",
    "\n",
    "fig,ax = plt.subplots(5,3,figsize=(17,40))\n",
    "font = {'family' : 'normal',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 12}\n",
    "\n",
    "plt.rc('font', **font)\n",
    "# plt.rcParams.update({'font.size': 12})\n",
    "# plt.rcParams.update({'font.weight': 'normal'})\n",
    "k = 0\n",
    "\n",
    "for i in np.arange(5):\n",
    "    for j in np.arange(3):\n",
    "        \n",
    "\n",
    "\n",
    "        if k < len(cols_to_plot):\n",
    "            temp_2 = pd.pivot_table(temp,values='AUC',columns=cols_to_plot[k],index='run_id').reset_index()\n",
    "\n",
    "            # sns.set_theme(style=\"whitegrid\")\n",
    "            # tips = sns.load_dataset(\"tips\")\n",
    "            # ax = sns.violinplot(x=tips[\"total_bill\"])\n",
    "            sns.boxplot(data=temp_2,ax=ax[i,j],color='gray')#,bw='scott'\n",
    "#             ax[i,j].set_xticks(fontsize=12)\n",
    "#             ax[i,j].set_yticks(fontsize=12)\n",
    "            # plt.legend(fontsize=14)\n",
    "            ax[i,j].set_xlabel(temp_2.columns.name,fontsize=12,fontweight='bold')\n",
    "\n",
    "\n",
    "            k +=1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>activation-inner</th>\n",
       "      <th>activation-output</th>\n",
       "      <th>batch-norm</th>\n",
       "      <th>batch-shuffle</th>\n",
       "      <th>batch-size</th>\n",
       "      <th>dropout-ratio</th>\n",
       "      <th>feature-lags</th>\n",
       "      <th>featureset</th>\n",
       "      <th>first-layer-neurons</th>\n",
       "      <th>...</th>\n",
       "      <th>pastobs-in-percentage</th>\n",
       "      <th>pre-processing</th>\n",
       "      <th>second-layer-neurons</th>\n",
       "      <th>id</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Train AUC</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Train Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_253</td>\n",
       "      <td>leakyrelu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3300</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>pow</td>\n",
       "      <td>32</td>\n",
       "      <td>253</td>\n",
       "      <td>0.75162</td>\n",
       "      <td>0.41127</td>\n",
       "      <td>1.38074</td>\n",
       "      <td>0.75160</td>\n",
       "      <td>0.43281</td>\n",
       "      <td>1.31058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>935</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_63</td>\n",
       "      <td>tanh</td>\n",
       "      <td>softmax</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10725</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>quantgau</td>\n",
       "      <td>128</td>\n",
       "      <td>63</td>\n",
       "      <td>0.74679</td>\n",
       "      <td>0.37793</td>\n",
       "      <td>1.45174</td>\n",
       "      <td>0.74672</td>\n",
       "      <td>0.46597</td>\n",
       "      <td>1.27700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_220</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>softmax</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10725</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>pow</td>\n",
       "      <td>64</td>\n",
       "      <td>220</td>\n",
       "      <td>0.74519</td>\n",
       "      <td>0.41424</td>\n",
       "      <td>1.35826</td>\n",
       "      <td>0.74517</td>\n",
       "      <td>0.42545</td>\n",
       "      <td>1.32736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_825</td>\n",
       "      <td>tanh</td>\n",
       "      <td>softmax</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3300</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>stacked</td>\n",
       "      <td>128</td>\n",
       "      <td>825</td>\n",
       "      <td>0.74181</td>\n",
       "      <td>0.41542</td>\n",
       "      <td>1.35494</td>\n",
       "      <td>0.74178</td>\n",
       "      <td>0.41990</td>\n",
       "      <td>1.33571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_52</td>\n",
       "      <td>relu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3300</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>stacked</td>\n",
       "      <td>32</td>\n",
       "      <td>52</td>\n",
       "      <td>0.74012</td>\n",
       "      <td>0.41991</td>\n",
       "      <td>1.34825</td>\n",
       "      <td>0.74011</td>\n",
       "      <td>0.41337</td>\n",
       "      <td>1.35095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_98</td>\n",
       "      <td>leakyrelu</td>\n",
       "      <td>linear</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10725</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>minmax</td>\n",
       "      <td>32</td>\n",
       "      <td>98</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>0.09983</td>\n",
       "      <td>1.40138</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>0.09868</td>\n",
       "      <td>1.42145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_314</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>linear</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3300</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>32</td>\n",
       "      <td>314</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>0.19718</td>\n",
       "      <td>7.92400</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>0.20024</td>\n",
       "      <td>8.09296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_892</td>\n",
       "      <td>leakyrelu</td>\n",
       "      <td>linear</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3300</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>minmax</td>\n",
       "      <td>32</td>\n",
       "      <td>892</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>0.40744</td>\n",
       "      <td>1.43294</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>0.39758</td>\n",
       "      <td>1.45652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_658</td>\n",
       "      <td>relu</td>\n",
       "      <td>linear</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21450</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>stacked</td>\n",
       "      <td>128</td>\n",
       "      <td>658</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.08349</td>\n",
       "      <td>1.35884</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.08467</td>\n",
       "      <td>1.38672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>HD_81ace623-e09b-4393-8a5e-131ea8749a35_834</td>\n",
       "      <td>leakyrelu</td>\n",
       "      <td>linear</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10725</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>64</td>\n",
       "      <td>834</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.40412</td>\n",
       "      <td>1.47544</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.39803</td>\n",
       "      <td>1.47696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          run_id activation-inner  \\\n",
       "746  HD_81ace623-e09b-4393-8a5e-131ea8749a35_253        leakyrelu   \n",
       "935   HD_81ace623-e09b-4393-8a5e-131ea8749a35_63             tanh   \n",
       "779  HD_81ace623-e09b-4393-8a5e-131ea8749a35_220          sigmoid   \n",
       "174  HD_81ace623-e09b-4393-8a5e-131ea8749a35_825             tanh   \n",
       "947   HD_81ace623-e09b-4393-8a5e-131ea8749a35_52             relu   \n",
       "..                                           ...              ...   \n",
       "901   HD_81ace623-e09b-4393-8a5e-131ea8749a35_98        leakyrelu   \n",
       "684  HD_81ace623-e09b-4393-8a5e-131ea8749a35_314          sigmoid   \n",
       "107  HD_81ace623-e09b-4393-8a5e-131ea8749a35_892        leakyrelu   \n",
       "342  HD_81ace623-e09b-4393-8a5e-131ea8749a35_658             relu   \n",
       "165  HD_81ace623-e09b-4393-8a5e-131ea8749a35_834        leakyrelu   \n",
       "\n",
       "    activation-output batch-norm batch-shuffle batch-size dropout-ratio  \\\n",
       "746           softmax          0             1       3300             0   \n",
       "935           softmax          1             0      10725             0   \n",
       "779           softmax          1             1      10725           0.2   \n",
       "174           softmax          1             1       3300           0.4   \n",
       "947           softmax          1             1       3300           0.2   \n",
       "..                ...        ...           ...        ...           ...   \n",
       "901            linear          0             0      10725           0.3   \n",
       "684            linear          0             1       3300           0.1   \n",
       "107            linear          0             1       3300           0.1   \n",
       "342            linear          0             1      21450           0.5   \n",
       "165            linear          0             1      10725           0.3   \n",
       "\n",
       "    feature-lags featureset first-layer-neurons  ... pastobs-in-percentage  \\\n",
       "746            1          3                  64  ...                     1   \n",
       "935            5          1                  64  ...                     1   \n",
       "779            3          2                 128  ...                     0   \n",
       "174            5          3                 128  ...                     0   \n",
       "947            1          2                  64  ...                     0   \n",
       "..           ...        ...                 ...  ...                   ...   \n",
       "901            0          0                  32  ...                     0   \n",
       "684            1          0                  64  ...                     1   \n",
       "107            0          0                  32  ...                     1   \n",
       "342            1          0                  64  ...                     1   \n",
       "165            0          2                  32  ...                     0   \n",
       "\n",
       "    pre-processing second-layer-neurons   id      AUC Accuracy     Loss  \\\n",
       "746            pow                   32  253  0.75162  0.41127  1.38074   \n",
       "935       quantgau                  128   63  0.74679  0.37793  1.45174   \n",
       "779            pow                   64  220  0.74519  0.41424  1.35826   \n",
       "174        stacked                  128  825  0.74181  0.41542  1.35494   \n",
       "947        stacked                   32   52  0.74012  0.41991  1.34825   \n",
       "..             ...                  ...  ...      ...      ...      ...   \n",
       "901         minmax                   32   98  0.00009  0.09983  1.40138   \n",
       "684           None                   32  314  0.00008  0.19718  7.92400   \n",
       "107         minmax                   32  892  0.00004  0.40744  1.43294   \n",
       "342        stacked                  128  658  0.00001  0.08349  1.35884   \n",
       "165           None                   64  834  0.00001  0.40412  1.47544   \n",
       "\n",
       "    Train AUC Train Accuracy  Train Loss  \n",
       "746   0.75160        0.43281     1.31058  \n",
       "935   0.74672        0.46597     1.27700  \n",
       "779   0.74517        0.42545     1.32736  \n",
       "174   0.74178        0.41990     1.33571  \n",
       "947   0.74011        0.41337     1.35095  \n",
       "..        ...            ...         ...  \n",
       "901   0.00009        0.09868     1.42145  \n",
       "684   0.00008        0.20024     8.09296  \n",
       "107   0.00004        0.39758     1.45652  \n",
       "342   0.00001        0.08467     1.38672  \n",
       "165   0.00001        0.39803     1.47696  \n",
       "\n",
       "[96 rows x 25 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_table[(combined_table.loc[:,'label-type']=='4')&(combined_table.loc[:,'nn-type']=='ffnn')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in combined_table['nn-type'].unique():\n",
    "    for j in combined_table['label-type'].unique():\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['0', '1', '2', '3', '4'], dtype=object),\n",
       " array([ 85, 119,  99,  92,  96], dtype=int64))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt, ss = np.unique(combined_table[combined_table['nn-type']=='ffnn']['label-type'],return_counts=True)\n",
    "tt, ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['0', '1', '2', '3', '4'], dtype=object),\n",
       " array([111, 108, 115,  84,  91], dtype=int64))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t,s = np.unique(combined_table[combined_table['nn-type']=='lstm']['label-type'],return_counts=True)\n",
    "t,s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Archieve',\n",
       " 'hyperparameters_lr_v1_1.txt',\n",
       " 'hyperparameters_lr_v2_4.txt',\n",
       " 'hyperparameters_lr_v3_1.txt',\n",
       " 'hyperparameters_nn_v4.txt',\n",
       " 'metrics_lr_v1_1.txt',\n",
       " 'metrics_lr_v2_4.txt',\n",
       " 'metrics_lr_v3_1.txt',\n",
       " 'metrics_nn_v4.txt']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('../AzureML/Output_from_cloud')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperfiles_lr = [i for i in os.listdir('../AzureML/Output_from_cloud') if ('hyper' in i) & ('lr' in i)]\n",
    "metricfiles_lr = [i for i in os.listdir('../AzureML/Output_from_cloud') if ('metric' in i) & ('lr' in i)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hyperparameters_lr_v1_1.txt',\n",
       " 'hyperparameters_lr_v2_4.txt',\n",
       " 'hyperparameters_lr_v3_1.txt']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperfiles_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line 380 in file <_io.TextIOWrapper name='../AzureML/Output_from_cloud/hyperparameters_lr_v1_1.txt' mode='r' encoding='cp1252'> caused an error, which was neglected\n",
      "Line 102 in file <_io.TextIOWrapper name='../AzureML/Output_from_cloud/hyperparameters_lr_v2_4.txt' mode='r' encoding='cp1252'> caused an error, which was neglected\n",
      "Line 170 in file <_io.TextIOWrapper name='../AzureML/Output_from_cloud/hyperparameters_lr_v3_1.txt' mode='r' encoding='cp1252'> caused an error, which was neglected\n"
     ]
    }
   ],
   "source": [
    "for j,file in enumerate(hyperfiles_lr):\n",
    "    \n",
    "    if j >= 0:\n",
    "        \n",
    "        ### Reading in the file\n",
    "\n",
    "        with open('../AzureML/Output_from_cloud/'+hyperfiles_lr[j],'r') as file:\n",
    "            content = file.readlines()\n",
    "\n",
    "        ## Going over each line in the text file\n",
    "        for a in np.arange(len(content)):\n",
    "\n",
    "            ## Split the lines on tabs\n",
    "            temp_parameters = re.split('[\\t]',content[a])[1]\n",
    "\n",
    "            ## Basic string cleaning, i.e. removing redundant characters\n",
    "#             test = [re.split(': ',i.strip()) for i in re.split(',',temp_parameters.replace('{','')\\\n",
    "#                                                                                .replace('}','')\\\n",
    "#                                                                                .replace('\\n','')\\\n",
    "#                                                                                .replace('\"',''))]\n",
    "            test = [re.split(': ',i.strip()) for i in re.split(',',temp_parameters.replace('{','')\\\n",
    "                                                                       .replace('}','')\\\n",
    "                                                                       .replace('\\n','')\\\n",
    "                                                                       .replace('\"','')\\\n",
    "                                                                       .replace('--','')\\\n",
    "                                                                       .replace('\\'',''))]\n",
    "\n",
    "            ## Output of test is a list of lists, where each sublist holds the name of a model variable and its value.\n",
    "            ## We create a dictornary to hold all model variables, making it easy to add the observation to the dataframe.\n",
    "            try:\n",
    "                test = {i[0]:i[1] for i in test}\n",
    "\n",
    "                # Constructing the dataframe\n",
    "                if (a == 0)&(j==0):\n",
    "                    parameters_lr = pd.DataFrame(test,index=[re.split('[\\t]',content[a])[0]])\n",
    "\n",
    "                else:\n",
    "\n",
    "                    parameters_lr.loc[re.split('[\\t]',content[a])[0]] = pd.Series(test)\n",
    "            except:\n",
    "                print('Line %i in file %s caused an error, which was neglected' % (a,file))\n",
    "        \n",
    "#         lastone = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch-shuffle</th>\n",
       "      <th>batch-size</th>\n",
       "      <th>feature-lags</th>\n",
       "      <th>featureset</th>\n",
       "      <th>l2-penalty</th>\n",
       "      <th>l2-type</th>\n",
       "      <th>label-type</th>\n",
       "      <th>learning-rate</th>\n",
       "      <th>loss-from-logits</th>\n",
       "      <th>n-epochs</th>\n",
       "      <th>pastobs-in-percentage</th>\n",
       "      <th>pre-processing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_379</th>\n",
       "      <td>0</td>\n",
       "      <td>3300</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>minmax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_377</th>\n",
       "      <td>1</td>\n",
       "      <td>3300</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>std</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_378</th>\n",
       "      <td>0</td>\n",
       "      <td>21450</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>10000000000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>minmax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_375</th>\n",
       "      <td>1</td>\n",
       "      <td>10725</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>minmax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_376</th>\n",
       "      <td>1</td>\n",
       "      <td>21450</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>pow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_9</th>\n",
       "      <td>0</td>\n",
       "      <td>3300</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>minmax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_6</th>\n",
       "      <td>0</td>\n",
       "      <td>10725</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>stacked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_10</th>\n",
       "      <td>0</td>\n",
       "      <td>10725</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>pow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_15</th>\n",
       "      <td>0</td>\n",
       "      <td>10725</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>std</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_11</th>\n",
       "      <td>0</td>\n",
       "      <td>21450</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>stacked</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>652 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            batch-shuffle batch-size  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_379             0       3300   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_377             1       3300   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_378             0      21450   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_375             1      10725   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_376             1      21450   \n",
       "...                                                   ...        ...   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_9               0       3300   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_6               0      10725   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_10              0      10725   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_15              0      10725   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_11              0      21450   \n",
       "\n",
       "                                            feature-lags featureset  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_379            5          2   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_377            1          3   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_378            3          2   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_375            3          3   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_376            0          1   \n",
       "...                                                  ...        ...   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_9              5          3   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_6              0          2   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_10             0          1   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_15             0          3   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_11             0          3   \n",
       "\n",
       "                                              l2-penalty l2-type label-type  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_379         1000       0          1   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_377       0.0001       5          2   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_378  10000000000       4          0   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_375        0.001       1          4   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_376        0.001       6          4   \n",
       "...                                                  ...     ...        ...   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_9              1       0          0   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_6            100       2          4   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_10          0.01       5          0   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_15          1000       4          0   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_11         0.001       3          3   \n",
       "\n",
       "                                            learning-rate loss-from-logits  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_379         0.001                0   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_377        0.0001                0   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_378        0.0001                1   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_375          0.01                1   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_376           0.1                0   \n",
       "...                                                   ...              ...   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_9           0.001                1   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_6            0.01                1   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_10           0.01                0   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_15         0.0001                0   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_11         0.0001                0   \n",
       "\n",
       "                                            n-epochs pastobs-in-percentage  \\\n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_379      150                     0   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_377      150                     1   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_378      150                     1   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_375      150                     0   \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_376      150                     1   \n",
       "...                                              ...                   ...   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_9        150                     1   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_6        150                     0   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_10       150                     1   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_15       150                     1   \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_11       150                     0   \n",
       "\n",
       "                                            pre-processing  \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_379         minmax  \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_377            std  \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_378         minmax  \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_375         minmax  \n",
       "HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_376            pow  \n",
       "...                                                    ...  \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_9           minmax  \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_6          stacked  \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_10             pow  \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_15             std  \n",
       "HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_11         stacked  \n",
       "\n",
       "[652 rows x 12 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j,file in enumerate(metricfiles_lr):\n",
    "    \n",
    "    if j >= 0:\n",
    "        \n",
    "        ## Readidng in the file\n",
    "        with open('../AzureML/Output_from_cloud/'+metricfiles_lr[j],'r') as file:\n",
    "            content = file.readlines()\n",
    "\n",
    "        ## Containers\n",
    "        t11 = []\n",
    "        t12 = []\n",
    "        t13 = []\n",
    "\n",
    "        t21 = []\n",
    "        t22 = []\n",
    "        t23 = []\n",
    "\n",
    "        ## Going over each line\n",
    "        for i in np.arange(len(content)):#\n",
    "\n",
    "            ## Split each line on tabs\n",
    "            temp = re.split('\\t',content[i].replace('\\n',''))\n",
    "\n",
    "            ## There are two types of observations in the text file; 1. final metrics of those models which where not stoppe early\n",
    "            ## and 2. a time series of a metric for each model.\n",
    "\n",
    "            ## If the length of the last element, in a line, is less than 50 (because it is just a number, i.e. final metric)\n",
    "            ## It stored separately for the time series.\n",
    "            if len(temp[2]) < 50:\n",
    "\n",
    "                t11.append(temp[0])\n",
    "                t12.append(temp[1])\n",
    "                t13.append(temp[2])\n",
    "\n",
    "            ## Time series\n",
    "            else:\n",
    "\n",
    "                container = np.zeros(155)\n",
    "                temp1 = [float(j.strip()) if j.strip() !=\"'NaN'\" else 0 for j in re.split(',',temp[2].replace('[','').replace(']',''))]\n",
    "\n",
    "                container[0:len(temp1)] = temp1\n",
    "                container[len(temp1):] = temp1[-1]\n",
    "\n",
    "                t21.append(temp[0])\n",
    "                t22.append(temp[1])\n",
    "                t23.append(container)        \n",
    "\n",
    "        ## Storing the time series in a dataframe\n",
    "        arrays = [t21,t22]\n",
    "        tuples = list(zip(*arrays))\n",
    "        if j == 0:\n",
    "            \n",
    "            runningMetrics_lr = pd.DataFrame(np.array(t23),\n",
    "                                              index=pd.MultiIndex.from_tuples(tuples),\n",
    "                                              columns = [np.arange(155).astype(str)]\n",
    "                                             )\n",
    "        else:\n",
    "            temp_1 = pd.DataFrame(np.array(t23),\n",
    "                                  index=pd.MultiIndex.from_tuples(tuples),\n",
    "                                  columns = [np.arange(155).astype(str)])\n",
    "            runningMetrics_lr = pd.concat([runningMetrics_lr,temp_1])\n",
    "        ## Storing the final metrics in a dataframe.\n",
    "        arrays = [t11,t12]\n",
    "        tuples = list(zip(*arrays))\n",
    "        if j == 0:\n",
    "            \n",
    "            finalMetrics_lr = pd.DataFrame(t13,index = pd.MultiIndex.from_tuples(tuples),columns = ['size'])\n",
    "        else:\n",
    "            \n",
    "            temp = pd.DataFrame(t13,index = pd.MultiIndex.from_tuples(tuples),columns = ['size'])\n",
    "            finalMetrics_lr = pd.concat([finalMetrics_lr,temp],axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attaching the last observation of each model, for each metric, to the parameters of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>batch-shuffle</th>\n",
       "      <th>batch-size</th>\n",
       "      <th>feature-lags</th>\n",
       "      <th>featureset</th>\n",
       "      <th>l2-penalty</th>\n",
       "      <th>l2-type</th>\n",
       "      <th>label-type</th>\n",
       "      <th>learning-rate</th>\n",
       "      <th>loss-from-logits</th>\n",
       "      <th>n-epochs</th>\n",
       "      <th>pastobs-in-percentage</th>\n",
       "      <th>pre-processing</th>\n",
       "      <th>id</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Train AUC</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Train Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_58</td>\n",
       "      <td>1</td>\n",
       "      <td>10725</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>quantgau</td>\n",
       "      <td>d62b1e6b8d95_58</td>\n",
       "      <td>0.770243</td>\n",
       "      <td>0.609699</td>\n",
       "      <td>0.899017</td>\n",
       "      <td>0.770233</td>\n",
       "      <td>0.607270</td>\n",
       "      <td>0.892077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_322</td>\n",
       "      <td>1</td>\n",
       "      <td>3300</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>pow</td>\n",
       "      <td>d62b1e6b8d95_322</td>\n",
       "      <td>0.769295</td>\n",
       "      <td>0.609793</td>\n",
       "      <td>1.025276</td>\n",
       "      <td>0.769279</td>\n",
       "      <td>0.607994</td>\n",
       "      <td>1.026104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_109</td>\n",
       "      <td>0</td>\n",
       "      <td>3300</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>pow</td>\n",
       "      <td>d62b1e6b8d95_109</td>\n",
       "      <td>0.765728</td>\n",
       "      <td>0.609536</td>\n",
       "      <td>0.899042</td>\n",
       "      <td>0.765704</td>\n",
       "      <td>0.607570</td>\n",
       "      <td>0.898071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_98</td>\n",
       "      <td>1</td>\n",
       "      <td>3300</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>minmax</td>\n",
       "      <td>d62b1e6b8d95_98</td>\n",
       "      <td>0.758545</td>\n",
       "      <td>0.609978</td>\n",
       "      <td>0.906770</td>\n",
       "      <td>0.758532</td>\n",
       "      <td>0.605583</td>\n",
       "      <td>0.908269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_153</td>\n",
       "      <td>1</td>\n",
       "      <td>3300</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>std</td>\n",
       "      <td>b36f03f5d186_153</td>\n",
       "      <td>0.757047</td>\n",
       "      <td>0.608576</td>\n",
       "      <td>1.034854</td>\n",
       "      <td>0.757034</td>\n",
       "      <td>0.606462</td>\n",
       "      <td>1.032217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>HD_914f915c-2cac-473e-bea5-c26e4c83673c_86</td>\n",
       "      <td>0</td>\n",
       "      <td>10725</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>quantgau</td>\n",
       "      <td>c26e4c83673c_86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>HD_914f915c-2cac-473e-bea5-c26e4c83673c_84</td>\n",
       "      <td>0</td>\n",
       "      <td>10725</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>minmax</td>\n",
       "      <td>c26e4c83673c_84</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>HD_914f915c-2cac-473e-bea5-c26e4c83673c_68</td>\n",
       "      <td>1</td>\n",
       "      <td>10725</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>quantgau</td>\n",
       "      <td>c26e4c83673c_68</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>HD_914f915c-2cac-473e-bea5-c26e4c83673c_48</td>\n",
       "      <td>0</td>\n",
       "      <td>3300</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>stacked</td>\n",
       "      <td>c26e4c83673c_48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>HD_914f915c-2cac-473e-bea5-c26e4c83673c_40</td>\n",
       "      <td>1</td>\n",
       "      <td>21450</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>minmax</td>\n",
       "      <td>c26e4c83673c_40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>652 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          run_id batch-shuffle batch-size  \\\n",
       "321   HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_58             1      10725   \n",
       "57   HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_322             1       3300   \n",
       "269  HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_109             0       3300   \n",
       "281   HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_98             1       3300   \n",
       "498  HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_153             1       3300   \n",
       "..                                           ...           ...        ...   \n",
       "396   HD_914f915c-2cac-473e-bea5-c26e4c83673c_86             0      10725   \n",
       "399   HD_914f915c-2cac-473e-bea5-c26e4c83673c_84             0      10725   \n",
       "405   HD_914f915c-2cac-473e-bea5-c26e4c83673c_68             1      10725   \n",
       "433   HD_914f915c-2cac-473e-bea5-c26e4c83673c_48             0       3300   \n",
       "448   HD_914f915c-2cac-473e-bea5-c26e4c83673c_40             1      21450   \n",
       "\n",
       "    feature-lags featureset l2-penalty l2-type label-type learning-rate  \\\n",
       "321            5          3     0.0001       0          2          0.01   \n",
       "57             5          2     0.0001       6          2         0.001   \n",
       "269            5          1     0.0001       0          2         0.001   \n",
       "281            1          0      0.001       0          2           0.1   \n",
       "498            5          3     0.0001       3          2         0.001   \n",
       "..           ...        ...        ...     ...        ...           ...   \n",
       "396            3          0         10       2          4          0.01   \n",
       "399            0          3      0.001       3          3          0.01   \n",
       "405            5          2        0.1       0          3         0.001   \n",
       "433            0          3      0.001       3          3          0.01   \n",
       "448            5          0       0.01       2          0        0.0001   \n",
       "\n",
       "    loss-from-logits n-epochs pastobs-in-percentage pre-processing  \\\n",
       "321                0      150                     0       quantgau   \n",
       "57                 0      150                     1            pow   \n",
       "269                0      150                     0            pow   \n",
       "281                0      150                     1         minmax   \n",
       "498                0      150                     0            std   \n",
       "..               ...      ...                   ...            ...   \n",
       "396                0      150                     0       quantgau   \n",
       "399                0      150                     1         minmax   \n",
       "405                1      150                     0       quantgau   \n",
       "433                0      150                     0        stacked   \n",
       "448                0      150                     0         minmax   \n",
       "\n",
       "                   id       AUC  Accuracy      Loss  Train AUC  \\\n",
       "321   d62b1e6b8d95_58  0.770243  0.609699  0.899017   0.770233   \n",
       "57   d62b1e6b8d95_322  0.769295  0.609793  1.025276   0.769279   \n",
       "269  d62b1e6b8d95_109  0.765728  0.609536  0.899042   0.765704   \n",
       "281   d62b1e6b8d95_98  0.758545  0.609978  0.906770   0.758532   \n",
       "498  b36f03f5d186_153  0.757047  0.608576  1.034854   0.757034   \n",
       "..                ...       ...       ...       ...        ...   \n",
       "396   c26e4c83673c_86       NaN       NaN       NaN        NaN   \n",
       "399   c26e4c83673c_84       NaN       NaN       NaN        NaN   \n",
       "405   c26e4c83673c_68       NaN       NaN       NaN        NaN   \n",
       "433   c26e4c83673c_48       NaN       NaN       NaN        NaN   \n",
       "448   c26e4c83673c_40       NaN       NaN       NaN        NaN   \n",
       "\n",
       "     Train Accuracy  Train Loss  \n",
       "321        0.607270    0.892077  \n",
       "57         0.607994    1.026104  \n",
       "269        0.607570    0.898071  \n",
       "281        0.605583    0.908269  \n",
       "498        0.606462    1.032217  \n",
       "..              ...         ...  \n",
       "396             NaN         NaN  \n",
       "399             NaN         NaN  \n",
       "405             NaN         NaN  \n",
       "433             NaN         NaN  \n",
       "448             NaN         NaN  \n",
       "\n",
       "[652 rows x 20 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Resetting indcies and rename columns\n",
    "runningMetrics_lr2 = runningMetrics_lr.reset_index().rename(columns={'level_0':'run_id','level_1':'metric'})\n",
    "runningMetrics_lr2.columns = runningMetrics_lr2.columns.get_level_values(0)\n",
    "\n",
    "## Adding a column of short ids, to merge on.\n",
    "runningMetrics_lr2['id'] = [re.split('-',i)[-1] for i in runningMetrics_lr2.run_id] #np.arange(runningMetrics_lr2.shape[0]).astype(str)#\n",
    "runningMetrics_lr2\n",
    "\n",
    "# ## Creating a table, having the short id in the rows and the last observation for each metric in the columns. \n",
    "table_lr = pd.pivot_table(runningMetrics_lr2[['run_id','metric','154','id']],index='id',columns=['metric'])\n",
    "table_lr.columns = table_lr.columns.get_level_values(1)\n",
    "table_lr = table_lr.round(7).reset_index()\n",
    "table_lr\n",
    "\n",
    "## Preparing the parameter dataframe.\n",
    "parameters_lr2 = parameters_lr.reset_index().rename(columns={'index':'run_id'})\n",
    "\n",
    "## Setting short ID\n",
    "parameters_lr2['id'] = [re.split('-',i)[-1] for i in parameters_lr2.run_id] #np.arange(parameters_lr2.shape[0]).astype(str) #[re.split('_',i)[-1] for i in parameters_lr.run_id]\n",
    "\n",
    "## Creating the combined table\n",
    "combined_table_lr = parameters_lr2.merge(table_lr,\n",
    "                                     on = 'id',\n",
    "                                     how='left').sort_values('AUC',ascending=False)\n",
    "combined_table_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>batch-shuffle</th>\n",
       "      <th>batch-size</th>\n",
       "      <th>feature-lags</th>\n",
       "      <th>featureset</th>\n",
       "      <th>l2-penalty</th>\n",
       "      <th>l2-type</th>\n",
       "      <th>label-type</th>\n",
       "      <th>learning-rate</th>\n",
       "      <th>loss-from-logits</th>\n",
       "      <th>n-epochs</th>\n",
       "      <th>pastobs-in-percentage</th>\n",
       "      <th>pre-processing</th>\n",
       "      <th>id</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Train AUC</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Train Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>HD_914f915c-2cac-473e-bea5-c26e4c83673c_97</td>\n",
       "      <td>1</td>\n",
       "      <td>21450</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>10000000000</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>std</td>\n",
       "      <td>c26e4c83673c_97</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>HD_914f915c-2cac-473e-bea5-c26e4c83673c_90</td>\n",
       "      <td>1</td>\n",
       "      <td>21450</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>std</td>\n",
       "      <td>c26e4c83673c_90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>HD_914f915c-2cac-473e-bea5-c26e4c83673c_100</td>\n",
       "      <td>1</td>\n",
       "      <td>21450</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>std</td>\n",
       "      <td>c26e4c83673c_100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>HD_914f915c-2cac-473e-bea5-c26e4c83673c_95</td>\n",
       "      <td>1</td>\n",
       "      <td>10725</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>10000</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>c26e4c83673c_95</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>HD_914f915c-2cac-473e-bea5-c26e4c83673c_93</td>\n",
       "      <td>0</td>\n",
       "      <td>10725</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>std</td>\n",
       "      <td>c26e4c83673c_93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>HD_914f915c-2cac-473e-bea5-c26e4c83673c_82</td>\n",
       "      <td>1</td>\n",
       "      <td>21450</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10000</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>stacked</td>\n",
       "      <td>c26e4c83673c_82</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>HD_914f915c-2cac-473e-bea5-c26e4c83673c_86</td>\n",
       "      <td>0</td>\n",
       "      <td>10725</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>quantgau</td>\n",
       "      <td>c26e4c83673c_86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>HD_914f915c-2cac-473e-bea5-c26e4c83673c_84</td>\n",
       "      <td>0</td>\n",
       "      <td>10725</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>minmax</td>\n",
       "      <td>c26e4c83673c_84</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>HD_914f915c-2cac-473e-bea5-c26e4c83673c_68</td>\n",
       "      <td>1</td>\n",
       "      <td>10725</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>quantgau</td>\n",
       "      <td>c26e4c83673c_68</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>HD_914f915c-2cac-473e-bea5-c26e4c83673c_48</td>\n",
       "      <td>0</td>\n",
       "      <td>3300</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>stacked</td>\n",
       "      <td>c26e4c83673c_48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>HD_914f915c-2cac-473e-bea5-c26e4c83673c_40</td>\n",
       "      <td>1</td>\n",
       "      <td>21450</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>minmax</td>\n",
       "      <td>c26e4c83673c_40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          run_id batch-shuffle batch-size  \\\n",
       "385   HD_914f915c-2cac-473e-bea5-c26e4c83673c_97             1      21450   \n",
       "388   HD_914f915c-2cac-473e-bea5-c26e4c83673c_90             1      21450   \n",
       "389  HD_914f915c-2cac-473e-bea5-c26e4c83673c_100             1      21450   \n",
       "391   HD_914f915c-2cac-473e-bea5-c26e4c83673c_95             1      10725   \n",
       "392   HD_914f915c-2cac-473e-bea5-c26e4c83673c_93             0      10725   \n",
       "395   HD_914f915c-2cac-473e-bea5-c26e4c83673c_82             1      21450   \n",
       "396   HD_914f915c-2cac-473e-bea5-c26e4c83673c_86             0      10725   \n",
       "399   HD_914f915c-2cac-473e-bea5-c26e4c83673c_84             0      10725   \n",
       "405   HD_914f915c-2cac-473e-bea5-c26e4c83673c_68             1      10725   \n",
       "433   HD_914f915c-2cac-473e-bea5-c26e4c83673c_48             0       3300   \n",
       "448   HD_914f915c-2cac-473e-bea5-c26e4c83673c_40             1      21450   \n",
       "\n",
       "    feature-lags featureset   l2-penalty l2-type label-type learning-rate  \\\n",
       "385            5          2  10000000000       3          2         0.001   \n",
       "388            1          3        0.001       0          3           0.1   \n",
       "389            3          1         1000       5          1         0.001   \n",
       "391            5          3        10000       3          4          0.01   \n",
       "392            1          3        10000       0          1           0.1   \n",
       "395            1          3        10000       0          4        0.0001   \n",
       "396            3          0           10       2          4          0.01   \n",
       "399            0          3        0.001       3          3          0.01   \n",
       "405            5          2          0.1       0          3         0.001   \n",
       "433            0          3        0.001       3          3          0.01   \n",
       "448            5          0         0.01       2          0        0.0001   \n",
       "\n",
       "    loss-from-logits n-epochs pastobs-in-percentage pre-processing  \\\n",
       "385                0      150                     1            std   \n",
       "388                0      150                     0            std   \n",
       "389                0      150                     0            std   \n",
       "391                0      150                     0           None   \n",
       "392                1      150                     0            std   \n",
       "395                0      150                     1        stacked   \n",
       "396                0      150                     0       quantgau   \n",
       "399                0      150                     1         minmax   \n",
       "405                1      150                     0       quantgau   \n",
       "433                0      150                     0        stacked   \n",
       "448                0      150                     0         minmax   \n",
       "\n",
       "                   id  AUC  Accuracy  Loss  Train AUC  Train Accuracy  \\\n",
       "385   c26e4c83673c_97  NaN       NaN   NaN        NaN             NaN   \n",
       "388   c26e4c83673c_90  NaN       NaN   NaN        NaN             NaN   \n",
       "389  c26e4c83673c_100  NaN       NaN   NaN        NaN             NaN   \n",
       "391   c26e4c83673c_95  NaN       NaN   NaN        NaN             NaN   \n",
       "392   c26e4c83673c_93  NaN       NaN   NaN        NaN             NaN   \n",
       "395   c26e4c83673c_82  NaN       NaN   NaN        NaN             NaN   \n",
       "396   c26e4c83673c_86  NaN       NaN   NaN        NaN             NaN   \n",
       "399   c26e4c83673c_84  NaN       NaN   NaN        NaN             NaN   \n",
       "405   c26e4c83673c_68  NaN       NaN   NaN        NaN             NaN   \n",
       "433   c26e4c83673c_48  NaN       NaN   NaN        NaN             NaN   \n",
       "448   c26e4c83673c_40  NaN       NaN   NaN        NaN             NaN   \n",
       "\n",
       "     Train Loss  \n",
       "385         NaN  \n",
       "388         NaN  \n",
       "389         NaN  \n",
       "391         NaN  \n",
       "392         NaN  \n",
       "395         NaN  \n",
       "396         NaN  \n",
       "399         NaN  \n",
       "405         NaN  \n",
       "433         NaN  \n",
       "448         NaN  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## How many NaN rows?\n",
    "print(len(combined_table_lr[combined_table_lr.isnull().any(axis=1)]))\n",
    "# 14 in total: 12 from run 881, 1 (last child run) from run 985 , 1 (last child run) from run 453\n",
    "# HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_380 doesn't exist in the experiment window in Azure, looks like it was initialised but not run (hyperparams file has it, metrics file does not)\n",
    "# HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_170 doesn't exist in the experiment window in Azure, looks like it was initialised but not run (hyperparams file has it, metrics file does not)\n",
    "# HD_914f915c-2cac-473e-bea5-c26e4c83673c has 11x NaNs because they failed (but metrics file does have all except _84! so they are included)\n",
    "# the 12 missed runs seems to be an error\n",
    "combined_table_lr[combined_table_lr.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating a top-X table for each label-type of a given metric, here AUC.\n",
    "temp_auc_lr = pd.pivot_table(combined_table_lr[['label-type','AUC','id']],index='id',columns='label-type')\n",
    "temp_acc_lr = pd.pivot_table(combined_table_lr[['label-type','Accuracy','id']],index='id',columns='label-type')\n",
    "\n",
    "## Final output - AUC\n",
    "final_output_auc_lr = pd.DataFrame(np.sort(temp_auc_lr.fillna(0).values,\n",
    "                             axis=0)[::-1],\n",
    "                             columns=temp_auc_lr.columns.get_level_values(1)).loc[0:10]\n",
    "## Final output - Accuracy\n",
    "final_output_acc_lr = pd.DataFrame(np.sort(temp_acc_lr.fillna(0).values,\n",
    "                             axis=0)[::-1],\n",
    "                             columns=temp_acc_lr.columns.get_level_values(1))#.loc[0:10]\n",
    "# final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>run_id</th>\n",
       "      <th>batch-shuffle</th>\n",
       "      <th>batch-size</th>\n",
       "      <th>feature-lags</th>\n",
       "      <th>featureset</th>\n",
       "      <th>l2-penalty</th>\n",
       "      <th>l2-type</th>\n",
       "      <th>label-type</th>\n",
       "      <th>learning-rate</th>\n",
       "      <th>...</th>\n",
       "      <th>n-epochs</th>\n",
       "      <th>pastobs-in-percentage</th>\n",
       "      <th>pre-processing</th>\n",
       "      <th>id</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Train AUC</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Train Loss</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label-type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>321</td>\n",
       "      <td>HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_58</td>\n",
       "      <td>1</td>\n",
       "      <td>10725</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>quantgau</td>\n",
       "      <td>d62b1e6b8d95_58</td>\n",
       "      <td>0.770243</td>\n",
       "      <td>0.609699</td>\n",
       "      <td>0.899017</td>\n",
       "      <td>0.770233</td>\n",
       "      <td>0.607270</td>\n",
       "      <td>0.892077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>285</td>\n",
       "      <td>HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_94</td>\n",
       "      <td>1</td>\n",
       "      <td>10725</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>10000000000</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>minmax</td>\n",
       "      <td>d62b1e6b8d95_94</td>\n",
       "      <td>0.724517</td>\n",
       "      <td>0.412573</td>\n",
       "      <td>42711.261357</td>\n",
       "      <td>0.724506</td>\n",
       "      <td>0.408811</td>\n",
       "      <td>9438.476361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>459</td>\n",
       "      <td>HD_914f915c-2cac-473e-bea5-c26e4c83673c_21</td>\n",
       "      <td>1</td>\n",
       "      <td>21450</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10000000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001</td>\n",
       "      <td>...</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>pow</td>\n",
       "      <td>c26e4c83673c_21</td>\n",
       "      <td>0.638079</td>\n",
       "      <td>0.299720</td>\n",
       "      <td>1.521505</td>\n",
       "      <td>0.638052</td>\n",
       "      <td>0.309349</td>\n",
       "      <td>1.511623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>358</td>\n",
       "      <td>HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_21</td>\n",
       "      <td>1</td>\n",
       "      <td>3300</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>...</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>stacked</td>\n",
       "      <td>d62b1e6b8d95_21</td>\n",
       "      <td>0.615782</td>\n",
       "      <td>0.421687</td>\n",
       "      <td>1.084780</td>\n",
       "      <td>0.615771</td>\n",
       "      <td>0.427520</td>\n",
       "      <td>1.084089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>638</td>\n",
       "      <td>HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_7</td>\n",
       "      <td>1</td>\n",
       "      <td>3300</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>stacked</td>\n",
       "      <td>b36f03f5d186_7</td>\n",
       "      <td>0.580920</td>\n",
       "      <td>0.547298</td>\n",
       "      <td>0.676906</td>\n",
       "      <td>0.580908</td>\n",
       "      <td>0.553431</td>\n",
       "      <td>0.676053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            index                                      run_id batch-shuffle  \\\n",
       "label-type                                                                    \n",
       "2             321  HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_58             1   \n",
       "4             285  HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_94             1   \n",
       "3             459  HD_914f915c-2cac-473e-bea5-c26e4c83673c_21             1   \n",
       "1             358  HD_fff734bd-f8f6-4100-bdb7-d62b1e6b8d95_21             1   \n",
       "0             638   HD_67ab2140-1435-47c1-a6b8-b36f03f5d186_7             1   \n",
       "\n",
       "           batch-size feature-lags featureset   l2-penalty l2-type label-type  \\\n",
       "label-type                                                                      \n",
       "2               10725            5          3       0.0001       0          2   \n",
       "4               10725            3          2  10000000000       0          4   \n",
       "3               21450            3          3  10000000000       0          3   \n",
       "1                3300            3          3       0.0001       3          1   \n",
       "0                3300            1          2       0.0001       4          0   \n",
       "\n",
       "           learning-rate  ... n-epochs pastobs-in-percentage pre-processing  \\\n",
       "label-type                ...                                                 \n",
       "2                   0.01  ...      150                     0       quantgau   \n",
       "4                   0.01  ...      150                     0         minmax   \n",
       "3                  0.001  ...      150                     0            pow   \n",
       "1                  0.001  ...      150                     0        stacked   \n",
       "0                 0.0001  ...      150                     1        stacked   \n",
       "\n",
       "                         id       AUC  Accuracy          Loss  Train AUC  \\\n",
       "label-type                                                                 \n",
       "2           d62b1e6b8d95_58  0.770243  0.609699      0.899017   0.770233   \n",
       "4           d62b1e6b8d95_94  0.724517  0.412573  42711.261357   0.724506   \n",
       "3           c26e4c83673c_21  0.638079  0.299720      1.521505   0.638052   \n",
       "1           d62b1e6b8d95_21  0.615782  0.421687      1.084780   0.615771   \n",
       "0            b36f03f5d186_7  0.580920  0.547298      0.676906   0.580908   \n",
       "\n",
       "            Train Accuracy   Train Loss  \n",
       "label-type                               \n",
       "2                 0.607270     0.892077  \n",
       "4                 0.408811  9438.476361  \n",
       "3                 0.309349     1.511623  \n",
       "1                 0.427520     1.084089  \n",
       "0                 0.553431     0.676053  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tempFinal_v0_lr = combined_table_lr[np.isin(combined_table_lr.AUC,final_output_auc_lr.loc[0].values.flatten())].reset_index()\n",
    "tempFinal_v0_lr.index = tempFinal_v0_lr.loc[:,'label-type']\n",
    "tempFinal_v0_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <th colspan=\"5\" halign=\"left\">lr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>second</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>638</td>\n",
       "      <td>358</td>\n",
       "      <td>321</td>\n",
       "      <td>459</td>\n",
       "      <td>285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>featureset</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pre-processing</th>\n",
       "      <td>stacked</td>\n",
       "      <td>stacked</td>\n",
       "      <td>quantgau</td>\n",
       "      <td>pow</td>\n",
       "      <td>minmax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pastobs-in-percentage</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature-lags</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batch-shuffle</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batch-size</th>\n",
       "      <td>3300</td>\n",
       "      <td>3300</td>\n",
       "      <td>10725</td>\n",
       "      <td>21450</td>\n",
       "      <td>10725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>learning-rate</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l2-penalty</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>10000000000</td>\n",
       "      <td>10000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l2-type</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label-type</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loss-from-logits</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC</th>\n",
       "      <td>0.581</td>\n",
       "      <td>0.616</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.638</td>\n",
       "      <td>0.725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.547</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss</th>\n",
       "      <td>0.677</td>\n",
       "      <td>1.085</td>\n",
       "      <td>0.899</td>\n",
       "      <td>1.522</td>\n",
       "      <td>42711.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train AUC</th>\n",
       "      <td>0.581</td>\n",
       "      <td>0.616</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.638</td>\n",
       "      <td>0.725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Accuracy</th>\n",
       "      <td>0.553</td>\n",
       "      <td>0.428</td>\n",
       "      <td>0.607</td>\n",
       "      <td>0.309</td>\n",
       "      <td>0.409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Loss</th>\n",
       "      <td>0.676</td>\n",
       "      <td>1.084</td>\n",
       "      <td>0.892</td>\n",
       "      <td>1.512</td>\n",
       "      <td>9438.48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "first                       lr                                             \n",
       "second                       0        1         2            3            4\n",
       "id                         638      358       321          459          285\n",
       "featureset                   2        3         3            3            2\n",
       "pre-processing         stacked  stacked  quantgau          pow       minmax\n",
       "pastobs-in-percentage        1        0         0            0            0\n",
       "feature-lags                 1        3         5            3            3\n",
       "batch-shuffle                1        1         1            1            1\n",
       "batch-size                3300     3300     10725        21450        10725\n",
       "learning-rate           0.0001    0.001      0.01        0.001         0.01\n",
       "l2-penalty              0.0001   0.0001    0.0001  10000000000  10000000000\n",
       "l2-type                      4        3         0            0            0\n",
       "label-type                   0        1         2            3            4\n",
       "loss-from-logits             0        0         0            0            0\n",
       "AUC                      0.581    0.616      0.77        0.638        0.725\n",
       "Accuracy                 0.547    0.422      0.61          0.3        0.413\n",
       "Loss                     0.677    1.085     0.899        1.522      42711.3\n",
       "Train AUC                0.581    0.616      0.77        0.638        0.725\n",
       "Train Accuracy           0.553    0.428     0.607        0.309        0.409\n",
       "Train Loss               0.676    1.084     0.892        1.512      9438.48"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_step_lr = tempFinal_v0_lr.copy(deep=True).drop(['run_id','n-epochs','id'],axis=1).sort_index().round({'AUC':3,#'label-type',\n",
    "                                                                                                              'Accuracy':3,\n",
    "                                                                                                              'Loss':3,\n",
    "                                                                                                              'Train AUC':3,\n",
    "                                                                                                              'Train Accuracy':3,\n",
    "                                                                                                              'Train Loss':3}).rename({'index':'id'},axis=1)\n",
    "\n",
    "###     First variables for indentification, the data related variables, estimation parameters, model parameters and then performance.\n",
    "columns_on_top_lr = ['id','featureset','pre-processing','pastobs-in-percentage','feature-lags',\n",
    "                  'batch-shuffle','batch-size','learning-rate','l2-penalty']\n",
    "residual_lr = [i for i in first_step_lr.columns if i not in columns_on_top_lr]\n",
    "correct_ordered_lr = []\n",
    "correct_ordered_lr += columns_on_top_lr\n",
    "correct_ordered_lr += residual_lr\n",
    "results_table_lr = first_step_lr.T.loc[correct_ordered_lr,:]\n",
    "\n",
    "iterables = [['lr'], results_table_lr.columns]\n",
    "\n",
    "results_table_lr.columns = pd.MultiIndex.from_product(iterables, names=['first', 'second'])\n",
    "\n",
    "results_table_lr\n",
    "# first_step.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <th colspan=\"5\" halign=\"left\">nn</th>\n",
       "      <th colspan=\"5\" halign=\"left\">lr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>second</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>nn-type</th>\n",
       "      <td>ffnn</td>\n",
       "      <td>lstm</td>\n",
       "      <td>lstm</td>\n",
       "      <td>ffnn</td>\n",
       "      <td>lstm</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>818</td>\n",
       "      <td>65</td>\n",
       "      <td>883</td>\n",
       "      <td>737</td>\n",
       "      <td>743</td>\n",
       "      <td>638</td>\n",
       "      <td>358</td>\n",
       "      <td>321</td>\n",
       "      <td>459</td>\n",
       "      <td>285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>featureset</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pre-processing</th>\n",
       "      <td>pow</td>\n",
       "      <td>std</td>\n",
       "      <td>std</td>\n",
       "      <td>pow</td>\n",
       "      <td>std</td>\n",
       "      <td>stacked</td>\n",
       "      <td>stacked</td>\n",
       "      <td>quantgau</td>\n",
       "      <td>pow</td>\n",
       "      <td>minmax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pastobs-in-percentage</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature-lags</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batch-norm</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batch-shuffle</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batch-size</th>\n",
       "      <td>10725</td>\n",
       "      <td>10725</td>\n",
       "      <td>10725</td>\n",
       "      <td>3300</td>\n",
       "      <td>10725</td>\n",
       "      <td>3300</td>\n",
       "      <td>3300</td>\n",
       "      <td>10725</td>\n",
       "      <td>21450</td>\n",
       "      <td>10725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dropout-ratio</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>learning-rate</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n-layers</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>activation-inner</th>\n",
       "      <td>relu</td>\n",
       "      <td>leakyrelu</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>tanh</td>\n",
       "      <td>relu</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>activation-output</th>\n",
       "      <td>softmax</td>\n",
       "      <td>softmax</td>\n",
       "      <td>softmax</td>\n",
       "      <td>softmax</td>\n",
       "      <td>softmax</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first-layer-neurons</th>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>128</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label-type</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>second-layer-neurons</th>\n",
       "      <td>128</td>\n",
       "      <td>64</td>\n",
       "      <td>32</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC</th>\n",
       "      <td>0.711</td>\n",
       "      <td>0.741</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.581</td>\n",
       "      <td>0.616</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.638</td>\n",
       "      <td>0.725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.533</td>\n",
       "      <td>0.382</td>\n",
       "      <td>0.581</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.397</td>\n",
       "      <td>0.547</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss</th>\n",
       "      <td>0.971</td>\n",
       "      <td>1.543</td>\n",
       "      <td>0.983</td>\n",
       "      <td>1.667</td>\n",
       "      <td>1.492</td>\n",
       "      <td>0.677</td>\n",
       "      <td>1.085</td>\n",
       "      <td>0.899</td>\n",
       "      <td>1.522</td>\n",
       "      <td>42711.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train AUC</th>\n",
       "      <td>0.711</td>\n",
       "      <td>0.741</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.581</td>\n",
       "      <td>0.616</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.638</td>\n",
       "      <td>0.725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Accuracy</th>\n",
       "      <td>0.749</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.665</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.466</td>\n",
       "      <td>0.553</td>\n",
       "      <td>0.428</td>\n",
       "      <td>0.607</td>\n",
       "      <td>0.309</td>\n",
       "      <td>0.409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Loss</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.771</td>\n",
       "      <td>1.363</td>\n",
       "      <td>1.254</td>\n",
       "      <td>0.676</td>\n",
       "      <td>1.084</td>\n",
       "      <td>0.892</td>\n",
       "      <td>1.512</td>\n",
       "      <td>9438.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l2-penalty</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>10000000000</td>\n",
       "      <td>10000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l2-type</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loss-from-logits</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "first                       nn                                             lr  \\\n",
       "second                       0          1        2        3        4        0   \n",
       "nn-type                   ffnn       lstm     lstm     ffnn     lstm            \n",
       "id                         818         65      883      737      743      638   \n",
       "featureset                   1          1        3        0        3        2   \n",
       "pre-processing             pow        std      std      pow      std  stacked   \n",
       "pastobs-in-percentage        1          0        0        0        1        1   \n",
       "feature-lags                 5          5        3        5        3        1   \n",
       "batch-norm                   1          0        1        1        1            \n",
       "batch-shuffle                1          1        1        1        0        1   \n",
       "batch-size               10725      10725    10725     3300    10725     3300   \n",
       "dropout-ratio                0          0      0.1        0        0            \n",
       "learning-rate              0.1       0.01     0.01     0.01    0.001   0.0001   \n",
       "n-layers                     3          4        4        4        4            \n",
       "activation-inner          relu  leakyrelu  sigmoid     tanh     relu            \n",
       "activation-output      softmax    softmax  softmax  softmax  softmax            \n",
       "first-layer-neurons        128        128      128       32      128            \n",
       "label-type                   0          1        2        3        4        0   \n",
       "second-layer-neurons       128         64       32      128       32            \n",
       "AUC                      0.711      0.741    0.804    0.684    0.753    0.581   \n",
       "Accuracy                 0.533      0.382    0.581    0.274    0.397    0.547   \n",
       "Loss                     0.971      1.543    0.983    1.667    1.492    0.677   \n",
       "Train AUC                0.711      0.741    0.804    0.684    0.753    0.581   \n",
       "Train Accuracy           0.749      0.636    0.665    0.415    0.466    0.553   \n",
       "Train Loss                 0.5      0.774    0.771    1.363    1.254    0.676   \n",
       "l2-penalty                                                             0.0001   \n",
       "l2-type                                                                     4   \n",
       "loss-from-logits                                                            0   \n",
       "\n",
       "first                                                               \n",
       "second                       1         2            3            4  \n",
       "nn-type                                                             \n",
       "id                         358       321          459          285  \n",
       "featureset                   3         3            3            2  \n",
       "pre-processing         stacked  quantgau          pow       minmax  \n",
       "pastobs-in-percentage        0         0            0            0  \n",
       "feature-lags                 3         5            3            3  \n",
       "batch-norm                                                          \n",
       "batch-shuffle                1         1            1            1  \n",
       "batch-size                3300     10725        21450        10725  \n",
       "dropout-ratio                                                       \n",
       "learning-rate            0.001      0.01        0.001         0.01  \n",
       "n-layers                                                            \n",
       "activation-inner                                                    \n",
       "activation-output                                                   \n",
       "first-layer-neurons                                                 \n",
       "label-type                   1         2            3            4  \n",
       "second-layer-neurons                                                \n",
       "AUC                      0.616      0.77        0.638        0.725  \n",
       "Accuracy                 0.422      0.61          0.3        0.413  \n",
       "Loss                     1.085     0.899        1.522      42711.3  \n",
       "Train AUC                0.616      0.77        0.638        0.725  \n",
       "Train Accuracy           0.428     0.607        0.309        0.409  \n",
       "Train Loss               1.084     0.892        1.512      9438.48  \n",
       "l2-penalty              0.0001    0.0001  10000000000  10000000000  \n",
       "l2-type                      3         0            0            0  \n",
       "loss-from-logits             0         0            0            0  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# agg_table = pd.concat([first_step.T.loc[correct_ordered,:],\n",
    "#                        first_step_lr.T.loc[correct_ordered_lr,:]],axis=1).fillna('')\n",
    "\n",
    "agg_table = pd.concat([results_table,\n",
    "                       results_table_lr],axis=1).fillna('')\n",
    "\n",
    "# agg_table.columns = agg_table.columns.sort_values()\n",
    "agg_table\n",
    "# agg_table.loc[:, agg_table.columns.sort_values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiIndex([('nn', '0'),\n",
       "            ('nn', '1'),\n",
       "            ('nn', '2'),\n",
       "            ('nn', '3'),\n",
       "            ('nn', '4'),\n",
       "            ('lr', '0'),\n",
       "            ('lr', '1'),\n",
       "            ('lr', '2'),\n",
       "            ('lr', '3'),\n",
       "            ('lr', '4')],\n",
       "           names=['first', 'second'])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_table.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nn_type_in',\n",
       " 'id_in',\n",
       " 'featureset_in',\n",
       " 'pre_processing_in',\n",
       " 'pastobs_in_percentage_in',\n",
       " 'feature_lags_in',\n",
       " 'batch_norm_in',\n",
       " 'batch_shuffle_in',\n",
       " 'batch_size_in',\n",
       " 'dropout_ratio_in',\n",
       " 'learning_rate_in',\n",
       " 'n_layers_in',\n",
       " 'activation_inner_in',\n",
       " 'activation_output_in',\n",
       " 'first_layer_neurons_in',\n",
       " 'label_type_in',\n",
       " 'second_layer_neurons_in',\n",
       " 'AUC_in',\n",
       " 'Accuracy_in',\n",
       " 'Loss_in',\n",
       " 'Train AUC_in',\n",
       " 'Train Accuracy_in',\n",
       " 'Train Loss_in',\n",
       " 'l2_penalty_in',\n",
       " 'l2_type_in',\n",
       " 'loss_from_logits_in']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i.replace('-','_')+'_in' for i in agg_table.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('nn', '0'): {'nn_type_in': 'ffnn',\n",
       "  'id_in': '818',\n",
       "  'featureset_in': '1',\n",
       "  'pre_processing_in': 'pow',\n",
       "  'pastobs_in_percentage_in': '1',\n",
       "  'feature_lags_in': '5',\n",
       "  'batch_norm_in': '1',\n",
       "  'batch_shuffle_in': '1',\n",
       "  'batch_size_in': '10725',\n",
       "  'dropout_ratio_in': '0',\n",
       "  'learning_rate_in': '0.1',\n",
       "  'n_layers_in': '3',\n",
       "  'activation_inner_in': 'relu',\n",
       "  'activation_output_in': 'softmax',\n",
       "  'first_layer_neurons_in': '128',\n",
       "  'label_type_in': '0',\n",
       "  'second_layer_neurons_in': '128',\n",
       "  'AUC_in': 0.711,\n",
       "  'Accuracy_in': 0.533,\n",
       "  'Loss_in': 0.971,\n",
       "  'Train AUC_in': 0.711,\n",
       "  'Train Accuracy_in': 0.749,\n",
       "  'Train Loss_in': 0.5,\n",
       "  'l2_penalty_in': '',\n",
       "  'l2_type_in': '',\n",
       "  'loss_from_logits_in': ''},\n",
       " ('nn', '1'): {'nn_type_in': 'lstm',\n",
       "  'id_in': '65',\n",
       "  'featureset_in': '1',\n",
       "  'pre_processing_in': 'std',\n",
       "  'pastobs_in_percentage_in': '0',\n",
       "  'feature_lags_in': '5',\n",
       "  'batch_norm_in': '0',\n",
       "  'batch_shuffle_in': '1',\n",
       "  'batch_size_in': '10725',\n",
       "  'dropout_ratio_in': '0',\n",
       "  'learning_rate_in': '0.01',\n",
       "  'n_layers_in': '4',\n",
       "  'activation_inner_in': 'leakyrelu',\n",
       "  'activation_output_in': 'softmax',\n",
       "  'first_layer_neurons_in': '128',\n",
       "  'label_type_in': '1',\n",
       "  'second_layer_neurons_in': '64',\n",
       "  'AUC_in': 0.741,\n",
       "  'Accuracy_in': 0.382,\n",
       "  'Loss_in': 1.543,\n",
       "  'Train AUC_in': 0.741,\n",
       "  'Train Accuracy_in': 0.636,\n",
       "  'Train Loss_in': 0.774,\n",
       "  'l2_penalty_in': '',\n",
       "  'l2_type_in': '',\n",
       "  'loss_from_logits_in': ''},\n",
       " ('nn', '2'): {'nn_type_in': 'lstm',\n",
       "  'id_in': '883',\n",
       "  'featureset_in': '3',\n",
       "  'pre_processing_in': 'std',\n",
       "  'pastobs_in_percentage_in': '0',\n",
       "  'feature_lags_in': '3',\n",
       "  'batch_norm_in': '1',\n",
       "  'batch_shuffle_in': '1',\n",
       "  'batch_size_in': '10725',\n",
       "  'dropout_ratio_in': '0.1',\n",
       "  'learning_rate_in': '0.01',\n",
       "  'n_layers_in': '4',\n",
       "  'activation_inner_in': 'sigmoid',\n",
       "  'activation_output_in': 'softmax',\n",
       "  'first_layer_neurons_in': '128',\n",
       "  'label_type_in': '2',\n",
       "  'second_layer_neurons_in': '32',\n",
       "  'AUC_in': 0.804,\n",
       "  'Accuracy_in': 0.581,\n",
       "  'Loss_in': 0.983,\n",
       "  'Train AUC_in': 0.804,\n",
       "  'Train Accuracy_in': 0.665,\n",
       "  'Train Loss_in': 0.771,\n",
       "  'l2_penalty_in': '',\n",
       "  'l2_type_in': '',\n",
       "  'loss_from_logits_in': ''},\n",
       " ('nn', '3'): {'nn_type_in': 'ffnn',\n",
       "  'id_in': '737',\n",
       "  'featureset_in': '0',\n",
       "  'pre_processing_in': 'pow',\n",
       "  'pastobs_in_percentage_in': '0',\n",
       "  'feature_lags_in': '5',\n",
       "  'batch_norm_in': '1',\n",
       "  'batch_shuffle_in': '1',\n",
       "  'batch_size_in': '3300',\n",
       "  'dropout_ratio_in': '0',\n",
       "  'learning_rate_in': '0.01',\n",
       "  'n_layers_in': '4',\n",
       "  'activation_inner_in': 'tanh',\n",
       "  'activation_output_in': 'softmax',\n",
       "  'first_layer_neurons_in': '32',\n",
       "  'label_type_in': '3',\n",
       "  'second_layer_neurons_in': '128',\n",
       "  'AUC_in': 0.684,\n",
       "  'Accuracy_in': 0.274,\n",
       "  'Loss_in': 1.667,\n",
       "  'Train AUC_in': 0.684,\n",
       "  'Train Accuracy_in': 0.415,\n",
       "  'Train Loss_in': 1.363,\n",
       "  'l2_penalty_in': '',\n",
       "  'l2_type_in': '',\n",
       "  'loss_from_logits_in': ''},\n",
       " ('nn', '4'): {'nn_type_in': 'lstm',\n",
       "  'id_in': '743',\n",
       "  'featureset_in': '3',\n",
       "  'pre_processing_in': 'std',\n",
       "  'pastobs_in_percentage_in': '1',\n",
       "  'feature_lags_in': '3',\n",
       "  'batch_norm_in': '1',\n",
       "  'batch_shuffle_in': '0',\n",
       "  'batch_size_in': '10725',\n",
       "  'dropout_ratio_in': '0',\n",
       "  'learning_rate_in': '0.001',\n",
       "  'n_layers_in': '4',\n",
       "  'activation_inner_in': 'relu',\n",
       "  'activation_output_in': 'softmax',\n",
       "  'first_layer_neurons_in': '128',\n",
       "  'label_type_in': '4',\n",
       "  'second_layer_neurons_in': '32',\n",
       "  'AUC_in': 0.753,\n",
       "  'Accuracy_in': 0.397,\n",
       "  'Loss_in': 1.492,\n",
       "  'Train AUC_in': 0.753,\n",
       "  'Train Accuracy_in': 0.466,\n",
       "  'Train Loss_in': 1.254,\n",
       "  'l2_penalty_in': '',\n",
       "  'l2_type_in': '',\n",
       "  'loss_from_logits_in': ''},\n",
       " ('lr', '0'): {'nn_type_in': '',\n",
       "  'id_in': 638,\n",
       "  'featureset_in': '2',\n",
       "  'pre_processing_in': 'stacked',\n",
       "  'pastobs_in_percentage_in': '1',\n",
       "  'feature_lags_in': '1',\n",
       "  'batch_norm_in': '',\n",
       "  'batch_shuffle_in': '1',\n",
       "  'batch_size_in': '3300',\n",
       "  'dropout_ratio_in': '',\n",
       "  'learning_rate_in': '0.0001',\n",
       "  'n_layers_in': '',\n",
       "  'activation_inner_in': '',\n",
       "  'activation_output_in': '',\n",
       "  'first_layer_neurons_in': '',\n",
       "  'label_type_in': '0',\n",
       "  'second_layer_neurons_in': '',\n",
       "  'AUC_in': 0.581,\n",
       "  'Accuracy_in': 0.547,\n",
       "  'Loss_in': 0.677,\n",
       "  'Train AUC_in': 0.581,\n",
       "  'Train Accuracy_in': 0.553,\n",
       "  'Train Loss_in': 0.676,\n",
       "  'l2_penalty_in': '0.0001',\n",
       "  'l2_type_in': '4',\n",
       "  'loss_from_logits_in': '0'},\n",
       " ('lr', '1'): {'nn_type_in': '',\n",
       "  'id_in': 358,\n",
       "  'featureset_in': '3',\n",
       "  'pre_processing_in': 'stacked',\n",
       "  'pastobs_in_percentage_in': '0',\n",
       "  'feature_lags_in': '3',\n",
       "  'batch_norm_in': '',\n",
       "  'batch_shuffle_in': '1',\n",
       "  'batch_size_in': '3300',\n",
       "  'dropout_ratio_in': '',\n",
       "  'learning_rate_in': '0.001',\n",
       "  'n_layers_in': '',\n",
       "  'activation_inner_in': '',\n",
       "  'activation_output_in': '',\n",
       "  'first_layer_neurons_in': '',\n",
       "  'label_type_in': '1',\n",
       "  'second_layer_neurons_in': '',\n",
       "  'AUC_in': 0.616,\n",
       "  'Accuracy_in': 0.422,\n",
       "  'Loss_in': 1.085,\n",
       "  'Train AUC_in': 0.616,\n",
       "  'Train Accuracy_in': 0.428,\n",
       "  'Train Loss_in': 1.084,\n",
       "  'l2_penalty_in': '0.0001',\n",
       "  'l2_type_in': '3',\n",
       "  'loss_from_logits_in': '0'},\n",
       " ('lr', '2'): {'nn_type_in': '',\n",
       "  'id_in': 321,\n",
       "  'featureset_in': '3',\n",
       "  'pre_processing_in': 'quantgau',\n",
       "  'pastobs_in_percentage_in': '0',\n",
       "  'feature_lags_in': '5',\n",
       "  'batch_norm_in': '',\n",
       "  'batch_shuffle_in': '1',\n",
       "  'batch_size_in': '10725',\n",
       "  'dropout_ratio_in': '',\n",
       "  'learning_rate_in': '0.01',\n",
       "  'n_layers_in': '',\n",
       "  'activation_inner_in': '',\n",
       "  'activation_output_in': '',\n",
       "  'first_layer_neurons_in': '',\n",
       "  'label_type_in': '2',\n",
       "  'second_layer_neurons_in': '',\n",
       "  'AUC_in': 0.77,\n",
       "  'Accuracy_in': 0.61,\n",
       "  'Loss_in': 0.899,\n",
       "  'Train AUC_in': 0.77,\n",
       "  'Train Accuracy_in': 0.607,\n",
       "  'Train Loss_in': 0.892,\n",
       "  'l2_penalty_in': '0.0001',\n",
       "  'l2_type_in': '0',\n",
       "  'loss_from_logits_in': '0'},\n",
       " ('lr', '3'): {'nn_type_in': '',\n",
       "  'id_in': 459,\n",
       "  'featureset_in': '3',\n",
       "  'pre_processing_in': 'pow',\n",
       "  'pastobs_in_percentage_in': '0',\n",
       "  'feature_lags_in': '3',\n",
       "  'batch_norm_in': '',\n",
       "  'batch_shuffle_in': '1',\n",
       "  'batch_size_in': '21450',\n",
       "  'dropout_ratio_in': '',\n",
       "  'learning_rate_in': '0.001',\n",
       "  'n_layers_in': '',\n",
       "  'activation_inner_in': '',\n",
       "  'activation_output_in': '',\n",
       "  'first_layer_neurons_in': '',\n",
       "  'label_type_in': '3',\n",
       "  'second_layer_neurons_in': '',\n",
       "  'AUC_in': 0.638,\n",
       "  'Accuracy_in': 0.3,\n",
       "  'Loss_in': 1.522,\n",
       "  'Train AUC_in': 0.638,\n",
       "  'Train Accuracy_in': 0.309,\n",
       "  'Train Loss_in': 1.512,\n",
       "  'l2_penalty_in': '10000000000',\n",
       "  'l2_type_in': '0',\n",
       "  'loss_from_logits_in': '0'},\n",
       " ('lr', '4'): {'nn_type_in': '',\n",
       "  'id_in': 285,\n",
       "  'featureset_in': '2',\n",
       "  'pre_processing_in': 'minmax',\n",
       "  'pastobs_in_percentage_in': '0',\n",
       "  'feature_lags_in': '3',\n",
       "  'batch_norm_in': '',\n",
       "  'batch_shuffle_in': '1',\n",
       "  'batch_size_in': '10725',\n",
       "  'dropout_ratio_in': '',\n",
       "  'learning_rate_in': '0.01',\n",
       "  'n_layers_in': '',\n",
       "  'activation_inner_in': '',\n",
       "  'activation_output_in': '',\n",
       "  'first_layer_neurons_in': '',\n",
       "  'label_type_in': '4',\n",
       "  'second_layer_neurons_in': '',\n",
       "  'AUC_in': 0.725,\n",
       "  'Accuracy_in': 0.413,\n",
       "  'Loss_in': 42711.261,\n",
       "  'Train AUC_in': 0.725,\n",
       "  'Train Accuracy_in': 0.409,\n",
       "  'Train Loss_in': 9438.476,\n",
       "  'l2_penalty_in': '10000000000',\n",
       "  'l2_type_in': '0',\n",
       "  'loss_from_logits_in': '0'}}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_table.index = [i.replace('-','_')+'_in' for i in agg_table.index]\n",
    "agg_table.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <th colspan=\"3\" halign=\"left\">nn</th>\n",
       "      <th colspan=\"3\" halign=\"left\">lr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>second</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>3</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>nn-type</th>\n",
       "      <td>ffnn</td>\n",
       "      <td>lstm</td>\n",
       "      <td>ffnn</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>818</td>\n",
       "      <td>65</td>\n",
       "      <td>737</td>\n",
       "      <td>638</td>\n",
       "      <td>358</td>\n",
       "      <td>459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>featureset</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pre-processing</th>\n",
       "      <td>pow</td>\n",
       "      <td>std</td>\n",
       "      <td>pow</td>\n",
       "      <td>stacked</td>\n",
       "      <td>stacked</td>\n",
       "      <td>pow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pastobs-in-percentage</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature-lags</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batch-norm</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batch-shuffle</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batch-size</th>\n",
       "      <td>10725</td>\n",
       "      <td>10725</td>\n",
       "      <td>3300</td>\n",
       "      <td>3300</td>\n",
       "      <td>3300</td>\n",
       "      <td>21450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dropout-ratio</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>learning-rate</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n-layers</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>activation-inner</th>\n",
       "      <td>relu</td>\n",
       "      <td>leakyrelu</td>\n",
       "      <td>tanh</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>activation-output</th>\n",
       "      <td>softmax</td>\n",
       "      <td>softmax</td>\n",
       "      <td>softmax</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first-layer-neurons</th>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>second-layer-neurons</th>\n",
       "      <td>128</td>\n",
       "      <td>64</td>\n",
       "      <td>128</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC</th>\n",
       "      <td>0.711</td>\n",
       "      <td>0.741</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.581</td>\n",
       "      <td>0.616</td>\n",
       "      <td>0.638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.533</td>\n",
       "      <td>0.382</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.547</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss</th>\n",
       "      <td>0.971</td>\n",
       "      <td>1.543</td>\n",
       "      <td>1.667</td>\n",
       "      <td>0.677</td>\n",
       "      <td>1.085</td>\n",
       "      <td>1.522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train AUC</th>\n",
       "      <td>0.711</td>\n",
       "      <td>0.741</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.581</td>\n",
       "      <td>0.616</td>\n",
       "      <td>0.638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Accuracy</th>\n",
       "      <td>0.749</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.553</td>\n",
       "      <td>0.428</td>\n",
       "      <td>0.309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Loss</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.774</td>\n",
       "      <td>1.363</td>\n",
       "      <td>0.676</td>\n",
       "      <td>1.084</td>\n",
       "      <td>1.512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l2-penalty</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>10000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l2-type</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loss-from-logits</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "first                       nn                           lr           \\\n",
       "second                       0          1        3        0        1   \n",
       "nn-type                   ffnn       lstm     ffnn                     \n",
       "id                         818         65      737      638      358   \n",
       "featureset                   1          1        0        2        3   \n",
       "pre-processing             pow        std      pow  stacked  stacked   \n",
       "pastobs-in-percentage        1          0        0        1        0   \n",
       "feature-lags                 5          5        5        1        3   \n",
       "batch-norm                   1          0        1                     \n",
       "batch-shuffle                1          1        1        1        1   \n",
       "batch-size               10725      10725     3300     3300     3300   \n",
       "dropout-ratio                0          0        0                     \n",
       "learning-rate              0.1       0.01     0.01   0.0001    0.001   \n",
       "n-layers                     3          4        4                     \n",
       "activation-inner          relu  leakyrelu     tanh                     \n",
       "activation-output      softmax    softmax  softmax                     \n",
       "first-layer-neurons        128        128       32                     \n",
       "second-layer-neurons       128         64      128                     \n",
       "AUC                      0.711      0.741    0.684    0.581    0.616   \n",
       "Accuracy                 0.533      0.382    0.274    0.547    0.422   \n",
       "Loss                     0.971      1.543    1.667    0.677    1.085   \n",
       "Train AUC                0.711      0.741    0.684    0.581    0.616   \n",
       "Train Accuracy           0.749      0.636    0.415    0.553    0.428   \n",
       "Train Loss                 0.5      0.774    1.363    0.676    1.084   \n",
       "l2-penalty                                           0.0001   0.0001   \n",
       "l2-type                                                   4        3   \n",
       "loss-from-logits                                          0        0   \n",
       "\n",
       "first                               \n",
       "second                           3  \n",
       "nn-type                             \n",
       "id                             459  \n",
       "featureset                       3  \n",
       "pre-processing                 pow  \n",
       "pastobs-in-percentage            0  \n",
       "feature-lags                     3  \n",
       "batch-norm                          \n",
       "batch-shuffle                    1  \n",
       "batch-size                   21450  \n",
       "dropout-ratio                       \n",
       "learning-rate                0.001  \n",
       "n-layers                            \n",
       "activation-inner                    \n",
       "activation-output                   \n",
       "first-layer-neurons                 \n",
       "second-layer-neurons                \n",
       "AUC                          0.638  \n",
       "Accuracy                       0.3  \n",
       "Loss                         1.522  \n",
       "Train AUC                    0.638  \n",
       "Train Accuracy               0.309  \n",
       "Train Loss                   1.512  \n",
       "l2-penalty             10000000000  \n",
       "l2-type                          0  \n",
       "loss-from-logits                 0  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_table.loc[:,(['nn','lr'],['0','1','3'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'sortlevel'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-40caa7f6dd20>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0magg_table\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msortlevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'second'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5272\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5273\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5274\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5275\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5276\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'sortlevel'"
     ]
    }
   ],
   "source": [
    "agg_table.sortlevel('second',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_table.reorder_levels(['second','first'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempFinal_v1_lr = combined_table_lr[np.isin(combined_table_lr.Accuracy,final_output_acc_lr.loc[0].values.flatten())].sort_values('label-type').copy(deep=True)\n",
    "tempFinal_v1_lr.index = tempFinal_v1_lr.loc[:,'label-type']\n",
    "tempFinal_v1_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = combined_table[(combined_table.loc[:,'label-type']=='0')&\\\n",
    "                      (combined_table_lr.loc[:,'loss-from-logits']=='1')&\\\n",
    "                      (combined_table.AUC>0.5)]\n",
    "\n",
    "cols_not_plot = []\n",
    "cols_to_plot = []\n",
    "\n",
    "for i,col in enumerate(temp.columns):\n",
    "    if (temp.loc[:,col].unique().shape[0]>1)&(temp.loc[:,col].unique().shape[0]<7):\n",
    "        cols_to_plot.append(col)\n",
    "        print(col,': ',temp.loc[:,col].unique(),'\\n')\n",
    "    else:\n",
    "        cols_not_plot.append(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label types\n",
    "\n",
    "Label type 0: 2 classes - equal split\n",
    "\n",
    "Label type 1: 3 classes - equal split\n",
    "\n",
    "Label type 2: 3 classes - non-equal split\n",
    "\n",
    "Label type 3: 5 classes - equal split\n",
    "\n",
    "Label type 4: 5 classes - non-equal split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# temp = combined_table_lr[(combined_table_lr.loc[:,'label-type']=='4')&\\\n",
    "#                       (combined_table_lr.loc[:,'loss-from-logits']=='1')&\\\n",
    "#                       (combined_table_lr.AUC>0.5)]\n",
    "\n",
    "fig,ax = plt.subplots(5,3,figsize=(17,40))\n",
    "font = {'family' : 'normal',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 12}\n",
    "\n",
    "plt.rc('font', **font)\n",
    "# plt.rcParams.update({'font.size': 12})\n",
    "# plt.rcParams.update({'font.weight': 'normal'})\n",
    "k = 0\n",
    "\n",
    "for i in np.arange(5):\n",
    "    for j in np.arange(3):\n",
    "        \n",
    "\n",
    "\n",
    "        if k < len(cols_to_plot):\n",
    "            temp_2 = pd.pivot_table(temp,values='AUC',columns=cols_to_plot[k],index='run_id').reset_index()\n",
    "\n",
    "            # sns.set_theme(style=\"whitegrid\")\n",
    "            # tips = sns.load_dataset(\"tips\")\n",
    "            # ax = sns.violinplot(x=tips[\"total_bill\"])\n",
    "            sns.boxplot(data=temp_2,ax=ax[i,j],color='gray')#,bw='scott'\n",
    "#             ax[i,j].set_xticks(fontsize=12)\n",
    "#             ax[i,j].set_yticks(fontsize=12)\n",
    "            # plt.legend(fontsize=14)\n",
    "            ax[i,j].set_xlabel(temp_2.columns.name,fontsize=12,fontweight='bold')\n",
    "\n",
    "\n",
    "            k +=1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-4f76a9dad686>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mstop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'stop' is not defined"
     ]
    }
   ],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reading in the market data (done automatically atm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping ETFS and market indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Ticker.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the XNTK ticker\n",
    "data = data[~data.Ticker.isin(['XNTK'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Ticker.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the XNTK ticker\n",
    "data = data[~data.Ticker.isin(['XNTK'])]\n",
    "\n",
    "etfs = ['IYH','IYM','IYK','IYJ','IYG','IYW','IYC','IYR','IDU','IYZ','IYE','IYF','SPY','DIA','QQQ']\n",
    "\n",
    "# Extracting the sector ETFs to a separate variable\n",
    "sectorETFS = data[data.Ticker.isin(etfs)]\n",
    "\n",
    "# Removing the ETFs\n",
    "data = data[~data.Ticker.isin(etfs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Generate Features ################\n",
    "\n",
    "n_feature_lags = 1\n",
    "\n",
    "# features = generateFeatures_multi_final(data = data, \n",
    "#                                   listOfFeatures = [\n",
    "#                                                     'pastobs',\n",
    "#                                                     'spread',\n",
    "#                                                     'bidsize',\n",
    "#                                                     'ofrsize',\n",
    "# #                                                     'stok',\n",
    "# #                                                     'stod',\n",
    "# #                                                     'sstod',\n",
    "# #                                                     'wilr',\n",
    "# #                                                     'roc',\n",
    "# #                                                     'rsi',\n",
    "# #                                                     'atr',\n",
    "# #                                                     'cci',\n",
    "# #                                                     'dpo',\n",
    "# #                                                     'sma',\n",
    "# #                                                     'ema',\n",
    "# #                                                     'macd',\n",
    "# #                                                       'macd_diff',\n",
    "# #                                                       'macd_signal',\n",
    "# #                                                     'dis5',\n",
    "# #                                                     'dis10',\n",
    "#                                                       'sector'\n",
    "#                                                    ], \n",
    "#                                    feature_lags = n_feature_lags\n",
    "#                                      ,stockTable=stockTable)\n",
    "features = generateFeatures_multi_final(data = data, \n",
    "                                  listOfFeatures = [\n",
    "                                                    'pastobs',\n",
    "                                                    'spread',\n",
    "                                                    'bidsize',\n",
    "                                                    'ofrsize',\n",
    "                                                    'stok',\n",
    "                                                    'stod',\n",
    "                                                    'sstod',\n",
    "#                                                     'wilr',\n",
    "                                                    'roc',\n",
    "                                                    'rsi',\n",
    "                                                    'atr',\n",
    "                                                    'cci',\n",
    "                                                    'dpo',\n",
    "                                                    'sma',\n",
    "                                                    'ema',\n",
    "                                                    'macd',\n",
    "                                                      'macd_diff',\n",
    "                                                      'macd_signal',\n",
    "                                                    'dis5',\n",
    "                                                    'dis10',\n",
    "                                                      'sector'\n",
    "                                                   ], \n",
    "                                   feature_lags = n_feature_lags\n",
    "                                     ,sectorETFS=sectorETFS)\n",
    "\n",
    "########### Generate Labels ################\n",
    "\n",
    "n_classes = 2\n",
    "# extract first 4 columns as the lag0 or raw OHLC prices (used for labelling)\n",
    "price_candles = data[['open','high','low','close','Ticker']]\n",
    "\n",
    "########### Align Data ################\n",
    "\n",
    "# from imported function (see testing_preprocessing_features_and_labels.ipynb for thorough experimenting with all the cut-offs):    \n",
    "X, y,indices = align_features_and_labels_multi_final(price_candles = price_candles, \n",
    "                                                 all_features = features,\n",
    "                                                 prediction_horizon = 1, \n",
    "                                                 n_feature_lags = n_feature_lags, \n",
    "                                                 n_classes = n_classes, # 5,\n",
    "                                                 safe_burn_in = False, \n",
    "                                                 data_sample = 'full',\n",
    "                                                 splitType='global',\n",
    "                                                 noise=False,ticker_dummies=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding ticker dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Adding ticker dummies\n",
    "tickers = X.pop('ticker')\n",
    "X = pd.concat([X, pd.get_dummies(tickers, prefix='ticker', drop_first=False)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing our final train/validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ds = pd.concat([X.iloc[start:end, :] for (start, end) in train_ranges]).reset_index(drop=True)\n",
    "# train_y = pd.concat([y.iloc[start:end] for (start, end) in train_ranges]).reset_index(drop=True)\n",
    "\n",
    "# validate_ds = pd.concat([X.iloc[start:end, :] for (start, end) in val_ranges]).reset_index(drop=True)\n",
    "# val_y = pd.concat([y.iloc[start:end] for (start, end) in val_ranges]).reset_index(drop=True)\n",
    "\n",
    "# train_ds.shape, train_y.shape, validate_ds.shape, val_y.shape, train_y.shape[0] + val_y.shape[0]\n",
    "\n",
    "# Let's have a proper split (along tickers & dates)\n",
    "train_size = 0.8\n",
    "\n",
    "# Sort the indices\n",
    "tempIndices = indices.sort_values(['days','timestamps','ticker'])\n",
    "\n",
    "# Sorting the data\n",
    "X = X.loc[tempIndices.index,:]#.head(66)\n",
    "y = y.loc[tempIndices.index,:]\n",
    "\n",
    "# extracting the first date for the validation data.\n",
    "first_val_day = int(np.floor(indices.days.unique().shape[0]*0.8))\n",
    "\n",
    "# Splitting the data\n",
    "X_train = X[tempIndices.days<tempIndices.days.unique()[first_val_day]].reset_index(drop=True)\n",
    "y_train = y[tempIndices.days<tempIndices.days.unique()[first_val_day]].reset_index(drop=True)\n",
    "\n",
    "X_test = X[tempIndices.days>=tempIndices.days.unique()[first_val_day]].reset_index(drop=True)\n",
    "y_test = y[tempIndices.days>=tempIndices.days.unique()[first_val_day]].reset_index(drop=True)\n",
    "\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where((np.sum(np.isinf(X_train.values), axis=1) == 0) == False),\n",
    "np.where((np.sum(np.isnan(X_train.values), axis=1) == 0) == False)#X_train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{i:colname for i,colname in enumerate(train_ds.columns)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating one ppdict for individual preprocessings\n",
    "# ppdict1 = {'open':'minmax',\n",
    "#           'high':'log',\n",
    "#           'low':'log',\n",
    "#           'close':'std'}\n",
    "# splitpoint = 32\n",
    "\n",
    "# # Standardize some features\n",
    "# ppdict1 = {i:'std' for i in train_ds.columns[0:splitpoint]} \n",
    "# # Keep some in actual levels (Dummies in this case).\n",
    "# ppdict2 = {i:'act' for i in train_ds.columns[splitpoint:]}\n",
    "\n",
    "pre_procesing_applied = 'std'\n",
    "\n",
    "# Merging the two\n",
    "# ppdict = {**ppdict1,**ppdict2}\n",
    "\n",
    "if  pre_procesing_applied == 'None':\n",
    "    # do nothing here\n",
    "    pass\n",
    "\n",
    "elif  pre_procesing_applied == 'std':\n",
    "\n",
    "    # splitpoint = int((args.feature-lags+1)*16)#32\n",
    "    # columns_to_pre_process = [col for col in X_train.columns if 'd_' != col[0:2]]\n",
    "\n",
    "    # Standardize some features\n",
    "    ppdict1 = {i:'std' for i in X_train.columns if 'd_' != i[0:2]} \n",
    "    # Keep some in actual levels (Dummies in this case).\n",
    "    ppdict2 = {i:'act' for i in X_train.columns if 'd_' == i[0:2]} \n",
    "\n",
    "    # Merging the two\n",
    "    ppdict = {**ppdict1,**ppdict2}\n",
    "\n",
    "    # x_train,x_test = pre_processing(x_train,x_test,pp_dict)\n",
    "\n",
    "elif pre_procesing_applied == 'minmax':\n",
    "\n",
    "    # splitpoint = int((args.feature-lags+1)*16)#32\n",
    "    # columns_to_pre_process = [col for col in X_train.columns if 'd_' != col[0:2]]\n",
    "\n",
    "    # Standardize some features\n",
    "    ppdict1 = {i:'minmax' for i in X_train.columns if 'd_' != i[0:2]} \n",
    "    # Keep some in actual levels (Dummies in this case).\n",
    "    ppdict2 = {i:'act' for i in X_train.columns if 'd_' == i[0:2]} \n",
    "\n",
    "    # Merging the two\n",
    "    ppdict = {**ppdict1,**ppdict2}\n",
    "\n",
    "    # x_train,x_test = pre_processing(X_train,X_test,pp_dict)\n",
    "\n",
    "elif pre_procesing_applied == 'pow':\n",
    "\n",
    "    # splitpoint = int((args.feature-lags+1)*16)#32\n",
    "    # columns_to_pre_process = [col for col in X_train.columns if 'd_' != col[0:2]]\n",
    "\n",
    "    # Standardize some features\n",
    "    ppdict1 = {i:'pow' for i in X_train.columns if 'd_' != i[0:2]} \n",
    "    # Keep some in actual levels (Dummies in this case).\n",
    "    ppdict2 = {i:'act' for i in X_train.columns if 'd_' == i[0:2]} \n",
    "\n",
    "    # Merging the two\n",
    "    ppdict = {**ppdict1,**ppdict2}\n",
    "\n",
    "    # x_train,x_test = pre_processing(x_train,x_test,pp_dict)\n",
    "\n",
    "elif pre_procesing_applied == 'quantgau':\n",
    "\n",
    "    # splitpoint = int((args.feature-lags+1)*16)#32\n",
    "    # columns_to_pre_process = [col for col in X_train.columns if 'd_' != col[0:2]]\n",
    "\n",
    "    # Standardize some features\n",
    "    ppdict1 = {i:'quantgau' for i in X_train.columns if 'd_' != i[0:2]} \n",
    "    # Keep some in actual levels (Dummies in this case).\n",
    "    ppdict2 = {i:'act' for i in X_train.columns if 'd_' == i[0:2]} \n",
    "\n",
    "    # Merging the two\n",
    "    ppdict = {**ppdict1,**ppdict2}\n",
    "\n",
    "    # x_train,x_test = pre_processing(x_train,x_test,pp_dict)\n",
    "\n",
    "elif pre_procesing_applied == 'individual':\n",
    "\n",
    "    # splitpoint = int((args.feature-lags+1)*16)#32\n",
    "    # columns_to_pre_process = [col for col in X_train.columns if 'd_' != col[0:2]]\n",
    "\n",
    "    # Standardize some features\n",
    "    \n",
    "    # ppdict1 = {i:'power' for i in X_train.columns if 'd_' != i[0:2]}\n",
    "\n",
    "\n",
    "    # Keep some in actual levels (Dummies in this case).\n",
    "    ppdict2 = {i:'act' for i in X_train.columns if 'd_' == i[0:2]} \n",
    "\n",
    "    # Merging the two\n",
    "    ppdict = {**ppdict1,**ppdict2}\n",
    "\n",
    "    # x_train,x_test = pre_processing(x_train,x_test,pp_dict)\n",
    "\n",
    "elif pre_procesing_applied == 'stacked':\n",
    "\n",
    "    # splitpoint = int((args.feature-lags+1)*16)#32\n",
    "    # columns_to_pre_process = [col for col in X_train.columns if 'd_' != col[0:2]]\n",
    "\n",
    "    # Standardize some features\n",
    "    \n",
    "    for j in ['pow','std','minmax']:\n",
    "\n",
    "        ppdict1 = {i:j for i in X_train.columns if 'd_' != i[0:2]}\n",
    "\n",
    "        # Keep some in actual levels (Dummies in this case).\n",
    "        ppdict2 = {i:'act' for i in X_train.columns if 'd_' == i[0:2]} \n",
    "\n",
    "        # Merging the two\n",
    "        ppdict = {**ppdict1,**ppdict2}\n",
    "\n",
    "        X_train,X_test = pre_processing(X_train,X_test,ppdict)\n",
    "\n",
    "if pre_procesing_applied not in ['None','stacked']:\n",
    "    X_train,X_test = pre_processing(X_train,X_test,ppdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppX_train.iloc[:,0].mean(),ppX_train.iloc[:,0].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepping for models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_VALIDATION = val_y.shape[0] #int(1e3)\n",
    "N_TRAIN = train_y.shape[0] #int(1e4)\n",
    "# BUFFER_SIZE = int(1e4)\n",
    "BATCH_SIZE = 256 #512 #32\n",
    "MAX_EPOCHS = 500\n",
    "\n",
    "STEPS_PER_EPOCH = N_TRAIN//BATCH_SIZE\n",
    "\n",
    "N_REPEAT = int(N_TRAIN / ((STEPS_PER_EPOCH * MAX_EPOCHS) / BATCH_SIZE))\n",
    "FEATURES = X.shape[1]\n",
    "\n",
    "N_TRAIN, N_VALIDATION, N_TRAIN + N_VALIDATION, STEPS_PER_EPOCH, N_REPEAT, STEPS_PER_EPOCH * MAX_EPOCHS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Logistic Regression model in TF/Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "      #keras.metrics.TruePositives(name='tp'),\n",
    "      #keras.metrics.FalsePositives(name='fp'),\n",
    "      #keras.metrics.TrueNegatives(name='tn'),\n",
    "      #keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      #keras.metrics.Precision(name='precision'),\n",
    "      #keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "]\n",
    "\n",
    "# def make_model(metrics = METRICS, output_bias=None):\n",
    "#   if output_bias is not None:\n",
    "#     output_bias = tf.keras.initializers.Constant(output_bias)\n",
    "#   model = keras.Sequential([\n",
    "#       keras.layers.Dense(\n",
    "#           16, activation='relu',\n",
    "#           input_shape=(train_features.shape[-1],)),\n",
    "#       keras.layers.Dropout(0.5),\n",
    "#       keras.layers.Dense(1, activation='sigmoid',\n",
    "#                          bias_initializer=output_bias),\n",
    "#   ])\n",
    "\n",
    "#   model.compile(\n",
    "#       optimizer=keras.optimizers.Adam(lr=1e-3),\n",
    "#       loss=keras.losses.BinaryCrossentropy(),\n",
    "#       metrics=metrics)\n",
    "\n",
    "#   return model\n",
    "\n",
    "# model = keras.Sequential({\n",
    "#   keras.layers.Dense(1, input_shape=(FEATURES,))\n",
    "# })\n",
    "\n",
    "model = keras.Sequential([\n",
    "#     keras.layers.Flatten(input_shape=(28, 28)),\n",
    "#     keras.layers.Dense(128, activation='relu'),\n",
    "#     keras.layers.Dense(10)\n",
    "    keras.layers.Dense(1,\n",
    "                       input_shape=(FEATURES,),\n",
    "                       activation='sigmoid',\n",
    "                       kernel_regularizer=regularizers.l2(1))\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# with final activation (Keras/TF tutorial advises against this practice, but they also use it later in the tutorial)\n",
    "# model = keras.Sequential({\n",
    "#   keras.layers.Dense(1, input_shape=(FEATURES,), activation='sigmoid')\n",
    "# })\n",
    "\n",
    "#model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['binary_accuracy', ])\n",
    "model.compile(\n",
    "              optimizer=keras.optimizers.Adam(), #lr=1e-3\n",
    "              loss=keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "              metrics=METRICS)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "                                                monitor='val_auc', \n",
    "                                                verbose=1,\n",
    "                                                patience=100,\n",
    "                                                mode='max',\n",
    "                                                restore_best_weights=True)\n",
    "\n",
    "def get_callbacks(run_id):\n",
    "      return [\n",
    "             tfdocs.modeling.EpochDots(),\n",
    "             early_stopping,\n",
    "             tf.keras.callbacks.TensorBoard(logdir), #/run_id),\n",
    "      ]\n",
    "\n",
    "baseline_history = model.fit(\n",
    "                            train_ds, #train_features,\n",
    "                            train_y, #train_labels,\n",
    "                            batch_size=512, #BATCH_SIZE,\n",
    "                            epochs=1000, #EPOCHS,\n",
    "                            callbacks = get_callbacks(run_id = 'first'), #[early_stopping],\n",
    "                            validation_data=(validate_ds, val_y),\n",
    "                            verbose=0) #(val_features, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(validate_ds,  val_y, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
