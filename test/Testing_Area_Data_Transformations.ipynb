{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\tmp7zbu0t88\\tensorboard_logs\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "import h5py\n",
    "import copy\n",
    "import datetime\n",
    "import ta\n",
    "import pathlib\n",
    "import shutil\n",
    "import tempfile\n",
    "import vaex as vx\n",
    "from IPython import display\n",
    "from IPython.display import clear_output\n",
    "import pyodbc\n",
    "\n",
    "# Tensorflow related\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "import tensorflow.compat.v2.feature_column as fc\n",
    "\n",
    "#!pip install -q git+https://github.com/tensorflow/docs\n",
    "\n",
    "import tensorflow_docs as tfdocs\n",
    "import tensorflow_docs.modeling\n",
    "import tensorflow_docs.plots\n",
    "\n",
    "print(tf.__version__)\n",
    "logdir = pathlib.Path(tempfile.mkdtemp())/\"tensorboard_logs\"\n",
    "shutil.rmtree(logdir, ignore_errors=True)\n",
    "print(logdir)\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, f1_score, log_loss\n",
    "\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.exceptions import ConvergenceWarning \n",
    "from sklearn import ensemble\n",
    "# ConvergenceWarning('ignore')\n",
    "# Do you wanna see?\n",
    "verbose = True\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "#sys.path.append('...../')\n",
    "\n",
    "from utils.data_extraction import load_data_final,load_data_and_save\n",
    "from utils.data_cleaning import HFDataCleaning\n",
    "from utils.generate_features import candleCreateNP_vect_final,\\\n",
    "                                    generateFeatures_final,\\\n",
    "                                    generateFeatures_multi_final\n",
    "\n",
    "from utils.preprocessing_features_and_labels import extract_labels,\\\n",
    "                                                    align_features_and_labels,\\\n",
    "                                                    pre_processing_initial,\\\n",
    "                                                    pre_processing_extended,\\\n",
    "                                                    pre_processing_final,\\\n",
    "                                                    extract_labels_multi_final,\\\n",
    "                                                    align_features_and_labels_multi_final,\\\n",
    "                                                    align_features_and_labels_multi_v5\n",
    "\n",
    "from utils.models import make_input_fn\n",
    "from utils.models import performanceTesting,scoreFunction\n",
    "from utils.plotting import plot_confusion_matrix\n",
    "from scipy.stats import kurtosis,skew,spearmanr,kendalltau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Atom.lnk',\n",
       " 'AU.txt',\n",
       " 'CryptoExtraction',\n",
       " 'desktop.ini',\n",
       " 'exchange-codes.txt',\n",
       " 'Git-2.27.0-64-bit.exe',\n",
       " 'Google Drev.lnk',\n",
       " 'Kristian',\n",
       " 'Kristian.zip',\n",
       " 'Mødrup.txt',\n",
       " 'Pensionsinfo - vejledning.pdf',\n",
       " 'SissePensionsInfo.pdf',\n",
       " 'SisseSkat2019.pdf',\n",
       " 'SupportAssistLauncher.exe',\n",
       " 'taqquote_20200501.h5',\n",
       " 'Vejledning til SKAT.pdf']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('../../../Desktop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "# sns.set_style(style=\"darkgrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which one do you want to load? \n",
      "\n",
      "0: aggregateTAQ_May2020_10sec.csv\n",
      "1: aggregateTAQ_May2020_30sec.csv\n",
      "2: aggregateTAQ_May2020_60sec.csv\n",
      "8: trueAggregateTAQ_60sec.csv\n",
      "\n",
      "\n",
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (19) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>sector</th>\n",
       "      <th>exchange</th>\n",
       "      <th>marketCap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>Technology</td>\n",
       "      <td>NMS</td>\n",
       "      <td>1.578173e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ABBV</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>NYQ</td>\n",
       "      <td>1.742612e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>ABT</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>NYQ</td>\n",
       "      <td>1.631410e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>AEP</td>\n",
       "      <td>Utilities</td>\n",
       "      <td>NYQ</td>\n",
       "      <td>4.089551e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>AMT</td>\n",
       "      <td>Real Estate</td>\n",
       "      <td>NYQ</td>\n",
       "      <td>1.171259e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>APD</td>\n",
       "      <td>Basic Materials</td>\n",
       "      <td>NYQ</td>\n",
       "      <td>5.464395e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>BA</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>NYQ</td>\n",
       "      <td>1.020356e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>BABA</td>\n",
       "      <td>Consumer Cyclical</td>\n",
       "      <td>NYQ</td>\n",
       "      <td>5.936536e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>BAC</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>NYQ</td>\n",
       "      <td>2.020550e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>BHP</td>\n",
       "      <td>Basic Materials</td>\n",
       "      <td>NYQ</td>\n",
       "      <td>1.258194e+11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ticker              sector exchange     marketCap\n",
       "12    AAPL          Technology      NMS  1.578173e+12\n",
       "20    ABBV          Healthcare      NYQ  1.742612e+11\n",
       "34     ABT          Healthcare      NYQ  1.631410e+11\n",
       "126    AEP           Utilities      NYQ  4.089551e+10\n",
       "379    AMT         Real Estate      NYQ  1.171259e+11\n",
       "428    APD     Basic Materials      NYQ  5.464395e+10\n",
       "697     BA         Industrials      NYQ  1.020356e+11\n",
       "699   BABA   Consumer Cyclical      NYQ  5.936536e+11\n",
       "700    BAC  Financial Services      NYQ  2.020550e+11\n",
       "870    BHP     Basic Materials      NYQ  1.258194e+11"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do we extract new data or read in?\n",
    "readIn = True\n",
    "# run load_data()\n",
    "if readIn:\n",
    "    \n",
    "    # Listing the data files \n",
    "    path = '../../../Google Drev/Thesis/Data/TAQ/AggregatedTAQ'\n",
    "#     path = 'F:/AggregatedTAQ/round3'\n",
    "    datafiles = os.listdir(path)\n",
    "    content = np.concatenate([['\\n\\n'],[str(j)+': '+i+'\\n' for j,i in enumerate(datafiles) if 'csv' in i],['\\n\\n']])\n",
    "    \n",
    "    # Asking for user input\n",
    "    file = input('Which one do you want to load? %s'%''.join(content))\n",
    "    if int(file) <= 2:\n",
    "        data = pd.read_csv(path + '/' + datafiles[int(file)],\n",
    "                           header = None,\n",
    "                           names=['open','high','low','close',\n",
    "                                  'spread_open','spread_high','spread_low','spread_close',\n",
    "                                  'bidsize_open','bidsize_high','bidsize_low','bidsize_close',\n",
    "                                  'ofrsize_open','ofrsize_high','ofrsize_low','ofrsize_close',\n",
    "                                  'Ticker'])\n",
    "        # Using the choice of the user to determine the correct market file\n",
    "        key = re.split('[_.]',datafiles[int(file)])[-2]\n",
    "        marketDataFile = [file for file in os.listdir(path+'/round5_market_tickers') if key in file]\n",
    "\n",
    "        # Reading in the market data\n",
    "        tempData = pd.read_csv(path+'/round5_market_tickers/'+marketDataFile[0]\n",
    "                               ,header = None\n",
    "                               ,names=['open','high','low','close',\n",
    "                                      'spread_open','spread_high','spread_low','spread_close',\n",
    "                                      'bidsize_open','bidsize_high','bidsize_low','bidsize_close',\n",
    "                                      'ofrsize_open','ofrsize_high','ofrsize_low','ofrsize_close',\n",
    "                                      'Ticker'])\n",
    "        # Adding the market data to the ticker data\n",
    "        data = pd.concat([data,tempData],axis=0)\n",
    "    else:\n",
    "        data = pd.read_csv(path + '/' + datafiles[int(file)],\n",
    "                           header = 0,\n",
    "                           index_col=[0,1]\n",
    "#                            names=['open','high','low','close',\n",
    "#                                   'spread_open','spread_high','spread_low','spread_close',\n",
    "#                                   'bidsize_open','bidsize_high','bidsize_low','bidsize_close',\n",
    "#                                   'ofrsize_open','ofrsize_high','ofrsize_low','ofrsize_close',\n",
    "#                                   'Ticker']\n",
    "                          )\n",
    "    \n",
    "    # Lower casing all column names\n",
    "#     data.columns = data.columns.str.lower()\n",
    "else:\n",
    "    \n",
    "    # print(os.listdir())\n",
    "    try:\n",
    "        path = 'a:/taqhdf5'  #'a:/taqhdf5'\n",
    "        os.listdir(path)\n",
    "    except:\n",
    "        path = 't:/taqhdf5'  #'a:/taqhdf5'\n",
    "        os.listdir(path)\n",
    "        \n",
    "    # Sample type\n",
    "    data_sample = 'full' # or 'stable'\n",
    "    # allFiles = os.listdir(path)\n",
    "    # print(len(allFiles), allFiles[:5], allFiles[-5:])\n",
    "    # print(allFiles[-10:])\n",
    "\n",
    "    #dates = np.array(['2020040' + str(i) if i < 10 else '202004' + str(i) for i in np.arange(1,16)]).astype(int)\n",
    "    dates = np.array(['20200501']).astype(int)#,'20200402','20200403','20200406','20200407'\n",
    "\n",
    "    # Provide a list of tickers of interest\n",
    "    \n",
    "    tickers = sorted(['TSLA','FB'])#'MSFT'\n",
    "    \n",
    "    # Do we need data on trades, quotes or both?\n",
    "    dataNeeded = 'quotes' # 'trades', 'quotes' or 'both'\n",
    "    \n",
    "    if dataNeeded == 'trades':\n",
    "        tradeData = load_data_final(dates, tickers, dataNeeded, path, verbose)\n",
    "    elif dataNeeded == 'quotes':\n",
    "        quoteData = load_data_final(dates,\n",
    "                                    tickers,\n",
    "                                    dataNeeded,\n",
    "                                    path,\n",
    "                                    verbose,\n",
    "                                    extract_candles = False,\n",
    "                                    aggHorizon = 1,\n",
    "                                    extra_features_from_quotes = None,\n",
    "                                    data_sample = data_sample)\n",
    "    elif dataNeeded == 'both':\n",
    "        tradeData, quoteData = load_data_final(dates, tickers, dataNeeded, path, verbose)\n",
    "\n",
    "# Reading in sector information\n",
    "stockInfo = pd.read_csv('../utils/stockInfo_v1.csv',header=[0,1])\n",
    "stockInfo.columns = ['ticker','sector','exchange','marketCap']\n",
    "\n",
    "# Creating a table with stock information based on the tickers available in the data.\n",
    "uniqueTickers = data.Ticker.unique()\n",
    "stockTable = stockInfo[stockInfo.ticker.isin(uniqueTickers)]\n",
    "stockTable.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reading in the market data (done automatically atm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping ETFS and market indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AAPL', 'ABBV', 'ABT', 'AEP', 'AMT', 'APD', 'BA', 'BABA', 'BAC',\n",
       "       'BHP', 'BP', 'CCI', 'CHL', 'COST', 'CSGP', 'D', 'DIS', 'ECL',\n",
       "       'ENB', 'EXC', 'FB', 'FMX', 'GOOG', 'INTC', 'JNJ', 'KO', 'LFC',\n",
       "       'LIN', 'LMT', 'MA', 'MCD', 'MSFT', 'NKE', 'NVDA', 'NVS', 'PBR',\n",
       "       'PEP', 'PFE', 'PLD', 'PSA', 'PTR', 'PYPL', 'RTX', 'SHW', 'SNP',\n",
       "       'SO', 'SRE', 'T', 'TM', 'TSLA', 'TSM', 'UNP', 'UPS', 'V', 'WMT'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Ticker.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the XNTK ticker\n",
    "data = data[~data.Ticker.isin(['XNTK'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AAPL', 'ABBV', 'ABT', 'AEP', 'AMT', 'APD', 'BA', 'BABA', 'BAC',\n",
       "       'BHP', 'BP', 'CCI', 'CHL', 'COST', 'CSGP', 'D', 'DIS', 'ECL',\n",
       "       'ENB', 'EXC', 'FB', 'FMX', 'GOOG', 'INTC', 'JNJ', 'KO', 'LFC',\n",
       "       'LIN', 'LMT', 'MA', 'MCD', 'MSFT', 'NKE', 'NVDA', 'NVS', 'PBR',\n",
       "       'PEP', 'PFE', 'PLD', 'PSA', 'PTR', 'PYPL', 'RTX', 'SHW', 'SNP',\n",
       "       'SO', 'SRE', 'T', 'TM', 'TSLA', 'TSM', 'UNP', 'UPS', 'V', 'WMT'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Ticker.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the XNTK ticker\n",
    "data = data[~data.Ticker.isin(['XNTK'])]\n",
    "\n",
    "etfs = ['IYH','IYM','IYK','IYJ','IYG','IYW','IYC','IYR','IDU','IYZ','IYE','IYF','SPY','DIA','QQQ']\n",
    "\n",
    "# Extracting the sector ETFs to a separate variable\n",
    "sectorETFS = data[data.Ticker.isin(etfs)]\n",
    "\n",
    "# Removing the ETFs\n",
    "data = data[~data.Ticker.isin(etfs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['open', 'high', 'low', 'close', 'spread_open', 'spread_high',\n",
       "       'spread_low', 'spread_close', 'bidsize_open', 'bidsize_high',\n",
       "       'bidsize_low', 'bidsize_close', 'ofrsize_open', 'ofrsize_high',\n",
       "       'ofrsize_low', 'ofrsize_close', 'Ticker', 'sector'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>spread_open</th>\n",
       "      <th>spread_high</th>\n",
       "      <th>spread_low</th>\n",
       "      <th>spread_close</th>\n",
       "      <th>bidsize_open</th>\n",
       "      <th>bidsize_high</th>\n",
       "      <th>bidsize_low</th>\n",
       "      <th>bidsize_close</th>\n",
       "      <th>ofrsize_open</th>\n",
       "      <th>ofrsize_high</th>\n",
       "      <th>ofrsize_low</th>\n",
       "      <th>ofrsize_close</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>sector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">20200501</th>\n",
       "      <th>0</th>\n",
       "      <td>286.250</td>\n",
       "      <td>289.260</td>\n",
       "      <td>285.870</td>\n",
       "      <td>289.260</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.24</td>\n",
       "      <td>6.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>289.260</td>\n",
       "      <td>289.350</td>\n",
       "      <td>288.365</td>\n",
       "      <td>289.020</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.10</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>289.035</td>\n",
       "      <td>289.705</td>\n",
       "      <td>288.280</td>\n",
       "      <td>288.580</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>288.485</td>\n",
       "      <td>289.315</td>\n",
       "      <td>288.280</td>\n",
       "      <td>289.095</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>289.100</td>\n",
       "      <td>290.435</td>\n",
       "      <td>288.940</td>\n",
       "      <td>290.320</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.10</td>\n",
       "      <td>13.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">20200529</th>\n",
       "      <th>385</th>\n",
       "      <td>123.950</td>\n",
       "      <td>124.110</td>\n",
       "      <td>123.910</td>\n",
       "      <td>124.100</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WMT</td>\n",
       "      <td>Consumer Defensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>124.085</td>\n",
       "      <td>124.085</td>\n",
       "      <td>123.920</td>\n",
       "      <td>123.995</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>WMT</td>\n",
       "      <td>Consumer Defensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>123.995</td>\n",
       "      <td>124.355</td>\n",
       "      <td>123.985</td>\n",
       "      <td>124.335</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.05</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>WMT</td>\n",
       "      <td>Consumer Defensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>124.335</td>\n",
       "      <td>124.355</td>\n",
       "      <td>124.060</td>\n",
       "      <td>124.075</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>WMT</td>\n",
       "      <td>Consumer Defensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>124.075</td>\n",
       "      <td>124.225</td>\n",
       "      <td>122.810</td>\n",
       "      <td>123.855</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.43</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.21</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WMT</td>\n",
       "      <td>Consumer Defensive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>429000 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 open     high      low    close  spread_open  spread_high  \\\n",
       "20200501 0    286.250  289.260  285.870  289.260         0.50         0.50   \n",
       "         1    289.260  289.350  288.365  289.020         0.24         0.45   \n",
       "         2    289.035  289.705  288.280  288.580         0.07         0.49   \n",
       "         3    288.485  289.315  288.280  289.095         0.49         0.49   \n",
       "         4    289.100  290.435  288.940  290.320         0.16         0.33   \n",
       "...               ...      ...      ...      ...          ...          ...   \n",
       "20200529 385  123.950  124.110  123.910  124.100         0.02         0.07   \n",
       "         386  124.085  124.085  123.920  123.995         0.01         0.06   \n",
       "         387  123.995  124.355  123.985  124.335         0.01         0.07   \n",
       "         388  124.335  124.355  124.060  124.075         0.05         0.12   \n",
       "         389  124.075  124.225  122.810  123.855         0.01         2.43   \n",
       "\n",
       "              spread_low  spread_close  bidsize_open  bidsize_high  \\\n",
       "20200501 0          0.01          0.24           6.0          95.0   \n",
       "         1          0.01          0.10           9.0          20.0   \n",
       "         2          0.01          0.30           1.0          50.0   \n",
       "         3          0.01          0.17           1.0          25.0   \n",
       "         4          0.01          0.10          13.0          71.0   \n",
       "...                  ...           ...           ...           ...   \n",
       "20200529 385        0.01          0.04           1.0          11.0   \n",
       "         386        0.01          0.01           1.0           8.0   \n",
       "         387        0.01          0.05           4.0          16.0   \n",
       "         388        0.01          0.01           3.0           6.0   \n",
       "         389        0.01          0.21           1.0          20.0   \n",
       "\n",
       "              bidsize_low  bidsize_close  ofrsize_open  ofrsize_high  \\\n",
       "20200501 0            1.0           10.0           1.0          85.0   \n",
       "         1            1.0            1.0           4.0          56.0   \n",
       "         2            1.0            1.0           1.0          13.0   \n",
       "         3            1.0           16.0           1.0           8.0   \n",
       "         4            1.0            1.0           1.0         236.0   \n",
       "...                   ...            ...           ...           ...   \n",
       "20200529 385          1.0            1.0           5.0           9.0   \n",
       "         386          1.0            3.0           1.0           9.0   \n",
       "         387          1.0            2.0           2.0          10.0   \n",
       "         388          1.0            2.0           2.0          10.0   \n",
       "         389          1.0            2.0           4.0          12.0   \n",
       "\n",
       "              ofrsize_low  ofrsize_close Ticker              sector  \n",
       "20200501 0            1.0            4.0   AAPL          Technology  \n",
       "         1            1.0            1.0   AAPL          Technology  \n",
       "         2            1.0            1.0   AAPL          Technology  \n",
       "         3            1.0            1.0   AAPL          Technology  \n",
       "         4            1.0            1.0   AAPL          Technology  \n",
       "...                   ...            ...    ...                 ...  \n",
       "20200529 385          1.0            1.0    WMT  Consumer Defensive  \n",
       "         386          1.0            2.0    WMT  Consumer Defensive  \n",
       "         387          1.0            2.0    WMT  Consumer Defensive  \n",
       "         388          1.0            4.0    WMT  Consumer Defensive  \n",
       "         389          1.0            1.0    WMT  Consumer Defensive  \n",
       "\n",
       "[429000 rows x 18 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00083005 -0.00152355  0.00178301 ...  0.00192698 -0.0024603\n",
      " -0.002372  ] \n",
      "\n",
      " [0.00083005 0.00152355 0.00178301 ... 0.00192698 0.0024603  0.002372  ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:MainThread:numexpr.utils:NumExpr defaulting to 4 threads.\n"
     ]
    }
   ],
   "source": [
    "for i,ticker in enumerate(data.Ticker.unique()):\n",
    "    \n",
    "    ## Price series\n",
    "    temp_price = data[data.Ticker==ticker].close\n",
    "    \n",
    "    ## Returns\n",
    "    simple_ticker_returns = ((temp_price.values[1:]/temp_price.values[:-1]) - 1)\n",
    "    log_ticker_returns = (np.log(temp_price.values[1:]) - np.log(temp_price.values[:-1]))\n",
    "    log_abs_ticker_returns = np.abs(log_ticker_returns)\n",
    "    \n",
    "    ## Returns over x period \n",
    "    simple_ticker_returns_x = [((temp_price.values[i:]/temp_price.values[:-i]) - 1)*100 for i in [3,5,10]]\n",
    "    log_ticker_returns_x = [(np.log(temp_price.values[i:]) - np.log(temp_price.values[:-i]))*100 for i in [3,5,10]]\n",
    "    log_abs_ticker_returns_x = np.abs(log_ticker_returns_x)\n",
    "    \n",
    "    ##### Autocorrelations\n",
    "    ## Pearsons\n",
    "    autocorr_log = np.correlate(log_ticker_returns,\n",
    "                                log_ticker_returns,\n",
    "                                mode='full')\n",
    "    autocorr_log = autocorr_log[autocorr_log.size//2:]\n",
    "#     if i == 0:\n",
    "#         print(log_ticker_returns,'\\n\\n',np.abs(log_ticker_returns))\n",
    "    autocorr_log_abs = np.correlate(np.abs(log_ticker_returns),\n",
    "                                np.abs(log_ticker_returns),\n",
    "                                mode='full')\n",
    "    autocorr_log_abs = autocorr_log_abs[autocorr_log_abs.size//2:]\n",
    "    \n",
    "    autocorr_simple = np.correlate(simple_ticker_returns,\n",
    "                                   simple_ticker_returns,\n",
    "                                   mode='full')\n",
    "    autocorr_simple = autocorr_simple[autocorr_simple.size//2:]\n",
    "    \n",
    "    ## Spearmans\n",
    "    s_auto_log,p_val_l = spearmanr(log_ticker_returns[0:-1],log_ticker_returns[1:])\n",
    "    s_auto_log_abs,p_val_l_abs = spearmanr(np.abs(log_ticker_returns[0:-1]),np.abs(log_ticker_returns[1:]))\n",
    "    s_auto_simple,p_val_s = spearmanr(simple_ticker_returns[0:-1],simple_ticker_returns[1:])\n",
    "    \n",
    "    ## Kendalls\n",
    "    k_auto_log,pval_l = kendalltau(log_ticker_returns[0:-1],log_ticker_returns[1:])\n",
    "    k_auto_log_abs,pval_l_abs = kendalltau(np.abs(log_ticker_returns[0:-1]),np.abs(log_ticker_returns[1:]))\n",
    "    k_auto_simple,pval_s = kendalltau(simple_ticker_returns[0:-1],simple_ticker_returns[1:])\n",
    "    \n",
    "    if i == 0:\n",
    "        simple_returns = pd.DataFrame()\n",
    "        log_returns = pd.DataFrame()\n",
    "        log_abs_returns = pd.DataFrame()\n",
    "        \n",
    "        additional_simple = pd.DataFrame(columns=['Kurt','Skew','Corr_P','Corr_S',\n",
    "                                                  'P_val_S','Corr_K','P_val_K',\n",
    "                                                  'Avg spread','Med spread','Med Return',\n",
    "                                                  'Med Return 3','Med Return 5','Med Return 10'])\n",
    "        \n",
    "        additional_log = pd.DataFrame(columns=['Kurt','Skew','Corr_P','Corr_S',\n",
    "                                               'P_val_S','Corr_K','P_val_K',\n",
    "                                               'Avg spread','Med spread','Med Return',\n",
    "                                               'Med Return 3','Med Return 5','Med Return 10'])\n",
    "        \n",
    "        additional_log_abs = pd.DataFrame(columns=['Kurt','Skew','Corr_P','Corr_S',\n",
    "                                               'P_val_S','Corr_K','P_val_K',\n",
    "                                               'Avg spread','Med spread','Med Return'\n",
    "                                                   ,'Med Return 3','Med Return 5','Med Return 10'])\n",
    "        \n",
    "        returns = pd.DataFrame({'simple_returns':simple_ticker_returns,\n",
    "                                'log_returns':log_ticker_returns,\n",
    "                                'log_abs_returns':log_abs_ticker_returns})\n",
    "        returns['ticker'] = ticker\n",
    "    else:\n",
    "        temp = pd.DataFrame({'simple_returns':simple_ticker_returns,\n",
    "                             'log_returns':log_ticker_returns,\n",
    "                             'log_abs_returns':log_abs_ticker_returns})\n",
    "        temp['ticker'] = ticker\n",
    "        returns = pd.concat([returns,temp])\n",
    "    \n",
    "    simple_returns.loc[:,ticker] = simple_ticker_returns*100\n",
    "    log_returns.loc[:,ticker] = log_ticker_returns*100\n",
    "    log_abs_returns.loc[:,ticker] = log_abs_ticker_returns*100\n",
    "    \n",
    "    ## Spread as a percentage of the price\n",
    "    spread_per_price = (data[data.Ticker==ticker].spread_close/temp_price)*100\n",
    "    \n",
    "    additional_simple.loc[ticker,['Kurt','Skew','Corr_P','Corr_S',\n",
    "                                  'P_val_S','Corr_K','P_val_K',\n",
    "                                  'Avg spread','Med spread','Med Return',\n",
    "                                  'Med Return 3','Med Return 5',\n",
    "                                  'Med Return 10']] = [kurtosis(simple_ticker_returns),\n",
    "                                                         skew(simple_ticker_returns),\n",
    "                                                         autocorr_simple[0],\n",
    "                                                         s_auto_simple,\n",
    "                                                         p_val_s,\n",
    "                                                         k_auto_simple,\n",
    "                                                         pval_s,\n",
    "                                                         np.mean(spread_per_price),\n",
    "                                                        np.median(spread_per_price),\n",
    "                                                       np.median(simple_ticker_returns),\n",
    "                                                       np.median(simple_ticker_returns_x[0]),\n",
    "                                                       np.median(simple_ticker_returns_x[1]),\n",
    "                                                       np.median(simple_ticker_returns_x[2])]\n",
    "    additional_log.loc[ticker,['Kurt','Skew','Corr_P','Corr_S',\n",
    "                               'P_val_S','Corr_K','P_val_K',\n",
    "                               'Avg spread','Med spread','Med Return',\n",
    "                               'Med Return 3','Med Return 5',\n",
    "                               'Med Return 10']] = [kurtosis(log_ticker_returns),\n",
    "                                                     skew(log_ticker_returns),\n",
    "                                                     autocorr_log[0],\n",
    "                                                      s_auto_log,\n",
    "                                                      p_val_l,\n",
    "                                                      k_auto_log,\n",
    "                                                      pval_l,\n",
    "                                                      np.mean(spread_per_price),\n",
    "                                                     np.median(spread_per_price),\n",
    "                                                    np.median(log_ticker_returns),\n",
    "                                                    np.median(log_ticker_returns_x[0]),\n",
    "                                                    np.median(log_ticker_returns_x[1]),\n",
    "                                                    np.median(log_ticker_returns_x[2])]\n",
    "    additional_log_abs.loc[ticker,['Kurt','Skew','Corr_P','Corr_S',\n",
    "                                   'P_val_S','Corr_K','P_val_K',\n",
    "                                   'Avg spread','Med spread','Med Return',\n",
    "                                   'Med Return 3','Med Return 5',\n",
    "                                   'Med Return 10']] = [kurtosis(log_abs_ticker_returns),\n",
    "                                                         skew(log_abs_ticker_returns),\n",
    "                                                         autocorr_log_abs[0],\n",
    "                                                          s_auto_log_abs,\n",
    "                                                          p_val_l_abs,\n",
    "                                                          k_auto_log_abs,\n",
    "                                                          pval_l_abs,\n",
    "                                                          np.mean(spread_per_price),\n",
    "                                                         np.median(spread_per_price),\n",
    "                                                        np.median(log_abs_ticker_returns),\n",
    "                                                        np.median(log_abs_ticker_returns_x[0]),\n",
    "                                                        np.median(log_abs_ticker_returns_x[1]),\n",
    "                                                        np.median(log_abs_ticker_returns_x[2])]\n",
    "#         simple_returns = (data.close.values[1:]/data.close.values[0:-1])-1\n",
    "# log_returns = np.log(data.close.values[1:]) - np.log(data.close.values[0:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAPL</th>\n",
       "      <th>ABBV</th>\n",
       "      <th>ABT</th>\n",
       "      <th>AEP</th>\n",
       "      <th>AMT</th>\n",
       "      <th>APD</th>\n",
       "      <th>BA</th>\n",
       "      <th>BABA</th>\n",
       "      <th>BAC</th>\n",
       "      <th>BHP</th>\n",
       "      <th>...</th>\n",
       "      <th>UNP</th>\n",
       "      <th>UPS</th>\n",
       "      <th>V</th>\n",
       "      <th>WMT</th>\n",
       "      <th>Day</th>\n",
       "      <th>Dt</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Hour category</th>\n",
       "      <th>H:M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.083005</td>\n",
       "      <td>0.921552</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.121330</td>\n",
       "      <td>0.252953</td>\n",
       "      <td>1.266613</td>\n",
       "      <td>0.368092</td>\n",
       "      <td>0.137206</td>\n",
       "      <td>-0.299401</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.460197</td>\n",
       "      <td>0.385997</td>\n",
       "      <td>0.219915</td>\n",
       "      <td>0.037172</td>\n",
       "      <td>20200501</td>\n",
       "      <td>2020-05-01</td>\n",
       "      <td>Friday</td>\n",
       "      <td>1</td>\n",
       "      <td>09.30-10.30</td>\n",
       "      <td>09:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.152355</td>\n",
       "      <td>-0.582663</td>\n",
       "      <td>-0.054828</td>\n",
       "      <td>-0.151870</td>\n",
       "      <td>0.678518</td>\n",
       "      <td>0.511132</td>\n",
       "      <td>-0.786908</td>\n",
       "      <td>-0.106699</td>\n",
       "      <td>0.213950</td>\n",
       "      <td>0.012825</td>\n",
       "      <td>...</td>\n",
       "      <td>0.348538</td>\n",
       "      <td>-0.026757</td>\n",
       "      <td>0.196657</td>\n",
       "      <td>0.276295</td>\n",
       "      <td>20200501</td>\n",
       "      <td>2020-05-01</td>\n",
       "      <td>Friday</td>\n",
       "      <td>2</td>\n",
       "      <td>09.30-10.30</td>\n",
       "      <td>09:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.178301</td>\n",
       "      <td>0.196645</td>\n",
       "      <td>-0.005484</td>\n",
       "      <td>-0.707708</td>\n",
       "      <td>0.008506</td>\n",
       "      <td>-0.488659</td>\n",
       "      <td>0.982671</td>\n",
       "      <td>-0.099180</td>\n",
       "      <td>0.042735</td>\n",
       "      <td>0.089726</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006384</td>\n",
       "      <td>-0.166055</td>\n",
       "      <td>0.199113</td>\n",
       "      <td>-0.078275</td>\n",
       "      <td>20200501</td>\n",
       "      <td>2020-05-01</td>\n",
       "      <td>Friday</td>\n",
       "      <td>3</td>\n",
       "      <td>09.30-10.30</td>\n",
       "      <td>09:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.422841</td>\n",
       "      <td>0.116575</td>\n",
       "      <td>0.010969</td>\n",
       "      <td>-0.024493</td>\n",
       "      <td>-0.257614</td>\n",
       "      <td>-0.488800</td>\n",
       "      <td>-0.549808</td>\n",
       "      <td>0.104263</td>\n",
       "      <td>-0.064109</td>\n",
       "      <td>0.064041</td>\n",
       "      <td>...</td>\n",
       "      <td>0.114855</td>\n",
       "      <td>0.026802</td>\n",
       "      <td>0.130630</td>\n",
       "      <td>-0.020609</td>\n",
       "      <td>20200501</td>\n",
       "      <td>2020-05-01</td>\n",
       "      <td>Friday</td>\n",
       "      <td>4</td>\n",
       "      <td>09.30-10.30</td>\n",
       "      <td>09:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.080978</td>\n",
       "      <td>-0.055203</td>\n",
       "      <td>-0.071317</td>\n",
       "      <td>-0.098033</td>\n",
       "      <td>0.125696</td>\n",
       "      <td>-0.117488</td>\n",
       "      <td>-0.179252</td>\n",
       "      <td>-0.066106</td>\n",
       "      <td>-0.192575</td>\n",
       "      <td>0.064000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.226645</td>\n",
       "      <td>-0.456610</td>\n",
       "      <td>0.189961</td>\n",
       "      <td>0.226463</td>\n",
       "      <td>20200501</td>\n",
       "      <td>2020-05-01</td>\n",
       "      <td>Friday</td>\n",
       "      <td>5</td>\n",
       "      <td>09.30-10.30</td>\n",
       "      <td>09:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7794</th>\n",
       "      <td>-0.048563</td>\n",
       "      <td>0.357008</td>\n",
       "      <td>0.235156</td>\n",
       "      <td>0.157798</td>\n",
       "      <td>0.141253</td>\n",
       "      <td>0.109358</td>\n",
       "      <td>-0.078936</td>\n",
       "      <td>0.186294</td>\n",
       "      <td>-0.247678</td>\n",
       "      <td>0.106090</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.047035</td>\n",
       "      <td>0.034950</td>\n",
       "      <td>0.035724</td>\n",
       "      <td>0.120943</td>\n",
       "      <td>20200529</td>\n",
       "      <td>2020-05-29</td>\n",
       "      <td>Friday</td>\n",
       "      <td>385</td>\n",
       "      <td>15.30-16.00</td>\n",
       "      <td>15:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7795</th>\n",
       "      <td>-0.078377</td>\n",
       "      <td>0.210362</td>\n",
       "      <td>0.319779</td>\n",
       "      <td>0.029195</td>\n",
       "      <td>0.038665</td>\n",
       "      <td>0.020620</td>\n",
       "      <td>-0.030905</td>\n",
       "      <td>-0.099152</td>\n",
       "      <td>0.082628</td>\n",
       "      <td>-0.084863</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020585</td>\n",
       "      <td>0.004992</td>\n",
       "      <td>-0.096996</td>\n",
       "      <td>-0.084645</td>\n",
       "      <td>20200529</td>\n",
       "      <td>2020-05-29</td>\n",
       "      <td>Friday</td>\n",
       "      <td>386</td>\n",
       "      <td>15.30-16.00</td>\n",
       "      <td>15:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7796</th>\n",
       "      <td>0.192698</td>\n",
       "      <td>-0.070071</td>\n",
       "      <td>0.255089</td>\n",
       "      <td>-0.105140</td>\n",
       "      <td>0.071490</td>\n",
       "      <td>-0.059810</td>\n",
       "      <td>0.075529</td>\n",
       "      <td>0.120904</td>\n",
       "      <td>-0.123967</td>\n",
       "      <td>0.021222</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029414</td>\n",
       "      <td>-0.029955</td>\n",
       "      <td>0.030640</td>\n",
       "      <td>0.273829</td>\n",
       "      <td>20200529</td>\n",
       "      <td>2020-05-29</td>\n",
       "      <td>Friday</td>\n",
       "      <td>387</td>\n",
       "      <td>15.30-16.00</td>\n",
       "      <td>15:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7797</th>\n",
       "      <td>-0.246030</td>\n",
       "      <td>0.123939</td>\n",
       "      <td>0.148502</td>\n",
       "      <td>-0.040918</td>\n",
       "      <td>-0.148834</td>\n",
       "      <td>0.010315</td>\n",
       "      <td>0.106330</td>\n",
       "      <td>0.007250</td>\n",
       "      <td>0.165255</td>\n",
       "      <td>0.021218</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002942</td>\n",
       "      <td>-0.059937</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.209331</td>\n",
       "      <td>20200529</td>\n",
       "      <td>2020-05-29</td>\n",
       "      <td>Friday</td>\n",
       "      <td>388</td>\n",
       "      <td>15.30-16.00</td>\n",
       "      <td>15:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7798</th>\n",
       "      <td>-0.237200</td>\n",
       "      <td>-0.161690</td>\n",
       "      <td>0.807584</td>\n",
       "      <td>-0.339678</td>\n",
       "      <td>-0.213005</td>\n",
       "      <td>-0.299559</td>\n",
       "      <td>-0.102898</td>\n",
       "      <td>-0.033836</td>\n",
       "      <td>-0.538081</td>\n",
       "      <td>-0.074282</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.170769</td>\n",
       "      <td>-0.405518</td>\n",
       "      <td>-0.848625</td>\n",
       "      <td>-0.177469</td>\n",
       "      <td>20200529</td>\n",
       "      <td>2020-05-29</td>\n",
       "      <td>Friday</td>\n",
       "      <td>389</td>\n",
       "      <td>15.30-16.00</td>\n",
       "      <td>15:59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7799 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          AAPL      ABBV       ABT       AEP       AMT       APD        BA  \\\n",
       "0    -0.083005  0.921552  0.000000 -0.121330  0.252953  1.266613  0.368092   \n",
       "1    -0.152355 -0.582663 -0.054828 -0.151870  0.678518  0.511132 -0.786908   \n",
       "2     0.178301  0.196645 -0.005484 -0.707708  0.008506 -0.488659  0.982671   \n",
       "3     0.422841  0.116575  0.010969 -0.024493 -0.257614 -0.488800 -0.549808   \n",
       "4    -0.080978 -0.055203 -0.071317 -0.098033  0.125696 -0.117488 -0.179252   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "7794 -0.048563  0.357008  0.235156  0.157798  0.141253  0.109358 -0.078936   \n",
       "7795 -0.078377  0.210362  0.319779  0.029195  0.038665  0.020620 -0.030905   \n",
       "7796  0.192698 -0.070071  0.255089 -0.105140  0.071490 -0.059810  0.075529   \n",
       "7797 -0.246030  0.123939  0.148502 -0.040918 -0.148834  0.010315  0.106330   \n",
       "7798 -0.237200 -0.161690  0.807584 -0.339678 -0.213005 -0.299559 -0.102898   \n",
       "\n",
       "          BABA       BAC       BHP  ...       UNP       UPS         V  \\\n",
       "0     0.137206 -0.299401  0.000000  ... -0.460197  0.385997  0.219915   \n",
       "1    -0.106699  0.213950  0.012825  ...  0.348538 -0.026757  0.196657   \n",
       "2    -0.099180  0.042735  0.089726  ... -0.006384 -0.166055  0.199113   \n",
       "3     0.104263 -0.064109  0.064041  ...  0.114855  0.026802  0.130630   \n",
       "4    -0.066106 -0.192575  0.064000  ... -0.226645 -0.456610  0.189961   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "7794  0.186294 -0.247678  0.106090  ... -0.047035  0.034950  0.035724   \n",
       "7795 -0.099152  0.082628 -0.084863  ... -0.020585  0.004992 -0.096996   \n",
       "7796  0.120904 -0.123967  0.021222  ... -0.029414 -0.029955  0.030640   \n",
       "7797  0.007250  0.165255  0.021218  ...  0.002942 -0.059937  0.000000   \n",
       "7798 -0.033836 -0.538081 -0.074282  ... -0.170769 -0.405518 -0.848625   \n",
       "\n",
       "           WMT       Day         Dt  Weekday  Hour  Hour category    H:M  \n",
       "0     0.037172  20200501 2020-05-01   Friday     1    09.30-10.30  09:31  \n",
       "1     0.276295  20200501 2020-05-01   Friday     2    09.30-10.30  09:32  \n",
       "2    -0.078275  20200501 2020-05-01   Friday     3    09.30-10.30  09:33  \n",
       "3    -0.020609  20200501 2020-05-01   Friday     4    09.30-10.30  09:34  \n",
       "4     0.226463  20200501 2020-05-01   Friday     5    09.30-10.30  09:35  \n",
       "...        ...       ...        ...      ...   ...            ...    ...  \n",
       "7794  0.120943  20200529 2020-05-29   Friday   385    15.30-16.00  15:55  \n",
       "7795 -0.084645  20200529 2020-05-29   Friday   386    15.30-16.00  15:56  \n",
       "7796  0.273829  20200529 2020-05-29   Friday   387    15.30-16.00  15:57  \n",
       "7797 -0.209331  20200529 2020-05-29   Friday   388    15.30-16.00  15:58  \n",
       "7798 -0.177469  20200529 2020-05-29   Friday   389    15.30-16.00  15:59  \n",
       "\n",
       "[7799 rows x 61 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_returns.loc[:,'Day'] = data[data.Ticker == 'AAPL'].index[1:].get_level_values(0)\n",
    "\n",
    "for i,d in enumerate(simple_returns.Day.unique().astype(str)):\n",
    "\n",
    "    if i == 0:\n",
    "        number_of_obs = simple_returns[simple_returns.Day == int(d)].shape[0]\n",
    "        \n",
    "        container = pd.DataFrame()\n",
    "        \n",
    "        container.loc[:,'timestamp'] = pd.date_range(d+' 09:31',periods = number_of_obs,freq='T')\n",
    "        \n",
    "    else:\n",
    "        number_of_obs = simple_returns[simple_returns.Day == int(d)].shape[0]\n",
    "        \n",
    "        temp = pd.DataFrame({'timestamp':pd.date_range(d+' 09:30',periods = number_of_obs,freq='T')})\n",
    "        \n",
    "        container = pd.concat([container,temp],axis=0)\n",
    "        \n",
    "container = container.reset_index(drop=True)\n",
    "\n",
    "total_obs = simple_returns[simple_returns.Day==20200504].shape[0]\n",
    "perhour = simple_returns[simple_returns.Day==20200504].shape[0]/6.5\n",
    "bins_hc = np.linspace(0,perhour*7,8)\n",
    "\n",
    "# Weekdays\n",
    "weekdays = {0: 'Monday'\n",
    "             ,1:'Tuesday'\n",
    "             ,2:'Wednesday'\n",
    "             ,3:'Thursday'\n",
    "             ,4:'Friday'}\n",
    "\n",
    "# temp_return = log_returns.copy(deep=True)\n",
    "log_returns.loc[:,'Day'] = data[data.Ticker == 'AAPL'].index[1:].get_level_values(0)\n",
    "log_returns.loc[:,'Dt'] = pd.to_datetime(log_returns.Day,format='%Y%m%d')\n",
    "log_returns.loc[:,'Weekday'] = log_returns.Dt.dt.dayofweek.apply(lambda x: weekdays[x])\n",
    "log_returns.loc[:,'Hour'] = data[data.Ticker == 'AAPL'].index[1:].get_level_values(1)\n",
    "log_returns.loc[:,'Hour category'] = pd.cut(log_returns.Hour,\n",
    "                                           bins=bins_hc,#[0,60,120,180,240,300,360,420],\n",
    "                                           right=True,\n",
    "                                           include_lowest=True,labels=['09.30-10.30',\n",
    "                                                                       '10.30-11.30',\n",
    "                                                                       '11.30-12.30',\n",
    "                                                                       '12.30-13.30',\n",
    "                                                                       '13.30-14.30',\n",
    "                                                                       '14.30-15.30',\n",
    "                                                                       '15.30-16.00'])\n",
    "log_returns.loc[:,'H:M'] = container.timestamp.dt.strftime('%H:%M')\n",
    "\n",
    "\n",
    "simple_returns.loc[:,'Day'] = data[data.Ticker == 'AAPL'].index[1:].get_level_values(0)\n",
    "simple_returns.loc[:,'Dt'] = pd.to_datetime(log_returns.Day,format='%Y%m%d')\n",
    "simple_returns.loc[:,'Weekday'] = log_returns.Dt.dt.dayofweek.apply(lambda x: weekdays[x])\n",
    "simple_returns.loc[:,'Hour'] = data[data.Ticker == 'AAPL'].index[1:].get_level_values(1)\n",
    "simple_returns.loc[:,'Hour category'] = pd.cut(log_returns.Hour,\n",
    "                                           bins=bins_hc,#[0,60,120,180,240,300,360,420],\n",
    "                                           right=True,\n",
    "                                           include_lowest=True,labels=['09.30-10.30',\n",
    "                                                                       '10.30-11.30',\n",
    "                                                                       '11.30-12.30',\n",
    "                                                                       '12.30-13.30',\n",
    "                                                                       '13.30-14.30',\n",
    "                                                                       '14.30-15.30',\n",
    "                                                                       '15.30-16.00'])\n",
    "simple_returns.loc[:,'H:M'] = container.timestamp.dt.strftime('%H:%M')\n",
    "\n",
    "### Prepping to look at other metrics as well\n",
    "data.loc[:,'Day'] = data.index.get_level_values(0)\n",
    "data.loc[:,'Dt'] = pd.to_datetime(data.Day,format='%Y%m%d')\n",
    "data.loc[:,'Weekday'] = data.Dt.dt.dayofweek.apply(lambda x: weekdays[x])\n",
    "data.loc[:,'Hour'] = data.index.get_level_values(1)\n",
    "data.loc[:,'Hour category'] = pd.cut(data.Hour,\n",
    "                                           bins=bins_hc,#[0,60,120,180,240,300,360,420],\n",
    "                                           right=True,\n",
    "                                           include_lowest=True,labels=['09.30-10.30',\n",
    "                                                                       '10.30-11.30',\n",
    "                                                                       '11.30-12.30',\n",
    "                                                                       '12.30-13.30',\n",
    "                                                                       '13.30-14.30',\n",
    "                                                                       '14.30-15.30',\n",
    "                                                                       '15.30-16.00'])\n",
    "\n",
    "data.loc[:,'H:M'] = container.timestamp.dt.strftime('%H:%M')\n",
    "\n",
    "\n",
    "log_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context(\"paper\", font_scale=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>spread_open</th>\n",
       "      <th>spread_high</th>\n",
       "      <th>spread_low</th>\n",
       "      <th>spread_close</th>\n",
       "      <th>bidsize_open</th>\n",
       "      <th>bidsize_high</th>\n",
       "      <th>...</th>\n",
       "      <th>ofrsize_low</th>\n",
       "      <th>ofrsize_close</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>sector</th>\n",
       "      <th>Day</th>\n",
       "      <th>Dt</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Hour category</th>\n",
       "      <th>H:M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">20200501</th>\n",
       "      <th>0</th>\n",
       "      <td>286.250</td>\n",
       "      <td>289.260</td>\n",
       "      <td>285.870</td>\n",
       "      <td>289.260</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.24</td>\n",
       "      <td>6.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Technology</td>\n",
       "      <td>20200501</td>\n",
       "      <td>2020-05-01</td>\n",
       "      <td>Friday</td>\n",
       "      <td>0</td>\n",
       "      <td>09.30-10.30</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>289.260</td>\n",
       "      <td>289.350</td>\n",
       "      <td>288.365</td>\n",
       "      <td>289.020</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.10</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Technology</td>\n",
       "      <td>20200501</td>\n",
       "      <td>2020-05-01</td>\n",
       "      <td>Friday</td>\n",
       "      <td>1</td>\n",
       "      <td>09.30-10.30</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>289.035</td>\n",
       "      <td>289.705</td>\n",
       "      <td>288.280</td>\n",
       "      <td>288.580</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Technology</td>\n",
       "      <td>20200501</td>\n",
       "      <td>2020-05-01</td>\n",
       "      <td>Friday</td>\n",
       "      <td>2</td>\n",
       "      <td>09.30-10.30</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>288.485</td>\n",
       "      <td>289.315</td>\n",
       "      <td>288.280</td>\n",
       "      <td>289.095</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Technology</td>\n",
       "      <td>20200501</td>\n",
       "      <td>2020-05-01</td>\n",
       "      <td>Friday</td>\n",
       "      <td>3</td>\n",
       "      <td>09.30-10.30</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>289.100</td>\n",
       "      <td>290.435</td>\n",
       "      <td>288.940</td>\n",
       "      <td>290.320</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.10</td>\n",
       "      <td>13.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Technology</td>\n",
       "      <td>20200501</td>\n",
       "      <td>2020-05-01</td>\n",
       "      <td>Friday</td>\n",
       "      <td>4</td>\n",
       "      <td>09.30-10.30</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">20200529</th>\n",
       "      <th>385</th>\n",
       "      <td>123.950</td>\n",
       "      <td>124.110</td>\n",
       "      <td>123.910</td>\n",
       "      <td>124.100</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WMT</td>\n",
       "      <td>Consumer Defensive</td>\n",
       "      <td>20200529</td>\n",
       "      <td>2020-05-29</td>\n",
       "      <td>Friday</td>\n",
       "      <td>385</td>\n",
       "      <td>15.30-16.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>124.085</td>\n",
       "      <td>124.085</td>\n",
       "      <td>123.920</td>\n",
       "      <td>123.995</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>WMT</td>\n",
       "      <td>Consumer Defensive</td>\n",
       "      <td>20200529</td>\n",
       "      <td>2020-05-29</td>\n",
       "      <td>Friday</td>\n",
       "      <td>386</td>\n",
       "      <td>15.30-16.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>123.995</td>\n",
       "      <td>124.355</td>\n",
       "      <td>123.985</td>\n",
       "      <td>124.335</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.05</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>WMT</td>\n",
       "      <td>Consumer Defensive</td>\n",
       "      <td>20200529</td>\n",
       "      <td>2020-05-29</td>\n",
       "      <td>Friday</td>\n",
       "      <td>387</td>\n",
       "      <td>15.30-16.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>124.335</td>\n",
       "      <td>124.355</td>\n",
       "      <td>124.060</td>\n",
       "      <td>124.075</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>WMT</td>\n",
       "      <td>Consumer Defensive</td>\n",
       "      <td>20200529</td>\n",
       "      <td>2020-05-29</td>\n",
       "      <td>Friday</td>\n",
       "      <td>388</td>\n",
       "      <td>15.30-16.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>124.075</td>\n",
       "      <td>124.225</td>\n",
       "      <td>122.810</td>\n",
       "      <td>123.855</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.43</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.21</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WMT</td>\n",
       "      <td>Consumer Defensive</td>\n",
       "      <td>20200529</td>\n",
       "      <td>2020-05-29</td>\n",
       "      <td>Friday</td>\n",
       "      <td>389</td>\n",
       "      <td>15.30-16.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>429000 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 open     high      low    close  spread_open  spread_high  \\\n",
       "20200501 0    286.250  289.260  285.870  289.260         0.50         0.50   \n",
       "         1    289.260  289.350  288.365  289.020         0.24         0.45   \n",
       "         2    289.035  289.705  288.280  288.580         0.07         0.49   \n",
       "         3    288.485  289.315  288.280  289.095         0.49         0.49   \n",
       "         4    289.100  290.435  288.940  290.320         0.16         0.33   \n",
       "...               ...      ...      ...      ...          ...          ...   \n",
       "20200529 385  123.950  124.110  123.910  124.100         0.02         0.07   \n",
       "         386  124.085  124.085  123.920  123.995         0.01         0.06   \n",
       "         387  123.995  124.355  123.985  124.335         0.01         0.07   \n",
       "         388  124.335  124.355  124.060  124.075         0.05         0.12   \n",
       "         389  124.075  124.225  122.810  123.855         0.01         2.43   \n",
       "\n",
       "              spread_low  spread_close  bidsize_open  bidsize_high  ...  \\\n",
       "20200501 0          0.01          0.24           6.0          95.0  ...   \n",
       "         1          0.01          0.10           9.0          20.0  ...   \n",
       "         2          0.01          0.30           1.0          50.0  ...   \n",
       "         3          0.01          0.17           1.0          25.0  ...   \n",
       "         4          0.01          0.10          13.0          71.0  ...   \n",
       "...                  ...           ...           ...           ...  ...   \n",
       "20200529 385        0.01          0.04           1.0          11.0  ...   \n",
       "         386        0.01          0.01           1.0           8.0  ...   \n",
       "         387        0.01          0.05           4.0          16.0  ...   \n",
       "         388        0.01          0.01           3.0           6.0  ...   \n",
       "         389        0.01          0.21           1.0          20.0  ...   \n",
       "\n",
       "              ofrsize_low  ofrsize_close  Ticker              sector  \\\n",
       "20200501 0            1.0            4.0    AAPL          Technology   \n",
       "         1            1.0            1.0    AAPL          Technology   \n",
       "         2            1.0            1.0    AAPL          Technology   \n",
       "         3            1.0            1.0    AAPL          Technology   \n",
       "         4            1.0            1.0    AAPL          Technology   \n",
       "...                   ...            ...     ...                 ...   \n",
       "20200529 385          1.0            1.0     WMT  Consumer Defensive   \n",
       "         386          1.0            2.0     WMT  Consumer Defensive   \n",
       "         387          1.0            2.0     WMT  Consumer Defensive   \n",
       "         388          1.0            4.0     WMT  Consumer Defensive   \n",
       "         389          1.0            1.0     WMT  Consumer Defensive   \n",
       "\n",
       "                   Day         Dt Weekday Hour  Hour category  H:M  \n",
       "20200501 0    20200501 2020-05-01  Friday    0    09.30-10.30  NaN  \n",
       "         1    20200501 2020-05-01  Friday    1    09.30-10.30  NaN  \n",
       "         2    20200501 2020-05-01  Friday    2    09.30-10.30  NaN  \n",
       "         3    20200501 2020-05-01  Friday    3    09.30-10.30  NaN  \n",
       "         4    20200501 2020-05-01  Friday    4    09.30-10.30  NaN  \n",
       "...                ...        ...     ...  ...            ...  ...  \n",
       "20200529 385  20200529 2020-05-29  Friday  385    15.30-16.00  NaN  \n",
       "         386  20200529 2020-05-29  Friday  386    15.30-16.00  NaN  \n",
       "         387  20200529 2020-05-29  Friday  387    15.30-16.00  NaN  \n",
       "         388  20200529 2020-05-29  Friday  388    15.30-16.00  NaN  \n",
       "         389  20200529 2020-05-29  Friday  389    15.30-16.00  NaN  \n",
       "\n",
       "[429000 rows x 24 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_data = data.iloc[0:50,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting plotly==4.14.1\n",
      "  Downloading plotly-4.14.1-py2.py3-none-any.whl (13.2 MB)\n",
      "Requirement already satisfied: six in c:\\users\\pc\\anaconda3\\lib\\site-packages (from plotly==4.14.1) (1.14.0)\n",
      "Collecting retrying>=1.3.3\n",
      "  Downloading retrying-1.3.3.tar.gz (10 kB)\n",
      "Building wheels for collected packages: retrying\n",
      "  Building wheel for retrying (setup.py): started\n",
      "  Building wheel for retrying (setup.py): finished with status 'done'\n",
      "  Created wheel for retrying: filename=retrying-1.3.3-py3-none-any.whl size=11435 sha256=bdb6177db813a8be948ab7ba44ddd6b33f4100e002234c2b457ac8ff6d0cabcb\n",
      "  Stored in directory: c:\\users\\pc\\appdata\\local\\pip\\cache\\wheels\\f9\\8d\\8d\\f6af3f7f9eea3553bc2fe6d53e4b287dad18b06a861ac56ddf\n",
      "Successfully built retrying\n",
      "Installing collected packages: retrying, plotly\n",
      "Successfully installed plotly-4.14.1 retrying-1.3.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install plotly==4.14.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'plotly'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-69413c972952>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph_objects\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mgo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# import pandas as pd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# df = pd.read_csv('https://raw.githubusercontent.com/plotly/datasets/master/finance-charts-apple.csv')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'plotly'"
     ]
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "# import pandas as pd\n",
    "\n",
    "# df = pd.read_csv('https://raw.githubusercontent.com/plotly/datasets/master/finance-charts-apple.csv')\n",
    "\n",
    "fig = go.Figure(data=[go.Candlestick(x=subset_data['Dt'],\n",
    "                open=subset_data['open'], high=subset_data['high'],\n",
    "                low=subset_data['low'], close=subset_data['close'])\n",
    "                     ])\n",
    "\n",
    "fig.update_layout(xaxis_rangeslider_visible=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:MainThread:numexpr.utils:NumExpr defaulting to 4 threads.\n",
      "C:\\Users\\PC\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:844: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "C:\\Users\\PC\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:965: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAPL done\n",
      "ABBV done\n",
      "ABT done\n",
      "AEP done\n",
      "AMT done\n",
      "APD done\n",
      "BA done\n",
      "BABA done\n",
      "BAC done\n",
      "BHP done\n",
      "BP done\n",
      "CCI done\n",
      "CHL done\n",
      "COST done\n",
      "CSGP done\n",
      "D done\n",
      "DIS done\n",
      "ECL done\n",
      "ENB done\n",
      "EXC done\n",
      "FB done\n",
      "FMX done\n",
      "GOOG done\n",
      "INTC done\n",
      "JNJ done\n",
      "KO done\n",
      "LFC done\n",
      "LIN done\n",
      "LMT done\n",
      "MA done\n",
      "MCD done\n",
      "MSFT done\n",
      "NKE done\n",
      "NVDA done\n",
      "NVS done\n",
      "Number of NaNs in label: 1. 1 is expected\n",
      "Returns that lead to NaNs in label: [0.0907158]\n",
      "PBR done\n",
      "PEP done\n",
      "PFE done\n",
      "PLD done\n",
      "PSA done\n",
      "PTR done\n",
      "PYPL done\n",
      "RTX done\n",
      "SHW done\n",
      "SNP done\n",
      "SO done\n",
      "SRE done\n",
      "T done\n",
      "TM done\n",
      "TSLA done\n",
      "TSM done\n",
      "UNP done\n",
      "UPS done\n",
      "V done\n",
      "WMT done\n"
     ]
    }
   ],
   "source": [
    "########### Generate Features ################\n",
    "\n",
    "n_feature_lags = 1\n",
    "\n",
    "# features = generateFeatures_multi_final(data = data, \n",
    "#                                   listOfFeatures = [\n",
    "#                                                     'pastobs',\n",
    "#                                                     'spread',\n",
    "#                                                     'bidsize',\n",
    "#                                                     'ofrsize',\n",
    "# #                                                     'stok',\n",
    "# #                                                     'stod',\n",
    "# #                                                     'sstod',\n",
    "# #                                                     'wilr',\n",
    "# #                                                     'roc',\n",
    "# #                                                     'rsi',\n",
    "# #                                                     'atr',\n",
    "# #                                                     'cci',\n",
    "# #                                                     'dpo',\n",
    "# #                                                     'sma',\n",
    "# #                                                     'ema',\n",
    "# #                                                     'macd',\n",
    "# #                                                       'macd_diff',\n",
    "# #                                                       'macd_signal',\n",
    "# #                                                     'dis5',\n",
    "# #                                                     'dis10',\n",
    "#                                                       'sector'\n",
    "#                                                    ], \n",
    "#                                    feature_lags = n_feature_lags\n",
    "#                                      ,stockTable=stockTable)\n",
    "features = generateFeatures_multi_final(data = data, \n",
    "                                  listOfFeatures = [\n",
    "                                                    'pastobs',\n",
    "                                                    'spread',\n",
    "                                                    'bidsize',\n",
    "                                                    'ofrsize',\n",
    "                                                    'stok',\n",
    "                                                    'stod',\n",
    "                                                    'sstod',\n",
    "#                                                     'wilr',\n",
    "                                                    'roc',\n",
    "                                                    'rsi',\n",
    "                                                    'atr',\n",
    "                                                    'cci',\n",
    "                                                    'dpo',\n",
    "                                                    'sma',\n",
    "                                                    'ema',\n",
    "                                                    'macd',\n",
    "                                                      'macd_diff',\n",
    "                                                      'macd_signal',\n",
    "                                                    'dis5',\n",
    "                                                    'dis10',\n",
    "                                                      'sector'\n",
    "                                                   ], \n",
    "                                   feature_lags = n_feature_lags\n",
    "                                     ,sectorETFS=sectorETFS)\n",
    "\n",
    "########### Generate Labels ################\n",
    "\n",
    "n_classes = 2\n",
    "# extract first 4 columns as the lag0 or raw OHLC prices (used for labelling)\n",
    "price_candles = data[['open','high','low','close','Ticker']]\n",
    "\n",
    "########### Align Data ################\n",
    "\n",
    "# from imported function (see testing_preprocessing_features_and_labels.ipynb for thorough experimenting with all the cut-offs):    \n",
    "X, y,indices = align_features_and_labels_multi_final(price_candles = price_candles, \n",
    "                                                 all_features = features,\n",
    "                                                 prediction_horizon = 1, \n",
    "                                                 n_feature_lags = n_feature_lags, \n",
    "                                                 n_classes = n_classes, # 5,\n",
    "                                                 safe_burn_in = False, \n",
    "                                                 data_sample = 'full',\n",
    "                                                 splitType='global',\n",
    "                                                 noise=False,ticker_dummies=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding ticker dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Adding ticker dummies\n",
    "tickers = X.pop('ticker')\n",
    "X = pd.concat([X, pd.get_dummies(tickers, prefix='ticker', drop_first=False)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['open_lag0', 'high_lag0', 'low_lag0', 'close_lag0', 'spread_open_lag0',\n",
       "       'spread_high_lag0', 'spread_low_lag0', 'spread_close_lag0',\n",
       "       'bidsize_open_lag0', 'bidsize_high_lag0',\n",
       "       ...\n",
       "       'ticker_SO', 'ticker_SRE', 'ticker_T', 'ticker_TM', 'ticker_TSLA',\n",
       "       'ticker_TSM', 'ticker_UNP', 'ticker_UPS', 'ticker_V', 'ticker_WMT'],\n",
       "      dtype='object', length=156)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing our final train/validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(341385, 156)\n",
      "(341385, 1)\n",
      "(85690, 156)\n",
      "(85690, 1)\n"
     ]
    }
   ],
   "source": [
    "# train_ds = pd.concat([X.iloc[start:end, :] for (start, end) in train_ranges]).reset_index(drop=True)\n",
    "# train_y = pd.concat([y.iloc[start:end] for (start, end) in train_ranges]).reset_index(drop=True)\n",
    "\n",
    "# validate_ds = pd.concat([X.iloc[start:end, :] for (start, end) in val_ranges]).reset_index(drop=True)\n",
    "# val_y = pd.concat([y.iloc[start:end] for (start, end) in val_ranges]).reset_index(drop=True)\n",
    "\n",
    "# train_ds.shape, train_y.shape, validate_ds.shape, val_y.shape, train_y.shape[0] + val_y.shape[0]\n",
    "\n",
    "# Let's have a proper split (along tickers & dates)\n",
    "train_size = 0.8\n",
    "\n",
    "# Sort the indices\n",
    "tempIndices = indices.sort_values(['days','timestamps','ticker'])\n",
    "\n",
    "# Sorting the data\n",
    "X = X.loc[tempIndices.index,:]#.head(66)\n",
    "y = y.loc[tempIndices.index,:]\n",
    "\n",
    "# extracting the first date for the validation data.\n",
    "first_val_day = int(np.floor(indices.days.unique().shape[0]*0.8))\n",
    "\n",
    "# Splitting the data\n",
    "X_train = X[tempIndices.days<tempIndices.days.unique()[first_val_day]].reset_index(drop=True)\n",
    "y_train = y[tempIndices.days<tempIndices.days.unique()[first_val_day]].reset_index(drop=True)\n",
    "\n",
    "X_test = X[tempIndices.days>=tempIndices.days.unique()[first_val_day]].reset_index(drop=True)\n",
    "y_test = y[tempIndices.days>=tempIndices.days.unique()[first_val_day]].reset_index(drop=True)\n",
    "\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open_lag0</th>\n",
       "      <th>high_lag0</th>\n",
       "      <th>low_lag0</th>\n",
       "      <th>close_lag0</th>\n",
       "      <th>spread_open_lag0</th>\n",
       "      <th>spread_high_lag0</th>\n",
       "      <th>spread_low_lag0</th>\n",
       "      <th>spread_close_lag0</th>\n",
       "      <th>bidsize_open_lag0</th>\n",
       "      <th>bidsize_high_lag0</th>\n",
       "      <th>...</th>\n",
       "      <th>ticker_SO</th>\n",
       "      <th>ticker_SRE</th>\n",
       "      <th>ticker_T</th>\n",
       "      <th>ticker_TM</th>\n",
       "      <th>ticker_TSLA</th>\n",
       "      <th>ticker_TSM</th>\n",
       "      <th>ticker_UNP</th>\n",
       "      <th>ticker_UPS</th>\n",
       "      <th>ticker_V</th>\n",
       "      <th>ticker_WMT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.545</td>\n",
       "      <td>0.205</td>\n",
       "      <td>-0.635</td>\n",
       "      <td>296.440</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.200</td>\n",
       "      <td>0.040</td>\n",
       "      <td>-0.255</td>\n",
       "      <td>82.805</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.030</td>\n",
       "      <td>-0.040</td>\n",
       "      <td>90.855</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.100</td>\n",
       "      <td>0.140</td>\n",
       "      <td>-0.110</td>\n",
       "      <td>81.510</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.070</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>234.230</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341380</th>\n",
       "      <td>0.035</td>\n",
       "      <td>0.165</td>\n",
       "      <td>-0.040</td>\n",
       "      <td>51.300</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>5.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341381</th>\n",
       "      <td>0.890</td>\n",
       "      <td>0.965</td>\n",
       "      <td>-0.290</td>\n",
       "      <td>169.435</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1.41</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341382</th>\n",
       "      <td>0.105</td>\n",
       "      <td>0.235</td>\n",
       "      <td>-0.465</td>\n",
       "      <td>97.955</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1.32</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341383</th>\n",
       "      <td>-0.080</td>\n",
       "      <td>0.540</td>\n",
       "      <td>-0.245</td>\n",
       "      <td>195.705</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.08</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341384</th>\n",
       "      <td>-0.560</td>\n",
       "      <td>0.055</td>\n",
       "      <td>-0.605</td>\n",
       "      <td>125.185</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.11</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>341385 rows × 156 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        open_lag0  high_lag0  low_lag0  close_lag0  spread_open_lag0  \\\n",
       "0          -0.545      0.205    -0.635     296.440              0.09   \n",
       "1          -0.200      0.040    -0.255      82.805              0.21   \n",
       "2           0.000      0.030    -0.040      90.855              0.07   \n",
       "3           0.100      0.140    -0.110      81.510              0.06   \n",
       "4           0.010      0.070    -0.045     234.230              0.26   \n",
       "...           ...        ...       ...         ...               ...   \n",
       "341380      0.035      0.165    -0.040      51.300              0.17   \n",
       "341381      0.890      0.965    -0.290     169.435              0.35   \n",
       "341382      0.105      0.235    -0.465      97.955              0.86   \n",
       "341383     -0.080      0.540    -0.245     195.705              0.75   \n",
       "341384     -0.560      0.055    -0.605     125.185              1.25   \n",
       "\n",
       "        spread_high_lag0  spread_low_lag0  spread_close_lag0  \\\n",
       "0                   0.20             0.01               0.06   \n",
       "1                   0.26             0.01               0.07   \n",
       "2                   0.10             0.01               0.09   \n",
       "3                   0.25             0.03               0.16   \n",
       "4                   0.30             0.11               0.18   \n",
       "...                  ...              ...                ...   \n",
       "341380              0.26             0.01               0.02   \n",
       "341381              1.41             0.01               0.93   \n",
       "341382              1.32             0.06               0.15   \n",
       "341383              1.08             0.01               0.07   \n",
       "341384              1.25             0.01               0.11   \n",
       "\n",
       "        bidsize_open_lag0  bidsize_high_lag0  ...  ticker_SO  ticker_SRE  \\\n",
       "0                     1.0               12.0  ...          0           0   \n",
       "1                     1.0                8.0  ...          0           0   \n",
       "2                     1.0                4.0  ...          0           0   \n",
       "3                     1.0                9.0  ...          0           0   \n",
       "4                     1.0                3.0  ...          0           0   \n",
       "...                   ...                ...  ...        ...         ...   \n",
       "341380                5.0               23.0  ...          0           0   \n",
       "341381                1.0               10.0  ...          0           0   \n",
       "341382                1.0                6.0  ...          0           0   \n",
       "341383                1.0                4.0  ...          0           0   \n",
       "341384                2.0                4.0  ...          0           0   \n",
       "\n",
       "        ticker_T  ticker_TM  ticker_TSLA  ticker_TSM  ticker_UNP  ticker_UPS  \\\n",
       "0              0          0            0           0           0           0   \n",
       "1              0          0            0           0           0           0   \n",
       "2              0          0            0           0           0           0   \n",
       "3              0          0            0           0           0           0   \n",
       "4              0          0            0           0           0           0   \n",
       "...          ...        ...          ...         ...         ...         ...   \n",
       "341380         0          0            0           1           0           0   \n",
       "341381         0          0            0           0           1           0   \n",
       "341382         0          0            0           0           0           1   \n",
       "341383         0          0            0           0           0           0   \n",
       "341384         0          0            0           0           0           0   \n",
       "\n",
       "        ticker_V  ticker_WMT  \n",
       "0              0           0  \n",
       "1              0           0  \n",
       "2              0           0  \n",
       "3              0           0  \n",
       "4              0           0  \n",
       "...          ...         ...  \n",
       "341380         0           0  \n",
       "341381         0           0  \n",
       "341382         0           0  \n",
       "341383         1           0  \n",
       "341384         0           1  \n",
       "\n",
       "[341385 rows x 156 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64),)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where((np.sum(np.isinf(X_train.values), axis=1) == 0) == False),\n",
    "np.where((np.sum(np.isnan(X_train.values), axis=1) == 0) == False)#X_train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{i:colname for i,colname in enumerate(train_ds.columns)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating one ppdict for individual preprocessings\n",
    "# ppdict1 = {'open':'minmax',\n",
    "#           'high':'log',\n",
    "#           'low':'log',\n",
    "#           'close':'std'}\n",
    "# splitpoint = 32\n",
    "\n",
    "# # Standardize some features\n",
    "# ppdict1 = {i:'std' for i in train_ds.columns[0:splitpoint]} \n",
    "# # Keep some in actual levels (Dummies in this case).\n",
    "# ppdict2 = {i:'act' for i in train_ds.columns[splitpoint:]}\n",
    "\n",
    "pre_procesing_applied = 'std'\n",
    "\n",
    "# Merging the two\n",
    "# ppdict = {**ppdict1,**ppdict2}\n",
    "\n",
    "if  pre_procesing_applied == 'None':\n",
    "    # do nothing here\n",
    "    pass\n",
    "\n",
    "elif  pre_procesing_applied == 'std':\n",
    "\n",
    "    # splitpoint = int((args.feature-lags+1)*16)#32\n",
    "    # columns_to_pre_process = [col for col in X_train.columns if 'd_' != col[0:2]]\n",
    "\n",
    "    # Standardize some features\n",
    "    ppdict1 = {i:'std' for i in X_train.columns if 'd_' != i[0:2]} \n",
    "    # Keep some in actual levels (Dummies in this case).\n",
    "    ppdict2 = {i:'act' for i in X_train.columns if 'd_' == i[0:2]} \n",
    "\n",
    "    # Merging the two\n",
    "    ppdict = {**ppdict1,**ppdict2}\n",
    "\n",
    "    # x_train,x_test = pre_processing(x_train,x_test,pp_dict)\n",
    "\n",
    "elif pre_procesing_applied == 'minmax':\n",
    "\n",
    "    # splitpoint = int((args.feature-lags+1)*16)#32\n",
    "    # columns_to_pre_process = [col for col in X_train.columns if 'd_' != col[0:2]]\n",
    "\n",
    "    # Standardize some features\n",
    "    ppdict1 = {i:'minmax' for i in X_train.columns if 'd_' != i[0:2]} \n",
    "    # Keep some in actual levels (Dummies in this case).\n",
    "    ppdict2 = {i:'act' for i in X_train.columns if 'd_' == i[0:2]} \n",
    "\n",
    "    # Merging the two\n",
    "    ppdict = {**ppdict1,**ppdict2}\n",
    "\n",
    "    # x_train,x_test = pre_processing(X_train,X_test,pp_dict)\n",
    "\n",
    "elif pre_procesing_applied == 'pow':\n",
    "\n",
    "    # splitpoint = int((args.feature-lags+1)*16)#32\n",
    "    # columns_to_pre_process = [col for col in X_train.columns if 'd_' != col[0:2]]\n",
    "\n",
    "    # Standardize some features\n",
    "    ppdict1 = {i:'pow' for i in X_train.columns if 'd_' != i[0:2]} \n",
    "    # Keep some in actual levels (Dummies in this case).\n",
    "    ppdict2 = {i:'act' for i in X_train.columns if 'd_' == i[0:2]} \n",
    "\n",
    "    # Merging the two\n",
    "    ppdict = {**ppdict1,**ppdict2}\n",
    "\n",
    "    # x_train,x_test = pre_processing(x_train,x_test,pp_dict)\n",
    "\n",
    "elif pre_procesing_applied == 'quantgau':\n",
    "\n",
    "    # splitpoint = int((args.feature-lags+1)*16)#32\n",
    "    # columns_to_pre_process = [col for col in X_train.columns if 'd_' != col[0:2]]\n",
    "\n",
    "    # Standardize some features\n",
    "    ppdict1 = {i:'quantgau' for i in X_train.columns if 'd_' != i[0:2]} \n",
    "    # Keep some in actual levels (Dummies in this case).\n",
    "    ppdict2 = {i:'act' for i in X_train.columns if 'd_' == i[0:2]} \n",
    "\n",
    "    # Merging the two\n",
    "    ppdict = {**ppdict1,**ppdict2}\n",
    "\n",
    "    # x_train,x_test = pre_processing(x_train,x_test,pp_dict)\n",
    "\n",
    "elif pre_procesing_applied == 'individual':\n",
    "\n",
    "    # splitpoint = int((args.feature-lags+1)*16)#32\n",
    "    # columns_to_pre_process = [col for col in X_train.columns if 'd_' != col[0:2]]\n",
    "\n",
    "    # Standardize some features\n",
    "    \n",
    "    # ppdict1 = {i:'power' for i in X_train.columns if 'd_' != i[0:2]}\n",
    "\n",
    "\n",
    "    # Keep some in actual levels (Dummies in this case).\n",
    "    ppdict2 = {i:'act' for i in X_train.columns if 'd_' == i[0:2]} \n",
    "\n",
    "    # Merging the two\n",
    "    ppdict = {**ppdict1,**ppdict2}\n",
    "\n",
    "    # x_train,x_test = pre_processing(x_train,x_test,pp_dict)\n",
    "\n",
    "elif pre_procesing_applied == 'stacked':\n",
    "\n",
    "    # splitpoint = int((args.feature-lags+1)*16)#32\n",
    "    # columns_to_pre_process = [col for col in X_train.columns if 'd_' != col[0:2]]\n",
    "\n",
    "    # Standardize some features\n",
    "    \n",
    "    for j in ['pow','std','minmax']:\n",
    "\n",
    "        ppdict1 = {i:j for i in X_train.columns if 'd_' != i[0:2]}\n",
    "\n",
    "        # Keep some in actual levels (Dummies in this case).\n",
    "        ppdict2 = {i:'act' for i in X_train.columns if 'd_' == i[0:2]} \n",
    "\n",
    "        # Merging the two\n",
    "        ppdict = {**ppdict1,**ppdict2}\n",
    "\n",
    "        X_train,X_test = pre_processing(X_train,X_test,ppdict)\n",
    "\n",
    "if pre_procesing_applied not in ['None','stacked']:\n",
    "    X_train,X_test = pre_processing(X_train,X_test,ppdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1.8927265537610815e-16, 1.000001457346533)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppX_train.iloc[:,0].mean(),ppX_train.iloc[:,0].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepping for models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(343090, 85800, 428890, 1340, 131, 670000)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_VALIDATION = val_y.shape[0] #int(1e3)\n",
    "N_TRAIN = train_y.shape[0] #int(1e4)\n",
    "# BUFFER_SIZE = int(1e4)\n",
    "BATCH_SIZE = 256 #512 #32\n",
    "MAX_EPOCHS = 500\n",
    "\n",
    "STEPS_PER_EPOCH = N_TRAIN//BATCH_SIZE\n",
    "\n",
    "N_REPEAT = int(N_TRAIN / ((STEPS_PER_EPOCH * MAX_EPOCHS) / BATCH_SIZE))\n",
    "FEATURES = X.shape[1]\n",
    "\n",
    "N_TRAIN, N_VALIDATION, N_TRAIN + N_VALIDATION, STEPS_PER_EPOCH, N_REPEAT, STEPS_PER_EPOCH * MAX_EPOCHS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Logistic Regression model in TF/Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 1)                 99        \n",
      "=================================================================\n",
      "Total params: 99\n",
      "Trainable params: 99\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:MainThread:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.390774). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0, accuracy:0.5352,  auc:0.5034,  loss:0.8996,  val_accuracy:0.5456,  val_auc:0.5453,  val_loss:0.6876,  \n",
      "....................................................................................................\n",
      "Epoch: 100, accuracy:0.5480,  auc:0.5440,  loss:0.6873,  val_accuracy:0.5454,  val_auc:0.5459,  val_loss:0.6879,  \n",
      "..................Restoring model weights from the end of the best epoch.\n",
      "Epoch 00118: early stopping\n"
     ]
    }
   ],
   "source": [
    "METRICS = [\n",
    "      #keras.metrics.TruePositives(name='tp'),\n",
    "      #keras.metrics.FalsePositives(name='fp'),\n",
    "      #keras.metrics.TrueNegatives(name='tn'),\n",
    "      #keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      #keras.metrics.Precision(name='precision'),\n",
    "      #keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "]\n",
    "\n",
    "# def make_model(metrics = METRICS, output_bias=None):\n",
    "#   if output_bias is not None:\n",
    "#     output_bias = tf.keras.initializers.Constant(output_bias)\n",
    "#   model = keras.Sequential([\n",
    "#       keras.layers.Dense(\n",
    "#           16, activation='relu',\n",
    "#           input_shape=(train_features.shape[-1],)),\n",
    "#       keras.layers.Dropout(0.5),\n",
    "#       keras.layers.Dense(1, activation='sigmoid',\n",
    "#                          bias_initializer=output_bias),\n",
    "#   ])\n",
    "\n",
    "#   model.compile(\n",
    "#       optimizer=keras.optimizers.Adam(lr=1e-3),\n",
    "#       loss=keras.losses.BinaryCrossentropy(),\n",
    "#       metrics=metrics)\n",
    "\n",
    "#   return model\n",
    "\n",
    "# model = keras.Sequential({\n",
    "#   keras.layers.Dense(1, input_shape=(FEATURES,))\n",
    "# })\n",
    "\n",
    "model = keras.Sequential([\n",
    "#     keras.layers.Flatten(input_shape=(28, 28)),\n",
    "#     keras.layers.Dense(128, activation='relu'),\n",
    "#     keras.layers.Dense(10)\n",
    "    keras.layers.Dense(1,\n",
    "                       input_shape=(FEATURES,),\n",
    "                       activation='sigmoid',\n",
    "                       kernel_regularizer=regularizers.l2(1))\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# with final activation (Keras/TF tutorial advises against this practice, but they also use it later in the tutorial)\n",
    "# model = keras.Sequential({\n",
    "#   keras.layers.Dense(1, input_shape=(FEATURES,), activation='sigmoid')\n",
    "# })\n",
    "\n",
    "#model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['binary_accuracy', ])\n",
    "model.compile(\n",
    "              optimizer=keras.optimizers.Adam(), #lr=1e-3\n",
    "              loss=keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "              metrics=METRICS)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "                                                monitor='val_auc', \n",
    "                                                verbose=1,\n",
    "                                                patience=100,\n",
    "                                                mode='max',\n",
    "                                                restore_best_weights=True)\n",
    "\n",
    "def get_callbacks(run_id):\n",
    "      return [\n",
    "             tfdocs.modeling.EpochDots(),\n",
    "             early_stopping,\n",
    "             tf.keras.callbacks.TensorBoard(logdir), #/run_id),\n",
    "      ]\n",
    "\n",
    "baseline_history = model.fit(\n",
    "                            train_ds, #train_features,\n",
    "                            train_y, #train_labels,\n",
    "                            batch_size=512, #BATCH_SIZE,\n",
    "                            epochs=1000, #EPOCHS,\n",
    "                            callbacks = get_callbacks(run_id = 'first'), #[early_stopping],\n",
    "                            validation_data=(validate_ds, val_y),\n",
    "                            verbose=0) #(val_features, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2682/2682 - 6s - loss: 0.6879 - accuracy: 0.5457 - auc: 0.5513\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6878659725189209, 0.5456876754760742, 0.5513222217559814]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(validate_ds,  val_y, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Timed out waiting for TensorBoard to start. It may still be running as pid 9296."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datetime\n",
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
