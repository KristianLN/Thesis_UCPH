{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "import h5py\n",
    "import copy\n",
    "import datetime\n",
    "\n",
    "# Do you wanna see?\n",
    "verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FMNS testing pull request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformData(dataset, datainfo):\n",
    "  \n",
    "    # Use the column-name information to rename the columns.\n",
    "    renameCol = {i:col[0] for i,col in enumerate(datainfo)}\n",
    "  \n",
    "    # Rename\n",
    "    dataset = dataset.rename(columns=renameCol)\n",
    "  \n",
    "    # Use the datatype information to convert the arrays back to the right datatype.\n",
    "    dt = {col[0]:str if col[1] == 'object' else col[1] for col in datainfo}\n",
    "\n",
    "    # Convert the datatypes\n",
    "    dataset = dataset.astype(dt)\n",
    "\n",
    "    # Strip the string-type arrays for the unintended characters.\n",
    "    for ele in datainfo:\n",
    "        # if the datatype is string, we need to do some additional conversion.\n",
    "        if ele[1] == 'object':\n",
    "\n",
    "            dataset[ele[0]] = list(map(f,dataset[ele[0]]))\n",
    "\n",
    "            if 'date' in ele[0].lower():\n",
    "                dataset[ele[0]] = dataset[ele[0]].astype(np.datetime64) \n",
    "\n",
    "    return dataset\n",
    "\n",
    "# We create a function to clean the string-type arrays\n",
    "f = lambda a: re.split('[\\']',a)[1]\n",
    "\n",
    "# Function to clean the unpacked data from the compressed files.\n",
    "def strList(ls):\n",
    "    return list(map(lambda x: x.decode('utf-8'),ls))\n",
    "\n",
    "# The following function is based on the research of (Lunde, 2016), summarized in the slides found here:\n",
    "# https://econ.au.dk/fileadmin/site_files/filer_oekonomi/subsites/creates/Diverse_2016/PhD_High-Frequency/HF_TrQuData_v01.pdf\n",
    "\n",
    "def formatDate(date,timestamps):\n",
    "    return list(map(lambda x: date[0:4]+'/'+date[4:6]+'/'+date[6:]+' '+str(datetime.timedelta(seconds = int(str(x)[0:5]),\n",
    "                                                     microseconds = int(str(x)[5:11]))),timestamps))\n",
    "def HFDataCleaning(cleaningProcedures,dataToClean,dataType,p3Exchanges = []):\n",
    "    \n",
    "    # There are 11 cleaning procedures, with 3 relevant for both trade and quote data and 4 for either trade or quote data.\n",
    "    # The cleaning procedures are listed below for simplicity\n",
    "    \n",
    "    # Applicable for both trade and quote data\n",
    "    \n",
    "    # P1. Delete entries with a time stamp outside the 9:30 am to 4 pm window when the exchange is open.\n",
    "    # P2. Delete entries with a bid, ask or transaction price equal to zero.\n",
    "    # P3. Retain entries originating from a single exchange. Delete other entries.\n",
    "    \n",
    "    # Applicable for just trade data\n",
    "    \n",
    "    # T1. Delete entries with corrected trades. (Trades with a Correction Indicator, CORR != 0).\n",
    "    # T2. Delete entries with abnormal Sale Condition. (Trades where COND has a letter code, except for “E” and “F”).\n",
    "    # T3. If multiple transactions have the same time stamp: use the median price.\n",
    "    # T4. Delete entries with prices that are above the ask plus the bid-ask spread. \n",
    "    # Similar for entries with prices below the bid minus the bid-ask spread.\n",
    "    \n",
    "    # Applicable for just quote data\n",
    "    \n",
    "    # Q1. When multiple quotes have the same timestamp, we replace all these with a single entry \n",
    "    # with the median bid and median ask price.\n",
    "    # Q2. Delete entries for which the spread is negative.\n",
    "    # Q3. Delete entries for which the spread is more that 50 times the median spread on that day.\n",
    "    # Q4. Delete entries for which the mid-quote deviated by more than 5 median absolute deviations from \n",
    "    # a centered median (excluding the observation under consideration) of 50 observations.\n",
    "\n",
    "    # Some comments, by (Lunde,2016), on the relative importance of the individual cleaning procedures\n",
    "    \n",
    "    # ➤ By far the most important rules here are P3, T3 and Q1.\n",
    "    # ➤ In our empirical work we will see the impact of suspending P3. It is used to reduce the impact\n",
    "    # of time-delays in the reporting of trades and quote updates.\n",
    "    # ➤ Some form of T3 and Q1 rule seems inevitable here, and it is these rules which lead to the largest deletion of data.\n",
    "    # ➤ T4 is an attractive rule, as it disciplines the trade data using quotes. However, it has the disadvantage \n",
    "    # that it cannot be applied when quote data is not available.\n",
    "    # ➤ In situations where quote data is not available, Q4 can be applied to the transaction prices in place of T4.\n",
    "\n",
    "    dataType = dataType.lower().strip()\n",
    "    \n",
    "  \n",
    "        \n",
    "    for cp in cleaningProcedures:\n",
    "        \n",
    "        cp = cp.lower().strip()\n",
    "        \n",
    "        \n",
    "        # check if cp is sensible\n",
    "        if (cp.startswith('t')) & (dataType != 'trade'):\n",
    "            raise ValueError(f'Cleaning procedure {cp} is not compatible with dataType {dataType}')  \n",
    "            \n",
    "        elif (cp.startswith('q')) & (dataType != 'quote'):\n",
    "            raise ValueError(f'Cleaning procedure {cp} is not compatible with dataType {dataType}') \n",
    "\n",
    "\n",
    "        # if the cleaning procedure in question is p1.\n",
    "        if cp == 'p1':\n",
    "            # ((tradeData.Hour+tradeData.Minute/60)>9.5)&((tradeData.Hour+tradeData.Minute/60)<16)\n",
    "#             dataToClean = dataToClean[(datetime.timedelta(hours = 9,\n",
    "#                                                          minutes = 30) <= dataToClean.Timestamp)&\\\n",
    "#                                       (dataToClean.Timestamp <= datetime.timedelta(hours = 16,\n",
    "#                                                                                    minutes = 0))].reset_index(drop=True)\n",
    "            dataToClean = dataToClean[((dataToClean.Hour+dataToClean.Minute/60)>=9.5)&\\\n",
    "                                      ((dataToClean.Hour+dataToClean.Minute/60)<16)]\n",
    "        \n",
    "        # if the cleaning procedure in question is p2.\n",
    "        elif cp == 'p2':\n",
    "            \n",
    "            # if the cleaning procedure in question is p1.\n",
    "            if dataType == 'trade':\n",
    "                \n",
    "                dataToClean = dataToClean[dataToClean.price != 0].reset_index(drop=True)\n",
    "                \n",
    "            elif dataType == 'quote':\n",
    "                \n",
    "                dataToClean = dataToClean[(dataToClean.bid != 0) | (dataToClean.ofr != 0)].reset_index(drop=True)\n",
    "                \n",
    "                \n",
    "        # if the cleaning procedure in question is p3.\n",
    "        elif cp == 'p3':\n",
    "            \n",
    "            if len(p3Exchanges) == 0:\n",
    "                \n",
    "                raise ValueError('No exchanges, to filter on, has been provided.\\nPlease provide a list with minimum one exchanges to filter on.')\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                # Ensuring correct format\n",
    "                p3Exchanges = [ele.lower().strip() for ele in p3Exchanges]\n",
    "                \n",
    "                # Filtering on exchanges ### Consider to use \"isin\" on the dataToClean.ex-Series instead, to improve execution time.\n",
    "                dataToClean = dataToClean[[True if ele.lower().strip() in p3Exchanges else False for ele in dataToClean.ex]].reset_index(drop=True)\n",
    "        \n",
    "        \n",
    "        # if the cleaning procedure in question is t1.\n",
    "        # T1. Delete entries with corrected trades. (Trades with a Correction Indicator, CORR != 0).\n",
    "        elif cp == 't1':\n",
    "\n",
    "            dataToClean = dataToClean[dataToClean.corr == 0].reset_index(drop=True)                \n",
    "                \n",
    "                \n",
    "        # if the cleaning procedure in question is t2.\n",
    "        # T2. Delete entries with abnormal Sale Condition. (Trades where COND has a letter code, except for “E” and “F”).\n",
    "        # FMNS: Most are COND = '@ XX' such as '@ TI', make sure this works properly. Assuming startswith('@') is cool\n",
    "        elif cp == 't2':\n",
    "            \n",
    "            dataToClean = dataToClean[(dataToClean.cond.startswith('@')) | (dataToClean.cond in ['E', 'F'])].reset_index(drop=True) \n",
    "            \n",
    "            \n",
    "        # if the cleaning procedure in question is t3.\n",
    "        # T3. If multiple transactions have the same time stamp: use the median price.\n",
    "        # FMNS: Let's consider if these median prices are cheating in relation to OHLC bars\n",
    "        elif cp == 't3':\n",
    "\n",
    "            # get unique timestamps\n",
    "            unique_ts_idx = np.unique(dataToClean.Timestamp, return_index=True)[1]\n",
    "            \n",
    "            # get median prices\n",
    "            median_price = dataToClean[['Timestamp', 'price']].groupby('Timestamp')['price'].median().values\n",
    "                \n",
    "            # keep only unique timestamps\n",
    "            dataToClean = dataToClean.iloc[unique_ts_idx, :].reset_index(drop=True)\n",
    "            \n",
    "            # fill the price variable with medians matched on unique_ts\n",
    "            dataToClean.loc[:,'price'] = median_price\n",
    "            \n",
    "            ### We could add a print to tell how many duplicated values there where? - Kris\n",
    "            \n",
    "            # note that all other variables now hold the first entry for each timestamp!\n",
    "\n",
    "            \n",
    "        # if the cleaning procedure in question is t3.        \n",
    "        # T4. Delete entries with prices that are above the ask plus the bid-ask spread. \n",
    "        # Similar for entries with prices below the bid minus the bid-ask spread.\n",
    "        # FMNS: We have no bid/ask/spread in trades-table. \n",
    "        #       To do this, we would probably need to cross-match timestamps between trades and quotes properly\n",
    "        elif cp == 't4':\n",
    "            \n",
    "            raise ValueError(f'Cleaning procedure {cp} is on hold')          \n",
    "\n",
    "            \n",
    "        # if the cleaning procedure in question is q1.\n",
    "        # Q1. When multiple quotes have the same timestamp, we replace all these with a single entry \n",
    "        # with the median bid and median ask price.   \n",
    "        # FMNS: Let's consider if these median prices are cheating in relation to OHLC bars\n",
    "        elif cp == 'q1':\n",
    "            \n",
    "            if datatype == 'quote':\n",
    "            \n",
    "                # get unique timestamps\n",
    "                unique_ts_idx = np.unique(dataToClean.Timestamp, return_index=True)[1]\n",
    "\n",
    "                # get median prices\n",
    "                median_price = dataToClean[['Timestamp', 'bid', 'ofr']].groupby('Timestamp')['bid', 'ofr'].median().values\n",
    "\n",
    "                # keep only unique timestamps\n",
    "                dataToClean = dataToClean.iloc[unique_ts_idx, :].reset_index(drop=True)\n",
    "\n",
    "                # fill the price variable with medians matched on unique_ts\n",
    "                dataToClean.loc[:,['bid','ofr']] = median_price\n",
    "\n",
    "                # note that all other variables now hold the first entry for each timestamp!\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                raise ValueError('The datatype has to be quote, in order to apply this cleaning procedure.\\nPlease revisit your request.')\n",
    "            \n",
    "\n",
    "        # if the cleaning procedure in question is q2.\n",
    "        # Q2. Delete entries for which the spread is negative.\n",
    "        elif cp == 'q2':\n",
    "            \n",
    "            if datatype == 'quote':\n",
    "                \n",
    "                dataToClean = dataToClean[dataToClean.ofr - dataToClean.bid >= 0].reset_index(drop=True)     \n",
    "            \n",
    "            else:\n",
    "                raise ValueError('The datatype has to be quote, in order to apply this cleaning procedure.\\nPlease revisit your request.')\n",
    "\n",
    "        # if the cleaning procedure in question is q3.\n",
    "        # Q3. Delete entries for which the spread is more that 50 times the median spread on that day.\n",
    "        elif cp == 'q3':\n",
    "            \n",
    "            if datatype == 'quote':\n",
    "                \n",
    "                # get all spreads across days, groupby Date and take daily median spreads\n",
    "                all_spreads = dataToClean[['Date', 'bid', 'ofr']]\n",
    "                all_spreads['spread'] =  dataToClean.ofr - dataToClean.bid\n",
    "                all_spreads.drop(['bid','ofr'], axis=1, inplace=True)\n",
    "\n",
    "                median_spreads = all_spreads.groupby('Date').median().values     \n",
    "\n",
    "\n",
    "                total_keep_idx = []\n",
    "                # for each unique day ...\n",
    "                for day in np.unique(dataToClean.Date):\n",
    "\n",
    "                    # for every spread within this day, check if it's below 50*median \n",
    "                    # (below_50median is a boolean with all existing index)\n",
    "                    below_50median = (all_spreads[all_spreads.Date == day].spread <= 50*median_spreads[median_spreads.index == day].values[0][0])\n",
    "\n",
    "                    # get the indices where below_50median == True (meaning individual spread is within 50*median)\n",
    "                    below_50median[below_50median].index\n",
    "\n",
    "                    total_keep_idx.append(below_50median[below_50median].index)\n",
    "\n",
    "\n",
    "                # after going through all days, flatten the list\n",
    "                total_keep_idx = [ele for intraday_idx in total_keep_idx for ele in intraday_idx]\n",
    "\n",
    "                # keep all entries that passed the filter\n",
    "                dataToClean = dataToClean.iloc[total_keep_idx, :]\n",
    "            \n",
    "            else:\n",
    "\n",
    "                raise ValueError('The datatype has to be quote, in order to apply this cleaning procedure.\\nPlease revisit your request.')\n",
    "        \n",
    "        # if the cleaning procedure in question is q4.\n",
    "        # Q4. Delete entries for which the mid-quote deviated by more than 5 median absolute deviations from \n",
    "        # a centered median (excluding the observation under consideration) of 50 observations.        \n",
    "        elif cp == 'q4':\n",
    "            \n",
    "            raise ValueError(f'Cleaning procedure {cp} is on hold')\n",
    "    return dataToClean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading in data, LOBSTER as well as TAQ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TAQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.git', '.gitignore', '.ipynb_checkpoints', 'CrunchTAQ.ipynb', 'hello.py', 'README.md', 'Speciale to-do.docx', 'Speciale to-do.txt']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir())\n",
    "path = 'a:/taqhdf5'\n",
    "allFiles = os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8512,\n",
       " ['taq_19930315.h5',\n",
       "  'taq_19930104.h5',\n",
       "  'taq_19930317.h5',\n",
       "  'taq_19930105.h5',\n",
       "  'taq_19930316.h5'],\n",
       " ['taqquote_20200519.h5',\n",
       "  'taqquote_20200520.h5',\n",
       "  'taqquote_20200521.h5',\n",
       "  'taqquote_20200522.h5',\n",
       "  'taqquote_20200526.h5'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#allFiles\n",
    "len(allFiles), allFiles[:5], allFiles[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['taqquote_20200512.h5',\n",
       " 'taqquote_20200513.h5',\n",
       " 'taqquote_20200514.h5',\n",
       " 'taqquote_20200515.h5',\n",
       " 'taqquote_20200518.h5',\n",
       " 'taqquote_20200519.h5',\n",
       " 'taqquote_20200520.h5',\n",
       " 'taqquote_20200521.h5',\n",
       " 'taqquote_20200522.h5',\n",
       " 'taqquote_20200526.h5']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allFiles[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Date range #####\n",
      "\n",
      "Date, Min: 20200401\n",
      "Date, Max: 20200401\n",
      "\n",
      "##### Data Extraction begins #####\n",
      "\n",
      "trade data is being extracted..\n",
      "\n",
      "### Trade Data ###\n",
      "\n",
      "The raw H5 trade file contains:  ['TradeIndex', 'Trades'] \n",
      "\n",
      "Ticker Information:  (b'GOOG            ', 26900500, 71427) \n",
      "\n",
      "Sneak peak of the data\n",
      "\n",
      "            utcsec ex  cond  volume    price TradeStopStockIndicator corr  \\\n",
      "0  14400048517953  P  @ TI      67  1139.44                           00   \n",
      "1  14422296771981  P  @ TI      20  1138.55                           00   \n",
      "2  14429472894282  Q  @FTI       1  1138.54                           00   \n",
      "3  14506997225243  P  @ TI      31  1143.65                           00   \n",
      "4  14516526073882  P  @ TI       1  1143.59                           00   \n",
      "\n",
      "   TradeSequenceNumber TradeID SourceOfTrade TradeReportingFacility  \\\n",
      "0                 1507       1             N                          \n",
      "1                 1552       2             N                          \n",
      "2                 1554       1             N                          \n",
      "3                 1581       3             N                          \n",
      "4                 1587       4             N                          \n",
      "\n",
      "   ParticipantTime  TRFTime TTE      Date                  Timestamp  \\\n",
      "0   14400048141056       99   0  20200401 2020-04-01 04:00:00.048517   \n",
      "1   14422296394240       99   0  20200401 2020-04-01 04:00:22.296771   \n",
      "2   14429472872353       99   1  20200401 2020-04-01 04:00:29.472894   \n",
      "3   14506996848640       99   0  20200401 2020-04-01 04:01:46.997225   \n",
      "4   14516525699840       99   0  20200401 2020-04-01 04:01:56.526073   \n",
      "\n",
      "  TSRemainder  Hour  Minute Ticker  \n",
      "0         953     4       0   GOOG  \n",
      "1         981     4       0   GOOG  \n",
      "2         282     4       0   GOOG  \n",
      "3         243     4       1   GOOG  \n",
      "4         882     4       1   GOOG  \n",
      "The extraction time was 16.792 seconds.\n"
     ]
    }
   ],
   "source": [
    "# Measuring the exraction time\n",
    "start = time.time()\n",
    "\n",
    "# Provide a list of dates of interest (format: yyyymmdd)\n",
    "dates = np.array(['20200401']).astype(int)#,'20200402'\n",
    "\n",
    "# Provide a list of tickers of interest\n",
    "tickers = ['GOOG']#'MSFT'\n",
    "\n",
    "# Do we need data on trades, quotes or both?\n",
    "dataNeeded = 'trades' # 'trades', 'quotes' or 'both'\n",
    "\n",
    "# Extracting just the dates of each file\n",
    "allDates = np.array([re.split(\"[._]\",ele)[1] if (\".\" in ele ) & (\"_\" in ele) else 0 for ele in allFiles]).astype(int)\n",
    "\n",
    "minDate = np.min(dates)\n",
    "maxDate = np.max(dates)\n",
    "\n",
    "if verbose:\n",
    "    print('##### Date range #####\\n\\nDate, Min: %i\\nDate, Max: %i\\n'%(minDate,maxDate))\n",
    "\n",
    "# Locating what files we need.\n",
    "index = np.where((minDate <= allDates) & (allDates <= maxDate))\n",
    "\n",
    "relevantFiles = np.array(allFiles)[index[0]]\n",
    "\n",
    "# Separating the files into trade and quote files.\n",
    "trade = [ele for ele in relevantFiles if 'trade' in ele]\n",
    "quote = [ele for ele in relevantFiles if 'quote' in ele]\n",
    "\n",
    "if verbose:\n",
    "    print('##### Data Extraction begins #####\\n')\n",
    "    \n",
    "    if dataNeeded.lower() == 'both':\n",
    "        print('Both trade and quote data is being extracted..\\n')\n",
    "    else:\n",
    "        print('%s data is being extracted..\\n' % dataNeeded[0:5])\n",
    "        \n",
    "if (dataNeeded == 'both') | (dataNeeded == 'trades'):\n",
    "           \n",
    "# Lets start out by extracting the trade data\n",
    "\n",
    "    for i,file in enumerate(trade):\n",
    "\n",
    "        if (verbose) & (i == 0):\n",
    "            print('### Trade Data ###\\n')\n",
    "\n",
    "        # Reading one file at a time\n",
    "        raw_data = h5py.File(path+'/'+file,'r')\n",
    "\n",
    "        # Store the trade indecies\n",
    "        TI = raw_data['TradeIndex']\n",
    "\n",
    "        if (verbose) & (i==0):\n",
    "            print('The raw H5 trade file contains: ',list(raw_data.keys()),'\\n')\n",
    "\n",
    "        # Extracting just the tickers\n",
    "        TIC = np.array([ele[0].astype(str).strip() for ele in TI])\n",
    "\n",
    "        # Lets get data on each ticker for the file processed at the moment\n",
    "        for j,ticker in enumerate(tickers):\n",
    "\n",
    "            # Getting the specific ticker information\n",
    "            tickerInfo = TI[TIC==ticker][0]\n",
    "\n",
    "            if (verbose) & (i == 0):\n",
    "                    print('Ticker Information: ',tickerInfo,'\\n')\n",
    "\n",
    "            # Raw data\n",
    "            tempData = raw_data['Trades'][np.arange(tickerInfo[1],tickerInfo[1]+tickerInfo[2])]\n",
    "\n",
    "            # For first file and first ticker.\n",
    "            if (i == 0) & (j == 0):    \n",
    "\n",
    "                tradeData = pd.DataFrame(tempData, columns= tempData.dtype.names)\n",
    "\n",
    "                tradeData.loc[:,'ex'] = strList(tradeData.ex)\n",
    "                tradeData.loc[:,'cond'] = strList(tradeData.cond)\n",
    "                tradeData.loc[:,'TradeStopStockIndicator'] = strList(tradeData.TradeStopStockIndicator)\n",
    "                tradeData.loc[:,'corr'] = strList(tradeData['corr'])\n",
    "                tradeData.loc[:,'TradeID'] = strList(tradeData.TradeID)\n",
    "                tradeData.loc[:,'TTE'] = strList(tradeData.TTE)\n",
    "                tradeData.loc[:,'TradeReportingFacility'] = strList(tradeData.TradeReportingFacility)\n",
    "                tradeData.loc[:,'SourceOfTrade'] = strList(tradeData.SourceOfTrade)\n",
    "\n",
    "                # Adding the date of the file to the dataframe.\n",
    "                tradeData['Date'] = re.split('[._]',file)[1]\n",
    "\n",
    "                # Adding a more readable timestamp - TEST IT\n",
    "                tradeData['Timestamp'] = pd.to_datetime(formatDate(re.split('[._]',file)[1],tradeData.utcsec))\n",
    "                tradeData['TSRemainder'] = list(map(lambda x: str(x)[11:], tradeData.utcsec))\n",
    "                tradeData['Hour'] = tradeData.Timestamp.dt.hour\n",
    "                tradeData['Minute'] = tradeData.Timestamp.dt.minute\n",
    "                # Adding the ticker\n",
    "                tradeData['Ticker'] = ticker\n",
    "\n",
    "                if (verbose) & (i==0) & (j==0):\n",
    "                    print('Sneak peak of the data\\n\\n',tradeData.head())\n",
    "\n",
    "            else:\n",
    "\n",
    "                # Storing the data on the following tickers in a temporary variable.\n",
    "\n",
    "                temp = pd.DataFrame(tempData, columns= tempData.dtype.names)\n",
    "\n",
    "                temp.loc[:,'ex'] = strList(temp.ex)\n",
    "                temp.loc[:,'cond'] = strList(temp.cond)\n",
    "                temp.loc[:,'TradeStopStockIndicator'] = strList(temp.TradeStopStockIndicator)\n",
    "                temp.loc[:,'corr'] = strList(temp['corr'])\n",
    "                temp.loc[:,'TradeID'] = strList(temp.TradeID)\n",
    "                temp.loc[:,'TTE'] = strList(temp.TTE)\n",
    "                temp.loc[:,'TradeReportingFacility'] = strList(temp.TradeReportingFacility)\n",
    "                temp.loc[:,'SourceOfTrade'] = strList(temp.SourceOfTrade)\n",
    "\n",
    "                # Adding the date of the file to the dataframe.\n",
    "                temp['Date'] = re.split('[._]',file)[1]\n",
    "\n",
    "                # Adding a more readable timestamp - TEST IT\n",
    "                temp['Timestamp'] = pd.to_datetime(formatDate(re.split('[._]',file)[1],temp.utcsec))\n",
    "                temp['TSRemainder'] = list(map(lambda x: str(x)[11:], temp.utcsec))\n",
    "                temp['Hour'] = temp.Timestamp.dt.hour\n",
    "                temp['Minute'] = temp.Timestamp.dt.minute\n",
    "\n",
    "                # Adding the ticker\n",
    "                temp['Ticker'] = ticker\n",
    "\n",
    "                # Adding the new data \n",
    "                tradeData = pd.concat([tradeData,temp])\n",
    "\n",
    "if (dataNeeded == 'both') | (dataNeeded == 'quotes'):\n",
    "    \n",
    "    # Now to the quote data\n",
    "    for i,file in enumerate(quote):\n",
    "\n",
    "        if (verbose) & (i == 0):\n",
    "            print('### Quote Data ###\\n')\n",
    "\n",
    "        # Reading one file at a time\n",
    "        raw_data = h5py.File(path+'/'+file,'r')\n",
    "\n",
    "        # Store the trade indecies\n",
    "        QI = raw_data['QuoteIndex']\n",
    "\n",
    "        if (verbose) & (i==0):\n",
    "            print('The raw H5 quote file contains: ',list(raw_data.keys()),'\\n')\n",
    "\n",
    "        # Extracting just the tickers\n",
    "        QIC = np.array([ele[0].astype(str).strip() for ele in QI])\n",
    "\n",
    "        # Lets get data on each ticker for the file processed at the moment\n",
    "        for j,ticker in enumerate(tickers):\n",
    "\n",
    "            # Getting the specific ticker information\n",
    "            tickerInfo = QI[QIC==ticker][0]\n",
    "\n",
    "            if (verbose) & (i == 0):\n",
    "                    print('Ticker Information: ',tickerInfo,'\\n')\n",
    "\n",
    "            # Raw data\n",
    "            tempData = raw_data['Quotes'][np.arange(tickerInfo[1],tickerInfo[1]+tickerInfo[2])]\n",
    "\n",
    "            # For first file and first ticker.\n",
    "            if (i == 0) & (j == 0):    \n",
    "\n",
    "                quoteData = pd.DataFrame(tempData, columns= tempData.dtype.names)\n",
    "                # We remove all unnecessary variables\n",
    "                unnecessaryVariables = ['NationalBBOInd',\n",
    "                                        'FinraBBOInd',\n",
    "                                        'FinraQuoteIndicator',\n",
    "                                        'SequenceNumber',\n",
    "                                        'FinraAdfMpidIndicator',\n",
    "                                        'QuoteCancelCorrection',\n",
    "                                        'SourceQuote',\n",
    "                                        'RPI',\n",
    "                                        'ShortSaleRestrictionIndicator',\n",
    "                                        'LuldBBOIndicator',\n",
    "                                        'SIPGeneratedMessageIdent',\n",
    "                                        'NationalBBOLuldIndicator',\n",
    "                                        'ParticipantTimestamp',\n",
    "                                        'FinraTimestamp',\n",
    "                                        'FinraQuoteIndicator',\n",
    "                                        'SecurityStatusIndicator']\n",
    "                \n",
    "                quoteData = quoteData.drop(columns=unnecessaryVariables)\n",
    "\n",
    "                quoteData.loc[:,'ex'] = strList(quoteData.ex)\n",
    "                quoteData.loc[:,'mode'] = strList(quoteData['mode'])\n",
    "                \n",
    "                # Adding the date of the file to the dataframe.\n",
    "                quoteData['Date'] = re.split('[._]',file)[1]\n",
    "\n",
    "                # Adding a more readable timestamp - TEST IT\n",
    "                quoteData['Timestamp'] = pd.to_datetime(formatDate(re.split('[._]',file)[1],quoteData.utcsec))\n",
    "                quoteData['TSRemainder'] = list(map(lambda x: str(x)[11:], quoteData.utcsec))\n",
    "                quoteData['Hour'] = quoteData.Timestamp.dt.hour\n",
    "                quoteData['Minute'] = quoteData.Timestamp.dt.minute\n",
    "                # Adding the ticker\n",
    "                quoteData['Ticker'] = ticker\n",
    "\n",
    "                if (verbose) & (i==0) & (j==0):\n",
    "                    print('Sneak peak of the data\\n\\n',quoteData.head())\n",
    "\n",
    "            else:\n",
    "\n",
    "                # Storing the data on the following tickers in a temporary variable.\n",
    "\n",
    "                temp = pd.DataFrame(tempData, columns= tempData.dtype.names)\n",
    "                # Removing all unnecessary variables\n",
    "                temp = temp.drop(columns=unnecessaryVariables)\n",
    "                \n",
    "                temp.loc[:,'ex'] = strList(temp.ex)\n",
    "                temp.loc[:,'mode'] = strList(temp['mode'])\n",
    "\n",
    "                # Adding the date of the file to the dataframe.\n",
    "                temp['Date'] = re.split('[._]',file)[1]\n",
    "\n",
    "                # Adding a more readable timestamp - TEST IT\n",
    "                temp['Timestamp'] = pd.to_datetime(formatDate(re.split('[._]',file)[1],temp.utcsec))\n",
    "                temp['TSRemainder'] = list(map(lambda x: str(x)[11:], temp.utcsec))\n",
    "                temp['Hour'] = temp.Timestamp.dt.hour\n",
    "                temp['Minute'] = temp.Timestamp.dt.minute\n",
    "\n",
    "                # Adding the ticker\n",
    "                temp['Ticker'] = ticker\n",
    "\n",
    "                # Adding the new data \n",
    "                quoteData = pd.concat([quoteData,temp])\n",
    "                    \n",
    "end = time.time()\n",
    "\n",
    "if verbose:\n",
    "    print('The extraction time was %.3f seconds.' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utcsec</th>\n",
       "      <th>ex</th>\n",
       "      <th>bid</th>\n",
       "      <th>bidsize</th>\n",
       "      <th>ofr</th>\n",
       "      <th>ofrsize</th>\n",
       "      <th>mode</th>\n",
       "      <th>Date</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>TSRemainder</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Minute</th>\n",
       "      <th>Ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14400049177409</td>\n",
       "      <td>P</td>\n",
       "      <td>963.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>R</td>\n",
       "      <td>20200401</td>\n",
       "      <td>2020-04-01 04:00:49.177</td>\n",
       "      <td>409</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>GOOG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14400049177610</td>\n",
       "      <td>P</td>\n",
       "      <td>985.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>R</td>\n",
       "      <td>20200401</td>\n",
       "      <td>2020-04-01 04:00:49.177</td>\n",
       "      <td>610</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>GOOG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14400049181518</td>\n",
       "      <td>P</td>\n",
       "      <td>999.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>R</td>\n",
       "      <td>20200401</td>\n",
       "      <td>2020-04-01 04:00:49.181</td>\n",
       "      <td>518</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>GOOG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14400049181691</td>\n",
       "      <td>P</td>\n",
       "      <td>1018.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>R</td>\n",
       "      <td>20200401</td>\n",
       "      <td>2020-04-01 04:00:49.181</td>\n",
       "      <td>691</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>GOOG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14400049274621</td>\n",
       "      <td>P</td>\n",
       "      <td>1018.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1188.88</td>\n",
       "      <td>3</td>\n",
       "      <td>R</td>\n",
       "      <td>20200401</td>\n",
       "      <td>2020-04-01 04:00:49.274</td>\n",
       "      <td>621</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>GOOG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           utcsec ex      bid  bidsize      ofr  ofrsize mode      Date  \\\n",
       "0  14400049177409  P   963.00        1     0.00        0    R  20200401   \n",
       "1  14400049177610  P   985.65        1     0.00        0    R  20200401   \n",
       "2  14400049181518  P   999.00        1     0.00        0    R  20200401   \n",
       "3  14400049181691  P  1018.00        1     0.00        0    R  20200401   \n",
       "4  14400049274621  P  1018.00        1  1188.88        3    R  20200401   \n",
       "\n",
       "                Timestamp TSRemainder  Hour  Minute Ticker  \n",
       "0 2020-04-01 04:00:49.177         409     4       0   GOOG  \n",
       "1 2020-04-01 04:00:49.177         610     4       0   GOOG  \n",
       "2 2020-04-01 04:00:49.181         518     4       0   GOOG  \n",
       "3 2020-04-01 04:00:49.181         691     4       0   GOOG  \n",
       "4 2020-04-01 04:00:49.274         621     4       0   GOOG  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quoteData.head()\n",
    "#tradeData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utcsec</th>\n",
       "      <th>ex</th>\n",
       "      <th>cond</th>\n",
       "      <th>volume</th>\n",
       "      <th>price</th>\n",
       "      <th>TradeStopStockIndicator</th>\n",
       "      <th>corr</th>\n",
       "      <th>TradeSequenceNumber</th>\n",
       "      <th>TradeID</th>\n",
       "      <th>SourceOfTrade</th>\n",
       "      <th>TradeReportingFacility</th>\n",
       "      <th>ParticipantTime</th>\n",
       "      <th>TRFTime</th>\n",
       "      <th>TTE</th>\n",
       "      <th>Date</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>TSRemainder</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Minute</th>\n",
       "      <th>Ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14400048517953</td>\n",
       "      <td>P</td>\n",
       "      <td>@ TI</td>\n",
       "      <td>67</td>\n",
       "      <td>1139.44</td>\n",
       "      <td></td>\n",
       "      <td>00</td>\n",
       "      <td>1507</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>14400048141056</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>20200401</td>\n",
       "      <td>2020-04-01 04:00:00.048517</td>\n",
       "      <td>953</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>GOOG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14422296771981</td>\n",
       "      <td>P</td>\n",
       "      <td>@ TI</td>\n",
       "      <td>20</td>\n",
       "      <td>1138.55</td>\n",
       "      <td></td>\n",
       "      <td>00</td>\n",
       "      <td>1552</td>\n",
       "      <td>2</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>14422296394240</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>20200401</td>\n",
       "      <td>2020-04-01 04:00:22.296771</td>\n",
       "      <td>981</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>GOOG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14429472894282</td>\n",
       "      <td>Q</td>\n",
       "      <td>@FTI</td>\n",
       "      <td>1</td>\n",
       "      <td>1138.54</td>\n",
       "      <td></td>\n",
       "      <td>00</td>\n",
       "      <td>1554</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>14429472872353</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>20200401</td>\n",
       "      <td>2020-04-01 04:00:29.472894</td>\n",
       "      <td>282</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>GOOG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14506997225243</td>\n",
       "      <td>P</td>\n",
       "      <td>@ TI</td>\n",
       "      <td>31</td>\n",
       "      <td>1143.65</td>\n",
       "      <td></td>\n",
       "      <td>00</td>\n",
       "      <td>1581</td>\n",
       "      <td>3</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>14506996848640</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>20200401</td>\n",
       "      <td>2020-04-01 04:01:46.997225</td>\n",
       "      <td>243</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>GOOG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14516526073882</td>\n",
       "      <td>P</td>\n",
       "      <td>@ TI</td>\n",
       "      <td>1</td>\n",
       "      <td>1143.59</td>\n",
       "      <td></td>\n",
       "      <td>00</td>\n",
       "      <td>1587</td>\n",
       "      <td>4</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>14516525699840</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>20200401</td>\n",
       "      <td>2020-04-01 04:01:56.526073</td>\n",
       "      <td>882</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>GOOG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           utcsec ex  cond  volume    price TradeStopStockIndicator corr  \\\n",
       "0  14400048517953  P  @ TI      67  1139.44                           00   \n",
       "1  14422296771981  P  @ TI      20  1138.55                           00   \n",
       "2  14429472894282  Q  @FTI       1  1138.54                           00   \n",
       "3  14506997225243  P  @ TI      31  1143.65                           00   \n",
       "4  14516526073882  P  @ TI       1  1143.59                           00   \n",
       "\n",
       "   TradeSequenceNumber TradeID SourceOfTrade TradeReportingFacility  \\\n",
       "0                 1507       1             N                          \n",
       "1                 1552       2             N                          \n",
       "2                 1554       1             N                          \n",
       "3                 1581       3             N                          \n",
       "4                 1587       4             N                          \n",
       "\n",
       "   ParticipantTime  TRFTime TTE      Date                  Timestamp  \\\n",
       "0   14400048141056       99   0  20200401 2020-04-01 04:00:00.048517   \n",
       "1   14422296394240       99   0  20200401 2020-04-01 04:00:22.296771   \n",
       "2   14429472872353       99   1  20200401 2020-04-01 04:00:29.472894   \n",
       "3   14506996848640       99   0  20200401 2020-04-01 04:01:46.997225   \n",
       "4   14516525699840       99   0  20200401 2020-04-01 04:01:56.526073   \n",
       "\n",
       "  TSRemainder  Hour  Minute Ticker  \n",
       "0         953     4       0   GOOG  \n",
       "1         981     4       0   GOOG  \n",
       "2         282     4       0   GOOG  \n",
       "3         243     4       1   GOOG  \n",
       "4         882     4       1   GOOG  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tradeData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quoteData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>utcsec</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th>Ticker</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20200401</th>\n",
       "      <th>GOOG</th>\n",
       "      <td>71427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 utcsec\n",
       "Date     Ticker        \n",
       "20200401 GOOG     71427"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tradeData[['Date','Ticker','utcsec']].groupby(['Date','Ticker']).count()\n",
    "# quoteData[['Date','Ticker','utcsec']].groupby(['Date','Ticker']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tradeData.cond.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tradeData[['cond','utcsec']].groupby('cond').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tradeData[tradeData.duplicated(['utcsec'])]\n",
    "quoteData[quoteData.duplicated(['utcsec'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing technical features\n",
    "\n",
    "A library: https://technical-analysis-library-in-python.readthedocs.io/en/latest/\n",
    "\n",
    "### Features used in the literature:\n",
    "\n",
    "* Stochastic K\n",
    "* Stochastic D\n",
    "* Slow Stochastic D\n",
    "* Momentum\n",
    "* ROC\n",
    "* Williams % R\n",
    "* A/D Oscillator\n",
    "* Disparity 5\n",
    "* Disparity 10\n",
    "* Price Oscillator\n",
    "* Commodity Channel Index\n",
    "* RSI\n",
    "\n",
    "Formulas: https://papers.ssrn.com/sol3/papers.cfm?abstract_id=876544\n",
    "\n",
    "* Moving Average\n",
    "* Bias\n",
    "* Exponential Moving Average\n",
    "* Difference\n",
    "* True Range\n",
    "* \n",
    "\n",
    "Formulas: https://www.sciencedirect.com/science/article/pii/S0957417407001819?via%3Dihub\n",
    "\n",
    "**Non-classical technical features**\n",
    "\n",
    "* Bid/Ask prices of top of book\n",
    "* Spread and mid price based on top og book\n",
    "* Price derivatives\n",
    "\n",
    "Formulas: https://www.tandfonline.com/doi/full/10.1080/14697688.2015.1032546?instName=UCL+%28University+College+London%29"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregation - going from irregular spaced data to regular spaced data.\n",
    "\n",
    "Financial econometric analysis at ultra-high frequency: Data handling concerns\n",
    "\n",
    "Paper: https://www.sciencedirect.com/science/article/pii/S0167947306003458"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utcsec</th>\n",
       "      <th>ex</th>\n",
       "      <th>cond</th>\n",
       "      <th>volume</th>\n",
       "      <th>price</th>\n",
       "      <th>TradeStopStockIndicator</th>\n",
       "      <th>corr</th>\n",
       "      <th>TradeSequenceNumber</th>\n",
       "      <th>TradeID</th>\n",
       "      <th>SourceOfTrade</th>\n",
       "      <th>TradeReportingFacility</th>\n",
       "      <th>ParticipantTime</th>\n",
       "      <th>TRFTime</th>\n",
       "      <th>TTE</th>\n",
       "      <th>Date</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>TSRemainder</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Minute</th>\n",
       "      <th>Ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14400048517953</td>\n",
       "      <td>P</td>\n",
       "      <td>@ TI</td>\n",
       "      <td>67</td>\n",
       "      <td>1139.44</td>\n",
       "      <td></td>\n",
       "      <td>00</td>\n",
       "      <td>1507</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>14400048141056</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>20200401</td>\n",
       "      <td>2020-04-01 04:00:48.517</td>\n",
       "      <td>953</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>GOOG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14422296771981</td>\n",
       "      <td>P</td>\n",
       "      <td>@ TI</td>\n",
       "      <td>20</td>\n",
       "      <td>1138.55</td>\n",
       "      <td></td>\n",
       "      <td>00</td>\n",
       "      <td>1552</td>\n",
       "      <td>2</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>14422296394240</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>20200401</td>\n",
       "      <td>2020-04-01 04:05:18.771</td>\n",
       "      <td>981</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>GOOG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14429472894282</td>\n",
       "      <td>Q</td>\n",
       "      <td>@FTI</td>\n",
       "      <td>1</td>\n",
       "      <td>1138.54</td>\n",
       "      <td></td>\n",
       "      <td>00</td>\n",
       "      <td>1554</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>14429472872353</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>20200401</td>\n",
       "      <td>2020-04-01 04:08:21.894</td>\n",
       "      <td>282</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>GOOG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14506997225243</td>\n",
       "      <td>P</td>\n",
       "      <td>@ TI</td>\n",
       "      <td>31</td>\n",
       "      <td>1143.65</td>\n",
       "      <td></td>\n",
       "      <td>00</td>\n",
       "      <td>1581</td>\n",
       "      <td>3</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>14506996848640</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>20200401</td>\n",
       "      <td>2020-04-01 04:18:23.225</td>\n",
       "      <td>243</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>GOOG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14516526073882</td>\n",
       "      <td>P</td>\n",
       "      <td>@ TI</td>\n",
       "      <td>1</td>\n",
       "      <td>1143.59</td>\n",
       "      <td></td>\n",
       "      <td>00</td>\n",
       "      <td>1587</td>\n",
       "      <td>4</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>14516525699840</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>20200401</td>\n",
       "      <td>2020-04-01 04:10:42.073</td>\n",
       "      <td>882</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>GOOG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           utcsec ex  cond  volume    price TradeStopStockIndicator corr  \\\n",
       "0  14400048517953  P  @ TI      67  1139.44                           00   \n",
       "1  14422296771981  P  @ TI      20  1138.55                           00   \n",
       "2  14429472894282  Q  @FTI       1  1138.54                           00   \n",
       "3  14506997225243  P  @ TI      31  1143.65                           00   \n",
       "4  14516526073882  P  @ TI       1  1143.59                           00   \n",
       "\n",
       "   TradeSequenceNumber TradeID SourceOfTrade TradeReportingFacility  \\\n",
       "0                 1507       1             N                          \n",
       "1                 1552       2             N                          \n",
       "2                 1554       1             N                          \n",
       "3                 1581       3             N                          \n",
       "4                 1587       4             N                          \n",
       "\n",
       "   ParticipantTime  TRFTime TTE      Date               Timestamp TSRemainder  \\\n",
       "0   14400048141056       99   0  20200401 2020-04-01 04:00:48.517         953   \n",
       "1   14422296394240       99   0  20200401 2020-04-01 04:05:18.771         981   \n",
       "2   14429472872353       99   1  20200401 2020-04-01 04:08:21.894         282   \n",
       "3   14506996848640       99   0  20200401 2020-04-01 04:18:23.225         243   \n",
       "4   14516525699840       99   0  20200401 2020-04-01 04:10:42.073         882   \n",
       "\n",
       "   Hour  Minute Ticker  \n",
       "0     4       0   GOOG  \n",
       "1     4       5   GOOG  \n",
       "2     4       8   GOOG  \n",
       "3     4      18   GOOG  \n",
       "4     4      10   GOOG  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tradeData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def HFDataCleaning(cleaningProcedures,dataToClean,dataType,p3Exchanges = []):\n",
    "\n",
    "cleanedData = HFDataCleaning(['P1'],tradeData,'trade')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69705, 20)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanedData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 10\n",
    "\n",
    "aggregateMinute = np.arange(0,60,step)\n",
    "aggregateHour = np.arange(9,16,1)\n",
    "\n",
    "remove = 30//step\n",
    "\n",
    "candle = np.zeros(((len(aggregateMinute)*len(aggregateHour)),4))\n",
    "candleNP = np.zeros(((len(aggregateMinute)*len(aggregateHour)),4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(candleNP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.8 s ± 336 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "def candleCreate():\n",
    "    ii = 0\n",
    "    for l in cleanedData.Date.unique():\n",
    "        for i in aggregateHour:\n",
    "            for j in aggregateMinute:\n",
    "\n",
    "                temp = cleanedData[((cleanedData.Date == l)&\\\n",
    "                                    (cleanedData.Hour==i)&\\\n",
    "                                    (cleanedData.Minute<j+step))&((cleanedData.Date == l)&\\\n",
    "                                                                  (cleanedData.Hour==i)&\\\n",
    "                                                                  (cleanedData.Minute>=j))]\n",
    "                if temp.shape[0] > 0:\n",
    "        #         print(np.array([temp.loc[0],temp.max(),temp.min(),temp.loc[-1]]))\n",
    "                    candle[ii] = np.array([temp.price.iloc[0],temp.price.max(),temp.price.min(),temp.price.iloc[-1]])\n",
    "\n",
    "                ii += 1\n",
    "\n",
    "%timeit candleCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0.    ,    0.    ,    0.    ,    0.    ],\n",
       "       [   0.    ,    0.    ,    0.    ,    0.    ],\n",
       "       [   0.    ,    0.    ,    0.    ,    0.    ],\n",
       "       ...,\n",
       "       [1106.5   , 1106.9   , 1103.07  , 1105.75  ],\n",
       "       [1105.65  , 1107.06  , 1104.59  , 1106.027 ],\n",
       "       [1105.48  , 1107.5612, 1105.    , 1105.62  ]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpiedData = cleanedData[['Date','Hour','Minute']].to_numpy()\n",
    "numpiedData = numpiedData.T\n",
    "numpiedPrice = cleanedData['price'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0.        0.        0.        0.    ]\n",
      " [   0.        0.        0.        0.    ]\n",
      " [   0.        0.        0.        0.    ]\n",
      " [1122.26   1128.7    1114.51   1124.06  ]\n",
      " [1125.184  1128.42   1118.     1120.    ]\n",
      " [1120.13   1122.     1115.     1115.55  ]\n",
      " [1115.35   1127.     1114.     1123.7887]\n",
      " [1124.135  1130.     1121.9    1125.    ]\n",
      " [1126.0699 1128.5    1121.     1123.39  ]\n",
      " [1122.85   1130.     1121.     1127.    ]\n",
      " [1127.64   1129.295  1125.     1126.    ]\n",
      " [1126.1987 1127.09   1120.45   1125.955 ]\n",
      " [1125.93   1129.14   1123.8    1128.12  ]\n",
      " [1128.12   1128.9999 1123.3501 1126.83  ]\n",
      " [1126.9    1127.4    1120.37   1121.66  ]\n",
      " [1120.3819 1123.98   1119.     1119.02  ]\n",
      " [1119.06   1120.4873 1115.5    1117.2   ]\n",
      " [1117.71   1121.1    1116.6301 1117.68  ]\n",
      " [1117.78   1118.7898 1114.8    1115.214 ]\n",
      " [1115.83   1118.02   1113.     1114.6048]\n",
      " [1113.86   1117.08   1111.     1112.43  ]\n",
      " [1111.44   1113.7699 1106.01   1106.6654]\n",
      " [1106.84   1108.3199 1103.33   1105.85  ]\n",
      " [1105.27   1111.79   1105.27   1108.78  ]\n",
      " [1108.44   1113.4899 1107.     1110.5576]\n",
      " [1111.09   1113.045  1107.68   1109.51  ]\n",
      " [1110.6779 1113.5    1108.5205 1111.7   ]\n",
      " [1110.74   1112.2999 1107.3901 1112.16  ]\n",
      " [1111.0201 1112.4999 1107.3    1108.    ]\n",
      " [1108.     1113.42   1107.3    1112.8199]\n",
      " [1111.77   1162.81   1110.15   1111.949 ]\n",
      " [1111.88   1113.0199 1107.5    1109.    ]\n",
      " [1109.05   1111.017  1106.     1109.7   ]\n",
      " [1109.14   1110.99   1105.1    1109.4233]\n",
      " [1109.73   1110.39   1106.745  1109.1286]\n",
      " [1109.1178 1109.6    1103.75   1104.66  ]\n",
      " [1105.1    1107.99   1104.8501 1105.57  ]\n",
      " [1105.57   1105.9595 1101.8    1104.31  ]\n",
      " [1104.1829 1104.35   1100.11   1100.23  ]\n",
      " [1100.37   1101.8899 1097.12   1097.94  ]\n",
      " [1097.43   1111.77   1097.11   1107.13  ]\n",
      " [1106.58   1111.4199 1102.42   1105.62  ]]\n",
      "42\n"
     ]
    }
   ],
   "source": [
    "# Alternative to above\n",
    "def candleCreateNP():\n",
    "    ii = 0\n",
    "    for l in cleanedData.Date.unique():\n",
    "#         print(l)\n",
    "        for i in aggregateHour:\n",
    "            for j in aggregateMinute:\n",
    "\n",
    "    #             temp = testTrade[((testTrade.Hour==i)&(testTrade.Minute<j+step))&((testTrade.Hour==i)&(testTrade.Minute>=j))]\n",
    "                p1 = numpiedPrice[((numpiedData[0]==l)&\\\n",
    "                                     (numpiedData[1]==i)&\\\n",
    "                                     (numpiedData[2]>=j))&((numpiedData[0]==l)&\\\n",
    "                                                           (numpiedData[1]==i)&\\\n",
    "                                                           (numpiedData[2]<j+step))]\n",
    "                if len(p1) > 0:\n",
    "#                     print(np.array([p1[0],p1.max(),p1.min(),p1[-1]]))\n",
    "        #         print(np.array([temp.loc[0],temp.max(),temp.min(),temp.loc[-1]]))\n",
    "                    candleNP[ii] = np.array([p1[0],p1.max(),p1.min(),p1[-1]])\n",
    "\n",
    "                ii += 1\n",
    "#         print(candleNP)\n",
    "    return candleNP[remove:]    \n",
    "# %timeit candleCreateNP()\n",
    "\n",
    "candleNP = candleCreateNP()\n",
    "print(ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1122.26  , 1128.7   , 1114.51  , 1124.06  ],\n",
       "       [1125.184 , 1128.42  , 1118.    , 1120.    ],\n",
       "       [1120.13  , 1122.    , 1115.    , 1115.55  ],\n",
       "       [1115.35  , 1127.    , 1114.    , 1123.7887],\n",
       "       [1124.135 , 1130.    , 1121.9   , 1125.    ],\n",
       "       [1126.0699, 1128.5   , 1121.    , 1123.39  ],\n",
       "       [1122.85  , 1130.    , 1121.    , 1127.    ],\n",
       "       [1127.64  , 1129.295 , 1125.    , 1126.    ],\n",
       "       [1126.1987, 1127.09  , 1120.45  , 1125.955 ],\n",
       "       [1125.93  , 1129.14  , 1123.8   , 1128.12  ],\n",
       "       [1128.12  , 1128.9999, 1123.3501, 1126.83  ],\n",
       "       [1126.9   , 1127.4   , 1120.37  , 1121.66  ],\n",
       "       [1120.3819, 1123.98  , 1119.    , 1119.02  ],\n",
       "       [1119.06  , 1120.4873, 1115.5   , 1117.2   ],\n",
       "       [1117.71  , 1121.1   , 1116.6301, 1117.68  ],\n",
       "       [1117.78  , 1118.7898, 1114.8   , 1115.214 ],\n",
       "       [1115.83  , 1118.02  , 1113.    , 1114.6048],\n",
       "       [1113.86  , 1117.08  , 1111.    , 1112.43  ],\n",
       "       [1111.44  , 1113.7699, 1106.01  , 1106.6654],\n",
       "       [1106.84  , 1108.3199, 1103.33  , 1105.85  ],\n",
       "       [1105.27  , 1111.79  , 1105.27  , 1108.78  ],\n",
       "       [1108.44  , 1113.4899, 1107.    , 1110.5576],\n",
       "       [1111.09  , 1113.045 , 1107.68  , 1109.51  ],\n",
       "       [1110.6779, 1113.5   , 1108.5205, 1111.7   ],\n",
       "       [1110.74  , 1112.2999, 1107.3901, 1112.16  ],\n",
       "       [1111.0201, 1112.4999, 1107.3   , 1108.    ],\n",
       "       [1108.    , 1113.42  , 1107.3   , 1112.8199],\n",
       "       [1111.77  , 1162.81  , 1110.15  , 1111.949 ],\n",
       "       [1111.88  , 1113.0199, 1107.5   , 1109.    ],\n",
       "       [1109.05  , 1111.017 , 1106.    , 1109.7   ],\n",
       "       [1109.14  , 1110.99  , 1105.1   , 1109.4233],\n",
       "       [1109.73  , 1110.39  , 1106.745 , 1109.1286],\n",
       "       [1109.1178, 1109.6   , 1103.75  , 1104.66  ],\n",
       "       [1105.1   , 1107.99  , 1104.8501, 1105.57  ],\n",
       "       [1105.57  , 1105.9595, 1101.8   , 1104.31  ],\n",
       "       [1104.1829, 1104.35  , 1100.11  , 1100.23  ],\n",
       "       [1100.37  , 1101.8899, 1097.12  , 1097.94  ],\n",
       "       [1097.43  , 1111.77  , 1097.11  , 1107.13  ],\n",
       "       [1106.58  , 1111.4199, 1102.42  , 1105.62  ]])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candleNP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candle==candleNP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1122.26  , 1128.7   , 1114.51  , 1124.06  , 1125.184 , 1128.42  ,\n",
       "       1118.    , 1120.    , 1120.13  , 1122.    , 1115.    , 1115.55  ,\n",
       "       1115.35  , 1127.    , 1114.    , 1123.7887, 1124.135 , 1130.    ,\n",
       "       1121.9   , 1125.    ])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featureWindow = 5\n",
    "npFeatures = np.zeros((len(candleNP)-featureWindow,featureWindow*len(candle[0])))\n",
    "candleNP[0:5].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "stepper = np.arange(featureWindow,len(npFeatures)+featureWindow)\n",
    "i = 0\n",
    "for s in stepper:\n",
    "    \n",
    "    npFeatures[i] = candleNP[i:s].flatten()\n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1122.26  , 1128.7   , 1114.51  , 1124.06  , 1125.184 , 1128.42  ,\n",
       "        1118.    , 1120.    , 1120.13  , 1122.    , 1115.    , 1115.55  ,\n",
       "        1115.35  , 1127.    , 1114.    , 1123.7887, 1124.135 , 1130.    ,\n",
       "        1121.9   , 1125.    ],\n",
       "       [1125.184 , 1128.42  , 1118.    , 1120.    , 1120.13  , 1122.    ,\n",
       "        1115.    , 1115.55  , 1115.35  , 1127.    , 1114.    , 1123.7887,\n",
       "        1124.135 , 1130.    , 1121.9   , 1125.    , 1126.0699, 1128.5   ,\n",
       "        1121.    , 1123.39  ],\n",
       "       [1120.13  , 1122.    , 1115.    , 1115.55  , 1115.35  , 1127.    ,\n",
       "        1114.    , 1123.7887, 1124.135 , 1130.    , 1121.9   , 1125.    ,\n",
       "        1126.0699, 1128.5   , 1121.    , 1123.39  , 1122.85  , 1130.    ,\n",
       "        1121.    , 1127.    ],\n",
       "       [1115.35  , 1127.    , 1114.    , 1123.7887, 1124.135 , 1130.    ,\n",
       "        1121.9   , 1125.    , 1126.0699, 1128.5   , 1121.    , 1123.39  ,\n",
       "        1122.85  , 1130.    , 1121.    , 1127.    , 1127.64  , 1129.295 ,\n",
       "        1125.    , 1126.    ],\n",
       "       [1124.135 , 1130.    , 1121.9   , 1125.    , 1126.0699, 1128.5   ,\n",
       "        1121.    , 1123.39  , 1122.85  , 1130.    , 1121.    , 1127.    ,\n",
       "        1127.64  , 1129.295 , 1125.    , 1126.    , 1126.1987, 1127.09  ,\n",
       "        1120.45  , 1125.955 ],\n",
       "       [1126.0699, 1128.5   , 1121.    , 1123.39  , 1122.85  , 1130.    ,\n",
       "        1121.    , 1127.    , 1127.64  , 1129.295 , 1125.    , 1126.    ,\n",
       "        1126.1987, 1127.09  , 1120.45  , 1125.955 , 1125.93  , 1129.14  ,\n",
       "        1123.8   , 1128.12  ],\n",
       "       [1122.85  , 1130.    , 1121.    , 1127.    , 1127.64  , 1129.295 ,\n",
       "        1125.    , 1126.    , 1126.1987, 1127.09  , 1120.45  , 1125.955 ,\n",
       "        1125.93  , 1129.14  , 1123.8   , 1128.12  , 1128.12  , 1128.9999,\n",
       "        1123.3501, 1126.83  ],\n",
       "       [1127.64  , 1129.295 , 1125.    , 1126.    , 1126.1987, 1127.09  ,\n",
       "        1120.45  , 1125.955 , 1125.93  , 1129.14  , 1123.8   , 1128.12  ,\n",
       "        1128.12  , 1128.9999, 1123.3501, 1126.83  , 1126.9   , 1127.4   ,\n",
       "        1120.37  , 1121.66  ],\n",
       "       [1126.1987, 1127.09  , 1120.45  , 1125.955 , 1125.93  , 1129.14  ,\n",
       "        1123.8   , 1128.12  , 1128.12  , 1128.9999, 1123.3501, 1126.83  ,\n",
       "        1126.9   , 1127.4   , 1120.37  , 1121.66  , 1120.3819, 1123.98  ,\n",
       "        1119.    , 1119.02  ],\n",
       "       [1125.93  , 1129.14  , 1123.8   , 1128.12  , 1128.12  , 1128.9999,\n",
       "        1123.3501, 1126.83  , 1126.9   , 1127.4   , 1120.37  , 1121.66  ,\n",
       "        1120.3819, 1123.98  , 1119.    , 1119.02  , 1119.06  , 1120.4873,\n",
       "        1115.5   , 1117.2   ],\n",
       "       [1128.12  , 1128.9999, 1123.3501, 1126.83  , 1126.9   , 1127.4   ,\n",
       "        1120.37  , 1121.66  , 1120.3819, 1123.98  , 1119.    , 1119.02  ,\n",
       "        1119.06  , 1120.4873, 1115.5   , 1117.2   , 1117.71  , 1121.1   ,\n",
       "        1116.6301, 1117.68  ],\n",
       "       [1126.9   , 1127.4   , 1120.37  , 1121.66  , 1120.3819, 1123.98  ,\n",
       "        1119.    , 1119.02  , 1119.06  , 1120.4873, 1115.5   , 1117.2   ,\n",
       "        1117.71  , 1121.1   , 1116.6301, 1117.68  , 1117.78  , 1118.7898,\n",
       "        1114.8   , 1115.214 ],\n",
       "       [1120.3819, 1123.98  , 1119.    , 1119.02  , 1119.06  , 1120.4873,\n",
       "        1115.5   , 1117.2   , 1117.71  , 1121.1   , 1116.6301, 1117.68  ,\n",
       "        1117.78  , 1118.7898, 1114.8   , 1115.214 , 1115.83  , 1118.02  ,\n",
       "        1113.    , 1114.6048],\n",
       "       [1119.06  , 1120.4873, 1115.5   , 1117.2   , 1117.71  , 1121.1   ,\n",
       "        1116.6301, 1117.68  , 1117.78  , 1118.7898, 1114.8   , 1115.214 ,\n",
       "        1115.83  , 1118.02  , 1113.    , 1114.6048, 1113.86  , 1117.08  ,\n",
       "        1111.    , 1112.43  ],\n",
       "       [1117.71  , 1121.1   , 1116.6301, 1117.68  , 1117.78  , 1118.7898,\n",
       "        1114.8   , 1115.214 , 1115.83  , 1118.02  , 1113.    , 1114.6048,\n",
       "        1113.86  , 1117.08  , 1111.    , 1112.43  , 1111.44  , 1113.7699,\n",
       "        1106.01  , 1106.6654],\n",
       "       [1117.78  , 1118.7898, 1114.8   , 1115.214 , 1115.83  , 1118.02  ,\n",
       "        1113.    , 1114.6048, 1113.86  , 1117.08  , 1111.    , 1112.43  ,\n",
       "        1111.44  , 1113.7699, 1106.01  , 1106.6654, 1106.84  , 1108.3199,\n",
       "        1103.33  , 1105.85  ],\n",
       "       [1115.83  , 1118.02  , 1113.    , 1114.6048, 1113.86  , 1117.08  ,\n",
       "        1111.    , 1112.43  , 1111.44  , 1113.7699, 1106.01  , 1106.6654,\n",
       "        1106.84  , 1108.3199, 1103.33  , 1105.85  , 1105.27  , 1111.79  ,\n",
       "        1105.27  , 1108.78  ],\n",
       "       [1113.86  , 1117.08  , 1111.    , 1112.43  , 1111.44  , 1113.7699,\n",
       "        1106.01  , 1106.6654, 1106.84  , 1108.3199, 1103.33  , 1105.85  ,\n",
       "        1105.27  , 1111.79  , 1105.27  , 1108.78  , 1108.44  , 1113.4899,\n",
       "        1107.    , 1110.5576],\n",
       "       [1111.44  , 1113.7699, 1106.01  , 1106.6654, 1106.84  , 1108.3199,\n",
       "        1103.33  , 1105.85  , 1105.27  , 1111.79  , 1105.27  , 1108.78  ,\n",
       "        1108.44  , 1113.4899, 1107.    , 1110.5576, 1111.09  , 1113.045 ,\n",
       "        1107.68  , 1109.51  ],\n",
       "       [1106.84  , 1108.3199, 1103.33  , 1105.85  , 1105.27  , 1111.79  ,\n",
       "        1105.27  , 1108.78  , 1108.44  , 1113.4899, 1107.    , 1110.5576,\n",
       "        1111.09  , 1113.045 , 1107.68  , 1109.51  , 1110.6779, 1113.5   ,\n",
       "        1108.5205, 1111.7   ],\n",
       "       [1105.27  , 1111.79  , 1105.27  , 1108.78  , 1108.44  , 1113.4899,\n",
       "        1107.    , 1110.5576, 1111.09  , 1113.045 , 1107.68  , 1109.51  ,\n",
       "        1110.6779, 1113.5   , 1108.5205, 1111.7   , 1110.74  , 1112.2999,\n",
       "        1107.3901, 1112.16  ],\n",
       "       [1108.44  , 1113.4899, 1107.    , 1110.5576, 1111.09  , 1113.045 ,\n",
       "        1107.68  , 1109.51  , 1110.6779, 1113.5   , 1108.5205, 1111.7   ,\n",
       "        1110.74  , 1112.2999, 1107.3901, 1112.16  , 1111.0201, 1112.4999,\n",
       "        1107.3   , 1108.    ],\n",
       "       [1111.09  , 1113.045 , 1107.68  , 1109.51  , 1110.6779, 1113.5   ,\n",
       "        1108.5205, 1111.7   , 1110.74  , 1112.2999, 1107.3901, 1112.16  ,\n",
       "        1111.0201, 1112.4999, 1107.3   , 1108.    , 1108.    , 1113.42  ,\n",
       "        1107.3   , 1112.8199],\n",
       "       [1110.6779, 1113.5   , 1108.5205, 1111.7   , 1110.74  , 1112.2999,\n",
       "        1107.3901, 1112.16  , 1111.0201, 1112.4999, 1107.3   , 1108.    ,\n",
       "        1108.    , 1113.42  , 1107.3   , 1112.8199, 1111.77  , 1162.81  ,\n",
       "        1110.15  , 1111.949 ],\n",
       "       [1110.74  , 1112.2999, 1107.3901, 1112.16  , 1111.0201, 1112.4999,\n",
       "        1107.3   , 1108.    , 1108.    , 1113.42  , 1107.3   , 1112.8199,\n",
       "        1111.77  , 1162.81  , 1110.15  , 1111.949 , 1111.88  , 1113.0199,\n",
       "        1107.5   , 1109.    ],\n",
       "       [1111.0201, 1112.4999, 1107.3   , 1108.    , 1108.    , 1113.42  ,\n",
       "        1107.3   , 1112.8199, 1111.77  , 1162.81  , 1110.15  , 1111.949 ,\n",
       "        1111.88  , 1113.0199, 1107.5   , 1109.    , 1109.05  , 1111.017 ,\n",
       "        1106.    , 1109.7   ],\n",
       "       [1108.    , 1113.42  , 1107.3   , 1112.8199, 1111.77  , 1162.81  ,\n",
       "        1110.15  , 1111.949 , 1111.88  , 1113.0199, 1107.5   , 1109.    ,\n",
       "        1109.05  , 1111.017 , 1106.    , 1109.7   , 1109.14  , 1110.99  ,\n",
       "        1105.1   , 1109.4233],\n",
       "       [1111.77  , 1162.81  , 1110.15  , 1111.949 , 1111.88  , 1113.0199,\n",
       "        1107.5   , 1109.    , 1109.05  , 1111.017 , 1106.    , 1109.7   ,\n",
       "        1109.14  , 1110.99  , 1105.1   , 1109.4233, 1109.73  , 1110.39  ,\n",
       "        1106.745 , 1109.1286],\n",
       "       [1111.88  , 1113.0199, 1107.5   , 1109.    , 1109.05  , 1111.017 ,\n",
       "        1106.    , 1109.7   , 1109.14  , 1110.99  , 1105.1   , 1109.4233,\n",
       "        1109.73  , 1110.39  , 1106.745 , 1109.1286, 1109.1178, 1109.6   ,\n",
       "        1103.75  , 1104.66  ],\n",
       "       [1109.05  , 1111.017 , 1106.    , 1109.7   , 1109.14  , 1110.99  ,\n",
       "        1105.1   , 1109.4233, 1109.73  , 1110.39  , 1106.745 , 1109.1286,\n",
       "        1109.1178, 1109.6   , 1103.75  , 1104.66  , 1105.1   , 1107.99  ,\n",
       "        1104.8501, 1105.57  ],\n",
       "       [1109.14  , 1110.99  , 1105.1   , 1109.4233, 1109.73  , 1110.39  ,\n",
       "        1106.745 , 1109.1286, 1109.1178, 1109.6   , 1103.75  , 1104.66  ,\n",
       "        1105.1   , 1107.99  , 1104.8501, 1105.57  , 1105.57  , 1105.9595,\n",
       "        1101.8   , 1104.31  ],\n",
       "       [1109.73  , 1110.39  , 1106.745 , 1109.1286, 1109.1178, 1109.6   ,\n",
       "        1103.75  , 1104.66  , 1105.1   , 1107.99  , 1104.8501, 1105.57  ,\n",
       "        1105.57  , 1105.9595, 1101.8   , 1104.31  , 1104.1829, 1104.35  ,\n",
       "        1100.11  , 1100.23  ],\n",
       "       [1109.1178, 1109.6   , 1103.75  , 1104.66  , 1105.1   , 1107.99  ,\n",
       "        1104.8501, 1105.57  , 1105.57  , 1105.9595, 1101.8   , 1104.31  ,\n",
       "        1104.1829, 1104.35  , 1100.11  , 1100.23  , 1100.37  , 1101.8899,\n",
       "        1097.12  , 1097.94  ],\n",
       "       [1105.1   , 1107.99  , 1104.8501, 1105.57  , 1105.57  , 1105.9595,\n",
       "        1101.8   , 1104.31  , 1104.1829, 1104.35  , 1100.11  , 1100.23  ,\n",
       "        1100.37  , 1101.8899, 1097.12  , 1097.94  , 1097.43  , 1111.77  ,\n",
       "        1097.11  , 1107.13  ]])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1122.26  , 1128.7   , 1114.51  , 1124.06  ],\n",
       "       [1125.184 , 1128.42  , 1118.    , 1120.    ],\n",
       "       [1120.13  , 1122.    , 1115.    , 1115.55  ],\n",
       "       [1115.35  , 1127.    , 1114.    , 1123.7887],\n",
       "       [1124.135 , 1130.    , 1121.9   , 1125.    ],\n",
       "       [1126.0699, 1128.5   , 1121.    , 1123.39  ],\n",
       "       [1122.85  , 1130.    , 1121.    , 1127.    ],\n",
       "       [1127.64  , 1129.295 , 1125.    , 1126.    ],\n",
       "       [1126.1987, 1127.09  , 1120.45  , 1125.955 ],\n",
       "       [1125.93  , 1129.14  , 1123.8   , 1128.12  ],\n",
       "       [1128.12  , 1128.9999, 1123.3501, 1126.83  ],\n",
       "       [1126.9   , 1127.4   , 1120.37  , 1121.66  ],\n",
       "       [1120.3819, 1123.98  , 1119.    , 1119.02  ],\n",
       "       [1119.06  , 1120.4873, 1115.5   , 1117.2   ],\n",
       "       [1117.71  , 1121.1   , 1116.6301, 1117.68  ],\n",
       "       [1117.78  , 1118.7898, 1114.8   , 1115.214 ],\n",
       "       [1115.83  , 1118.02  , 1113.    , 1114.6048],\n",
       "       [1113.86  , 1117.08  , 1111.    , 1112.43  ],\n",
       "       [1111.44  , 1113.7699, 1106.01  , 1106.6654],\n",
       "       [1106.84  , 1108.3199, 1103.33  , 1105.85  ],\n",
       "       [1105.27  , 1111.79  , 1105.27  , 1108.78  ],\n",
       "       [1108.44  , 1113.4899, 1107.    , 1110.5576],\n",
       "       [1111.09  , 1113.045 , 1107.68  , 1109.51  ],\n",
       "       [1110.6779, 1113.5   , 1108.5205, 1111.7   ],\n",
       "       [1110.74  , 1112.2999, 1107.3901, 1112.16  ],\n",
       "       [1111.0201, 1112.4999, 1107.3   , 1108.    ],\n",
       "       [1108.    , 1113.42  , 1107.3   , 1112.8199],\n",
       "       [1111.77  , 1162.81  , 1110.15  , 1111.949 ],\n",
       "       [1111.88  , 1113.0199, 1107.5   , 1109.    ],\n",
       "       [1109.05  , 1111.017 , 1106.    , 1109.7   ],\n",
       "       [1109.14  , 1110.99  , 1105.1   , 1109.4233],\n",
       "       [1109.73  , 1110.39  , 1106.745 , 1109.1286],\n",
       "       [1109.1178, 1109.6   , 1103.75  , 1104.66  ],\n",
       "       [1105.1   , 1107.99  , 1104.8501, 1105.57  ],\n",
       "       [1105.57  , 1105.9595, 1101.8   , 1104.31  ],\n",
       "       [1104.1829, 1104.35  , 1100.11  , 1100.23  ],\n",
       "       [1100.37  , 1101.8899, 1097.12  , 1097.94  ],\n",
       "       [1097.43  , 1111.77  , 1097.11  , 1107.13  ],\n",
       "       [1106.58  , 1111.4199, 1102.42  , 1105.62  ]])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candleNP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1124.06  , 1120.    , 1115.55  , 1123.7887, 1125.    , 1123.39  ,\n",
       "       1127.    , 1126.    , 1125.955 , 1128.12  , 1126.83  , 1121.66  ,\n",
       "       1119.02  , 1117.2   , 1117.68  , 1115.214 , 1114.6048, 1112.43  ,\n",
       "       1106.6654, 1105.85  , 1108.78  , 1110.5576, 1109.51  , 1111.7   ,\n",
       "       1112.16  , 1108.    , 1112.8199, 1111.949 , 1109.    , 1109.7   ,\n",
       "       1109.4233, 1109.1286, 1104.66  , 1105.57  , 1104.31  , 1100.23  ,\n",
       "       1097.94  , 1107.13  , 1105.62  ])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candleNP.T[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.06  , -4.45  ,  8.2387,  1.2113, -1.61  ,  3.61  , -1.    ,\n",
       "       -0.045 ,  2.165 , -1.29  , -5.17  , -2.64  , -1.82  ,  0.48  ,\n",
       "       -2.466 , -0.6092, -2.1748, -5.7646, -0.8154,  2.93  ,  1.7776,\n",
       "       -1.0476,  2.19  ,  0.46  , -4.16  ,  4.8199, -0.8709, -2.949 ,\n",
       "        0.7   , -0.2767, -0.2947, -4.4686,  0.91  , -1.26  , -4.08  ,\n",
       "       -2.29  ,  9.19  , -1.51  ])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returns = candleNP.T[-1][1:]-candleNP.T[-1][0:-1]\n",
    "returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
